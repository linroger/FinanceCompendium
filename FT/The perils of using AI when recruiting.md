---
title: "The perils of using AI when recruiting"
source: "https://www.ft.com/content/229983ee-c11f-44fb-8e61-2ac61d8d100a"
published: 2025-12-10
description: "Companies are using chatbots to research candidates — but convenience comes with risks"
primary_tags: "AI in recruitment, Generative AI hallucinations"
secondary_tags: "Hiring discrimination risk, HR technology, Candidate privacy"
parent_directory: "FT"
section: "Technology "
subsection: "Artificial intelligence"
category: "Recruitment"
article_description: "Companies are using chatbots to research candidates — but convenience comes with risks"
---
Companies are using chatbots to research candidates — but convenience comes with risks

![Montage image of a woman looking confused at a laptop with a speech bubble with question marks](https://images.ft.com/v3/image/raw/ftcms%3A56ae2478-7b48-42c7-8142-d76fe463699f?source=next-article&fit=scale-down&quality=highest&width=700&dpr=1)

© FT montage/Dreamstime

While job hunting recently, I asked a few artificial intelligence chatbots for summaries of my career. The resulting write-ups were broadly accurate. But there was one, glaring, error.

According to Grok, Elon Musk’s “maximally truth-seeking” chatbot, Olivia Gagan (that’s me) “recently announced being on maternity leave, following the birth of her first child in 2025”.

This was news to me. I am not on maternity leave; nor am I a mother. There is no baby.

Being confronted with a hallucination about myself was unsettling. But such errors are a red flag for a bigger problem. As AI is increasingly used in recruitment, the risk of misinformation influencing hiring decisions is rising too.

“It’s definitely quite concerning,” says Jamie Kohn, HR research director at consultancy Gartner. “AI can be wrong about candidates, and even worse, it can reveal protected information. Companies should warn managers against using AI to learn about candidates, but it’s hard to control what people do.”

Quite. According to a Boston Consulting Group report this year, 70 per cent of the companies experimenting with generative AI are using it in human resources. Within that, the top use case is talent acquisition.

Much of this is through specialised recruitment software, which uses generative AI to scan profiles online and suggests potential matches for roles.

Recruiters also report using off-the-shelf chatbots to research candidates, although the practice is not always approved by employers. “We use it when we’re meeting new people, to see what it says about them,” says the chief executive of a UK science recruiter. “It will often tell you something personal, so we can start building rapport quicker.”

Uroš Zver, partner at executive headhunter Heidrick & Struggles, says this use is informal, but potentially widespread. “There is a highly fragmented, commoditised recruitment market hiring for mid-management level and more junior roles, that is... less discriminating in the uptake of every available tool,” he says. “It could be a really serious problem.”

Alice Ashcroft, a technology researcher and CEO of inclusive recruitment start-up JobFair, says AI is likely to “exacerbate existing cultural biases” when it makes inferences based on data online. Grok, for example, was “likely to have taken my age and gender into account” when concluding I had just had a baby.

Refusing to hire or consider someone for a job because of pregnancy or maternity is unlawful in the UK. But discrimination happens and, if employers decide not to progress an application, can be hard to prove. If AI is likely to erroneously label prospective jobseekers with protected characteristics, it could expose employers to violations in equality law.

Amy Wren, senior counsel at law firm Farrer & Co, says this has been an issue “for several years”, even without AI. “There is danger in researching candidates online. The risk of you inadvertently discovering a personal characteristic about somebody — whether true or not — and then acting on that information is high. That would be a discrimination risk.”

In the UK, there is no dedicated regulation to protect job hunters who think recruitment decisions may have been influenced by AI misinformation about them. Wren says regulators “are pushing the onus on to employers to have responsible practices”. Businesses must use AI “at their own risk”, carry out impact assessments, follow good governance practices and be transparent with candidates about AI use.

It remains a useful tool. “Generative AI is of course being used as a tool in candidate sourcing processes”, says Bryan Ackermann, head of AI strategy at recruiter Korn Ferry. Saving time and accessing big pools of talent are “great uses” if used carefully, he says. “It is as much an opportunity as it is a risk.”

Can jobseekers do anything to mitigate the problem? When contacted for comment, Grok’s press team responded only with the statement: “Legacy Media Lies.” The AI itself was more helpful. It suggested I should inform it if the information given was false. As of the time of writing, it no longer reports that I have an AI baby.

As well as our in-person presence, and our online profiles, jobseekers now have a third identity to manage: the person AI says we are.

[Reuse this content](https://enterprise.ft.com/en-gb/services/republishing/republish-content-request?ft-content-uuid=229983ee-c11f-44fb-8e61-2ac61d8d100a)