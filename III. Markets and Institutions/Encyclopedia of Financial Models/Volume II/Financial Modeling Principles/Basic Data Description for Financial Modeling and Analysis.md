---
title: Basic Data Description for Financial Modeling and Analysis
parent_directory: Financial Modeling Principles
formatted: 2025-12-21 11:15:00 AM
formatter_model: claude-sonnet-4-5-20251001
cli_tool: claude-code
primary_tags:
  - data types classification
  - measurement scales hierarchy
  - frequency distributions
  - cross sectional data
  - time series data
  - data classes formation
secondary_tags:
  - qualitative data
  - quantitative data
  - nominal scaling
  - ordinal scaling
  - interval scaling
  - ratio scaling
  - absolute scaling
  - empirical cumulative distribution
  - sturges rule
  - freedman diaconis rule
  - data aggregation
  - statistical distributions
  - financial data analysis
  - descriptive statistics
  - data visualization
  - frequency analysis
cssclasses: academia
---

# Basic Data Description for Financial Modeling and Analysis

MARKUS HÖCHSTÖTTER, PhD

Assistant Professor, University of Karlsruhe

SVETLOZAR T. RACHEV, PhD, DrSci

Frey Family Foundation Chair-Professor, Department of Applied Mathematics and Statistics, Stony Brook University, and Chief Scientist, FinAnalytica

FRANK J. FABOZZI, PhD, CFA, CPA

Professor of Finance, EDHEC Business School

Abstract: We are confronted with data every day, constantly. Daily newspapers contain information on stock prices, economic figures, quarterly business reports on earnings and revenues, and much more. These data offer observed values of given quantities. The basic data types can be qualitative, ordinal, or quantitative.

In this entry, we will present the first essentials of data description. We describe all data types and levels. We explain and illustrate why one has to be careful about the permissible computations concerning each data level.

We will restrict ourselves to univariate data, that is, data of only one dimension. For example, if you follow the daily returns of one particular stock, you obtain a one-dimensional series of observations. If you had observed two stocks, then you would have obtained a two-dimensional series of data, and so on. Moreover, the notion of frequency distributions, empirical frequency distributions, and cumulative frequency distributions is introduced. The goal of this entry is to provide the first methods necessary to begin data analysis. After reading this entry you will learn how to formalize the first impression you obtain from the data in order to retrieve the most basic structure inherent in the data. That is essential for any subsequent tasks you may undertake with the data. Above all, though, you will have to be fully aware of what you want to learn from the data. That step is maybe the most important task before getting started in investigating the data. For example, you may just want to know what the minimum return has been of your favorite stock during the last year before you decide to purchase. Or you are interested in all returns from last year to learn how this stock typically performs, that is, which returns occur more often than others, and how often. In the latter case, you definitely have to be more involved to obtain the necessary information than in the first case.

# DATA TYPES

Data are gathered by several methods. In the financial industry, we have market data based on regular trades recorded by the exchanges. Theses data are directly observable. Aside from the regular trading process, there is so-called over-the-counter (OTC) business whose data are less accessible. Annual reports and quarterly reports, on the other hand, are published by companies themselves in print or electronically. These data are available also in the business and finance sections of most major business oriented print media and the Internet. The fields of marketing and the social sciences know additional forms of data collection methods. There are telephone surveys, mail questionnaires, and even experiments.

Once the data are gathered, it is the objective of descriptive statistics to visually and computationally convert the amount of information given into quantities revealing the essentials in which we are interested. Commonly in this context, visual support is added since very often that allows for a much easier grasp of the information.

The field of descriptive statistics discerns different types of data. Very generally, there are two types: qualitative and quantitative data.

If certain attributes of an item can only be assigned to categories, these data are referred to as qualitative. For example, stocks listed on the New York Stock Exchange (NYSE) can be categorized as belonging to a specific industry sector such as "banking," "energy," "media and telecommunications," and so on. That way, we assign the item stock as its attribute sector one or possibly more values from the set containing banking, energy, media and telecommunications, and so on. (Instead of attribute, we will most of the time use the term "variable.") Another example would be the credit ratings assigned to debt obligations by commercial rating companies such as Standard & Poor's, Moody's, and Fitch Ratings. Except for retrieving the value of an attribute, nothing more can be done with qualitative data. One may use a numerical code to indicate the different sectors (e.g.,  $1 =$  banking,  $2 =$  energy, and so on). However, we are not allowed to perform any computation with these figures since they are simply proxies of the underlying attribute sector.

However, if an item is assigned a quantitative variable, the value of this variable is numerical. Generally, all real numbers are eligible. Depending on the case, however, one will use discrete values only, such as integers. Stock prices or dividends, for example, are quantitative data drawing from—up to some digits—positive real numbers. Quantitative data have the feature that one can perform transformations and computations with them. One can easily think of the average price of all companies comprising some index on a certain day, while it would make absolutely no sense to do the same with qualitative data.

# Data Levels and Scale

In descriptive statistics, we group data according to measurement levels. The measurement level gives an indication as to the sophistication of the analysis techniques that one can apply to the data collected. Typically, a hierarchy with five levels of measurement—nominal, ordinal, interval, ratio, and absolute—is used to group data. The latter three form the set of quantitative data. If the data are of a certain measurement level, they are said to be scaled accordingly. That is, the data are referred to as nominally scaled, and so on.


Nominally scaled data are on the bottom of the hierarchy. Despite the low level of sophistication, this type of data are commonly used. An example is the attribute sector of stocks. We already learned that, even though we can assign numbers as proxies to nominal values, these numbers have no numerical meaning whatsoever. We might just as well assign letters to the individual nominal values, for example, "B = banking," "E = energy," and so on.

Ordinally scaled data are one step higher in the hierarchy. We also refer to this type as "rank data," since we can already perform a ranking within the set of values. We can make use of a relationship among the different values by treating them as quality grades. For example, we can divide the stocks listed in a particular stock index according to their market capitalization into five groups of equal size. Let "A" denote the top  $20\%$  of the stocks. Also, let "B" denote the next  $20\%$  below, and so on, until we obtain the five groups: A, B, C, D, and E. After ordinal scaling, we can make statements such as "Group A is better than group C." Hence, we have a natural ranking or order among the values. However, we cannot quantify the difference between them. Also, the credit rating of debt obligations is ordinarily scaled.

Until now, we can summarize that while we can test the relationship between nominal data for equality only, we can additionally determine a greater or less than relationship between ordinal data.

Data on an interval scale are given if they can be reasonably transformed by a linear equation. Suppose we are given values  $x$ . It is now feasible to express a new variable  $y$  by the relationship  $y = a \cdot x + b$ , where the  $x's$  are our original data. If  $x$  has a meaning, then so does  $y$ . It is obvious that data have to possess a numerical meaning and therefore be quantitative in order to be measured on an interval scale. For example, consider the temperature  $F$  given in degrees Fahrenheit. Then, the corresponding temperature in degrees Celsius,  $C$ , will result from the equation  $C = (F - 32) / 1.8$ . Equivalently, if one is familiar with physics, the same temperature measured in degrees Kelvin,  $K$ , will result from  $K = C + 273.15$ . So, say it is  $55^{\circ}$  Fahrenheit for Americans, the same temperature will mean approximately  $13^{\circ}$  Celsius for Europeans, and they will not feel any cooler. Generally, interval data allow for the calculation of differences. For example,  $70^{\circ} - 60^{\circ}$  Fahrenheit  $= 10^{\circ}$  Fahrenheit may reasonably express the difference in temperature between Los Angeles and San Francisco. But be careful—the difference in temperature measured in Celsius between the two cities is not the same. How much is it?


Data measured on a ratio scale share all the properties of interval data. In addition, ratio data have a fixed or true zero point. This is not the case with interval data. Their intercept,  $b$ , can be arbitrarily changed through transformation. Since the zero point of ratio data is invariable, one can only transform the slope,  $a$ . So, for example,  $y = a \cdot x$  is always a multiple of  $x$ . In other words, there is a relationship between  $y$  and  $x$  given by the ratio  $a$ , hence the name used to describe this type of data. One would not have this feature if one would permit some  $b$  different from zero in the transformation. Consider, for example, the stock price,  $E$ , of some European stock given in euro units. The same price in U.S. dollars,  $D$ , would be  $D = E$  times the exchange rate between euros and U.S. dollars. But if the company's price after bankruptcy went to zero, the price in either currency would be zero, even at different rates determined by the ratio of U.S. dollar per euro. This is a result of the invariant zero point.

Absolute data are given by quantitative data measured on a scale even stricter than for ratio data. Here, along with the zero point, the units are invariant as well. Data measured on an absolute scale occur when transformation would be mathematically feasible but lacks any interpretational implication. A common example is provided by counting numbers. Anybody would agree on the number of stocks listed in a certain stock index. There is no ambiguity as to the zero point and the count increments. If one stock is added to the index, it is immediately clear that the difference to the content of the old index is exactly one unit of stock, assuming that no stock is deleted. This absolute scale is the most intuitive and needs no further discussion.


# Cross-Sectional and Time Series Data

There is another way of classifying data. Imagine collecting data from one and the same quantity of interest or variable. A variable is some quantity that can assume values from a value set. For example, the variable "stock price" can technically assume any nonnegative real number of currency but only one value at a time. Each day, it assumes a certain value, which is the day's stock price. As another example, a variable could be the dividend payments from a specific company over some period of time. In the case of dividends, the observations are made each quarter. The accumulated data then form what is called time series data. In contrast, one could pick a particular time period of interest such as the first quarter of the current year and observe the dividend payments of all companies listed in the Standard & Poor's 500 index. By doing so, one would obtain cross-sectional data of the universe of stocks in the S&P 500 index at that particular time.

Summarizing, time series data are data related to a variable successively observed at a sequence of points in time. Cross-sectional data are values of a particular variable across some universe of items observed at a unique point in time. This is visualized in Figure 1.

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-29/76a29b67-ac4d-47f0-86d4-1e10a3a8dda0/662807c956d102db24cb5e06cf78013f6836410f7cc4dde785983f94b5587668.jpg)
Figure 1 Relationship between Cross-Sectional and Time Series Data

# FREQUENCY DISTRIBUTIONS

# Sorting and Counting Data

One of the most important aspects when dealing with data is that they are effectively organized and transformed in order to convey the essential information contained in them. This processing of the original data helps to display the inherent meaning in a way that is more accessible for intuition. But before advancing to the graphical presentation of the data, we will first describe the methods of structuring data.

Suppose that we are interested in a particular variable that can assume a set of either finite or infinitely many values. These values may be qualitative or quantitative by nature. In either case, the initial step when obtaining a data sample for some variable is to sort the values of each observation and then to determine the frequency distribution of the dataset. This is done simply by counting the number of observations for each possible value of the variable. Alternatively, if the variable can assume values on all or part of the real line, the frequency can be determined by counting the number of observations that fall into nonoverlapping intervals partitioning the real line.

In our illustration, we will begin with qualitative data first and then move on to the

Table 1 DJIA Components as of December 12, 2006

<table><tr><td>Company</td><td>Industrial Classification Benchmark (ICB) Subsector</td></tr><tr><td>3M Co.</td><td>Diversified Industrials</td></tr><tr><td>Alcoa Inc.</td><td>Aluminum</td></tr><tr><td>Altria Group Inc.</td><td>Tobacco</td></tr><tr><td>American Express Co.</td><td>Consumer Finance</td></tr><tr><td>American International Group Inc.</td><td>Full Line Insurance</td></tr><tr><td>AT&amp;T Inc.</td><td>Fixed Line Telecommunications</td></tr><tr><td>Boeing Co.</td><td>Aerospace</td></tr><tr><td>Caterpillar Inc.</td><td>Commercial Vehicles &amp; Trucks</td></tr><tr><td>Citigroup Inc.</td><td>Banks</td></tr><tr><td>Coca-Cola Co.</td><td>Soft Drinks</td></tr><tr><td>E.I. DuPont de Nemours &amp; Co.</td><td>Commodity Chemicals</td></tr><tr><td>Exxon Mobil Corp.</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>General Electric Co.</td><td>Diversified Industrials</td></tr><tr><td>General Motors Corp.</td><td>Automobiles</td></tr><tr><td>Hewlett-Packard Co.</td><td>Computer Hardware</td></tr><tr><td>Home Depot Inc.</td><td>Home Improvement Retailers</td></tr><tr><td>Honeywell International Inc.</td><td>Diversified Industrials</td></tr><tr><td>Intel Corp.</td><td>Semiconductors</td></tr><tr><td>International Business Machines Corp.</td><td>Computer Services</td></tr><tr><td>Johnson &amp; Johnson</td><td>Pharmaceuticals</td></tr><tr><td>JPMorgan Chase &amp; Co.</td><td>Banks</td></tr><tr><td>McDonald&#x27;s Corp.</td><td>Restaurants &amp; Bars</td></tr><tr><td>Merck &amp; Co. Inc.</td><td>Pharmaceuticals</td></tr><tr><td>Microsoft Corp.</td><td>Software</td></tr><tr><td>Pfizer Inc.</td><td>Pharmaceuticals</td></tr><tr><td>Procter &amp; Gamble Co.</td><td>Nondurable Household Products</td></tr><tr><td>United Technologies Corp.</td><td>Aerospace</td></tr><tr><td>Verizon Communications Inc.</td><td>Fixed Line Telecommunications</td></tr><tr><td>Wal-Mart Stores Inc.</td><td>Broadline Retailers</td></tr><tr><td>Walt Disney Co.</td><td>Broadcasting &amp; Entertainment</td></tr></table> quantitative aspects in the sequel. For example, suppose we want to analyze the frequency of the industry subsectors of the components listed in the Dow Jones Industrial Average (DJIA), an index comprised of 30 U.S. stocks. Table 1 displays the 30 companies in the index along with their respective industry sectors as of December 12, 2006. By counting the observed number of each possible Industry Clas


Table 2 Frequency Distribution of the Industry Subsectors

<table><tr><td>ICB Subsector</td><td>Frequency ai</td></tr><tr><td>Aerospace</td><td>2</td></tr><tr><td>Aluminum</td><td>1</td></tr><tr><td>Automobiles</td><td>1</td></tr><tr><td>Banks</td><td>2</td></tr><tr><td>Broadcasting &amp; Entertainment</td><td>1</td></tr><tr><td>Broadline Retailers</td><td>1</td></tr><tr><td>Commercial Vehicles &amp; Trucks</td><td>1</td></tr><tr><td>Commodity Chemicals</td><td>1</td></tr><tr><td>Computer Hardware</td><td>1</td></tr><tr><td>Computer Services</td><td>1</td></tr><tr><td>Consumer Finance</td><td>1</td></tr><tr><td>Diversified Industrials</td><td>3</td></tr><tr><td>Fixed Line Telecommunications</td><td>2</td></tr><tr><td>Full Line Insurance</td><td>1</td></tr><tr><td>Home Improvement Retailers</td><td>1</td></tr><tr><td>Integrated Oil &amp; Gas</td><td>1</td></tr><tr><td>Nondurable Household Products</td><td>1</td></tr><tr><td>Pharmaceuticals</td><td>3</td></tr><tr><td>Restaurants &amp; Bars</td><td>1</td></tr><tr><td>Semiconductors</td><td>1</td></tr><tr><td>Soft Drinks</td><td>1</td></tr><tr><td>Software</td><td>1</td></tr><tr><td>Tobacco</td><td>1</td></tr></table> sification Benchmark (ICB) subsector, we obtain Table 2, which shows the frequency distribution of the variable subsector. Note in the table that many subsector values appear only once. Hence, this might suggest employing a coarser set for the ICB subsector values in order to reduce the amount of information in the data to a necessary minimum.


Now suppose you would like to compare this to the Dow Jones Global Titans 50 Index (DJGTI). This index includes the 50 largest-capitalization and best-known blue-chip companies listed on the NYSE. The companies contained in this index are listed in Table 3 along with their respective ICB subsectors. The next step would also be to sort the data according to their values and count each hit of a value, finally listing the respective count numbers for each value. A problem arises now, however, when you want to directly compare the numbers with those obtained for the DJIA because the number of stocks contained in each index is not the same. Hence, we cannot compare the respective

Table 3 Dow Jones Global Titans 50 Index as of December 12, 2006

<table><tr><td>Company Name</td><td>ICB Subsector</td></tr><tr><td>Abbott Laboratories</td><td>Pharmaceuticals</td></tr><tr><td>Altria Group Inc.</td><td>Tobacco</td></tr><tr><td>American International Group Inc.</td><td>Full Line Insurance</td></tr><tr><td>AstraZeneca PLC</td><td>Pharmaceuticals</td></tr><tr><td>AT&amp;T Inc.</td><td>Fixed Line Telecommunications</td></tr><tr><td>Bank of America Corp.</td><td>Banks</td></tr><tr><td>Barclays PLC</td><td>Banks</td></tr><tr><td>BP PLC</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Chevron Corp.</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Cisco Systems Inc.</td><td>Telecommunications Equipment</td></tr><tr><td>Citigroup Inc.</td><td>Banks</td></tr><tr><td>Coca-Cola Co.</td><td>Soft Drinks</td></tr><tr><td>ConocoPhillips</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Dell Inc.</td><td>Computer Hardware</td></tr><tr><td>ENI S.p.A.</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Exxon Mobil Corp.</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>General Electric Co.</td><td>Diversified Industrials</td></tr><tr><td>GlaxoSmithKline PLC</td><td>Pharmaceuticals</td></tr><tr><td>HBOS PLC</td><td>Banks</td></tr><tr><td>Hewlett-Packard Co.</td><td>Computer Hardware</td></tr><tr><td>HSBC Holdings PLC (UK Reg)</td><td>Banks</td></tr><tr><td>ING Groep N.V.</td><td>Life Insurance</td></tr><tr><td>Intel Corp.</td><td>Semiconductors</td></tr><tr><td>International Business Machines Corp.</td><td>Computer Services</td></tr><tr><td>Johnson &amp; Johnson</td><td>Pharmaceuticals</td></tr><tr><td>JPMorgan Chase &amp; Co.</td><td>Banks</td></tr><tr><td>Merck &amp; Co. Inc.</td><td>Pharmaceuticals</td></tr><tr><td>Microsoft Corp.</td><td>Software</td></tr><tr><td>Mitsubishi UFJ Financial Group Inc.</td><td>Banks</td></tr><tr><td>Morgan Stanley</td><td>Investment Services</td></tr><tr><td>Nestle S.A.</td><td>Food Products</td></tr><tr><td>Nokia Corp.</td><td>Telecommunications Equipment</td></tr><tr><td>Novartis AG</td><td>Pharmaceuticals</td></tr><tr><td>PepsiCo Inc.</td><td>Soft Drinks</td></tr><tr><td>Pfizer Inc.</td><td>Pharmaceuticals</td></tr><tr><td>Procter &amp; Gamble Co.</td><td>Nondurable Household Products</td></tr><tr><td>Roche Holding AG Part. Cert.</td><td>Pharmaceuticals</td></tr><tr><td>Royal Bank of Scotland Group PLC</td><td>Banks</td></tr><tr><td>Royal Dutch Shell PLC A</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Samsung Electronics Co. Ltd.</td><td>Semiconductors</td></tr><tr><td>Siemens AG</td><td>Electronic Equipment</td></tr><tr><td>Telefonica S.A.</td><td>Fixed Line Telecommunications</td></tr><tr><td>Time Warner Inc.</td><td>Broadcasting &amp; Entertainment</td></tr><tr><td>Total S.A.</td><td>Integrated Oil &amp; Gas</td></tr><tr><td>Toyota Motor Corp.</td><td>Automobiles</td></tr><tr><td>UBS AG</td><td>Banks</td></tr><tr><td>Verizon Communications Inc.</td><td>Fixed Line Telecommunications</td></tr><tr><td>Vodafone Group PLC</td><td>Mobile Telecommunications</td></tr><tr><td>Wal-Mart Stores Inc.</td><td>Broadline Retailers</td></tr><tr><td>Wyeth</td><td>Pharmaceuticals</td></tr></table>

Table 4 Comparison of Relative Frequencies of DJIA and DJGTI

<table><tr><td rowspan="2">ICB Subsector</td><td colspan="2">Relative Frequencies</td></tr><tr><td>DJIA</td><td>DJGTI</td></tr><tr><td>Aerospace</td><td>0.067</td><td>0.000</td></tr><tr><td>Aluminum</td><td>0.033</td><td>0.000</td></tr><tr><td>Automobiles</td><td>0.033</td><td>0.020</td></tr><tr><td>Banks</td><td>0.067</td><td>0.180</td></tr><tr><td>Broadcasting &amp; Entertainment</td><td>0.033</td><td>0.020</td></tr><tr><td>Broadline Retailers</td><td>0.033</td><td>0.020</td></tr><tr><td>Commercial Vehicles &amp; Trucks</td><td>0.033</td><td>0.000</td></tr><tr><td>Commodity Chemicals</td><td>0.033</td><td>0.000</td></tr><tr><td>Computer Hardware</td><td>0.033</td><td>0.040</td></tr><tr><td>Computer Services</td><td>0.033</td><td>0.020</td></tr><tr><td>Consumer Finance</td><td>0.033</td><td>0.000</td></tr><tr><td>Diversified Industrials</td><td>0.100</td><td>0.020</td></tr><tr><td>Electronic Equipment</td><td>0.000</td><td>0.020</td></tr><tr><td>Fixed Line Telecommunications</td><td>0.067</td><td>0.060</td></tr><tr><td>Food Products</td><td>0.000</td><td>0.020</td></tr><tr><td>Full Line Insurance</td><td>0.033</td><td>0.020</td></tr><tr><td>Home Improvement Retailers</td><td>0.033</td><td>0.000</td></tr><tr><td>Integrated Oil &amp; Gas</td><td>0.033</td><td>0.140</td></tr><tr><td>Investment Services</td><td>0.000</td><td>0.020</td></tr><tr><td>Life Insurance</td><td>0.000</td><td>0.020</td></tr><tr><td>Mobile Telecommunications</td><td>0.000</td><td>0.020</td></tr><tr><td>Nondurable Household Products</td><td>0.033</td><td>0.020</td></tr><tr><td>Pharmaceuticals</td><td>0.100</td><td>0.180</td></tr><tr><td>Restaurants &amp; Bars</td><td>0.033</td><td>0.000</td></tr><tr><td>Semiconductors</td><td>0.033</td><td>0.040</td></tr><tr><td>Soft Drinks</td><td>0.033</td><td>0.040</td></tr><tr><td>Software</td><td>0.033</td><td>0.020</td></tr><tr><td>Telecommunications Equipment</td><td>0.000</td><td>0.040</td></tr><tr><td>Tobacco</td><td>0.033</td><td>0.020</td></tr></table> absolute frequencies. Instead, we have to resort to something that creates comparability of the two datasets. This is done by expressing the number of observations of a particular value as the proportion of the total number of observations in a specific dataset. That means we have to compute the relative frequency. See Table 4.


# Formal Presentation of Frequency

For a better formal presentation, we denote the (absolute) frequency by  $a$  and, in particular, by  $a_{i}$  for the  $i$ th value of the variable. Formally, the relative frequency  $f_{i}$  of the  $i$ th value is, then, defined by

$$ f_{i} = \frac{a_{i}}{n}
$$ where  $n$  is the total number of observations. With  $k$  being the number of the different values, the following holds:


$$ n = \sum_{i = 1}^{k} f_{i}
$$

In our illustration, let  $n_1 = 30$  be the number of total observations in the DJIA and  $n_2 = 50$  the total number of observations in the DJGTI. Table 4 shows the relative frequencies for all possible values. Notice that each index has some values that were observed with zero frequency, which still have to be listed for comparison. When we look at the DJIA, we find out that the sectors Diversified Industrials and Pharmaceuticals each account for  $10\%$  of all sectors and therefore are the sectors with the highest frequencies. Comparing these two sectors to the DJGTI, we find out that Pharmaceuticals play as important a role as a sector with an  $18\%$  share, while Diversified Industrials are of minor importance. In this index, Banks are a very important sector with  $18\%$  also. A comparison of this sort can now be carried through for all subsectors thanks to the relative frequencies.

Naturally, frequency (absolute and relative) distributions can be computed for all types of data since they do not require that the data have a numerical value.

# EMPIRICAL CUMULATIVE FREQUENCY DISTRIBUTION

# Accumulating Frequencies

In addition to the frequency distribution, there is another quantity of interest for comparing data that is closely related to the absolute or relative frequency distribution. Suppose that one is interested in the percentage of all large-capitalization stocks in the DJIA with closing prices of at most US 50 on a specific day. One can sort the observed closing prices by their numerical values in ascending order to obtain something like the array shown in Table 5 for market prices as of December 15, 2006. Note that

Table 5 DJIA Stocks by Share Price in Ascending Order as of December 15, 2006

<table><tr><td>Company</td><td>Share Price</td></tr><tr><td>Intel Corp.</td><td>20.77</td></tr><tr><td>Pfizer Inc.</td><td>25.56</td></tr><tr><td>General Motors Corp.</td><td>29.77</td></tr><tr><td>Microsoft Corp.</td><td>30.07</td></tr><tr><td>Alcoa Inc.</td><td>30.76</td></tr><tr><td>Walt Disney Co.</td><td>34.72</td></tr><tr><td>AT&amp;T Inc.</td><td>35.66</td></tr><tr><td>Verizon Communications Inc.</td><td>36.09</td></tr><tr><td>General Electric Co.</td><td>36.21</td></tr><tr><td>Hewlett-Packard Co.</td><td>39.91</td></tr><tr><td>Home Depot Inc.</td><td>39.97</td></tr><tr><td>Honeywell International Inc.</td><td>42.69</td></tr><tr><td>Merck &amp; Co. Inc.</td><td>43.60</td></tr><tr><td>McDonald&#x27;s Corp.</td><td>43.69</td></tr><tr><td>Wal-Mart Stores Inc.</td><td>46.52</td></tr><tr><td>JPMorgan Chase &amp; Co.</td><td>47.95</td></tr><tr><td>E.I. DuPont de Nemours &amp; Co.</td><td>48.40</td></tr><tr><td>Coca-Cola Co.</td><td>49.00</td></tr><tr><td>Citigroup Inc.</td><td>53.11</td></tr><tr><td>American Express Co.</td><td>61.90</td></tr><tr><td>United Technologies Corp.</td><td>62.06</td></tr><tr><td>Caterpillar Inc.</td><td>62.12</td></tr><tr><td>Procter &amp; Gamble Co.</td><td>63.35</td></tr><tr><td>Johnson &amp; Johnson</td><td>66.25</td></tr><tr><td>American International Group Inc.</td><td>72.03</td></tr><tr><td>Exxon Mobil Corp.</td><td>78.73</td></tr><tr><td>3M Co.</td><td>78.77</td></tr><tr><td>Altria Group Inc.</td><td>84.97</td></tr><tr><td>Boeing Co.</td><td>89.93</td></tr><tr><td>International Business Machines Corp.</td><td>95.36</td></tr></table>

Since each value occurs once only, we have to assign each value an absolute frequency of 1 or a relative frequency of 1/30, respectively, since there are 30 component stocks in the DJIA. We start with the lowest entry (20.77) and advance up to the largest value still less than 50, which is 49 (Coca-Cola). Each time we observe less than or equal to 50, we add 1/30, accounting for the frequency of each company to obtain an accumulated frequency of 18/30 representing the total share of closing prices below 50. This accumulated frequency is called the "empirical cumulative frequency" at the value 50. If one computes this for all values, one obtains the empirical cumulative frequency distribution. The term "empirical" is used because the distribution is computed from observed data.

Source: www.dj.com/TheCompany/FactSheets.htm, December 15, 2006.


# Formal Presentation of Cumulative Frequency Distributions

Formally, the empirical cumulative frequency distribution  $F_{emp}$  is defined as

$$
F_{e m p} (x) = \sum_{i = 1}^{k} a_{i}
$$ where  $k$  is the index of the largest value observed that is still less than  $x$ . In our example,  $k$  is 18. When we use relative frequencies, we obtain the empirical relative cumulative frequency distribution defined analogously to the empirical cumulative frequency distribution, this time using relative frequencies. Hence, we have


$$
F_{e m p}^{f} (x) = \sum_{i = 1}^{k} f_{i}
$$

In our example,  $F_{emp}^{f}(50) = 18 / 30 = 0.6 = 60\%$ .

Note that the empirical cumulative frequency distribution can be evaluated at any real  $x$  even though  $x$  need not be an observation. For any value  $x$  between two successive observations  $x_{(i)}$  and  $x_{(i+1)}$ , the empirical cumulative frequency distribution as well as the empirical cumulative relative frequency distribution remain at their respective levels at  $x_{(i)}$ ; that is, they are of constant level  $F_{emp}(x_{(i)})$  and  $F_{emp}^{f}(x_{(i)})$ , respectively. For example, consider the empirical relative cumulative frequency distribution for the data shown in Table 5. We can extend the distribution to a function that determines the value of the distribution at each possible value of the share price. The function is given in Table 6. Notice that if no value is observed more than once, then the empirical relative cumulative frequency distribution jumps by  $1/N$  at each observed value. In our illustration, the jump size is  $1/30$ .

In Figure 2 the empirical relative cumulative frequency distribution is shown as a graph. Note that the values of the function are constant on the extended line between two successive observations, indicated by the solid point to the

Table 6 Empirical Relative Cumulative Frequency Distribution of DJIA Stocks from Table 5

<table><tr><td colspan="4">Ffemp(x)</td></tr><tr><td>0.00</td><td></td><td>x &lt;</td><td>20.77</td></tr><tr><td>0.03</td><td>20.77</td><td>≤ x &lt;</td><td>25.56</td></tr><tr><td>0.07</td><td>25.56</td><td>≤ x &lt;</td><td>29.77</td></tr><tr><td>0.10</td><td>29.77</td><td>≤ x &lt;</td><td>30.07</td></tr><tr><td>0.13</td><td>30.07</td><td>≤ x &lt;</td><td>30.76</td></tr><tr><td>0.17</td><td>30.76</td><td>≤ x &lt;</td><td>34.72</td></tr><tr><td>0.20</td><td>34.72</td><td>≤ x &lt;</td><td>35.66</td></tr><tr><td>0.23</td><td>35.66</td><td>≤ x &lt;</td><td>36.09</td></tr><tr><td>0.27</td><td>36.09</td><td>≤ x &lt;</td><td>36.21</td></tr><tr><td>0.30</td><td>36.21</td><td>≤ x &lt;</td><td>39.91</td></tr><tr><td>0.33</td><td>39.91</td><td>≤ x &lt;</td><td>39.97</td></tr><tr><td>0.37</td><td>39.97</td><td>≤ x &lt;</td><td>42.69</td></tr><tr><td>0.40</td><td>42.69</td><td>≤ x &lt;</td><td>43.60</td></tr><tr><td>0.43</td><td>43.60</td><td>≤ x &lt;</td><td>43.69</td></tr><tr><td>0.47</td><td>43.69</td><td>≤ x &lt;</td><td>46.52</td></tr><tr><td>0.50</td><td>46.52</td><td>≤ x &lt;</td><td>47.95</td></tr><tr><td>0.53</td><td>47.95</td><td>≤ x &lt;</td><td>48.40</td></tr><tr><td>0.57</td><td>48.40</td><td>≤ x &lt;</td><td>49.00</td></tr><tr><td>0.60</td><td>49.00</td><td>≤ x &lt;</td><td>53.11</td></tr><tr><td>0.63</td><td>53.11</td><td>≤ x &lt;</td><td>61.90</td></tr><tr><td>0.67</td><td>61.90</td><td>≤ x &lt;</td><td>62.06</td></tr><tr><td>0.70</td><td>62.06</td><td>≤ x &lt;</td><td>62.12</td></tr><tr><td>0.73</td><td>62.12</td><td>≤ x &lt;</td><td>63.35</td></tr><tr><td>0.77</td><td>63.35</td><td>≤ x &lt;</td><td>66.25</td></tr><tr><td>0.80</td><td>66.25</td><td>≤ x &lt;</td><td>72.03</td></tr><tr><td>0.83</td><td>72.03</td><td>≤ x &lt;</td><td>78.73</td></tr><tr><td>0.87</td><td>78.73</td><td>≤ x &lt;</td><td>78.77</td></tr><tr><td>0.90</td><td>78.77</td><td>≤ x &lt;</td><td>84.97</td></tr><tr><td>0.93</td><td>84.97</td><td>≤ x &lt;</td><td>89.93</td></tr><tr><td>0.97</td><td>89.93</td><td>≤ x &lt;</td><td>95.36</td></tr><tr><td>1.00</td><td>95.36</td><td>≤ x</td><td></td></tr></table> left of each horizontal line. At each observation, the vertical distance between the horizontal line extending to the right from the preceding observation and the value of the function is exactly the increment  $1/30$ .


![](https://cdn-mineru.openxlab.org.cn/result/2025-11-29/76a29b67-ac4d-47f0-86d4-1e10a3a8dda0/9a7ed9b6877b81aee48ff2bbf930d36cada35898138d5c2ceab89cfa317d1e6a.jpg)
Figure 2 Empirical Relative Cumulative Frequency Distribution of DJIA Stocks from Table 5

The computation of either form of empirical cumulative distribution function is obviously not intuitive for categorical data unless we assign some meaningless numerical proxy to each value such as "Sector A" = 1, "Sector B" = 2, and so on.

# DATA CLASSES

# Reasons for Classifying

When quantitative variables are such that the set of values—whether observed or theoretically possible—includes intervals or the entire real numbers, then the variable is continuous. This is in contrast to discrete variables, which assume values only from a limited or countable set. Variables on a nominal scale cannot be considered in this context. And because of the difficulties with interpreting the results, we will not attempt to explain the issue of classes for rank data either.

When one counts the frequency of observed values of a continuous variable, one notices that hardly any value occurs more than once. (Naturally, the precision given by the number of digits rounded may result in higher occurrences of certain values.) Theoretically, with  $100\%$  chance, all observations will yield different values. Thus, the method of counting the frequency of each value is not feasible. Instead, the continuous set of values is divided into mutually exclusive intervals. Then, for each such interval, the number of values falling within that interval can be counted again. In other words, one groups the data into classes for which the frequencies can be computed. Classes should be such that their respective lower and upper bounds are real numbers. Also, whether the class bounds are elements of the classes or not must be specified. The class bounds of a class must be bounds of the respective adjacent classes as well, such that the classes seamlessly cover the entire data. The width should be the same for all classes. However, if there are areas where the data are very intensely dense in contrast to areas of lesser density, then the class width can vary according to significant changes in value density. In certain cases, most of the data are relatively evenly scattered within some range, while there are extreme values that are located in isolated areas on either end of the data array. Then, it is sometimes advisable to specify no lower bound to the lowest class and no upper bound to the uppermost class. Classes of this sort are called "open classes." Moreover, one should consider the precision to which the data are given. If values are rounded to the first decimal but there is the chance that the exact value might vary within half a decimal about the value given, class bounds have to consider this lack of certainty by admitting plus half a decimal on either end of the class.


# Formal Procedure of Classifying

Formally, there are four criteria that the classes need to meet:

Criterion 1: Mutual Exclusiveness: Each value can be placed in only one class.

Criterion 2: Completeness: The set of classes needs to cover all values.

Criterion 3: Equidistance: If possible, form classes of equal width.

Criterion 4: Nonemptiness: If possible, avoid forming empty classes.

It is intuitive that the number of classes should increase with an increasing range of values and increasing number of data. Though there are no stringent rules, two rules of thumb are given here with respect to the advised number of classes (first rule) and the best class width (second rule). The first, the so-called Sturge's rule, states that for a given set of continuous data of size  $n$ , one should use the nearest integer figure to

$$
1 + \log_{2} n = 1 + 3.322 \log_{10} n.
$$

Here,  $\log_a n$  denotes the logarithm of  $n$  to the base  $a$ , with  $a$  being either 2 or 10.

The second guideline is the so-called Freedman-Diaconis rule for the appropriate class width or bin size. Before turning to the second rule of thumb in more detail, we have to introduce the notion of the inner quartile range (IQR). This quantity measures the distance between the value where  $F_{emp}^{f}$  is closest to 0.25 (that is, the so-called 0.25-quantile), and the value where  $F_{emp}^{f}$  is closest to 0.75 (that is, the so-called 0.75-quantile). (The term "percentile" is used interchangeably with "quantile.") So the IQR range states how remote the lowest  $25\%$  of the observations are from the highest  $25\%$ . As a consequence, the IQR comprises the central  $50\%$  of a data sample. A little more attention will be given to the determination of the above-mentioned quantiles when we discuss sample moments and quantiles, since formally there might arise some ambiguity when computing them. (Note that the IQR cannot be computed for nominal or categorical data in a natural way.)


Now we can return to the Freedman-Diaconis rule. It states that a good class width is given by the nearest integer to

$$
2 \times I Q R \times N^{- 1 / 3}
$$ where  $N$  is the number of observations in the dataset. Note that there is an inverse relationship between the class width and the number of classes for each set of data. That is, given that the partitioning of the values into classes covers all observations, the number of classes  $n$  has to be equal to the difference between largest and smallest value divided by the class width, if classes are all of equal size  $w$ . Mathematically, that means


$$ n = (x_{\max } - x_{\min }) / w
$$ where  $x_{\mathrm{max}}$  denotes the largest value and  $x_{\mathrm{min}}$  denotes the smallest value considered, respectively.


One should not be intimidated by all these rules. Generally, by mere ordering of the data in an array, intuition produces quite a good feeling of what the classes should look like. Some thought can be given to the timing of the formation of the classes. That is, when classes are formed prior to the data-gathering process, one does not have to store the specific values but rather count only the number of hits within each class.


# Example of Classing Procedures

Let's illustrate these rules. Table 7 gives the 12-month returns (in percent) of the 235 Franklin Templeton Investments Funds on January 11, 2007. With this many data, it becomes obvious that it cannot be helpful to anyone to know the relative performance for the 235 funds. To obtain an overall impression of the distribution of the data without getting lost in detail, one has to aggregate the information given by classifying the data.

For the sake of a better overview, the ordered array is given in Table 8. A quick glance at the data sorted in ascending order gives us the lowest (minimum) and largest (maximum) return, respectively. Here, we have  $x_{\mathrm{min}} = -18.3\%$  and  $x_{\mathrm{max}} = 41.3\%$ , respectively, yielding a range of  $59.6\%$  to cover.

We first classify the data according to Sturge's rule. For the number of classes,  $n$ , we obtain the nearest integer to  $1 + \log_2 235 = 8.877$ , which is 9. The class width is then determined by the range divided by the number of classes,  $56.6\% / 9$ , yielding a width of roughly  $6.62\%$ . This is not a nice number to deal with, so we may choose  $7\%$  instead without deviating noticeably from the exact numbers given by Sturge's rule. We now cover a range of  $9 \times 7\% = 63\%$ , which is slightly larger than the original range of the data.

Selecting a value for the lower class bound of the lowest class slightly below our minimum, say  $-20.0\%$ , and an upper class bound of the highest class, say  $43.0\%$ , we spread the surplus of the range  $(3.4\%)$  evenly. The resulting classes can be viewed in Table 9, where in the first row the index of the respective class is given. The second row contains the class bounds. Brackets indicate that the value belongs to the class, whereas parentheses exclude given values. So, we obtain a half-open interval for each class containing all real numbers between the lower bound and just below the upper bound, thus excluding that value. In row three, we have the number of observations that fall into the respective classes.


We can check for the compliance with the four criteria given earlier. Because we use half-open intervals, we guarantee that Criterion 1 is fulfilled. Since the lowest class starts at  $-20\%$ , and the highest class ends at  $43\%$ , Criterion 2 is satisfied. All nine classes are of width  $7\%$ , which complies with Criterion 3. Finally, the compliance with Criterion 4 can be checked easily.

Next, we apply the Freedman-Diaconis rule. With our ordered array of data, we can determine the 0.25 quartile by selecting the observation whose index is the first to exceed  $0.25 \times N = .25 \times 235 = 58.75$ . This yields the value of observation 59, which is  $4.2\%$ . Accordingly, the 0.75-quartile is given by the value whose index is the first to exceed  $0.75 \times 235 = 176.25$ . For our return data, it is  $x_{177}$ , which is  $18.9\%$ . The IQR is computed as

$$
18.9 \% - 4.2 \% = 14.7 \%
$$ such that the bin size of the classes (or class width) is now determined according to  $w = 2 \times IQR \times \sqrt[1]{\frac{1}{3} \sqrt{235}} = 4.764\%$ . Taking the data range of  $59.6\%$  from the previous calculation, we obtain as the suggested number of classes  $59.6\% / 4.764 = 12.511$ . Once again, this is not a neat-looking figure. We stick with the initial class width of  $w = 4.764\%$  as closely as possible by selecting the next integer, say  $5\%$ . And, without any loss, we extend the range artificially to  $60\%$ . So, we obtain for the number of classes  $60\% / 5 = 12$ , which is close to our original real number, 12.511, computed according to the Freedman-Diaconis rule but much nicer to handle. We again spread the range surplus of  $0.4\%$  ( $60\% - 59.6\%$ ) evenly across either end of the range such that we begin our lowest class at  $-18.5\%$  and end our highest class at  $41.5\%$ . The classes are given in Table 10. The first row of the table indicates the index of the respective class, while the second row gives the class bounds. The number of observations that fall into each class is shown in the last row. (One can easily


Table 7 12-Month Returns (in \%) for the 235 Franklin Templeton Investment Funds (Luxembourg) on January 11, 2007

<table><tr><td>Aggr Growth A Acc</td><td>1.9</td><td>Mut Gb Discov A Acc EUR</td><td>8.1</td><td>Asian Grth A Dis USD</td><td>21.3</td><td>Gbl Bd A Dis GBP</td><td>-0.7</td></tr><tr><td>Aggr Growth A Dis</td><td>-6.9</td><td>Mut Gb Discov A Acc USD</td><td>16.4</td><td>Asian Grth C Acc</td><td>20.6</td><td>Gbl Bd B Dis</td><td>7.5</td></tr><tr><td>Aggr Growth B Acc</td><td>0.9</td><td>Mut Gb Discov A Dis GBP</td><td>5.9</td><td>Asian Grth I Acc EUR</td><td>14.0</td><td>Gbl Bd C Dis</td><td>8.2</td></tr><tr><td>Aggr Growth I Acc</td><td>2.9</td><td>Mut Gb Discov B Acc USD</td><td>14.9</td><td>Asian Grth I Acc USD</td><td>22.6</td><td>Gbl Bd I Acc EUR</td><td>1.4</td></tr><tr><td>Biotech Disc A Acc</td><td>-0.4</td><td>Mut Gb Discov C Acc USD</td><td>15.7</td><td>BRIC A Acc EUR</td><td>25.3</td><td>Gbl Bd I Acc USD</td><td>9.9</td></tr><tr><td>Biotech Disc B Acc</td><td>-1.8</td><td>Mut Gb Discov I Acc EUR</td><td>9.1</td><td>BRIC A Acc USD</td><td>34.8</td><td>Gbl Bd(Euro) A Acc</td><td>1.5</td></tr><tr><td>Biotech Disc I Acc</td><td>0.6</td><td>Mut Gb Discov I Acc USD</td><td>17.4</td><td>BRIC A Dis GBP</td><td>22.7</td><td>Gbl Bd(Euro) A Dis</td><td>1.4</td></tr><tr><td>Europ Growth A Acc</td><td>20.0</td><td>T Japan A Acc EUR</td><td>-18.3</td><td>BRIC B Acc USD</td><td>33.2</td><td>Gbl Bd(Euro) I Acc</td><td>2.0</td></tr><tr><td>Europ Growth I Acc</td><td>21.3</td><td>T Japan A Acc JPY</td><td>-8.3</td><td>BRIC C Acc USD</td><td>34.1</td><td>Global Euro A Acc</td><td>11.1</td></tr><tr><td>EurSMidCapGr A Acc</td><td>33.1</td><td>T Japan A Acc USD</td><td>-12.2</td><td>BRIC I Acc USD</td><td>36.4</td><td>Global Euro A Dis</td><td>11.1</td></tr><tr><td>EurSMidCapGr I Acc</td><td>33.3</td><td>T Japan C Acc USD</td><td>-12.6</td><td>China A Acc</td><td>36.1</td><td>Global Euro I Acc</td><td>12.1</td></tr><tr><td>EurSMidCapGrBAccUSD</td><td>41.3</td><td>T Japan I Acc EUR</td><td>-17.6</td><td>China A Dis</td><td>23.7</td><td>Global A Acc</td><td>20.5</td></tr><tr><td>Global Growth A Acc</td><td>15.5</td><td>T Japan I Acc USD</td><td>-11.4</td><td>China I Acc</td><td>37.6</td><td>Global A Dis</td><td>20.4</td></tr><tr><td>GblMidCapGr A Acc</td><td>10.7</td><td>T Glb Gr&amp;Val A Acc</td><td>16.7</td><td>Eastern Europe A Acc EUR</td><td>13.3</td><td>Global B Acc</td><td>18.9</td></tr><tr><td>GblMidCapGr B Acc</td><td>9.3</td><td>T Glb Gr&amp;Val B Acc</td><td>15.3</td><td>Eastern Europe A Acc USD</td><td>21.9</td><td>Global C Acc</td><td>19.7</td></tr><tr><td>GblRealEst A Acc EUR</td><td>19.7</td><td>T Glb Gr&amp;Val C Acc</td><td>16.0</td><td>Eastern Europe A Dis EUR</td><td>13.3</td><td>Global I Acc</td><td>21.5</td></tr><tr><td>GblRealEst I Acc EUR</td><td>20.7</td><td>T Glb Gr&amp;Val I Acc</td><td>17.8</td><td>Eastern Europe A Dis GBP</td><td>11.0</td><td>Gbl Eq Inc A Acc EUR</td><td>11.4</td></tr><tr><td>GblRealEst A Dis GBP</td><td>17.1</td><td>Technology A Acc</td><td>-0.4</td><td>Eastern Europe C Acc EUR</td><td>12.6</td><td>Gbl Eq Inc A Acc USD</td><td>19.9</td></tr><tr><td>GblRealEst A Acc USD</td><td>22.1</td><td>Technology B Acc</td><td>-1.4</td><td>Eastern Europe C Acc USD</td><td>21.2</td><td>Gbl Eq Inc A Dis</td><td>19.9</td></tr><tr><td>GblRealEst A Dis USD</td><td>22.1</td><td>US Eqty A Acc EUR</td><td>0.2</td><td>Eastern Europe I Acc</td><td>14.7</td><td>Gbl Eq Inc B Dis</td><td>18.4</td></tr><tr><td>GblRealEst B Dis USD</td><td>20.5</td><td>US Eqty A Acc EUR Hdg</td><td>4.9</td><td>Emg Mkt A Acc</td><td>14.4</td><td>Gbl Eq Inc C Dis</td><td>19.3</td></tr><tr><td>GblRealEst C Dis USD</td><td>21.4</td><td>US Eqty A Acc USD</td><td>7.7</td><td>Emg Mkt A Dis</td><td>14.4</td><td>Gbl Eq Inc I Acc</td><td>20.5</td></tr><tr><td>GblRealEst I Acc USD</td><td>23.1</td><td>US Eqty B Acc</td><td>6.4</td><td>Emg Mkt B Acc</td><td>13.0</td><td>Gbl Inc A Acc EUR</td><td>10.4</td></tr><tr><td>GblRealEst I Dis USD</td><td>23.1</td><td>US Eqty C Acc</td><td>7.1</td><td>Emg Mkt C Acc</td><td>13.7</td><td>Gbl Inc A Acc USD</td><td>18.7</td></tr><tr><td>High Yield A Acc</td><td>6.9</td><td>US Eqty I Acc EUR</td><td>-5.9</td><td>Emg Mkt I Acc</td><td>15.8</td><td>Gbl Inc A Dis</td><td>18.7</td></tr><tr><td>High Yield A Dis</td><td>7.1</td><td>US Eqty I Acc USD</td><td>8.9</td><td>EmMktBd A Dis EUR</td><td>5.2</td><td>Gbl Inc B Dis</td><td>17.2</td></tr><tr><td>High Yield B Dis</td><td>5.6</td><td>US Gov A Dis</td><td>3.1</td><td>EmMktBd A Dis USD</td><td>13.2</td><td>Gbl Inc C Dis</td><td>17.9</td></tr><tr><td>High Yield C Acc</td><td>6.2</td><td>US Gov B Dis</td><td>1.8</td><td>Emg Mkt Bd B Dis</td><td>11.9</td><td>Gbl Inc I Acc</td><td>19.4</td></tr><tr><td>High Yield I Dis</td><td>7.8</td><td>US Gov B Acc</td><td>1.9</td><td>Emg Mkt Bd C Acc</td><td>12.6</td><td>Gbl Sm Co A Acc</td><td>21.3</td></tr><tr><td>High Yld Eur A Acc</td><td>8.3</td><td>US Gov C Acc</td><td>2.2</td><td>Emg Mkt Bd I Acc</td><td>14.3</td><td>Gbl Sm Co A Dis</td><td>21.3</td></tr><tr><td>High Yld Eur A Dis</td><td>8.3</td><td>US Gov I Dis</td><td>3.8</td><td>Euro Liq Res A Acc</td><td>1.9</td><td>Gbl Sm Co C Acc</td><td>12.1</td></tr><tr><td>High Yld Eur I Acc</td><td>9.1</td><td>US Growth A Acc</td><td>3.8</td><td>Euro Liq Res A Dis</td><td>1.9</td><td>Gbl Sm Co I Acc</td><td>22.4</td></tr><tr><td>High Yld Eur I Dis</td><td>9.1</td><td>US Growth B Acc</td><td>2.5</td><td>Euroland Bd A Dis</td><td>-1.8</td><td>Dbl Tot Ret A Acc</td><td>12.6</td></tr><tr><td>Income A Dis</td><td>12.8</td><td>US Growth C Acc</td><td>3.3</td><td>Euroland Bd I Acc</td><td>-1.2</td><td>Dbl Tot Ret A Dis</td><td>12.6</td></tr><tr><td>Income B Dis</td><td>11.4</td><td>US Growth I Acc</td><td>6.4</td><td>Euroland A Acc</td><td>18.5</td><td>Dbl Tot Ret B Acc</td><td>10.9</td></tr><tr><td>Income C Acc</td><td>12.1</td><td>US Ultra Sh Bd A Dis</td><td>3.7</td><td>Euroland A Dis</td><td>19.8</td><td>Dbl Tot Ret B Dis</td><td>10.9</td></tr><tr><td>Income C Dis</td><td>12.1</td><td>US Ultra Sh Bd B Acc</td><td>2.5</td><td>Euroland C Acc</td><td>17.8</td><td>Dbl Tot Ret C Dis</td><td>11.8</td></tr><tr><td>Income I Acc</td><td>13.7</td><td>US Ultra Sh Bd B Dis</td><td>2.5</td><td>Euroland I Acc</td><td>19.6</td><td>Dbl Tot Ret I Acc</td><td>13.1</td></tr><tr><td>India A Acc EUR</td><td>29.0</td><td>US Ultra Sh Bd C Dis</td><td>2.6</td><td>European A Acc USD</td><td>24.0</td><td>Dbl Tot Ret I Dis</td><td>10.0</td></tr><tr><td>India A Acc USD</td><td>38.7</td><td>US Ultra Sh Bd I Acc</td><td>4.2</td><td>European A Acc EUR</td><td>15.3</td><td>Growth(Euro) A Acc</td><td>7.5</td></tr><tr><td>India A Dis GBP</td><td>26.2</td><td>US SmMidCapGro A Ac</td><td>2.5</td><td>European A Dis EUR</td><td>15.2</td><td>Growth(Euro) A Dis</td><td>7.4</td></tr><tr><td>India B Acc USD</td><td>36.9</td><td>US SmMidCapGro B Ac</td><td>1.2</td><td>European A Dis USD</td><td>24.0</td><td>Growth(Euro) I Acc</td><td>8.4</td></tr><tr><td>India C Acc USD</td><td>37.9</td><td>US SmMidCapGro C Ac</td><td>2.0</td><td>European C Acc EUR</td><td>14.6</td><td>Growth(Euro) I Dis</td><td>8.4</td></tr><tr><td>India I Acc EUR</td><td>30.2</td><td>US Tot Rtn A Acc</td><td>4.1</td><td>European I Acc</td><td>16.4</td><td>Japan A Acc</td><td>-8.0</td></tr><tr><td>India I Acc USD</td><td>40.0</td><td>US Tot Rtn A Dis</td><td>4.2</td><td>Euro Tot Ret A Acc</td><td>-0.4</td><td>Korea A Acc</td><td>-3.8</td></tr><tr><td>Mut Beacon AAccEUR</td><td>7.4</td><td>US Tot Rtn B Acc</td><td>2.6</td><td>Euro Tot Ret A Dis EUR</td><td>-0.5</td><td>Latin Amer A Acc</td><td>35.9</td></tr><tr><td>Mut Beacon AAccUSD</td><td>15.5</td><td>US Tot Rtn B Dis</td><td>2.7</td><td>Euro Tot Ret A Dis GBP</td><td>-2.6</td><td>Latin Amer A Dis GBP</td><td>23.6</td></tr><tr><td>Mut Beacon ADisUSD</td><td>15.5</td><td>US Tot Rtn C Dis</td><td>3.1</td><td>Euro Tot Ret A Dis USD</td><td>7.1</td><td>Latin Amer A Dis USD</td><td>35.9</td></tr><tr><td>Mut Beacon Bacc</td><td>14.0</td><td>US Tot Rtn I Acc</td><td>4.8</td><td>Euro Tot Ret C Acc EUR</td><td>-1.3</td><td>Latin Amer I Acc USD</td><td>37.4</td></tr><tr><td>Mut Beacon Cacc</td><td>14.8</td><td>Asian Bond A Acc EUR</td><td>5.9</td><td>Euro Tot Ret C Dis USD</td><td>6.2</td><td>Thailand A Acc</td><td>-11.0</td></tr><tr><td>Mut Beacon IAcc</td><td>16.6</td><td>Asian Bond A Acc USD</td><td>14.1</td><td>Euro Tot Ret I Acc</td><td>-0.3</td><td>US$ Liq Res A Acc</td><td>4.2</td></tr><tr><td>Mut Europ AAcc EUR</td><td>15.9</td><td>Asian Bond A Dis USD</td><td>14.0</td><td>Glbl Bal A Acc EUR</td><td>6.5</td><td>US$ Liq Res A Dis</td><td>4.1</td></tr><tr><td>Mut Europ AAcc USD</td><td>24.7</td><td>Asian Bond B Dis USD</td><td>12.4</td><td>Glbl Bal A Acc USD</td><td>14.6</td><td>US$ Liq Res B Dis</td><td>3.1</td></tr><tr><td>Mut Europ ADis EUR</td><td>15.9</td><td>Asian Bond C Dis USD</td><td>13.0</td><td>Glbl Bal A Dis</td><td>14.6</td><td>US$ Liq Res C Acc</td><td>3.2</td></tr><tr><td>Mut Europ ADis GBP</td><td>14.0</td><td>Asian Bond I Acc USD</td><td>14.6</td><td>Glbl Bal B Acc</td><td>13.1</td><td>US Value A Acc</td><td>14.5</td></tr><tr><td>Mut Europ B Acc</td><td>23.1</td><td>Asian Grth A Acc EUR</td><td>12.7</td><td>Glbl Bal C Dis</td><td>13.9</td><td>US Value A Acc</td><td>13.0</td></tr><tr><td>Mut Europ C Acc USD</td><td>23.9</td><td>Asian Grth A Acc USD</td><td>21.4</td><td>Glbl Bd A Dis USD</td><td>9.2</td><td>US Value C Acc</td><td>13.8</td></tr><tr><td>Mut Europ C Acc EUR</td><td>15.2</td><td>Asian Grth A Dis EUR</td><td>12.8</td><td>Glbl Bd A Acc EUR</td><td>1.5</td><td>US Value I Acc</td><td>15.6</td></tr><tr><td>Mut Europ I Acc</td><td>16.9</td><td>Asian Grth A Dis GBP</td><td>10.4</td><td>Glbl Bd A Dis EUR</td><td>1.5</td><td></td><td></td></tr></table>

Table 8 Ordered Array of the 235 12-month Returns for the Franklin Templeton Investment Funds (Luxembourg)

<table><tr><td>Obs. (i)</td><td>Value</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>x(1)</td><td>-18.3</td><td>x(40)</td><td>2.2</td><td>x(79)</td><td>7.5</td><td>x(118)</td><td>12.7</td><td>x(157)</td><td>15.7</td><td>x(196)</td><td>21.3</td></tr><tr><td>x(2)</td><td>-17.6</td><td>x(41)</td><td>2.5</td><td>x(80)</td><td>7.5</td><td>x(119)</td><td>12.8</td><td>x(158)</td><td>15.8</td><td>x(197)</td><td>21.3</td></tr><tr><td>x(3)</td><td>-12.6</td><td>x(42)</td><td>2.5</td><td>x(81)</td><td>7.7</td><td>x(120)</td><td>12.8</td><td>x(159)</td><td>15.9</td><td>x(198)</td><td>21.4</td></tr><tr><td>x(4)</td><td>-12.2</td><td>x(43)</td><td>2.5</td><td>x(82)</td><td>7.8</td><td>x(121)</td><td>13</td><td>x(160)</td><td>15.9</td><td>x(199)</td><td>21.4</td></tr><tr><td>x(5)</td><td>-11.4</td><td>x(44)</td><td>2.5</td><td>x(83)</td><td>8.1</td><td>x(122)</td><td>13</td><td>x(161)</td><td>16</td><td>x(200)</td><td>21.5</td></tr><tr><td>x(6)</td><td>-11</td><td>x(45)</td><td>2.6</td><td>x(84)</td><td>8.2</td><td>x(123)</td><td>13</td><td>x(162)</td><td>16.4</td><td>x(201)</td><td>21.9</td></tr><tr><td>x(7)</td><td>-8.3</td><td>x(46)</td><td>2.6</td><td>x(85)</td><td>8.3</td><td>x(124)</td><td>13.1</td><td>x(163)</td><td>16.4</td><td>x(202)</td><td>22.1</td></tr><tr><td>x(8)</td><td>-8</td><td>x(47)</td><td>2.7</td><td>x(86)</td><td>8.3</td><td>x(125)</td><td>13.1</td><td>x(164)</td><td>16.6</td><td>x(203)</td><td>22.1</td></tr><tr><td>x(9)</td><td>-6.9</td><td>x(48)</td><td>2.9</td><td>x(87)</td><td>8.4</td><td>x(126)</td><td>13.2</td><td>x(165)</td><td>16.7</td><td>x(204)</td><td>22.4</td></tr><tr><td>x(10)</td><td>-5.9</td><td>x(49)</td><td>3.1</td><td>x(88)</td><td>8.4</td><td>x(127)</td><td>13.3</td><td>x(166)</td><td>16.9</td><td>x(205)</td><td>22.6</td></tr><tr><td>x(11)</td><td>-3.8</td><td>x(50)</td><td>3.1</td><td>x(89)</td><td>8.9</td><td>x(128)</td><td>13.3</td><td>x(167)</td><td>17.1</td><td>x(206)</td><td>22.7</td></tr><tr><td>x(12)</td><td>-2.6</td><td>x(51)</td><td>3.1</td><td>x(90)</td><td>9.1</td><td>x(129)</td><td>13.7</td><td>x(168)</td><td>17.2</td><td>x(207)</td><td>23.1</td></tr><tr><td>x(13)</td><td>-1.8</td><td>x(52)</td><td>3.2</td><td>x(91)</td><td>9.1</td><td>x(130)</td><td>13.7</td><td>x(169)</td><td>17.4</td><td>x(208)</td><td>23.1</td></tr><tr><td>x(14)</td><td>-1.8</td><td>x(53)</td><td>3.3</td><td>x(92)</td><td>9.1</td><td>x(131)</td><td>13.8</td><td>x(170)</td><td>17.8</td><td>x(209)</td><td>23.1</td></tr><tr><td>x(15)</td><td>-1.4</td><td>x(54)</td><td>3.7</td><td>x(93)</td><td>9.2</td><td>x(132)</td><td>13.9</td><td>x(171)</td><td>17.8</td><td>x(210)</td><td>23.6</td></tr><tr><td>x(16)</td><td>-1.3</td><td>x(55)</td><td>3.8</td><td>x(94)</td><td>9.3</td><td>x(133)</td><td>14</td><td>x(172)</td><td>17.9</td><td>x(211)</td><td>23.7</td></tr><tr><td>x(17)</td><td>-1.2</td><td>x(56)</td><td>3.8</td><td>x(95)</td><td>9.9</td><td>x(134)</td><td>14</td><td>x(173)</td><td>18.4</td><td>x(212)</td><td>23.9</td></tr><tr><td>x(18)</td><td>-0.7</td><td>x(57)</td><td>4.1</td><td>x(96)</td><td>10</td><td>x(135)</td><td>14</td><td>x(174)</td><td>18.5</td><td>x(213)</td><td>24</td></tr><tr><td>x(19)</td><td>-0.5</td><td>x(58)</td><td>4.1</td><td>x(97)</td><td>10.4</td><td>x(136)</td><td>14</td><td>x(175)</td><td>18.7</td><td>x(214)</td><td>24</td></tr><tr><td>x(20)</td><td>-0.4</td><td>x(59)</td><td>4.2</td><td>x(98)</td><td>10.4</td><td>x(137)</td><td>14.1</td><td>x(176)</td><td>18.7</td><td>x(215)</td><td>24.7</td></tr><tr><td>x(21)</td><td>-0.4</td><td>x(60)</td><td>4.2</td><td>x(99)</td><td>10.7</td><td>x(138)</td><td>14.3</td><td>x(177)</td><td>18.9</td><td>x(216)</td><td>25.3</td></tr><tr><td>x(22)</td><td>-0.4</td><td>x(61)</td><td>4.2</td><td>x(100)</td><td>10.9</td><td>x(139)</td><td>14.4</td><td>x(178)</td><td>19.3</td><td>x(217)</td><td>26.2</td></tr><tr><td>x(23)</td><td>-0.3</td><td>x(62)</td><td>4.8</td><td>x(101)</td><td>10.9</td><td>x(140)</td><td>14.4</td><td>x(179)</td><td>19.4</td><td>x(218)</td><td>29</td></tr><tr><td>x(24)</td><td>0.2</td><td>x(63)</td><td>4.9</td><td>x(102)</td><td>11</td><td>x(141)</td><td>14.5</td><td>x(180)</td><td>19.6</td><td>x(219)</td><td>30.2</td></tr><tr><td>x(25)</td><td>0.6</td><td>x(64)</td><td>5.2</td><td>x(103)</td><td>11.1</td><td>x(142)</td><td>14.6</td><td>x(181)</td><td>19.7</td><td>x(220)</td><td>33.1</td></tr><tr><td>x(26)</td><td>0.9</td><td>x(65)</td><td>5.6</td><td>x(104)</td><td>11.1</td><td>x(143)</td><td>14.6</td><td>x(182)</td><td>19.7</td><td>x(221)</td><td>33.2</td></tr><tr><td>x(27)</td><td>1.2</td><td>x(66)</td><td>5.9</td><td>x(105)</td><td>11.4</td><td>x(144)</td><td>14.6</td><td>x(183)</td><td>19.8</td><td>x(222)</td><td>33.3</td></tr><tr><td>x(28)</td><td>1.4</td><td>x(67)</td><td>5.9</td><td>x(106)</td><td>11.4</td><td>x(145)</td><td>14.6</td><td>x(184)</td><td>19.9</td><td>x(223)</td><td>34.1</td></tr><tr><td>x(29)</td><td>1.4</td><td>x(68)</td><td>6.2</td><td>x(107)</td><td>11.8</td><td>x(146)</td><td>14.7</td><td>x(185)</td><td>19.9</td><td>x(224)</td><td>34.8</td></tr><tr><td>x(30)</td><td>1.5</td><td>x(69)</td><td>6.2</td><td>x(108)</td><td>11.9</td><td>x(147)</td><td>14.8</td><td>x(186)</td><td>20</td><td>x(225)</td><td>35.9</td></tr><tr><td>x(31)</td><td>1.5</td><td>x(70)</td><td>6.4</td><td>x(109)</td><td>12.1</td><td>x(148)</td><td>14.9</td><td>x(187)</td><td>20.4</td><td>x(226)</td><td>35.9</td></tr><tr><td>x(32)</td><td>1.5</td><td>x(71)</td><td>6.4</td><td>x(110)</td><td>12.1</td><td>x(149)</td><td>15.2</td><td>x(188)</td><td>20.5</td><td>x(227)</td><td>36.1</td></tr><tr><td>x(33)</td><td>1.8</td><td>x(72)</td><td>6.5</td><td>x(111)</td><td>12.1</td><td>x(150)</td><td>15.2</td><td>x(189)</td><td>20.5</td><td>x(228)</td><td>36.4</td></tr><tr><td>x(34)</td><td>1.9</td><td>x(73)</td><td>6.9</td><td>x(112)</td><td>12.1</td><td>x(151)</td><td>15.3</td><td>x(190)</td><td>20.5</td><td>x(229)</td><td>36.9</td></tr><tr><td>x(35)</td><td>1.9</td><td>x(74)</td><td>7.1</td><td>x(113)</td><td>12.4</td><td>x(152)</td><td>15.3</td><td>x(191)</td><td>20.6</td><td>x(230)</td><td>37.4</td></tr><tr><td>x(36)</td><td>1.9</td><td>x(75)</td><td>7.1</td><td>x(114)</td><td>12.6</td><td>x(153)</td><td>15.5</td><td>x(192)</td><td>20.7</td><td>x(231)</td><td>37.6</td></tr><tr><td>x(37)</td><td>1.9</td><td>x(76)</td><td>7.1</td><td>x(115)</td><td>12.6</td><td>x(154)</td><td>15.5</td><td>x(193)</td><td>21.2</td><td>x(232)</td><td>37.9</td></tr><tr><td>x(38)</td><td>2</td><td>x(77)</td><td>7.4</td><td>x(116)</td><td>12.6</td><td>x(155)</td><td>15.5</td><td>x(194)</td><td>21.3</td><td>x(233)</td><td>38.7</td></tr><tr><td>x(39)</td><td>2</td><td>x(78)</td><td>7.4</td><td>x(117)</td><td>12.6</td><td>x(156)</td><td>15.6</td><td>x(195)</td><td>21.3</td><td>x(234)</td><td>40</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>x(235)</td><td>41.3</td></tr></table> check that the four requirements for the classes are met again.)


Let us next compare Tables 9 and 10. We observe a finer distribution when the Freedman-Diaconis rule is employed because this rule generates more classes for the same data. However, it is generally difficult to judge which rule provides us with the better information because, as is seen, the two rules set up completely different classes. But the choice of class bounds is essential. By just slightly shifting the bounds between two adjacent classes, many observations may fall from one class into the other due to this alteration. As a result, this might produce a totally different picture about the data distribution. So, we have to be very careful when we interpret the two different results.


For example, class 7, that is, [22,29) in Table 9 contains 16 observations. Classes 9 and 10 of Table 10 cover approximately the same range, [21.5,31.5). Together they account for 20 observations. We could now easily present two

Table 9 Classes for the 235 Fund Returns According to Sturge's Rule

<table><tr><td colspan="10">Class Index</td></tr><tr><td>I</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td>[a_i; b_i]</td><td>[-20, -13)</td><td>[-13, -6)</td><td>[-6,1)</td><td>[1,8)</td><td>[8,15)</td><td>[15,22)</td><td>[22,29)</td><td>[29,36)</td><td>[36,43)</td></tr><tr><td>a_I</td><td>2</td><td>7</td><td>17</td><td>56</td><td>66</td><td>53</td><td>16</td><td>9</td><td>9</td></tr></table> scenarios that would provide rather different conceptions about the frequency. In scenario one, suppose one assumes that two observations are between 21.5 and 22.0. Then, there would have to be 16 observations between 22.0 and 26.5 to add up to 18 observations in class 9 of Table 10. This, in return, would mean that the 16 observations of class 7 from Table 9 would all have to lie between 22.0 and 26.5 as well. Then, the two observations from class 10 of Table 10 must lie beyond 29.0. The other scenario could assume that we have four observations between 21.5 and 22.0. Then, for similar reasons as before, we would have 14 observations between 22.0 and 26.5. The two observations from class 10 of Table 10 would now have to be between 26.5 and 29.0, so that the total of 16 observations in class 7 of Table 9 is met. See how easily slightly different classes can lead to ambiguous interpretation? Looking at all classes at once, many of these puzzles can be solved. However, some uncertainty remains. As can be seen, the choice of the number of classes and thus the class bounds can have a significant impact on the information that the data conveys when condensed into classes.


# CUMULATIVE FREQUENCY DISTRIBUTIONS

In contrast to the empirical cumulative frequency distributions, in this section we will introduce functions that convey basically the same information, that is, the frequency distribu tion, but rely on a few more assumptions. These cumulative frequency distributions introduced here, however, should not be confused with the theoretical definitions given in probability theory even though the notion is akin to both.


The absolute cumulative frequency at each class bound states how many observations have been counted up to this particular class bound. However, we do not exactly know how the data are distributed within the classes. When relative frequencies are used, though, the cumulative relative frequency distribution states the overall proportion of all values up to a certain lower or upper bound of some class.

So far, things are not much different from the definition of the empirical cumulative frequency distribution and empirical cumulative relative frequency distribution. At each bound, the empirical cumulative frequency distribution and cumulative frequency coincide. However, an additional assumption is made regarding the distribution of the values between bounds of each class when computing the cumulative frequency distribution. The data are thought of as being continuously distributed and equally spread between the particular bounds. (This type of assumed behavior is defined as a "uniform distribution of data.") Hence, both forms (absolute and relative) of the cumulative frequency distributions increase in a linear fashion between the two class bounds. So, for both forms of cumulative distribution functions, one can compute the accumulated frequencies at values inside of classes.

Table 10 Classes for the 235 Fund Returns According to the Freedman-Diaconis Rule

<table><tr><td>I</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>[a_i; b_i]</td><td>[-18.5; -13.5)</td><td>[-13.5; -8.5)</td><td>[-8.5; -3.5)</td><td>[-3.5;1.5)</td><td>[1.5;6.5)</td><td>[6.5;11.5)</td><td>[11.5;16.5)</td><td>[16.5;21.5)</td><td>[21.5;26.5)</td><td>[26.5;31.5)</td><td>[31.5;36.5)</td><td>[36.41.5)</td></tr><tr><td>a_I</td><td>2</td><td>4</td><td>5</td><td>18</td><td>42</td><td>35</td><td>57</td><td>36</td><td>18</td><td>2</td><td>9</td><td>7</td></tr></table>

For a more thorough summary of this, let's use a more formal presentation. Let  $I$  denote the set of all class index  $i$  with  $i$  being some integer value between 1 and  $n_I = |I|$  (that is, the number of classes). Moreover, let  $a_j$  and  $f_j$  denote the (absolute) frequency and relative frequency of some class  $j$ , respectively. The cumulative frequency distribution at some upper bound,  $x_u^i$ , of a given class  $i$  is computed as

$$
F \left(x_{u}^{i}\right) = \sum_{j: x_{u}^{j} \leq x_{u}^{i}} a_{j} = \sum_{j: x_{u}^{l} \leq x_{l}^{i}} a_{j} + a_{i} \tag {1}
$$

In words, this means that we sum up the frequencies of all classes whose upper bound is less than  $x_{u}^{i}$  plus the frequency of class  $i$  itself. The corresponding cumulative relative frequency distribution at the same value is then

$$
F^{f} \left(x_{u}^{i}\right) = \sum_{j: x_{u}^{j} \leq x_{u}^{i}} f_{j} = \sum_{j: x_{u}^{j} \leq x_{l}^{i}} f_{j} + f_{i} \tag {2}
$$

This describes the same procedure as in equation (1) using relative frequencies instead of frequencies. For any value  $x$  in between the boundaries of, say, class  $i$ ,  $x_{l}^{i}$  and  $x_{u}^{i}$ , the cumulative relative frequency distribution is defined by

$$
F^{f} (x) = F^{f} \left(x_{l}^{i}\right) + \frac{x - x_{l}^{i}}{x_{u}^{i} - x_{l}^{i}} f_{i} \tag {3}
$$

In words, this means that we compute the cumulative relative frequency distribution at value  $x$  as the sum of two things. First, we take the cumulative relative frequency distribution at the lower bound of class  $i$ . Second, we add that share of the relative frequency of class  $i$  that is determined by the part of the whole interval of class  $i$  that is covered by  $x$ .

Figure 3 might appeal more to intuition. At the bounds of class  $i$ , we have values of the cumulative relative frequency given by  $F^{f}(x_{l}^{i})$  and  $F^{f}(x_{u}^{i})$  respectively. We assume that the cumulative relative frequency increases linearly along the line connecting  $F^{f}(x_{l}^{1})$  and  $F^{f}(x_{u}^{i})$ . Then, at any value  $x^{*}$  inside of class  $i$ , we find the corresponding value  $F^{f}(x^{*})$  by the intersection of the dashed line and the vertical axis as shown. The dashed line is obtained by ex tending a horizontal line through the intersection of the vertical line through  $x^{*}$  and the line connecting  $F^{f}(x_{l}^{1})$  and  $F^{f}(x_{u}^{i})$  with slope  $F^{f}(x^{*}) - F^{f}(x_{l}^{i}) / x^{*} - x_{l}^{i}$ .

![](https://cdn-mineru.openxlab.org.cn/result/2025-11-29/76a29b67-ac4d-47f0-86d4-1e10a3a8dda0/625ae6ae2acceab004cfceb896d6cd73ea6a2c2d7a7cbc5f68010ba8b6cfac5d.jpg)
Figure 3 Determination of Frequency Distribution within Class Bounds


# KEY POINTS

- The field of descriptive statistics discerns different types of data. Very generally, there are two types: qualitative and quantitative data. If certain attributes of an item can only be assigned to categories, these data are referred to as qualitative. However, if an item is assigned a quantitative variable, the value of this variable is numerical. Generally, all real numbers are eligible.
- In descriptive statistics, data are grouped according to measurement levels. The measurement level gives an indication as to the sophistication of the analysis techniques that can be applied to the data collected. Typically, a hierarchy with five levels of measurement—nominal, ordinal, interval, ratio, and absolute data—are used to group data. The latter three form the set of quantitative data. If the data are of a certain measurement level, they are said to be scaled accordingly. That is, the data are referred to as nominally scaled, and so on.
- Another way of classifying data is in terms of cross-sectional and time series data.

Cross-sectional data are values of a particular variable across some universe of items observed at a unique point in time. Time series data are data related to a variable successively observed at a sequence of points in time.

- Frequency (absolute and relative) distributions can be computed for all types of data since they do not require that the data have a numerical value. The cumulative frequency distribution is another quantity of interest for comparing data that is closely related to the absolute or relative frequency distribution.
- Four criteria that data classes need to satisfy are (1) each value can be placed in only one class (mutual exclusiveness), (2) the set of classes needs to cover all values (completeness), (3) if possible, form classes of equal width (equidistance), and (4) if possible, avoid forming empty classes (nonemptiness).

# NOTES

1. For a more detailed discussion, see Rachev et al. (2010).
2. The 0.75-quantile divides the data into the lowest  $75\%$  and the highest  $25\%$ .

# REFERENCES

Rachev, S. T., Hoechstooetter, S., Fabozzi, F. J., and Focardi, S. M. (2010). Probability and Statistics for Finance. Hoboken, NJ: John Wiley & Sons.

Rachev, S. T., Mittnik, S., Fabozzi, F. J., Focardi, S. M., and Jasic, R. (2007). Financial Econometrics: From Basics to Advanced Modeling Techniques. Hoboken, NJ: John Wiley & Sons.
