---
aliases:
tags:
key_concepts:
parent_directory:
cssclasses: academia
title: "Case: Long-Term Capital Management, L.P. (A) [HBS 9-200-007]"
linter-yaml-title-alias: "Case: Long-Term Capital Management, L.P. (A) [HBS 9-200-007]"
---

<div style="text-align: right"> Mark Hendricks </div>

<left>FINM 36700 - Portfolio Theory and Risk Management</left> 

<br>
<left>Fall 2022</left>

<h2><center> Homework 8 - Long-Term Capital Management, L.P. </center></h2>

<center>Due on Monday, Nov 28</center>

<h3><span style="color:#00008B">Solution - Piyush Kontu</span></h3>

<h3><span style="color:#00008B">Email - pkontu@uchicago.edu</span></h3>

# Case: Long-Term Capital Management, L.P. (A) [HBS 9-200-007]

# 1)  Conceptual issues for LTCM

## 1.1) Describe LTCM's investment strategy with regard to the following aspects:
- #### Securities traded

<span style="color:#00008B"> **Solution:**  LTCM tried to trade on market mispricing and arbitrage, Relative Value and Convergence trades. They go long-short on these arbitrages. Use leverage to trade bigger principal on these small mispricings and try to hedge out their positions via their long-short trades.</span>

<span style="color:#00008B"> LTCM was also heavily involved income and credit, and they also have sizeable positions in equities. In all these asset classes, they trade a large number of securities, across global markets.</span>

- #### Trading frequency

<span style="color:#00008B"> **Solution:**  LTCM's trading frequency varied according to their strategies. Their largest investment in the form of convergence trades had a long term trading horizon and frequency (weeks or months).</span>

<span style="color:#00008B"> **Solution:**  Mostly they are not trying to arbitrage intraday movements and nor odo they make long-term directional bets. </span>

- #### Skewness (Do they seek many small wins or a few big hits?)

<span style="color:#00008B"> **Solution:** They seek small positive returns using leverage and do not bet significantly on any specific events. Have lower skewness than SPY. <br> However, they are susceptible to extreme market events.</span>

- #### Forecasting (What is behind their selection of trades?)

<span style="color:#00008B"> **Solution:** Build models to find mispricing and the reason behind the mispricing. Then forecast their P&L on these trades. Their forecast is not better because of better mathematical model (the convergence trade/ relative value theory is not the edge), it is their knowledge of the market.</span>

## 1.2) What are LTCM's biggest advantages over its competitors?

<span style="color:#00008B"> **Solution:** <br> <b> 1) Efficient financing:  </b>Their edge was on financing and funding, along with their proprietary trading and modelling capabilities.<br> <b>2)  Fund Size:  </b>They had a larger AUM, meaning they could lever at favorable rates <br> <b>3) Collatralization:</b> Better collatralize these positions. (pay lower haircuts) <br> <b>4) Long-term Horizon:  </b> Long term commitment of capital from investors as well as availability of credit line <br> <b>5) Liquidity and Hedging:</b> LTCM has in place many mechanisms to ensure liquidity. They also avoid taking too much default risk or explicit directional bets.  </span>

## 1.3) The case discusses four types of funding risk facing LTCM:

## The case discusses specific ways in which LTCM manages each of these risks. Briefly discuss them.

- #### collateral haircuts

<span style="color:#00008B"> **Solution:** The haircuts go up in a market disruption event leading to unfavorable collateral terms for LTCM in terms of funding a spread trade </span>

<span style="color:#00008B">For most trades, LTCM obtains 100% financing on a fully collateralized basis. Furthermore, LTCM stress tests the haircuts across its asset classes.</span>

- #### repo maturity

<span style="color:#00008B"> **Solution:** In an adverse situation, where their credit risk goes up, they wont be able to secure these longer term repos which were favorable to their trades. </span>

<span style="color:#00008B"> LTCM goes against the norm by entering into relatively long-maturity repo. While much of it is overnight, LTCM uses contracts that typically have maturity of 6-12 months. Furthermore, LTCM manages their aggregate repo maturity. </span>

- #### equity redemption

<span style="color:#00008B"> **Solution:** If in a convergence trade, the two securities, before converging, diverge a lot, LTCM are facing redemption risk from their investors at a time where the Margin calls need them to further finance their strategies.<br><br> Equity Redemption at a unfavorable time also leads LTCM to unwind their positions at unfavorable rates leading to further losses of capital. </span>

<span style="color:#00008B">  The firm is highly levered, so equity funding risk is especially important. LTCM restricts redemptions of equity year by year. The restriction is particularly strong in that unredeemed money is re-locked. </span>

- #### loan access

<span style="color:#00008B"> **Solution:**  Loan access can be tough to come by in times of a crisis, leading to a further decline in the fund's performance.</span>

<span style="color:#00008B">  For debt funding, LTCM negotiated a revolving loan that has no Material Adverse Change clause. Thus, the availability of debt funding is not so highly correlated with fund performance. </span>

## 1.4) LTCM is largely in the business of selling liquidity and volatility. Describe how LTCM accounts for liquidity risk in their quantitative measurements.

<span style="color:#00008B"> **Solution:**  LTCM required counterparties to maintain the collateral balance via a 'two-way mark to market process on a daily basis. Thus the cash flow coming in from the counterparties mark to market would fund LTCM's outflow for the mark to market call on their offsetting position.</span>

<span style="color:#00008B">LTCM also also estimated theoretical worst case haircuts it would face in adverse market situations. Forecasting these worst case liquidity LTCM was able to better structure its financing so as not to liquidate its positions solely due to these adverse market events.</span>

<span style="color:#00008B">LTCM attempts to account for liquidity risk quantitatively by adjusting security correlations. For short-term horizons, LTCM assumes positive correlation between all trade categories. Even if their net exposure to a strategy flips sides, they still assume positive correlation to the new net position</span>

## 1.5) Is leverage risk currently a concern for LTCM?

<span style="color:#00008B"> **Solution:**  Currently since there were no extreme market events, leverage risk is not a concern, but still a potential threat for LTCM. Given the size of their committed capital and fewer opportunites for the excess capital to enhance LTCM's return, they are considering returning some of the investments made, which would reduce the leverage.</span>

## 1.6) Many strategies of LTCM rely on converging spreads. LTCM feels that these are almost win/win situations because of the fact that if the spread converges, they make money. If it diverges, the trade becomes even more attractive, as convergence is still expected at a future date. <br> <br> What is the risk in these convergence trades?

<span style="color:#00008B"> **Solution:**  About a year after the time of the case, the fund loses most of its value due to non-converging trades. So clearly there is some risk! </span>

<span style="color:#00008B">Positions are subject to liquidity risk. If market liquidity dries up or the markets become segmented, the divergent spreads can persist for a long time. This indeed happens later to LTCM. The trades that get them in trouble ultimately pay off, but not before LTCM blows up. LTCM believes it can exit these convergence trades if they become too unprofitable. However, a stop-loss order is not the same as a put option. If the price jumps discontinuously through the stop-loss, then it is ineffective.</span>

<span style="color:#00008B">Or a market may be paralyzed/illiquid when trying to execute the stop-loss. A put option does not need to worry about price impact, whereas a stop-loss does. Finally, a stop-loss ensures that an investor sells as soon as a security price hits a worst-case scenario, ensuring unfavorable market timing.</span>

# Imports

```python
import pandas as pd
import numpy as np
import scipy.stats as stats
from scipy.stats import kurtosis, skew
from scipy.stats import norm
import seaborn as sns
import statsmodels.api as sm
from statsmodels.regression.rolling import RollingOLS
import warnings
warnings.filterwarnings("ignore")

%matplotlib inline


import matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=[15, 6]
import matplotlib.cm as cm
```

# Helper Functions

```python
def performance_summary(return_data):
    """ 
        Returns the Performance Stats for given set of returns
        Inputs: 
            return_data - DataFrame with Date index and Monthly Returns for different assets/strategies.
        Output:
            summary_stats - DataFrame with annualized mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and
                            CVaR (0.5) and drawdown based on monthly returns. 
    """
    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*12)
    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(12))
    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']
    
    summary_stats['Skewness'] = return_data.skew()
    summary_stats['Excess Kurtosis'] = return_data.kurtosis()
    summary_stats['VaR (0.5)'] = return_data.quantile(.05, axis = 0)
    summary_stats['CVaR (0.5)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()
    summary_stats['Min'] = return_data.min()
    summary_stats['Max'] = return_data.max()
    
    wealth_index = 1000*(1+return_data).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/previous_peaks

    summary_stats['Max Drawdown'] = drawdowns.min()
    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]
    summary_stats['Bottom'] = drawdowns.idxmin()
    
    recovery_date = []
    for col in wealth_index.columns:
        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()
        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T
        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())
    summary_stats['Recovery'] = recovery_date
    
    return summary_stats
```

```python
def regression_based_performance(factor,fund_ret,rf,constant = True):
    """ 
        Returns the Regression based performance Stats for given set of returns and factors
        Inputs:
            factor - Dataframe containing monthly returns of the regressors
            fund_ret - Dataframe containing monthly excess returns of the regressand fund
            rf - Monthly risk free rate of return
        Output:
            summary_stats - (Beta of regression, treynor ratio, information ratio, alpha). 
    """
    if constant:
        X = sm.tools.add_constant(factor)
    else:
        X = factor
    y=fund_ret
    model = sm.OLS(y,X,missing='drop').fit()
    
    if constant:
        beta = model.params[1:]
        alpha = round(float(model.params['const']),6) *12

        
    else:
        beta = model.params
    treynor_ratio = ((fund_ret - rf).mean()*12)/beta[0]
    tracking_error = (model.resid.std()*np.sqrt(12))
    if constant:        
        information_ratio = model.params[0]*12/tracking_error
    r_squared = model.rsquared
    if constant:
        return (beta,treynor_ratio,information_ratio,alpha,r_squared,tracking_error,model.resid)
    else:
        return (beta,treynor_ratio,r_squared,tracking_error,model.resid)
```

# Reading Data

```python
ltcm_returns = pd.read_excel(r'C:\Users\piyus\Documents\Repos\finm-portfolio-2022\data\ltcm_exhibits_data.xlsx', header=[2], sheet_name='Exhibit 2')
ltcm_returns = ltcm_returns[1:].rename(columns={'Unnamed: 0':'Date'})
ltcm_returns = ltcm_returns.set_index('Date')
ltcm_returns = ltcm_returns.loc[:,['Fund Capital ($billions)','Gross Monthly Performancea','Net Monthly Performanceb','Index of Net Performance']]
ltcm_returns = ltcm_returns[:53].rename(columns={'Gross Monthly Performancea':'Gross Monthly Performance','Net Monthly Performanceb':'Net Monthly Performance'})
ltcm_returns.index = pd.to_datetime(ltcm_returns.index) + pd.offsets.MonthEnd(0) 
ltcm_returns.head()
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Fund Capital ($billions)</th>
	  <th>Gross Monthly Performance</th>
	  <th>Net Monthly Performance</th>
	  <th>Index of Net Performance</th>
	</tr>
	<tr>
	  <th>Date</th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>1994-03-31</th>
	  <td>1.1</td>
	  <td>-0.011</td>
	  <td>-0.013</td>
	  <td>0.99</td>
	</tr>
	<tr>
	  <th>1994-04-30</th>
	  <td>1.1</td>
	  <td>0.014</td>
	  <td>0.008</td>
	  <td>1.00</td>
	</tr>
	<tr>
	  <th>1994-05-31</th>
	  <td>1.2</td>
	  <td>0.068</td>
	  <td>0.053</td>
	  <td>1.05</td>
	</tr>
	<tr>
	  <th>1994-06-30</th>
	  <td>1.2</td>
	  <td>-0.039</td>
	  <td>-0.029</td>
	  <td>1.02</td>
	</tr>
	<tr>
	  <th>1994-07-31</th>
	  <td>1.4</td>
	  <td>0.116</td>
	  <td>0.084</td>
	  <td>1.10</td>
	</tr>
  </tbody>
</table>
</div>

```python
gmo_total_ret = pd.read_excel(r'C:\Users\piyus\Documents\Repos\finm-portfolio-2022\data\gmo_analysis_data.xlsx',sheet_name = 'returns (total)',index_col = 0)
gmo_total_ret.index.name = 'Date'
spy_total_ret = gmo_total_ret.loc[:,['SPY']]

rf = pd.read_excel(r'C:\Users\piyus\Documents\Repos\finm-portfolio-2022\data\gmo_analysis_data.xlsx',sheet_name = 'risk-free rate',index_col = 0)
rf.index.name = 'Date'

spy_excess_ret = spy_total_ret.copy()
for col in spy_excess_ret.columns:
    spy_excess_ret[col] = spy_excess_ret[col] - rf['US3M']

ltcm_returns['Net Excess Returns'] = ltcm_returns['Net Monthly Performance'] - rf['US3M']
ltcm_returns['Gross Excess Returns'] = ltcm_returns['Gross Monthly Performance'] - rf['US3M']

spy_er_ltcm = spy_excess_ret[ltcm_returns.index[0]:ltcm_returns.index[-1]]
spy_er_ltcm.tail()


```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>SPY</th>
	</tr>
	<tr>
	  <th>Date</th>
	  <th></th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>1998-03-31</th>
	  <td>0.044458</td>
	</tr>
	<tr>
	  <th>1998-04-30</th>
	  <td>0.008624</td>
	</tr>
	<tr>
	  <th>1998-05-31</th>
	  <td>-0.024961</td>
	</tr>
	<tr>
	  <th>1998-06-30</th>
	  <td>0.038341</td>
	</tr>
	<tr>
	  <th>1998-07-31</th>
	  <td>-0.017764</td>
	</tr>
  </tbody>
</table>
</div>

## 2) LTCM Risk Decomposition

- <h4> On Canvas, find the data file, <code>ltcm exhibits data.xlsx</code>. Get the gross and net (total) returns of LTCM from "Exhibit 2".</h4> <br>
- <h4>  Get the returns on SPY as well as the risk-free rate from the file, <code>gmo analysis data</code>.</h4> 

### 2.1) Summary stats.

### 2.1.a) For both the gross and net series of LTCM excess returns, report the mean, volatility, and Sharpe ratios. (Annualize them.)

```python
ltcm_summary = performance_summary(ltcm_returns.loc[:,['Gross Excess Returns','Net Excess Returns']])
ltcm_summary.loc[:,['Mean','Volatility','Sharpe Ratio']]
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Mean</th>
	  <th>Volatility</th>
	  <th>Sharpe Ratio</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Gross Excess Returns</th>
	  <td>0.242077</td>
	  <td>0.136232</td>
	  <td>1.776946</td>
	</tr>
	<tr>
	  <th>Net Excess Returns</th>
	  <td>0.155360</td>
	  <td>0.111765</td>
	  <td>1.390059</td>
	</tr>
  </tbody>
</table>
</div>

### 2.1.b) Report the skewness, kurtosis, and (historic) VaR(.05).

```python
ltcm_summary.loc[:,['Skewness','Excess Kurtosis','VaR (0.5)']]
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Skewness</th>
	  <th>Excess Kurtosis</th>
	  <th>VaR (0.5)</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Gross Excess Returns</th>
	  <td>-0.287725</td>
	  <td>1.586625</td>
	  <td>-0.030445</td>
	</tr>
	<tr>
	  <th>Net Excess Returns</th>
	  <td>-0.810239</td>
	  <td>2.926921</td>
	  <td>-0.026415</td>
	</tr>
  </tbody>
</table>
</div>

### 2.1.c) Comment on how these stats compare to SPY and other assets we have seen. How much do they differ between gross and net?

Comparing the Net Monthly Performance of LTCM and Excess returns of SPY, LTCM displays a higher return, with a very similar volatility to SPY. Thus the sharpe ratio of LTCM net of fee and other charges is slightly higher than SPY's. 

The excess net returns of LTCM however, underperform SPY with similar volatility levels and thus have a slightly lower sharpe ratio.

However, looking at other moments, LTCM Net returns are more negatively skewed and have a significantly fatter tail compared to SPY, indicating the presence of heavy negative monthly returns over the sample period. Although, since the VaR of LTCM is lower compared to SPY, the indication is that these negative returns are fewer in frequency.

```python
spy_er_summary = performance_summary(spy_er_ltcm)
spy_er_summary.loc[:,['Mean','Volatility','Sharpe Ratio','Skewness','Excess Kurtosis','VaR (0.5)']]
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Mean</th>
	  <th>Volatility</th>
	  <th>Sharpe Ratio</th>
	  <th>Skewness</th>
	  <th>Excess Kurtosis</th>
	  <th>VaR (0.5)</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>SPY</th>
	  <td>0.173823</td>
	  <td>0.112294</td>
	  <td>1.547923</td>
	  <td>-0.433516</td>
	  <td>-0.362022</td>
	  <td>-0.04636</td>
	</tr>
  </tbody>
</table>
</div>

### 2.2) Using the series of net LTCM excess returns, denoted $\tilde{r}^{LTCM}$, estimate the following regression: <br>

\begin{align}

\tilde{r}^{LTCM} = \alpha + \beta^{m}\tilde{r}^{m}_{t} +\epsilon_t

\end{align}

### 2.2.a) Report  $\alpha$ and $\beta^{m}$. Report the $R^{2}$ stat.

```python
factor = spy_er_ltcm['SPY']
reg_sum = []
for rets in ['Gross Excess Returns','Net Excess Returns']:
    fund_ret = ltcm_returns.loc[:,[rets]]
    reg = regression_based_performance(factor,fund_ret,0)
    beta_mkt = reg[0][0]
    treynor_ratio = reg[1][0]
    information_ratio = reg[2]
    alpha = reg[3]
    r_squared = reg[4]
    reg_sum.append(pd.DataFrame([[alpha,beta_mkt,r_squared,treynor_ratio,information_ratio]],columns=['Alpha','Market Beta','R-Squared','Treynor Ratio','Information Ratio'],index = [rets]))

mkt_reg_sum = pd.concat(reg_sum)
mkt_reg_sum

```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Alpha</th>
	  <th>Market Beta</th>
	  <th>R-Squared</th>
	  <th>Treynor Ratio</th>
	  <th>Information Ratio</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Gross Excess Returns</th>
	  <td>0.210816</td>
	  <td>0.179845</td>
	  <td>0.021976</td>
	  <td>1.346034</td>
	  <td>1.564766</td>
	</tr>
	<tr>
	  <th>Net Excess Returns</th>
	  <td>0.131532</td>
	  <td>0.137114</td>
	  <td>0.018979</td>
	  <td>1.133077</td>
	  <td>1.188141</td>
	</tr>
  </tbody>
</table>
</div>

### 2.2.b) From this regression, does LTCM appear to be a "closet indexer"?

The R-Squared and $\beta$ of this univariate regression is fairly low, indicating very low correlation between LTCM and SPY. Based on this, LTCM does not seem to be a closet indexer.

This is due to the fact that most of their trades are long-short in nature.

### 2.2.c) From the regression, does LTCM appear to deliver excess returns beyond the risk premium we expect from market exposure?

With a significant higher annualized alpha of ~13.15%, LTCM does deliver excess returns beyond the market risk premium.

### 2.3) Let's check for non-linear market exposure. Run the following regression on LTCM's net excess returns:<br>

\begin{align}

\tilde{r}^{LTCM} = \alpha + \beta_{1}\tilde{r}^{m}_{t} + \beta_{2}(\tilde{r}^{m}_{t})^{2} +\epsilon_t

\end{align}

### 2.3.a) Report $\beta_{1}\, \beta_{2}$, and the $R^{2}$ stat.

```python
spy_er_ltcm['$SPY^{2}$'] = spy_er_ltcm['SPY']**2
factor_squared = spy_er_ltcm.loc[:,['SPY','$SPY^{2}$']]
quad_reg_sum = []
for rets in ['Gross Excess Returns','Net Excess Returns']:
    fund_ret = ltcm_returns.loc[:,[rets]]
    reg_squared = regression_based_performance(factor_squared,fund_ret,0)
    beta_mkt = reg_squared[0][0]
    beta_mkt_squared = reg_squared[0][1]
    treynor_ratio = reg_squared[1][0]
    information_ratio = reg_squared[2]
    alpha = reg_squared[3]
    r_squared = reg_squared[4]
    quad_reg_sum.append(pd.DataFrame([[alpha,beta_mkt,beta_mkt_squared,r_squared,treynor_ratio,information_ratio]],columns=['Alpha','SPY Beta','$SPY^{2}$ Beta','R-Squared','Treynor Ratio','Information Ratio'],index = [rets]))

mkt_quad_reg_sum = pd.concat(quad_reg_sum)
mkt_quad_reg_sum

```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Alpha</th>
	  <th>SPY Beta</th>
	  <th>$SPY^{2}$ Beta</th>
	  <th>R-Squared</th>
	  <th>Treynor Ratio</th>
	  <th>Information Ratio</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Gross Excess Returns</th>
	  <td>0.242388</td>
	  <td>0.219805</td>
	  <td>-2.586773</td>
	  <td>0.028458</td>
	  <td>1.101330</td>
	  <td>1.805091</td>
	</tr>
	<tr>
	  <th>Net Excess Returns</th>
	  <td>0.155040</td>
	  <td>0.166878</td>
	  <td>-1.926746</td>
	  <td>0.024321</td>
	  <td>0.930984</td>
	  <td>1.404397</td>
	</tr>
  </tbody>
</table>
</div>

### 2.3.b) Does the quadratic market factor do much to increase the overall LTCM variation explained by the market?

- The Quadratic Market Factor, does lead to slight improvement in the R-Squared of the regression, but the value still remains fairly low, to indicate any relation between LTCM and the market returns.
- The increased R-Squared could also be just a factor of multicolinearity, as the alpha in the regression also increases, meaning there is more unexplained returns on adding the quadratic market factor.
- The huge negative beta on $\text{SPY}^2$ is a feature of the factor. The monthly returns are small, thus the squared returns are even smaller, thus the beta has to be larger in magnitude to fir these small returns properly.

### 2.3.c) From the regression evidence, does LTCM's market exposure behave as if it is long market options or short market options?

Since the beta to $\text{SPY}^{2}$ returns is negative, LTCM's market exposure behaves as if it were short the market options. The beta to SPY can be interpreted as the delta of the market option and the beta to $\text{SPY}^{2}$ as the gamma to market options (through taylor expansion of market options). Since the gamma of an option is always positive, LTCM seems to be short the positive gamma or short the market options.

### 2.3.d) Should we describe LTCM as being positively or negatively exposed to market volatility?

- For a big monthly return, the negative beta for SPY Squared would lead to heavy underperformance of LTCM returns. Big market movements would lead to big underperformance of LTCM.
- Thus, LTCM seems to be taking on a negative exposure to market volatility underperforming big deviations in the market and the performance not being impacted much by small deviations.

### 2.4) Let's try to pinpoint the nature of LTCM's nonlinear exposure. Does it come more from exposure to up-markets or down-markets? Run the following regression on LTCM's net excess returns:<br>

\begin{align}

\tilde{r}^{LTCM} = \alpha + \beta\tilde{r}^{m}_{t} + \beta_{u}max(\tilde{r}^{m}_{t} - k_{1},0) + + \beta_{d}max(k_{2} - \tilde{r}^{m}_{t},0) +\epsilon_t

\end{align}

where $k_{1}$ = .03 and $k_{2}$ = -.03. (This is roughly one standard deviation of $\tilde{r}^{m}$.)

### 2.4.a) Report $\beta,\beta_{u}, \beta_{d}$, and the $R^{2}$ stat.

```python
spy_er_ltcm['SPY_call'] = np.where(spy_er_ltcm['SPY'] - 0.03 >= 0, spy_er_ltcm['SPY'] - 0.03,0)
spy_er_ltcm['SPY_put'] = np.where(-0.03 - spy_er_ltcm['SPY'] >= 0, -0.03 - spy_er_ltcm['SPY'],0)

factor = spy_er_ltcm.loc[:,['SPY','SPY_call','SPY_put']]
asym_reg_sum = []
for rets in ['Gross Excess Returns','Net Excess Returns']:
    fund_ret = ltcm_returns.loc[:,[rets]]
    reg = regression_based_performance(factor,fund_ret,0)
    beta_mkt = reg[0][0]
    beta_mkt_call = reg[0][1]
    beta_mkt_put = reg[0][2]
    treynor_ratio = reg[1]
    information_ratio = reg[2]
    alpha = reg[3]
    r_squared = reg[4]
    asym_reg_sum.append(pd.DataFrame([[alpha,beta_mkt,beta_mkt_call,beta_mkt_put,r_squared]],columns=['Alpha','SPY Beta','SPY Call Beta','SPY Put Beta','R-Squared'],index = [rets]))

mkt_asym_reg_sum = pd.concat(asym_reg_sum)
mkt_asym_reg_sum
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Alpha</th>
	  <th>SPY Beta</th>
	  <th>SPY Call Beta</th>
	  <th>SPY Put Beta</th>
	  <th>R-Squared</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Gross Excess Returns</th>
	  <td>0.173796</td>
	  <td>0.608536</td>
	  <td>-1.03835</td>
	  <td>1.632452</td>
	  <td>0.063774</td>
	</tr>
	<tr>
	  <th>Net Excess Returns</th>
	  <td>0.101232</td>
	  <td>0.466610</td>
	  <td>-0.78214</td>
	  <td>1.289575</td>
	  <td>0.055486</td>
	</tr>
  </tbody>
</table>
</div>

### 2.4.b) Is LTCM long or short the call-like factor? And the put-like factor?

Based on the regression betas, LTCM seem to be short the call-like factor and long the put-like factor.

### 2.4.c) Which factor moves LTCM more, the call-like factor, or the put-like factor?

Since, the magnitude of the put-like factor is significantly higher than the call-like factor, it would drive much of the movement in LTCM returns.

The beta to put-like factor seems to be irrelevant.

### 2.4.d) In the previous problem, you commented on whether LTCM is positively or negatively exposed to market volatility. Using this current regression, does this volatility exposure come more from being long the market's upside? Short the market's downside? Something else?

Since the LTCM returns seem to be shorting the call-like factor and long on put-like factor, they are negatively exposed to market volatility. The negative exposure comes from both the combination of the short position on call-like and long position on put-like factor.

## 3) The FX Carry Trade

Find an Excel data file, `fx carry data.xlsx`. The file has two sets of data:

- Risk-free rates across 5 currencies, as measured by annualized 3-month LIBOR rates.
- Spot FX rates, as direct quotes to the USD. (Note that all currencies are quoted as USD per
the foreign currency.)

For use in the homework, note the following:

- For risk-free rate data, $\tilde{r}^{f,i}_{t,t+1}$, the rate is known and reported in the data at time t. <b> Namely,
any given date t in the data file is reporting both ${S}^{i}_{t}$ and $\tilde{r}^{f,i}_{t,t+1}$</b> <br>
- The theory says to use log risk-free rates. You have the risk-free rate in levels: use the following equation to convert them:<br>

\begin{align}

\tilde{r}^{f,i}_{t,t+1} = ln(1+ \tilde{r}^{f,i}_{t,t+1})

\end{align}

- The theory says to use log spot FX prices. You have the FX prices in levels, so directly take their logarithims:<br>

\begin{align}

{s}^{i}_{t} = ln({S}^{i}_{t})

\end{align}

```python
risk_free_rates = pd.read_excel(r'C:\Users\piyus\Documents\Repos\finm-portfolio-2022\data\fx_carry_data.xlsx', sheet_name='risk-free rates')
risk_free_rates.index = risk_free_rates['DATE']
risk_free_rates = risk_free_rates.drop(['DATE'],axis=1)
for col in risk_free_rates.columns:
    risk_free_rates[col] = risk_free_rates[col]
    risk_free_rates['log_'+col] = np.log(1+risk_free_rates[col])

risk_free_rates.head()
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>USD1M</th>
	  <th>GBP1M</th>
	  <th>EUR1M</th>
	  <th>CHF1M</th>
	  <th>JPY1M</th>
	  <th>log_USD1M</th>
	  <th>log_GBP1M</th>
	  <th>log_EUR1M</th>
	  <th>log_CHF1M</th>
	  <th>log_JPY1M</th>
	</tr>
	<tr>
	  <th>DATE</th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>1999-01-31</th>
	  <td>0.004116</td>
	  <td>0.004938</td>
	  <td>0.002598</td>
	  <td>0.000995</td>
	  <td>0.000335</td>
	  <td>0.004107</td>
	  <td>0.004926</td>
	  <td>0.002595</td>
	  <td>0.000995</td>
	  <td>0.000335</td>
	</tr>
	<tr>
	  <th>1999-02-28</th>
	  <td>0.004135</td>
	  <td>0.004624</td>
	  <td>0.002600</td>
	  <td>0.001036</td>
	  <td>0.000232</td>
	  <td>0.004127</td>
	  <td>0.004614</td>
	  <td>0.002597</td>
	  <td>0.001036</td>
	  <td>0.000232</td>
	</tr>
	<tr>
	  <th>1999-03-31</th>
	  <td>0.004114</td>
	  <td>0.004434</td>
	  <td>0.002492</td>
	  <td>0.000993</td>
	  <td>0.000143</td>
	  <td>0.004106</td>
	  <td>0.004424</td>
	  <td>0.002489</td>
	  <td>0.000992</td>
	  <td>0.000143</td>
	</tr>
	<tr>
	  <th>1999-04-30</th>
	  <td>0.004085</td>
	  <td>0.004404</td>
	  <td>0.002141</td>
	  <td>0.000801</td>
	  <td>0.000099</td>
	  <td>0.004077</td>
	  <td>0.004394</td>
	  <td>0.002139</td>
	  <td>0.000801</td>
	  <td>0.000099</td>
	</tr>
	<tr>
	  <th>1999-05-31</th>
	  <td>0.004120</td>
	  <td>0.004420</td>
	  <td>0.002141</td>
	  <td>0.000833</td>
	  <td>0.000075</td>
	  <td>0.004111</td>
	  <td>0.004411</td>
	  <td>0.002138</td>
	  <td>0.000833</td>
	  <td>0.000075</td>
	</tr>
  </tbody>
</table>
</div>

```python
fx_rates = pd.read_excel(r'C:\Users\piyus\Dropbox\UChicago\FINM 36700 - Portfolio Theory and Risk Management I\Week 8 - 2021-11-15\HW 8 - Due 29th Nov\fx_carry_data.xlsx', sheet_name='fx rates')
fx_rates.index = fx_rates['DATE']
fx_rates = fx_rates.drop(['DATE'],axis=1)
for col in fx_rates.columns:
    fx_rates['log_'+col] = np.log(fx_rates[col])

fx_rates.head()
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>USUK</th>
	  <th>USEU</th>
	  <th>USSZ</th>
	  <th>USJP</th>
	  <th>log_USUK</th>
	  <th>log_USEU</th>
	  <th>log_USSZ</th>
	  <th>log_USJP</th>
	</tr>
	<tr>
	  <th>DATE</th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>1999-01-31</th>
	  <td>1.6457</td>
	  <td>1.1371</td>
	  <td>0.705816</td>
	  <td>0.008621</td>
	  <td>0.498166</td>
	  <td>0.128481</td>
	  <td>-0.348401</td>
	  <td>-4.753590</td>
	</tr>
	<tr>
	  <th>1999-02-28</th>
	  <td>1.6027</td>
	  <td>1.0995</td>
	  <td>0.689893</td>
	  <td>0.008425</td>
	  <td>0.471690</td>
	  <td>0.094856</td>
	  <td>-0.371219</td>
	  <td>-4.776599</td>
	</tr>
	<tr>
	  <th>1999-03-31</th>
	  <td>1.6140</td>
	  <td>1.0808</td>
	  <td>0.676819</td>
	  <td>0.008444</td>
	  <td>0.478716</td>
	  <td>0.077702</td>
	  <td>-0.390351</td>
	  <td>-4.774322</td>
	</tr>
	<tr>
	  <th>1999-04-30</th>
	  <td>1.6085</td>
	  <td>1.0564</td>
	  <td>0.655437</td>
	  <td>0.008373</td>
	  <td>0.475302</td>
	  <td>0.054867</td>
	  <td>-0.422453</td>
	  <td>-4.782730</td>
	</tr>
	<tr>
	  <th>1999-05-31</th>
	  <td>1.6020</td>
	  <td>1.0422</td>
	  <td>0.654450</td>
	  <td>0.008273</td>
	  <td>0.471253</td>
	  <td>0.041334</td>
	  <td>-0.423960</td>
	  <td>-4.794798</td>
	</tr>
  </tbody>
</table>
</div>

### 3.1) The Static Carry Trade

Define the log return of holding the foreign currency using log values of the risk-free rate and

log values of the FX rates:<br>

\begin{align}

{r}^{i}_{t+1} = {s}^{i}_{t+1} - {s}^{i}_{t} + {r}^{f,i}_{t,t+1} 

\end{align}

Then the excess log return relative to USD, is expressed as

\begin{align}

\tilde{r}^{i}_{t+1} = {s}^{i}_{t+1} - {s}^{i}_{t} + {r}^{f,i}_{t,t+1} - {r}^{f,\$}_{t,t+1}

\end{align}

For each foreign currency, i, calculate the excess log return series, $\tilde{r}_{t+1}$. Report the following

stats, (based on the excess log returns.) Annualize them.

- mean
- volatility
- sharpe ratio

```python
fx_spot_map = {'log_GBP1M':'log_USUK'
               ,'log_EUR1M':'log_USEU'
               ,'log_CHF1M':'log_USSZ'
               ,'log_JPY1M':'log_USJP'
}

fx_hldg_lst = []
for k,v in fx_spot_map.items():
    fx_hldg_excess_ret = fx_rates[v] - fx_rates[v].shift(1) + risk_free_rates[k].shift(1) - risk_free_rates['log_USD1M'].shift(1)
    fx_hldg_summary = performance_summary(fx_hldg_excess_ret.to_frame().dropna())
    fx_hldg_summary.index = [k[4:7]]
    fx_hldg_summary.index.name = 'Currency Held'
    fx_hldg_lst.append(fx_hldg_summary)

fx_hldg_perf_summary = pd.concat(fx_hldg_lst)
fx_hldg_perf_summary.loc[:,['Mean','Volatility','Sharpe Ratio','Min','Max']]
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Mean</th>
	  <th>Volatility</th>
	  <th>Sharpe Ratio</th>
	  <th>Min</th>
	  <th>Max</th>
	</tr>
	<tr>
	  <th>Currency Held</th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	  <th></th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>GBP</th>
	  <td>-0.003502</td>
	  <td>0.086303</td>
	  <td>-0.040574</td>
	  <td>-0.094861</td>
	  <td>0.088332</td>
	</tr>
	<tr>
	  <th>EUR</th>
	  <td>-0.004351</td>
	  <td>0.094714</td>
	  <td>-0.045944</td>
	  <td>-0.103716</td>
	  <td>0.093510</td>
	</tr>
	<tr>
	  <th>CHF</th>
	  <td>0.004312</td>
	  <td>0.098757</td>
	  <td>0.043662</td>
	  <td>-0.118548</td>
	  <td>0.129996</td>
	</tr>
	<tr>
	  <th>JPY</th>
	  <td>-0.017415</td>
	  <td>0.091492</td>
	  <td>-0.190342</td>
	  <td>-0.085030</td>
	  <td>0.074347</td>
	</tr>
  </tbody>
</table>
</div>

### What differences do you see across currencies?

An FX Carry trade on CHF produces positive mean excess returns for the sample period and thus a positive sharpe. For remaining 3 currencies, we see negative returns and higher volatility and subsequently worsening sharpe ratios.

### 3.2) Implications for UIP:

### 3.2.a) Do any of these stats contradict the (log version) of Uncovered Interest Parity (UIP)?

UIP states that the mean return of these currencies positions should be zero as the change in the spot fx rate is completely explained by the changes in risk free rates. However, none of the mean returns for the currencies are 0. 

On closer inspection the sharpe ratio of all currencies seem to be within the 95% confidence interval significance value and thus the mean return stats might not be significantly different from 0.

### 3.2.b) A long position in which foreign currency offered the best Sharpe ratio over the sample?

Over the sample, a long position in CHF would have offered positive returns but a low sharpe ratio of ~0.04.

### 3.2.c) Are there any foreign currencies for which a long position earned a negative excess return (in USD) over the sample?

All currencies except CHF earned a negative or near zero excess returns in USD terms. JPY especially had significant negative returns during the sample periods, with increased volatilities.

### 3.3) Predicting FX

For each foreign currency, test whether interest-rate differentials can predict growth in the foreign-exchange rate.1 Do this by estimating the following forecasting regression:

\begin{align}

{s}^{i}_{t+1} - {s}^{i}_{t} = \alpha^{i} + \beta^{i}({r}^{f,$}_{t,t+1} -  {r}^{f,i}_{t,t+1})+\epsilon_{t+1}

\end{align}

where  ${r}^{f,i}$ denotes the risk-free rate of currency i, and $s^{i}$ denotes the FX rate for currency i.<br>
Again, note that both ${r}^{f,\$}_{t,t+1}$ and $s_{t}$ are determined at time t.

### 3.3.a) Make a table with columns corresponding to a different currency regression. Report the regression estimates $\alpha^{i}$ and $\beta^{i}$ in the first two rows. Report the $R^{2}$ stat in the third row.

```python
fx_hldg_reg = []
for k,v in fx_spot_map.items():
    factor = risk_free_rates['log_USD1M'] - risk_free_rates[k]
    strat = fx_rates[v].diff()
    reg = regression_based_performance(factor,strat,0)
    beta_currency = reg[0][0]
    treynor_ratio = reg[1]
    information_ratio = reg[2]
    alpha = reg[3]
    r_squared = reg[4]
    fx_hldg_reg.append(pd.DataFrame([[alpha,beta_currency,r_squared]],columns=['Alpha','Beta','R-Squared'],index = [k[4:7]]))


fx_hldg_reg_summary = pd.concat(fx_hldg_reg)
fx_hldg_reg_summary = fx_hldg_reg_summary.T
fx_hldg_reg_summary
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>GBP</th>
	  <th>EUR</th>
	  <th>CHF</th>
	  <th>JPY</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>Alpha</th>
	  <td>-0.007596</td>
	  <td>0.008868</td>
	  <td>0.049584</td>
	  <td>-0.00114</td>
	</tr>
	<tr>
	  <th>Beta</th>
	  <td>0.110666</td>
	  <td>-1.633806</td>
	  <td>-2.066667</td>
	  <td>0.10538</td>
	</tr>
	<tr>
	  <th>R-Squared</th>
	  <td>0.000020</td>
	  <td>0.004398</td>
	  <td>0.006156</td>
	  <td>0.00004</td>
	</tr>
  </tbody>
</table>
</div>

### 3.3.b) Suppose the foreign risk-free rate increases relative to the US rate.

### i. For which foreign currencies would we predict a relative strengthening of the USD in the following period?

A strengthening U.S. dollar means that it now buys more of the other currency than it did before.If risk-free rate of a currency were to increase relative to the US rate, the currencies with a positive beta in the previous regression would see a decrease in the fx rates (USD per foreign currency). This indicates that there will be a relative strengthening of the USD as a dollar would now buy more of those currencies.

From the regression, we see only JPY and GBP having a positive beta and thus would have lower exchange rates in case the risk-free rate of Japan increases. Thus USD would relatively strengthen against JPY and GBP.

### ii. For which currencies would we predict relative weakening of the USD in the following period?

If risk-free rate of a currency were to increase relative to the US rate, the currencies with a negative beta in the previous regression would see an increase in the fx rates (USD per foreign currency). This indicates that there will be a relative weakening of the USD as a dollar would now buy less of those currencies.

EUR and CHF both have a negative beta to USD. Thus, USD would experience a relative weakening relative to these 2 currencies.

### iii. This FX predictability is strongest in the case of which foreign currency?

Indicated by the R-Squared in the regression, the FX predictibility seems to be strongest in case of CHF. However, it should be noted that this R-Squared is still fairly low and might not indicate towards a strong enough prediction.

### 3.4) The Dynamic Carry Trade

Use this to write $\mathbb{E}_{t}[\tilde{r}^{i}_{t+1}]$ as a function of the interest-rate differential as well as $\alpha$ and $\beta$ from this FX regression.<br>

\begin{align}

\mathbb{E}_{t}[{s}_{t+1} - {s}_{t}] = \alpha + \beta({r}^{f,\$}_{t,t+1} -  {r}^{f,i}_{t,t+1})

\end{align}

Then use the definition of excess (log) returns on FX:<br>

\begin{align}

\tilde{r}^{i}_{t+1} = {s}_{t+1} - {s}_{t} - ({r}^{f,\$}_{t,t+1} -  {r}^{f,i}_{t,t+1})

\end{align}

Rearranging, this implies the following forecast for excess log returns:<br>

\begin{align}

\mathbb{E}_{t}[{s}_{t+1} - {s}_{t}] = \alpha + (\beta-1) ({r}^{f,\$}_{t,t+1} -  {r}^{f,i}_{t,t+1})

\end{align}

### 3.4.a) Use your regression estimates from Problem 3 along with the formula above to calculate the fraction of months for which the estimated FX risk premium positive. That is, for each i, calculate how often in the time-series we have <br>

\begin{align}

\mathbb{E}_{t}[\tilde{r}^{i}_{t+1}] > 0

\end{align}

```python
fx_prem_lst = []
for k,v in fx_spot_map.items():
    fx_er_usd = (risk_free_rates['log_USD1M'].shift(1) - risk_free_rates[k].shift(1)).to_frame('ER_over_USD')
    expected_fx_premium = float(fx_hldg_reg_summary.loc['Alpha',[k[4:7]]])/12 + (fx_er_usd.loc[:,['ER_over_USD']]  * float(fx_hldg_reg_summary.loc['Beta',[k[4:7]]] - 1))
    expected_fx_premium = expected_fx_premium.rename(columns={'ER_over_USD':k[4:7]})
    positive_premium =  len(expected_fx_premium[expected_fx_premium[k[4:7]] > 0])
    fx_prem_lst.append(pd.DataFrame([[positive_premium,len(expected_fx_premium),positive_premium*100/len(expected_fx_premium)]],columns=['Months - Positive Premium','Total Months','Frequency(%)-Positive Premium'],index=[k[4:7]]))
fx_premium = pd.concat(fx_prem_lst)
fx_premium
```

<div>
<style scoped>
	.dataframe tbody tr th:only-of-type {
		vertical-align: middle;
	}

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
	<tr style="text-align: right;">
	  <th></th>
	  <th>Months - Positive Premium</th>
	  <th>Total Months</th>
	  <th>Frequency(%)-Positive Premium</th>
	</tr>
  </thead>
  <tbody>
	<tr>
	  <th>GBP</th>
	  <td>70</td>
	  <td>274</td>
	  <td>25.547445</td>
	</tr>
	<tr>
	  <th>EUR</th>
	  <td>140</td>
	  <td>274</td>
	  <td>51.094891</td>
	</tr>
	<tr>
	  <th>CHF</th>
	  <td>172</td>
	  <td>274</td>
	  <td>62.773723</td>
	</tr>
	<tr>
	  <th>JPY</th>
	  <td>1</td>
	  <td>274</td>
	  <td>0.364964</td>
	</tr>
  </tbody>
</table>
</div>

### 3.4.b) Which currencies most consistently have a positive FX risk premium? And for which currencies does the FX risk premium most often go negative?

CHF displays the highest consistency in producing positive FX risk premium followed by EUR. On the other hand JPY has a negative FX risk premium during all but 1 month in the sample. GBP also has negative premiums ~75% of the months in the sample period.

### 3.4.c) Explain how we could use these conditional risk premia to improve the static carry trade returns calculated in Problem 1.

Since from 3.4.a) JPY returns seem to be away from the expected value of 0, an improvement in the carry trade would be to short the JPY i.e. borrow at the JPY risk-free rate to invest in the USD risk-free rate. With our forecast of the USD strengthening relative to the JPY, we could be potentially getting a positive risk premia from this carry trade.
