---
aliases:
tags:
key_concepts:
parent_directory:
cssclasses: academia
title: Asset Management
linter-yaml-title-alias: Asset Management
---

# Asset Management

Paolo Vanini

University of Basel

January 26, 2020

# Contents

# 1 Introduction 9

# 2 Asset Management Overview 13

2.1 Wealth of Nations and Assets under Management (AuM) 15  
2.2 Investors 18

2.2.1 Private Investors 19  
2.2.2 Sovereign Wealth Funds (SWFs) 21

2.3 Pension Funds 22

2.3.1 Management of Pension Funds 27  
2.3.2 Demography and Pension Funds 29

2.4 Who Decides? 38

2.4.1MiFID II 39  
2.4.2 Investment Process for Retail Clients 42  
2.4.3 Robos 44  
2.4.4 Mandate Solutions for Pension Funds 45  
2.4.5 Conduct Risk 47

2.5 Risk, Return, Diversification and Reward-Risk Ratios 50

2.5.1 Long-term Risk and Return Distribution 51  
2.5.2 Diversification of Assets - Portfolios 51  
2.5.3 Two Mathematical Facts About Diversification 55  
2.5.4 Risk Model 57  
2.5.5 When Diversification Fails 59  
2.5.6 Concentration and Diversity 60  
2.5.7 Risk Scaling 66  
2.5.8 Costs and Performance 66  
2.5.9 Passive versus Active Investment; a First Step 67

2.6 Market Figures 69

2.6.1 The Demand and Supply Side in Asset Management 69  
2.6.2 Asset Management Industry - the Eurozone 70  
2.6.3 Global Figures 2007-2014, Market Structure 72  
2.6.4 Asset Management vs Trading Characteristics 75  
2.6.5 Institutional Asset Management versus Wealth Management 76

2.7 The Fund Industry 77

2.7.1 Mutual Funds and SICAVs 79  
2.7.2 US Mutual Funds versus European UCITS 80  
2.7.3 Functions of Mutual Funds 81  
2.7.4 Fees for Mutual Funds 84  
2.7.5 The European Fund Industry -UCITS 86

2.8 Index Funds and ETFs 88

2.8.1 Index Construction 89  
2.8.2 Capital Weighted Index Funds 91  
2.8.3 Risk Weighted Index Funds 94  
2.8.4 ETFs 95  
2.8.5 Evolution of Expense Ratios 102

2.9 Alternative Investments (AI) - Insurance-Linked Investments 102

2.10 Private Markets 106

2.11 Hedge Funds 108

2.11.1 What is a hedge fund (HF)? 108  
2.11.2 Hedge Fund Industry 109  
2.11.3 CTA Strategy 111  
2.11.4 Fees and Leverage 112  
2.11.5 Withdrawing Restrictions, Fund Flows and Capital Formation 113  
2.11.6 Biases, Entries and Exits 114  
2.11.7 Investment Performance 115

2.12 AM Innovation - Views on Disruption 121

2.12.1 Replacement and Prices 121  
2.12.2 Market Entrants 124  
2.12.3 Value Chain, Investment Process and Technology 128  
2.12.4 Some Innovations 130

2.13 ESG Investing 132

2.14 Green Investing 135

2.14.1 Green Bonds 140  
2.14.2 Energy Contracting and Structured Finance 142

2.15 Uniformity of Minds 145

2.15.1 The Great Depression and the Great Recession 145  
2.15.2 Uniformity of Minds 146

3 Fundamentals Theory 149

3.1 Returns and Performance Attribution 149

3.1.1 Time Value of Money (TVM) 149  
3.1.2 Interest Rate Swaps 153  
3.1.3 Forward Rate Agreements 159  
3.1.4 Constructing Discount Factors 160  
3.1.5 Return Bookkeeping 162  
3.1.6 Returns and Rebalancing 164  
3.1.7 Rebalancing Example 166

3.1.8 Rebalancing  $=$  Short Volatility Strategy 168  
3.1.9 Optimal Investment Strategy and Rebalancing 170  
3.1.10 Stochastic Portfolio Theory (SPT) 175  
3.1.11 Return Attribution 179  
3.1.12 Returns and Leverage 182

3.2 Basics of No Arbitrage 184  
3.3 No Arbitrage and Derivative Pricing 191  
3.4 Application 196

3.4.1 TAA Construction, Forwards and Futures 196  
3.4.2 Currency Forward and Futures 204  
3.4.3 Call-Put-Parity 209  
3.4.4 Market Structure 209  
3.4.5 Incomplete Market 210  
3.4.6 Multi Period Derivative Pricing 211  
3.4.7 Black and Scholes 217  
3.4.8 Hedging and Greeks 219  
3.4.9 Structured Products (SP) and Structured Investments 223  
3.4.10 Pricing of Structured Products 226  
3.4.11 Political Events: Swiss National Bank (SNB) and ECB and SP Investment 229  
3.4.12 Market Events 232

3.5 Collateral 235

3.5.1 Prime Finance 235  
3.5.2 Repo Transaction 236

3.6 The Efficient Market Hypothesis (EMH) 239

3.6.1 Predictability 243  
3.6.2 Testing Predictability 247  
3.6.3 Cross-Sectional vs Time Series Predictability 251  
3.6.4 EMH Extensions and Critique 252

3.7 Asset Pricing 254

3.7.1 Equivalent Formulation of the Fundamental Asset Pricing Equation 254  
3.7.2 Geometry of Asset Pricing 256  
3.7.3 Absolute Pricing (General Equilibrium 261  
3.7.4 Projection Pricing and SDF Formulation 266  
3.7.5 Arbitrage Pricing Theory (APT) 272  
3.7.6 Pricing Real-Estate Risk 274  
3.7.7 Multi-Period Asset Pricing and Multi-Risk-Factors Models 281

3.8 Applications 282

3.8.1 Low Volatility Strategies 282  
3.8.2 What Happens if an Investment Strategy is Known to Everyone? 285  
3.8.3 Short-Term versus Long-Term Investment Horizons 286  
3.8.4 Time-Varying Investment Opportunities 286  
3.8.5 Model Portfolios 288

3.8.6 Fallacies in Long Term Investment 291

# 4 Portfolio Construction 295

4.1 Steps in Portfolio Construction 295  
4.2 Allocation - Foundations of Investment Decisions 296

4.2.1 Statistical Models, Quadratic Optimization 296  
4.2.2 Rational Dynamic Decision Making 302  
4.2.3 Growth Optimal Portfolios 303  
4.2.4 Heuristic Models 305

4.3 Portfolio Construction Examples 308

4.3.1 Heuristic Allocation: Static 60/40 Portfolio 308  
4.3.2 Optimal Allocation: Dynamic Merton Model 310  
4.3.3 Optimal Allocation: Goal Based Investment 311  
4.3.4 Optimal Allocation: Markowitz 312  
4.3.5 Review Markowitz Model 325  
4.3.6 Views and Portfolio Construction - The Black-Litterman Model . 329  
4.3.7 Heuristic Allocation: Risk Budgeting Portfolio Construction 335

4.4 Estimation: The Covariance Matrix 341

4.4.1 Dimension Reduction: Eigenvalues and Eigenvectors 345  
4.4.2 Linear Shrinkage of the Covariance Matrix 351  
4.4.3 Non-Linear Shrinkage of the Covariance Matrix 353  
4.4.4 Comparing Different Approaches - Asymptotics 354

4.5 Factor Models 357

4.5.1 Industry Perspective 362  
4.5.2 Non-Performance of Alternative Risk Premia 367  
4.5.3 A Critical Review of the Industry Perspective 369  
4.5.4 The CAPM as a Beta Pricing Model 371  
4.5.5 Factor Investing: 3-Factor Model of Fama and French 381  
4.5.6 Factor Investing: 5-Factor Model of Fama and French 384  
4.5.7 Risk Factor Allocation 386  
4.5.8 Factors and Advisor Portfolios 387

4.6 Backtests 389

4.6.1 Data Snooping 389  
4.6.2 Overfitting 391  
4.6.3 Backtesting and Multiple Testing 393  
4.6.4 Application to Factor Investing 397  
4.6.5 p-Hacking 400  
4.6.6 Active vs Passive Investments 402

# 5 Investment Theory Synthesis 413

5.1 Absolute Pricing 413  
5.2 Simple General Equilibrium Model 414  
5.3 Fundamental Asset Pricing Equation 416  
5.4 State Prices, Risk Neutral Probabilities 419

# 6 Asset Management Innovation 421

6.1 Big Data 421

6.1.1 Definitions 421  
6.1.2 Demand for Big Data 422  
6.1.3 Algorithms 423  
6.1.4 Machine Learning (ML) 424  
6.1.5 Linear Threshold Model 445  
6.1.6 Support Vector Machines (SVM) 447  
6.1.7 Tree Based Learning 449  
6.1.8 Naive Bayes Classifier 452  
6.1.9 Nearest Neighbour Analytics 454  
6.1.10 'Sentimental Risk' 455  
6.1.11 Customer Retention: Text Mining 456  
6.1.12 Portfolio Construction with Machine Learning, I 458  
6.1.13 Portfolio Construction with Machine Learning, II 462

6.2 Blockchain 466

6.2.1 Cryptography 466  
6.2.2 Modular Arithmetic (MA) 468  
6.2.3 RSA Algorithm 470  
6.2.4 Hash Functions 472  
6.2.5 Digital Signatures 473  
6.2.6 Blockchain 475  
6.2.7 Different Blockchain Types, Type of Consensus 481  
6.2.8 Blockchain Examples 483

6.3 Currencies and Crypto-Currencies 489

6.3.1 Money and Payment Systems 489  
6.3.2 Fiat Money 489  
6.3.3 Bitcoin 490  
6.3.4 Bitcoin Blockchain Security 497  
6.3.5 Libra 498

7 Proofs 503  
8 Appendix 519  
9 References 521

# Chapter 1

# Introduction

Assets and their management (AM) are a key discipline in a modern economy: we manage our assets to maintain the standard of living after retirement, to buy property later, or because a sovereign wealth fund does not want to lose the assets of future generations. AM is a process of building, distributing, and maintaining assets throughout the life-cycle cost-efficient and compliant. Pension funds, institutional investors or private investors are different users of the AM process.

# Game Changers

PwC (2015, 2012), McKinsey (2015), Oliver Wyman (2016) and many others identify the following game changers for the asset management industry:

- Growth of wealth: Global assets under management (AuM) will exceed USD 100 trillion by 2020, up from USD 64 trillion in 2012.  
- Regulation: In the past, banks dominated the financial industry. They were the innovators. Regulation focused on banks and insurers after the 2008 Great Financial Crisis (GFC). AM initially faced fewer regulatory requirements and is now moving more and more center stage.  
- Technological Disruptions: Platforms, data analysis and mutual distributed ledger technologies allow greater connectivity between market participants, a redesign of the AM value chains, a reduction in life cycle costs, access to new customers and new approaches to horizontal integration.  
- Longevity and demographics: Retirement and health care will become critical issues as aging grows. The ratio of pensioners to the working-age population will reach 25.4 percent by 2050, up from 11.7 percent in 2010. This puts a strain on pension systems. The still increasing life expectancy - each new generation will live three months longer in the developed world - increases the need for individual wealth

management solutions when people are retired. Asset managers will therefore focus on long-term investments and on individual asset decumulation. This change affects in particular the US, Japan, most European countries, South Korea, Singapore, Taiwan and China.

- The distribution of AM services will be redesigned. Economies of scale force global distribution on global platforms, and on the other hand, increasing compliance complexity strengthens regional platforms.  
- Fees will continue to decrease for most asset management solutions and regulation requires to transform many existing fee models.  
- Alternative investments transform into traditional ones and exchange traded funds (ETFs) continue to proliferate.

Climate change is missing in the list above, although it will be one of the most important game changer. Furthermore, the game changer 'performance' is missing although performance is a notorious problem for many investors and there is no consensus about optimal investment behavior. We will give this topic wide scope.

Today's technology enables new approaches to investment. Such connections between technology and investment methodology are as important as the technology seen in terms of process efficiency, change in market infrastructure, and data integration. Asset managers face competition from new entrants - FinTechs with technological advantage but no customer base. The Medallion Fund of Renaissance shows that the interplay between technology and scientific mastery can make all the difference: In 26 years of investment history (1988-2016), the fund has returned  $88\%$  annually per year with only a loss of  $4\%$  in a year. Today, even the question arises as to whether technology can generally replace human abilities - can one generate a digital alpha? But it works or went without technology. Lord Keynes for more than 19 years outperformed by  $17\%$  per annum the S&P500.

While regulation dominated the decade after the GFC, the changes caused by technology are even more profound for the future of AM.

- Technology is irreversible while regulation is not. Regulators could revoke any regulatory rules. But technology which proves useful to the people cannot be stopped - how to stop the use of iPhones?  
- Technology has still an overall positive connotation - it improves the circumstances of living and it is creative. Regulation, despite its goals to make the financial system safer and to protect customers, fails to be seen in the same way.  
- Technology puts clients center stage. Regulation intends to do so.

The current digitization wave differs from the well-known automation. The technology has matured to a level where abstract banking and asset management products can be

understood, researched and valued by clients in a completely different way than in the past. Today's technology is closer to humans than it ever was. Technology is also able to replace human labor even for complex activities in the AM value chain - which work will still be human-specific in the AM industry?

# Contents

The content is from a methodological point of view split into two parts: Classical methods and innovation. The former one considers some of the main developments in the last decades which are in use in the AM industry. These can be the many ways how portfolios are constructed using the models or methods of Markowitz, factor investing, Black Litterman and many others. But it also means the way how the AM value chain is structured and organized. We focus in innovation on two topics: Data science, i.e. the way how possibly better forecasts can be made or customer needs measured. The second one are platforms and blockchain. This means new forms how the asset management infrastructure and value chain can be designed. The traditional models are discussed in Chapter 4 and innovation is considered in Chapter 6.

From a topical perspective, standard and trend topics can be differentiated. The first one includes to understand how different asset or asset classes behave, how their are selected and managed. Besides the technological trends described above the focus is on retirement provision. The standard material appears in all first five chapters. The trends in retirement provision are presented in Chapter 6

Finally, in AM need-to-know and need-to-think both matter. It is important to know facts about the status and the projections of the AM industry. Therefore, facts and figures about the AM industry are given full weight. Since AM always means to turn information into numbers analytical methods play a prominent role. Besides traditional techniques, we introduce to machine learning and blockchain technology.

I am grateful for the assistance of Dave Brooks and Theresia Büsser. I would like to thank Sean Flanagan, Barbara Doebeli, Bruno Gmur, Jacqueline Henn-Overbeck, Tim Jenkinson, Andrew Lo, Helma Klüver-Trahe, Roger Kunz, Tom Leake, Robini Matthias, Attilio Meucci, Tobias Moskowitz, Tarun Ramadorai, Blaise Roduit, Olivier Scaillet, Stephen Schaefer and Andreas Schlatter for their collaboration, their support or the possibility to learn from them.

# Chapter 2

# Asset Management Overview

The expression 'Asset Management' (AM) requires: What do we mean by an 'asset,' who 'manages' the assets, and how is this done?

Definition 1. Financial assets are financial contracts that define resources over which property rights are enforced and from which future economic benefits can flow to the owner. An asset class is a group of financial assets that share predefined economic, legal and regulatory characteristics.

Financial assets are intangible, non-physical assets. Financial assets often are more liquid than tangible assets. Securities are tradable financial assets. They are issued through financial intermediaries (primary market) and can often be traded on the secondary market. They differ among others in their ownership, complexity, liquidity, risk and reward profile, transaction fees, accessibility and regulatory compliance. Traditional asset classes are equities, fixed income securities, money market instruments and currencies. Alternative asset classes include real estate, commodities and private equity. Hedge funds are not an asset class but an investment strategy defined for liquid asset classes.

Asset management is a systematic process of analyzing, trading, lending and borrowing assets of all kinds. Since all assets belong to a person, the management of the assets is a decision made by the owner of the assets or by a third party. McKinsey (2013) estimates that third-party asset managers managed a quarter of global financial assets worldwide. Main outsourcers of assets are pension funds, sovereign wealth funds, family offices, insurance companies, and private households. Third-party managed portfolios are either mutual fund companies or discretionary mandates. In a mandate, the owner of the asset delegates the investment decision to the asset manager. Funds combine assets with a certain level of risk into a collective system. Diversification is the key risk concept. Investors buy and sell shares in funds (mutual funds, ETFs or hedge funds). The asset management function can be organized as an independent firm (Blackrock, Amundi) or the AM division of a bank or insurer (Goldman Sachs Asset Management).

The goal of investing is to save today for the benefits of future consumption. The

benefit after an investment period should be greater than the present direct consumption of all resources. Investments are made through the use of securities of all kinds - that is, money, stocks, bonds, ETFs, mutual funds or derivatives.

The AM firm's role to channel savings towards investment can be structured as follow. It creates products that match investors' needs. By trading the assets AM contributes to liquidity of financial markets. Investments are used by firms and governments. AM are one of the biggest investors in government bonds.

AM makes investment in issued bonds and stocks accessible to small private investors by using wrappers such as funds: Investors get for a small amount of money access to the economics of a diversified portfolio of assets. AM also engage with investee companies. As shareholders they hold the companies accountable and integrate environmental, social and governance (ESG) concerns in their investment processes.

AM firms are required by law to act in the best interests of their clients and to invest in accordance with a predefined set of rules and principles. They charge a fee which is based on the value of the assets under management (AuM). AuM grow if investment is performing which leads to higher fees for AM and higher returns for investors. The incentives of investors and asset managers to achieve positive returns are aligned. AuM refers to all the assets managed by a financial service provider. This includes assets managed under a discretionary asset management mandate as well as assets managed under an advisory asset management mandate. Definitions and formulas for calculating the AUM vary from company to company. Some financial institutions include bank deposits, investment funds and cash in their calculations; others limit them to funds where the investor assigns responsibility for investment decisions to the company.

Pricing and price forecasts of assets are important for investors. There are two ways to price assets in theory: absolute pricing as an equilibrium outcome in an economy, and relative pricing using the concept of no arbitrage. Equilibrium pricing is not relevant for AM industry except for the CAPM as a benchmark model, while no arbitrage pricing is key in derivative pricing. To price stocks and bonds, also called cash assets, often empirical pricing models are used. They follow from working with data such as the Fama-French model or more recently by using machine learning and AI. This approach is the far most used one in the industry although lack of theoretical foundations and misuse of statistics often lead to flawed investment strategies - data mining, data snooping, inaccurate backtestings are examples.

Four key questions in AM are:

1. Who decides?  
2. How do we invest? The investment method question.  
3. Where do we invest? The asset selection question.
4. How are asset management services produced and distributed in different jurisdictions? - the profitability, process, client segmentation, regulation and technology question.

In the past, technology was mostly needed to implement the investment strategies. New technologies enable radically new investment approaches that differ from traditional statistical models such as the Capital Asset Pricing Model (CAPM). But technology is also the key factor in scaling the business and managing regulatory complexity, i.e. to keep or increase profitability.

Question 4. attracted a large part of the asset management resources in the decade after the GFC due to regulatory and technological changes and also to different client expectations. This question can be considered as the sum of the following strategic business issues (UBS [2015]):

- In which countries does an AM firm want to compete in? The answer to this geographical question depends on the AM firm's actual strength, its potential, the costs to comply with the country specific regulation, the costs to build up the human capital and the business and technological complexity.  
- Which clients should be served?  
- Which products and investment areas should the AM firm focus on? Often large AM firms offer up to several hundred investment strategies.  
- What services should be provided and which technologies should be used for them?  
- What operating model should be used? This question has a distribution dimension (global vs. (multi)-local offering), an operational one (centralized vs. decentralized), a value-chain one (in-house vs. outsourcing) and a legal/tax environment one (on-shore vs. offshore).

# 2.1 Wealth of Nations and Assets under Management (AuM)

Prosperity growth is the raw material for asset management. Figure 2.1 shows the relative distribution of wealth worldwide in the last 2000 years.

In the period up to 1500, the distribution of wealth was stable and proportional to the population but not to the distribution within a population. This reflects the small global productivity differences. This changed radically as Europe and then North America ruled the rest of the world. Globalization and the end of colonialism, in which the economic differences between countries are shrinking, are changing the distribution of GDP towards the time of the Roman Empire. In absolute terms, it took 400 years to double global GDP from  \$1 trillion to\$ 2 trillion (1500-1900), but it only took 30 years from 1960-1990 to triple global wealth.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/49236dd7d8012190087f535a1f4d21582d9516fe4d2d200dd49630b467042d71.jpg)  
Figure 2.1: The size of the area indicates the proportion of global GDP produced in that area during the years concerned. GDP is measured in USD to offset purchasing power parity. In each chart, the total assets are displayed in USD. 1 AD means the year 1 anno Domini in the Julian calendar (worldmapper.org).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0171eaee2f1bbd561fe79df7582bc8a518ac108b0b41dff7ef4131001839ff36.jpg)

Assets under Management (AuM) is the market value of assets that an investment company manages on behalf of investors. AuM is often used as a measure of growth between asset managers. As profitability varies widely for different types of assets, AuM should be used with caution to draw conclusions about the asset manager's profitability. GIPS (Global Investment Performance Standards) is the market standard or AuM reportings investors.

PwC (2015) estimates that global AuM will exceed USD 100 trillion by 2020, up from USD 64 trillion in 2012. Other estimates are similar. These figures would result in an annual global compounded growth rate of 6 percent. This rate varies for different geographic regions (Boston Consulting Group [2016]):

- Western Europe, northern America, Japan:  $1.6\%$  p.a.  
- Emerging Markets (EM): South America, BRIC states, Middle East, Eastern Europe:  $8.5\%$  p.a.

The different growth rates define opportunities for wealth managers in developed markets to offer solutions in fast-growing markets. Therefore, market access for the development of AM plays a prominent role. At the individual level, per capita GDP in 2016 was USD 11'000 for the emerging economies and USD 47'000 for the industrialized countries. The

estimates for the period 2016-2021 are  $150\%$  for the EM and  $50\%$  for the developed ones (IMF World Economic Outlook [2016]).

The evolution of EM can also be seen by considering specific assets, see Table 2.1 for the emerging market E(M) bonds market share growth. 20 years ago almost  $100\%$  of

<table><tr><td>Markets</td><td>31 Dec 1989</td><td>31 Mar 2016</td><td>trn USD</td></tr><tr><td>US</td><td>61.30%</td><td>38.10%</td><td>37</td></tr><tr><td>Developed Markets ex US</td><td>37.80%</td><td>44.30%</td><td>44</td></tr><tr><td>Emerging Markets</td><td>1.00%</td><td>17.50%</td><td>17</td></tr></table>

the EM bonds had a high yield creditworthiness, in 2016 only  $45\%$  had such a rating in the JP Morgan EM bond index and therefore with  $55\%$  with an investment grade rating. Figure 2.2 shows other dimensions of the EM developments.

Wealth growth must be compared to the dynamics of wealth inequality. Increase in inequality is likely to destabilize the growth of wealth as it leads to social and political instability. Inequality risks are among the highest risks in the annual global risk map of the World Economic Forum. On the one hand, the global increase in wealth has been the main reason for poverty to fall worldwide at a level never seen before in history. CO2 emissions due to the changed living conditions, mobility, meat dominated food and tourism among others will trigger or reinforce global economic and social tension.

The global wealth projections of PwC (2015) for different types of investors are shown in Table 2.2.

Table 2.1: Bond market shares (Barclays Capital, BIS, FactSet, J.P. Morgan Asset Management [2016]).  

<table><tr><td>Clients</td><td>2012, USD tr.</td><td>2016, USD tr.</td><td>E2020, USD tr.</td><td>Growth rate p.a.</td></tr><tr><td>Pension funds</td><td>33.9</td><td>38.3</td><td>53.1</td><td>6.5%</td></tr><tr><td>Insurance companies</td><td>24.1</td><td>29.4</td><td>38.4</td><td>4.8%</td></tr><tr><td>SWF</td><td>5.2</td><td>7.4</td><td>10</td><td>6.9%</td></tr><tr><td>HNWIs</td><td>52.4</td><td>72.3</td><td>93.4</td><td>4.9%</td></tr><tr><td>Mass affluent</td><td>59.5</td><td>67.2</td><td>84.4</td><td>6.7%</td></tr></table>

Table 2.2: There are double counts. Assets of wealthy individuals (HNWIs) are invested in insurance and pension funds. Mass affluent refers to individuals with liquid assets between USD  $1 - 3\mathrm{mn}$ . HNWIs possess liquid assets of USD  $3 - 20\mathrm{mn}$ . The categorization is not unique. The predictions of the 2020 AuM changed from 2015 and 2018 vista time. While the numbers were stable for pension funds and insurance companies, the forecast for HWNI was significantly corrected upwards and the mass affluent number for 2020 is now significantly lower (PwC [2015], PwC [2018]).

Mass affluent clients and HNWIs in emerging markets are the main drivers of AuM

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/225cf50baeb6b1c783915a2e518f64be552a750c11d6710c430471f9b055fe3d.jpg)  
EM Sovereign spread trading at around long-term average JPM EMBI Global Diversified Index spread, basis points

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/91722d925b88c316335bbe44a9d130cfbed67ff312ffa259addbf793613ab851.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/258de0111bbf5ba127e43409d7246e98d1eb80519556b68a9d6d7c190258dbdc.jpg)  
Figure 2.2: Upper left panel: Share of global nominal consumption measured in current USD expenditures. Upper right panel: EM country fundamentals at the time of the taper-tantrum and measured at the beginning of 2017. Lower panel: Creditworthiness of EM countries. The right panel shows the divergence for different EM countries. (J.P. Morgan Guide to the Markets, UN, World Bank, J.P. Morgan Global Economics Research [2013, 2015, 2016])

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f6ee96344b644454a109f86a8d3f823d8f1adf0c6450b2e8f56dee4d3c6e4008.jpg)

growth. The global middle class is projected to grow by 180 percent between 2010 and 2040, with Asia replacing Europe as home to the highest proportion of middle classes as early as in 2015 (OECD, European Environment Agency, PwC [2014]). The growth of pension funds will be large in countries with fast growing GDPs, weak demographics and defined contribution pension schemes.

# 2.2 Investors

There are different types of investors: private clients, high net worth individuals, pension funds, family offices or state investment funds. At a higher level, investors are divided into private investors and institutional investors. The ownership of assets between these two categories changes over time, see Figure 2.3 for the US.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/5950ee400a3945b15a853d901fc5cdc2cdc1afb9f740116a622ded5a64dfd05f.jpg)  
Figure 2.3: Equity ownership in the US. In the 1950s,  $90\%$  of equity in the US were held by private investors. This number dropped almost linearly to  $40\%$  by the end of 2010 and then began to rise slightly. The fraction of equity ownership held by institutional investor follows the opposite evolution. Source: Rohner [2014].

# 2.2.1 Private Investors

Private investors differ in many ways from sovereign wealth funds and pension funds. Their biggest asset is human capital, which interacts with assets along the life cycle as follows. As a young, they only have human capital. In the course of their lives, human capital generates an income that is converted into financial capital. When retiring, most people no longer use their human capital to generate finance capital but consume accumulated finance capital. Pension funds for example are timeless.

Private investors show a strong real estate dependence in their balance sheet, see Figure 2.4 for the Swiss case. In particular younger investor face a large leverage effect of mortgage financing: the ratio of assets (real estate) to existing capital is large. Small changes in the property asset price have a significant impact on the balance sheet equity of the investor. Interest rate risk and real estate market price risk affect the asset. The latter risk is more dangerous for the investor's default.

Consider a private investor which bought a house worth CHF 1 million. The 'golden rule of affordability' in Swiss banking states that the investor needs to cover  $20\%$  of the house price with his own capital and that the interest rate charge for the mortgage should not exceed  $1/3$  of regularly income assuming a hypothetical high interest rate level of  $5\%$ . For a mortgage of CHF  $800'000$  regular income of the investor has to be not lower than

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d882b442f6d907bb56e80aeececd65e327963be21e60a77ac0268a8a560782c7.jpg)  
Figure 2.4: Balance sheet of private households in Switzerland (SNB [2018]).

CHF  $3 \times 0.05 \times 800'000 = 120'000$ . Suppose that the investor gets a mortgage with fixed 5 year rate of  $1\%$  which is a plausible number in a zero interest rate risk environment. He therefore pays for the next 5 years without any amortization payments CHF  $8'000$  per annum which is much less than renting the same object. Assume that the remaining liquid capital of the investor is CHF  $100'000$  and an annual salary of CHF  $150'000$ .

The leverage ratio of the investor, the ratio of the asset value to equity value, is  $\lambda = \frac{1'000'000}{100'000} = 10$ . Consider two scenarios. First, interest rates are up in five years to  $3\%$ . Second, house price fall by  $15\%$  in the next five years. The first scenario implies that the investor has to pay CHF  $24'000$  per annum for the interest rate charge for the new mortgage after five years. Three times more than in the past but still an affordable part of income. In the second scenario, the house is only worth CHF  $850'000$ . Since the investor should always cover  $20\%$  of the house price, a maximum mortgage of  $80\%$  means a value of CHF  $680'000$  since the new house price is CHF  $850'000$ . The investor has to pay the difference of the old and new mortgage value of CHF  $120'000$ . This is an annual salary! Hence, house price risk is more severe risk than interest rate risk.

Given the importance of real estate risk for private clients it is not understandable why the myriad of sophisticated wealth management tools almost always only consider the financial assets leaving aside the house asset and mortgage debt. But not only retail investors use mostly an asset only approach in investment. Research from State Street (2014), using data from a worldwide survey of 3,744 investors, shows that although

nearly 80 percent of investors realize the importance of achieving long-term goals but proficiency in achieving them can strongly deviate. In the US, public pension funds were on average less than 70 percent funded, with more than USD 1.3 trillion of unfunded liabilities. A similar picture holds for private investors. While 73 percent cited long-term goals only 12 percent could say with confidence that they were on target to meet those goals. Many academic papers address the misalignment between what investor's say is important (ALM) and what they do (asset only). There is a myriad of possible reasons for this difference between what they state and what they do which are discussed in the papers.

Investors differ also in the type of financial assets they buy. The more professional investors are, the more they invest in cash products. They do not use mutual funds or structured products, since they can create the same payoffs without paying the wrapper costs. Figure 2.4 shows on the aggregate of all investors that bond investments and structured products did not grow in the last decade opposite to the growth of funds and shares.

Individuals and smaller pension funds prefer mutual funds and structured products. One reason is lack of capital to reach a reasonable diversification. We discuss below that a Swiss investor needs about CHF 1.5 million in order to achieve a reasonable diversification by investing in cash products. The second reason is that individuals fail to have direct access to some markets and they cannot enter into short positions or are not allowed to trade derivatives under the International Swaps and Derivatives Association (ISDA) agreement. They are forced to buy derivatives in the packaged form of a mutual fund or a structured product.

# 2.2.2 Sovereign Wealth Funds (SWFs)

SWFs are among the largest wealth owners in the world. The largest SWF in 2018 was the Norwegian government's pension fund with assets of \$ 1,002 billion. The next largest are from the Middle or Far East: Abu Dhabi, United Arab Emirates, Saudi Arabia, China, Kuwait, Hong Kong, Singapore and Qatar. All manage funds with assets ranging from $ 200 to $ 800 billion.

Why are there so many SWFs in emerging markets? More than 50 percent of all large SWFs originate in oil and Asian governments are much more active in managing their economies than some of their western counterparts. According to Ang (2014), another reason is that the US, after the many state bankruptcies of the 1980s and 1990s, told emerging markets to save more. In recent years, a debate has begun on whether it is productive to accumulate so much capital in sovereign wealth funds. Would it not be more productive to invest capital directly in the local economy?

Many SWFs accumulate liquid assets as reserves for unexpected future economic shocks. This forms a long-term precautionary savings motive for future generations.

This motivation is crucial for the acceptance of a SWF. A SWF can only exist if it has public support. This public support is a sensitive issue. Scandals due to incompetent fund management, lack of integration of the fund into economic strategies, political mismanagement and criminal acts should be avoided. All changes in the risk policy for asset management must be documented and communicated to the owners of the Fund. For example, the Norwegian SWF initially invested only in bonds. Only after a broad public discussion was a diversification of investments into other asset classes considered. This behavior of Norwegians is unique and rooted in their democratic tradition.

# 2.3 Pension Funds

Large pension funds can be managed at the state level, but most are privately owned, unlike SWFs. The assets managed by pension funds vary between 70 percent (US) and 130 percent (Netherlands) of GDP (2017). Why are there pension funds? Pension funds can provide individuals with risk-sharing mechanisms that are not feasible on their own. Consider a 25 year old person who wants to protect their future capital at retirement. The financial markets do not offer capital-protected products with a maturity of 40 years - the markets are incomplete. A retirement plan can mitigate today's generation risks by creating buffer stocks over the next 40 years across generations. A risk sharing between generations takes place: In this sense, pension funds complete the market by adding a synthetic infinite lived market participant - the aggregate over all generation - which allows individual to share their life cycle-specific investment risk.

Pension funds are one part of the total pension system of a country, which is often divided into three pillars:

- Pillar I - This pillar should cover the subsistence level and is often organized according to the pay-as-you-go system. Each month, employees pay part of their salary, which is immediately distributed to pensioners.  
- Pillar II - This is the pillar of the pension funds. It should be enough to cover the cost of living after retirement together with pillar I. The asset owners only have limited access to their assets. There are two types of funds: Defined Benefit (DB) and Defined Contribution (DC). DB plans are based on predetermined future benefits for the beneficiaries, but keep the contributions flexible. DC plans fix the contributions but not the future benefits. In summary, the contributions define the benefits in the DC plans and the benefits define the contributions in the DB plans.  
- Pillar III - Privately managed investments, which often have tax advantages. Access to assets before retirement is usually limited.

Figure 2.5 illustrates the importance of different pillars in different countries. Retirement systems are under pressure in most industrialized countries due to demographic changes and increasing longevity. For the first pillar, demographic change means that working people pay on average for a growing number of retirees. This jeopardizes the

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b110a74cde6a2788004d4bf13c614ba42099b4de69f16cdbd5263c3ceaf50a5e.jpg)  
Figure 2.5: Left panel: The importance of the three pillars in percentage of retirement income (ABP [2014]). Right Panel: Basic form of DC and DB pension plans.

concept of intergenerational risk sharing.

The threat to the first pillar has major implications for national budgets. The first pillar accounts for more than 90 percent of retirement income in Spain. For Germany, France and Italy, the value is between 75 percent and 82 percent. Given the extremely low fertility rates and high unemployment among young people in Spain and Italy, the first pillar can not survive. Shifts into the second or third pillar are required, which represents an opportunity for asset management. But this only makes sense for the workers with a regular income. The pension problem of the mass of today young people without work remains unresolved.

# The drivers in pay-as-you-go systems

The above statements can be illustrated by the following back-on-the-envelope calculation. Assume that people work 40 years, retire and live for another 20, that the population is the same for every year (normalized to 1), that all workers earn 1 unit per year and that they pay in the benchmark case  $20\%$  of their income to the first pillar. Therefore, retired earn 0.4 units per year from the first pillar which is enough to survive but also requires a second pillar. This defines the benchmark We consider four scenarios.:

Benchmark  

- Unemployment 10 percent, earn 0.4  
Demography: Working cohorts  $10\%$  smaller than retired ones (demography)  
- Longevity

The results indicate the increase in first pillar contributions. The assumptions in the scenarios are mild given that in southern Europe unemployment rate for generations of young workers are higher than  $20\%$  and that the working class in Japan will most likely drop by  $50\%$  in the next 20 years. This is the reason why Japan heavily invests in robot technology to substitute missing human workforce.

In the DB plans, the pension is set in relation to the last average salaries, see Figure 2.5. The contributions are calculated in such a way that they generate a predefined capital stock at the end of working life. Therefore, an increase in salary requires additional funds in order to maintain the full rent. On the other side, a year with very low income can have dramatic effects for the contributor in the retirement period. Since the financing amount can change on an annual basis, they are considered intransparent.

In DC plans, the fixed contributions are invested in several asset classes and the rent is only weakly related to the most recent salary of the contributor. The growth of the invested capital, including interest payments, implies a final capital value at the end of working life. The conversion rate applied to that final capital level finally defines the annual rent. Contributors to DC plans - contrary to those who contribute to DB plans - bear the investment risk. This makes this form of pension system cheaper to offer for employers. Unlike DB plans, the contributors can at least partially influence investment decisions - that is, choose the risk and return levels of the investments. This is one reason why DC plans have become more attractive to contributors than their DB counterparts. Finally, in some jurisdictions, DC plans are portable from one job to the next, while DB plans often are not portable.

Underfunding is a serious problem. The S&P 500's biggest pension plans faced 2018 a \$382 bn funding gap, of the 200 biggest DB plans in the S&P 186 aren't fully funded in 2018. Companies like Intel have a ratio of pension assets to pension obligation of less than fifty percent. In Switzerland, the average funding ratio of private pension funds in 2013 was 107.9 percent (Kunz [2014]). The ratio for public funds was 87.8 percent, showing strong underfunding. Private and public pension funds differ even more severely when comparing the overfunding and underfunding gaps: For the Swiss private sector, there is CHF 16.2 billion of overfunding capital and CHF 6.4 billion of underfunding. In the public domain, the situation is the opposite: CHF 1.4 billion of overfunding versus a CHF 49.5 billion funding gap.

# 2.3.0.1 DB versus DC Planes

There was a rapid shift from the DB plans in the 1980s to DC systems in the US and UK. In the United States, nearly 70 percent of the 2017 pension funds are DC. This is a percentage reversal from the situation 30 years ago. This system change took place more quickly in the private sector than in the public sector, as the state can rely on taxpayers. What are the causes of these changes? One reason is regulation, which, according to the proposals of the Basel Committee and also under Solvency II, requires a certain coverage ratio for the insurance industry. Furthermore, IFRS accounting standards since 2006 state that a funding deficit should be included in the balance sheet of the companies. For DB systems, the shortfalls are financed by the employer, so that guarantees are on the balance sheet of the companies. By switching to DC plans, which are not guaranteed, the burden on the balance sheet disappears for the companies.

Another perspective associated with the transition to DC-based plans is the average undersavings in such plans. Munnell et al. (2014) report that in 2013 the average DC portfolio at retirement is USD 110,000, while over USD 200,000 is needed. Finally, DB and DC differ in their costs. The CEM benchmarking (2011) which considers 360 global DB plans with 7 trillion USD assets find a fee range between 36 and 46 bps. Munnell and Soto (2007) estimate the fees for DC plans between 60 and 170 bps.

Another perspective on DC and DB is financial literacy - the ability of decision makers to understand their investments. By definition, employees make investment decisions in DC plans. Several studies document that a majority of employees want to delegate their investment decision. One reason is their knowledge in financial matters. Gale and Levine (2011) are testing four traditional approaches to financial education - employer-based, school-based, credit counseling or community-based. They note that none of the literacy efforts have had a positive and substantial impact.

# 2.3.0.2 Demographic Changes and Longevity

An AM trend in many countries will reflect the increasing importance of asset consumption by the baby boomer generation in retirement, compared to previous generations whose main goal was saving. This shift from an accumulation regime to asset consumption has a deep impact on the delivery of AM solutions. Asset consumption in retirement is a personalized asset-liability management problem. Accumulation of wealth, on the other hand, is much less individualized. Baby boomers will therefore demand tailored asset-liability management solutions.

Furthermore, private savings are becoming more important due to the problems in the first pillar. They will be responsible for a larger part of their assets and bear the investment risk. Given the inability to cover retirement losses, pension fund clients will ask for less risky assets.

Several financing and redistribution risks between the active insured and the retirees exist. Many countries define a legal minimum fixed interest rate which has to be applied to the minimum benefit pension plan. This rate is in Switzerland  $1.75\%$  for 2015 and  $1.25\%$  in 2016. Given the CHF swap rate for 10 years in 2015 close to zero, it is not possible for a pension fund to generate the legally fixed rate using risk free investments. This defines financing risk for the contributing population to a pension plan.

To understand redistribution risk, we consider the technical interest rate. This is by definition the discount rate for pensions. Since pensions cannot be changed in Switzerland after the day of retirement (constitution), any reduction of the technical interest rate leads to higher capital for the retired population in order to maintain their pensions unchanged. The technical rates are 2016 significantly higher in most low-interest countries than the interest rates: The pensions paid out are simply too high, see Figure 2.7. Axa Winterthur (2015) estimates that in Switzerland CHF 3.4 bn are redistributed from active insured to retired persons every year. If the ratio between the active and retired populations changes in the future due to the demographics and longevity issue, future low interest periods will sharply increase the annually redistributed amounts.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2c8545702adc3816d350c37aeefc424ca1c5c27a68ca87ec3e7429d300fc80fd.jpg)  
Figure 2.7: The return of the 10y Swiss government bond, the minimum legal rate for Swiss pension plans and the technical rate for privately insured retired individuals. If this status remains unchanged in the next years then underfunding becomes a serious issue and there can be no significant return expected from investment in the fixed income asset class. The technical rates are even higher than the minimum rates which indicates the extent at which actual pensions are too high. (Swisscanto [2015], SNB [2015], OAK [2014]).

If interest rates are low, pension funds are forced to consider alternative investments: Invest more or newly in stock markets, credit-linked notes, private markets, liquid investment strategies (smart beta or factor investing), insurance-linked investments, high-grade securitized mortgages or senior unsecured loans. These alternatives induce different risks and the experience of many pension funds is limited. Pension funds can also reduce their costs. This would help but not solve any of the above problems due to demographics, low interest rates or longevity risk.

# 2.3.1 Management of Pension Funds

The obvious approach to manage pension funds is to match the assets' cash flows with the liabilities' ones. This means optimizing the difference between asset and liability (surplus). This is not a trivial task. Reasons are mismatches of risk, growth and maturity between assets and liabilities. While assets and risks are market-driven, the values and risks of liabilities are defined primarily by the characteristics of contributors to pension funds, demographic changes and policy interventions - all non-market factors. Furthermore, the growth rate of liabilities is more stable than for assets.

Another reason is implicit or explicit return guarantees on the liability side. Guarantees cut linear payoffs of liabilities; i.e. options are generated. Unlike standard financial derivatives on stocks, the pricing of these options is much more complex and opaque: the underlying assets are not tradeable and risk-sharing mechanisms must be considered in option pricing. These options are often neither valued nor hedged. But they exist adversely affect the goals of a pension fund. A third reason is the overlapping of generations in the design of the pension system, i.e. generation  $x$  pays also for say a yet retired generation.

We are pursuing the less ambitious task of taking the asset side management into account, with the liability side implicitly included in the asset return benchmark. It is customary to divide the yield contribution into three parts: strategic asset allocation (SAA), tactical asset allocation (TAA) and stock selection. The SAA is an asset allocation over a long-term period of 5-10 years. It is based on unconditional past information; returns are unconditional expectations. The TAA seeks to exploit the predictability of returns over a short to medium term horizon. TAA forecasts are conditional expectations, the current status of the financial market or the business cycle matter. As a result, SAA weights change slowly over time while TAA weights are more dynamic. Formally,

$$
\mathrm {S A A}: E _ {P} (R _ {t + 1}), \mathrm {T A A}: E _ {P} (R _ {t + 1} | \mathcal {F} _ {t})
$$

with  $\mathcal{F}_t$  the information set at time  $t$ . The definition of this set is basic in the Efficient Market Hypothesis or the predictability of asset prices.

Definition 2. (Sharpe (2007)) In a SAA, an investor's return objectives, risk tolerance, and investment constraints are integrated with long-run capital market expectations to

establish exposures to permissible asset classes and currencies. The end result is a set of portfolio weights (of asset classes) that defines the investor's risk-return trade-off.

The SAA's primary objective is to create a long-term optimal expected risk and return asset mix. The SAA divides assets into different asset classes, geographic regions, sectors, currencies and various credit rating levels.

The TAA bets on the predictability of asset return. But are asset returns predictable? Although the concept of a TAA has existed for more than 40 years, practitioners and scientists attribute different meanings to a TAA. Practitioners use a one-period setup to define a TAA. Academics often use intertemporal portfolio theory to derive dynamic optimal investment rules. This theoretical optimal TAA that has a short-sighted one-period and a dynamic hedging demand component. The short-sighted part of the optimal TAA corresponds to the TAA of practitioners. The other component is missing in practice, see Sections 4.3.4.6 and 3.1.9.

# Example Historical background TAA

The first investment firm to consider a TAA was Wells Fargo in the 1970s. The decline in many assets during the 1973-1974 oil crisis increased investor demand for alternatives to shifts within a particular asset class. Wells Fargo proposed shifts across asset classes and bonds. The system was able to generate positive returns over a period when stock markets fell more than 40 percent. In the 1980s, portfolio insurance became popular based on the option price theory. These dynamic strategies seek to maintain a guaranteed minimum portfolio return (floor). The Constant Proportion Portfolio Insurance (CPPI) approach largely simplified the option approach, making portfolio insurance even more attractive to investors. The global stock crash in 1987 shifted the investor's interest away from portfolio insurance back to TAA, as portfolio insurance strategies mostly did not deliver the guaranteed floor, while TAA strategies suffered before the crash, but outperformed shortly thereafter. We refer to Lee (2000) for a detailed discussion.

Let's go back to the management of pension funds. We assume that the people at the top of the funds have little investment knowledge. Their decisions concern the SAA. At the lower end of the fund hierarchy are the experienced asset managers. Their success is measured in relation to TAA and they seek to generate excess returns over the TAA benchmark by selecting assets. However, many empirical studies show that SAA is the most important determinant of total return and risk of a broadly diversified portfolio. This defines the discrepancy between economic relevance and know-how in the hierarchy of decision-makers.

- Brinson et al. (1986) report that around 90 percent of the return variance arrives from the passive investment part. Subsequent papers clarified these findings and estimate the importance of these returns being between 40 percent and 90 percent (see, for example, Ibbotson and Kaplan [2000]). Schaefer (2015), one author of the

professors report to the Norway's Government Pension Fund Global, states that the variance attribution to the benchmark return was  $99.1\%$  and only  $0.9\%$  was attributed to the active return.

- Between 5 and 25 percent are due to TAA and related to the Chief Investment Officer (CIO) function.  
- Between 1 and 5 percent are due to security selection by the portfolio managers.

# 2.3.2 Demography and Pension Funds

We already considered parts of the topics demography, retirement provision and pension systems. Before we continue to discuss these topics also from an asset management perspective I remark that asset management is only a important tool for the solution of the problems in the different retirement pillars which many countries face. Necessary for the change of the different systems are deep political reforms which will restore the trust of the populations in the retirement systems.

# 2.3.2.1 Demographic Facts

Though population explosion is no longer the burning issue it once was, we are still experiencing staggering population growth of 2 to 3 percent per annum. Population pressure will of course mean a growing likelihood of mass emigration to other parts of the world; in particular if those countries with strong population growth are hit by the effects of climate change or war.

The economically most advanced societies face another population problem. Each future generation will be smaller than the one that preceded it. For some, this has already become a matter of national survival. Triggered by low fertility rates, this phenomenon is gaining ground worldwide: 46 percent of the world's population has fallen into a low-fertility regime. There is nothing to indicate that this rate is going to recover. Magnus (2013) states that (i) the ratio of children to older citizens stands at about  $3:1$  but is declining. By 2050, there will be twice as many older citizens as there are children, (ii) the number of over-60s in the rich world is predicted to rise by 2.5 times by 2050 to 418 million and (iii) in the emerging and developing worlds, the number of over-60s will grow by more than seven times to over 1.5 billion by 2050, and behind this, you can see a 17-fold increase in the expected population of those aged over 80, to about 262 million. Magnus (2013)

Malthus (1798) were the first to study the interdependence between economic growth and population growth. He assumed that as long as there was enough to eat, people would continue to produce children.

Since this would lead to population growth rates in excess of the growth in the food supply,

people would be pushed down to the subsistence level. According to Malthus's theory, sustained growth in per capita incomes was not possible; population growth would always catch up with increases in production and push per capita incomes down. Of course, today we know that Malthus was wrong, at least as far as the now industrialized countries are concerned. Still, his theory was an accurate description of population dynamics before the industrial revolution, and in many countries it seems to apply even today. Doepke (2012).

Hence, for Malthus children were a normal good. When income went up more children were consumed by parents. Using a micro economic model the equilibrium supports the above intuition: An increase in productivity causes a rise in the population, but only until the wage is driven back down to its steady-state level. Even sustained growth in productivity will not raise per capita incomes. The population size will catch up with technological progress and put downward pressure on per capita incomes. This model explains the relationship between population and out-put for almost all of history, and it still applies to large parts of the world today. Doepke (2012).

In developed, Western countries, persistent sub-replacement fertility levels, ageing, and immigration are recognized as the three major population policy issues. Sub-replacement fertility and immigration, in particular, are areas in which effective policies are hard to come by. The debate, May (2012), is marred by controversy and passion and discussions on policy issues are polarized. Policy actors seem to be torn between a laissez-faire attitude and increasing immigration. Increasing immigration has two serious limitations. First, the level of immigration cannot grow arbitrarily high without generating political tensions. Second, it is becoming increasingly difficult to find the kind of migrants one wishes to attract since more and more countries are striving to attract highly skilled migrants. Japan, South Korea, and Taiwan populations are shrinking. Yet they still resist immigration. They choose automation as a response to dwindling manpower. In Western democracies, immigration has become an ideology to the extent that any rational discussion thereof is barely possible. While any forecasts regarding personal longevity are uncertain, in the last 150 years women have seen their average life expectancies increase at a rate of three months each year. All those who have forecast that growth in personal longevity will come to a standstill have been proved wrong. But there are currently two factors that could well put a stop to growth in average longevity: the rapid growth of so-called lifestyle illnesses and increasing medical care costs. The breakdown of the Soviet Union showed that once medical care fails to maintain its level of quality for the whole population, that population's life expectancy quickly falls significantly.

But ageing in developed countries occurs in parallel with better health, more extensive education, and related societal changes. We are not just living longer, we are slower to age. Boersch-Suppan et al. (2005, 2006, 2013) make this precise. They find that:

- The average expected healthy life expectancy of men at the age of 65 is larger than 5 years for men living in any European country.  
- Using more than 4.8 million data sets of a large insurance company, the authors measured the productivity of different aged workers for different type of work classes: Contract negotiation (the most challenging jobs), standard advice of customers and repetitive jobs. They found that older workers made more error in the repetitive jobs than the younger ones but were significantly more productive in the challenging jobs than their younger counter parts.  
- The intergenerational warfare is a myth. There is no support in the data used to analyse conflicts between children and parents of such a potential warfare.

Fact 3. The discussion whether we can work until the age of say 67 is for the average population not related to its healthiness. The retirement age could from a health point of view be raised to 70 years. The tendency of firing older works is destruction productivity since the experience of the older, motivated workers generates a higher productivity for demanding jobs as this is achieved by younger ones.

We spend longer in education; we travel more before permanently joining the workforce; we start families later. We don't think of ourselves as being as old as previous generations would have at the same age. The effect of all these changes taken together is not that society is ageing, but that it is getting younger. Finally, a society with a predominantly young population has a different productivity level than a more aged population. Syl and Galenson show that 40 percent of productivity increases are down to young people who enter new markets. These young people break with tradition and manifest new ways of thinking. Google and Facebook are two prominent examples. Older individuals possess more experience and wisdom. But Syl and Galenson state that this only gradually changes productivity.

To manage the emerging demographic regime, innovative policies and new ways of thinking about population are called for. Romaniuk (2012). This change in the structure of society will have many consequences. One of the most significant will be a labor shortage. If societies are going to maintain their standard of living, they are going to have to avoid any reduction in the workforce as a proportion of the total population. At the same time, many people are going to reach retirement age and realize that they do not have enough income to maintain what they feel is an acceptable standard of living. The combination of these two issues will put a lot of pressure on our current views on the relationship between working and retirement. Employment and retirement laws designed for a young and growing population no longer suit populations that are predominantly old but healthy and capable of being productive, all the more so in a work environment of automated technology. Prevailing family assistance policies are equally antiquated. Though the maternity instinct may still be present as it always was, women's conditions have radically changed. The women of today in developed countries, and throughout the modernizing world, are faced with many deterrents to maternity (e.g., widespread

celibacy, marital instability, financial insecurity) on the one hand, and with many fulfilling, financially well-rewarded opportunities on the other. So much that they are left with little incentive to trade the latter for the uncertainties of motherhood.

It is easier to bring population down than to make it up, writes John May (2012). And that is why - in order to escape the sub-replacement fertility trap and to bring the fertility rate to, and sustain it at, even a generational replacement level, Romaniuk (2012) - we need to bring to bear meaningful financial and social rewards for maternity. The current family allowance and other welfare-type assistance to families cannot do this. Societies under a demographic maturity regime may need to have in place permanent, 'life-sustaining' mechanisms to prevent fertility from sliding ever lower. Instead we need a more balanced resource allocation between production and reproduction.

# Impact on Retirement Systems

With such demographic development, it will not be possible to meet the promises of the three pillars of social welfare in many countries. This will lead to more saving behavior on an individual basis and solidarity between generations (the first pillar) will come under stress. In order for the retirement system not to collapse, the state will have to define reforms, see Albrecher et al. (2016). Will it save the first pillar - that is, it will secure the minimum necessary standard of living for all? How will the second and third pillars be changed or will they disappear? As a result, people will individually save more - because they have to and because confidence in the social welfare system will not increase.

The Melbourne Mercer Global Pension Index report (MMGPI [2015]) from the Australian Centre for Financial Studies and Mercer compared the status of the retirement systems of 25 countries. The index is based on the following construction; see Figure 2.8.

Although it is called a 'pension index', it allows one to consider the entire retirement systems of the different countries. Figure 2.9 summarizes the results for the 25 countries surveyed.

# 2.3.2.2 Pension Funds

The pension fund assets in the OECD member countries encompassed USD 23 trillion in 2014. The collision between demographics and the strong reliance on pay-as-you-go systems in developed countries requires resolution; if not, these problems can be expected to spread to the rest of the world. There are a number of ways of approaching this, including (Walter (2007)):

- Raising mandatory social charges on employees to cover increasing pension obligations. This is very problematic due to the 'inverse' demographic pyramid and becomes even more difficult to implement in countries where individuals already face a high tax burden.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3fd18f4b5f1c237805d8d058afbbc486655fedd64c9f884407fa9b056297e876.jpg)  
Figure 2.8: The Melbourne Mercer Global Pension Index (GMMPI [2015]).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4a5fcfbea9f4179851f830aaa1c0ee1cc718abb9de0ac5a3f841fc0d96eac7fd.jpg)  
Figure 2.9: Summary for the 25 countries in the Melbourne Mercer Global Pension Index as of 2015 (Adapted from GMMPI [2015]).

- Cutting retirement benefits. Limiting the growth of pension expenditures to the projected rate of economic growth starting in 2015 reduces the income-replacement rate from 45 percent to 30 percent over a period of 15 years. Walter (2007). This would push retired people with low personal saving resources into poverty.  
- Increasing the retirement age. For countries with a high unemployment rate this is not a feasible alternative.  
- Reforming the systems away from pay-as-you-go toward defined-contributions or defined-benefit pension plans. This is a possibility, and would create a huge demand for professional asset management.  
- Keeping the pay-as-you-go systems and reducing the contribution to the pension funds.

These changes impact asset management. The demographic problems in developed countries and the difficulties in finding structural solutions will force pension funds to increase their investment performance.

The asset allocation of pension fund assets differs significantly between countries. The exposure to growth assets (including equities and property) varies and ranges from less than 10 percent, in India, Korea, and Singapore, to about 70 percent in Australia, South Africa, the UK, the US, and Switzerland. GlobalPensionIndex (2015). The more growth assets are included in the asset allocation, the larger are the risks: there were significant declines in the value of assets in 2010 and 2011 reflecting the consequences of the global financial crisis of 2007 and 2008. However, since that time there has been a steady recovery in the level of pension assets in each country surveyed as equity markets have recovered. GlobalPensionIndex (2015).

# 2.3.2.3 Role of Asset Management

Asset management can support the pension system in three respects: First, asset management could become more efficient - this means to save costs. Second, asset management could expand the range of solutions - the investment strategies and finally, asset management could expand the investment opportunity set - the assets.

The expansion of investment strategies means to apply factor investing for example. All pros and cons of last sections also apply to the pension system case. The third possibility means to make some illiquid asset classes accessible for pension funds. Examples are private equity, insurance-linked investments and securitized loans. These are the typical examples given.

Example

Asset managers can become more important financial actors by driving the raising of capital and the capital deployment required to meet the demands of growing urbanization and cross-border trade. The world urban population is expected to increase by 75 percent between 2010 and 2050, from 3.6 billion to 6.3 billion. The urban profile in the east will see many more 'megacities' (cities with a population in excess of 10 million) emerging. Today's number of 23 megacities will be augmented by a further 14 by 2025, of which 12 will be in emerging markets.

This will create significant pressure on infrastructures. According to the OECD, USD 40 trillion needs to be spent on global infrastructure through 2030 to keep pace with the growth of the global economy. Some policy makers appear to have taken the problem on board: in Europe - after considerable debate - the European Long Term Investment Funds (ELTIF) initiative was finally created in 2013, helping European asset managers to invest in infrastructure. But infrastructure investments will disproportionately target emerging markets and emerging markets' asset managers have recognized this and already started to focus on it.

Whatever of the above measure is considered, it is evident that asset management alone is not able to solve some of the fundamental problems of pension funds which we discussed above. At its best, the asset management function can help to reduce some costs or to improve the likelihood of higher investment returns. But it cannot produce what it is not possible - this means, to solve the problem of the demographic change.

But the asset management function can play an important role in two other aspects. First, it can provide solutions for the baby-boomers with their asset decumulation needs. Second, asset management will be central for increased private savings of individuals due to the weakness of the first and second pillar. The growth of the future AuM will arise much more from this channel than from the traditional pension fund channel.

# 2.3.2.4 Investment Consultants

Investment consultants play an important role as intermediaries, in particular for institutional investors and pension funds. They offer the following services: asset/liability modelling, strategic asset allocation, benchmark selection, fund manager selection, and performance monitoring. Goyal and Wahal (2008) estimate that 82 percent of US public plan sponsors use investment consultants, as do 50 percent of corporate sponsors. Investment consultants have largely avoided the attention of academics with one notable exception - Jenkinson et al. (2014). A recent survey by Pension and Investments [2013] found that 94 percent of plan sponsors employed investment consultants. The five leading investment consultants worldwide - ranked by 'assets under advisement' - in 2011 were Hewitt Ennis Knupp (USD 4.4 trillion), Mercer (USD 4.0 trillion), Cambridge Associates (USD 2.5 trillion), Russell Investments (USD 2.4 trillion), and Towers Watson (USD 2.1 trillion).

Jenkinson et al. (2014) ask the following questions: What drives investment consultants' recommendations of institutional funds? What impact do these recommendations have on flows? Do recommendations add value for plan sponsors?

The authors use data from eVestment and limit their analysis to US long-only equity products, which can be considered to be among the efficient markets. In the approximate period 1999 to 2011, one-quarter of these products were recommended annually by investment consultants and the rest were not recommended. This much larger number of recommended products compared to the non-recommended ones remains stable in the different years studied.

The authors find, the first question, that consultants' recommendations are partly driven by past fund performance, but also by other soft factors such as service quality and investment quality factors, Jenkinson et al. (2014): to be recommended it is not sufficient to have a strong return history. The authors then analyze whether the size of the fees charged has an impact on the recommendation rate. If this were the case, conflicts of interest would be suspected. The analysis shows that this is not the case. Fees are very similar for recommended and non-recommended products independent of the size of the products and their styles (growth, value, smalland mid-cap). The fees are in line with the fees in Section 2.7.4.3 - that is to say, close to 70 bps for larger products.

Recommendations, and in particular changes in recommendations, have a strong impact on product flows (question 2): Moving from zero-recommendation to the case where all consultants recommend leads to an additional inflow of assets of USD 2.4 billion. On a percentage basis, on average the extra inflow equals 29 percent of the assets managed by that product in the previous year, compared to a not shortlisted product.

The answer to the third question created a lot of public attention. They construct equaland value-weighted portfolio returns of recommended and non-recommended products. Using the returns of these portfolios they estimate one- (the CAPM), three- (FF), and fourfactor (FFC) alphas and excess returns over portfolios of selected benchmarks.

For the equally weighted portfolios, the returns of the recommended products were significantly lower than those of the non-recommended ones by the order of 1 percent in magnitude, independent of the factor model chosen (see Figure 2.10). For value-weighted portfolios, different factor models lead to different returns for the two alternatives. Value-weighted returns and alphas are consistently lower, suggesting that smaller products perform relatively better. Jenkinson et al. (2014). Summarizing the evidence: investment consultants are not able consistently to add value by selecting superior investment products.

The underperformance of recommended products in the equally weighted case could be explained by the tendency of consultants to recommend large products that perform

worse. However, after adjusting for different sizes, the explanation turns out to be wrong.

<table><tr><td rowspan="2" colspan="2"></td><td colspan="5">12 Month Period Following Addition/Deletion</td></tr><tr><td>Avg. Returns</td><td>Avg. Excess Ret. over Benchmark</td><td>One Factor Alpha</td><td>Three Factor Alpha</td><td>Four Factor Alpha</td></tr><tr><td rowspan="3">Equally Weighted</td><td>Increase in Number of Recommendations</td><td>5.34% (0.95)</td><td>0.62% (1.02)</td><td>2.26% (2.31)**</td><td>0.99% (1.25)</td><td>0.94% (1.19)</td></tr><tr><td>Decrease in Number of Recommendations</td><td>6.58% (1.20)</td><td>1.19% (2.13)**</td><td>3.55% (2.34)**</td><td>1.48% (1.21)</td><td>1.54% (1.32)</td></tr><tr><td>Difference</td><td>-1.24% (-0.86)</td><td>-0.57% (-0.80)</td><td>-1.29% (-0.89)</td><td>-0.49% (-0.49)</td><td>-0.59% (-0.69)</td></tr><tr><td rowspan="3">Value Weighted</td><td>Increase in Number of Recommendations</td><td>2.12% (0.36)</td><td>-0.35% (-0.24)</td><td>-0.98% (-0.56)</td><td>-0.22% (-0.19)</td><td>-0.30% (-0.29)</td></tr><tr><td>Decrease in Number of Recommendations</td><td>4.62% (0.90)</td><td>0.54% (0.75)</td><td>1.63% (1.09)</td><td>0.74% (0.67)</td><td>0.81% (0.78)</td></tr><tr><td>Difference</td><td>-2.51% (-0.83)</td><td>-0.89% (-0.54)</td><td>-2.61% (-0.88)</td><td>-0.97% (-0.50)</td><td>-1.12% (-0.65)</td></tr></table>

Figure 2.10: The table shows the performance of portfolios of actively managed US equity products that experience a net increase (decrease) in the number of recommendations in the twelve or twenty-four month period following the recommendation change. Performance is measured using raw returns; returns in excess of a benchmark chosen to match the product style and market capitalization; and one-, three-, and four-factor alphas (corresponding to the CAPM, the Fama - French three-factor model, and the Fama - French - Carhart model). Excess returns and alphas are expressed in percent per year. All reported figures are gross of fees. The first part of the table shows the results for equally weighted portfolios of products whereas the second part of the table shows the same statistics for portfolios of products weighted using total net assets at the end of the previous year. t-statistics based on standard errors - robust to conditional heteroscedasticity and serial correlation of up to two lags as in Newey and West (1987) - are reported in parentheses. ***, **, * mean statistically significant at the 1, 5, and 10 percent levels, respectively. The benchmarks for the investment products are the corresponding Russell indices. Investment product large cap growth is benchmarked by the Russell 1000 Growth, the small cap value by the Russell 2000 Value, etc. (Jenkinson et al. [2014]).

These results raise several questions. First, why do pension funds use - on a rational basis - investment consultants that add no value? The argument, that consultants act as insurance against being sued is simply not justifiable. Second, it is difficult to understand why investment consultants are virtually unregulated in most jurisdictions.

# 2.4 Who Decides?

Investors can decide for themselves or delegate the decision to third parties. Each type of decision is subject to a comprehensive regulatory framework. After the introduction, we focus on the MiFID II rules.

An investment decision today has to meet much more regulatory standards than in the past. Regulation defines restrictions and rules for decision-making, but it never sets an AM firm goals.

Individual regulations can have strategic or operational implications for AM. High operational impacts have UCITS, PRIIPS, EMIR or MiFID II. Low Strategic Impact have PRIIPS and MAD II. MiFID II, the Volcker Rule or Dodd-Frank Act, UCITS have a high strategic importance. The ability of international banks and large AMs after the GFC to comply quickly and integrate the regulatory program into their strategic planning resulted in a competitive advantage over smaller institutions. The know-how of the international institutions enables them to participate actively in the technological change efficiently. They are almost invulnerable, despite the many and heavy fines imposed on them by the many scandals in recent years.

Example Impact of Regulation on the Swiss banking sector and asset management

Regulatory burden togetherness with broken business models impact the financial industry. It is estimated that of the approximately 300 Swiss banks in 2014, about one-third will stop operating as an independent brand. A KPMG study from 2013 (KPMG [2013]) summarizes:

<sup>1</sup>PRIIPs are the Packaged Retail Investment and Insurance-based investment Products documents and UCITS is The Undertakings for Collective Investment in Transferable Securities Directive for collective investments by the European Union. Obligations for central clearing and reporting (EMIR, Dodd Frank) and higher capital requirements for non-centrally cleared contracts (CRR), the obligation to trade on exchanges or electronic trading platforms is considered by revising MiFID, the so-called The Markets in Financial Instruments Regulation (MiFIR). US T+2 means the realization of a T+2 settlement cycle in the US financial markets for trades in cash products and unit investment trusts (UITs). FIDLEG is part of the new Swiss financial architecture which should be equivalent to MiFID II of the euro zone. In 2013, following the LIBOR and EURIBOR market-rigging scandals, the EU Commission published legislative proposal for a new regulation on benchmarks (Benchmark Regulation). The Asia Derivative Reform mainly focus on the regulation of OTC derivatives and should therefore be compared with EMIR and Dodd-Frank Act. The Market Abuse Directive (MAD) in 2005 and its update MADII resulted in an EU-wide market abuse regime and a framework for establishing a proper flow of information to the market. BCBS considers principles of risk data aggregation and reporting by the Basel Committee on Banking Supervision. Comprehensive Capital Analysis and Review (CCAR) is a regulatory framework introduced by the Federal Reserve in order to assess, regulate, and supervise large banks and financial institutions. EU FTT means the EU Financial Transaction Tax. IRS 871 (m) are regulations of the IRS about dividend equivalent payment withholding rules for equity derivatives. CRS are the Common Reporting Standards of the OECD for the automatic bank account information exchange.

- A total of 23 percent of Swiss banks faced losses in 2012. All of them with AuM of less than CHF 25 billion.  
- Non-profitable banks in 2012 were mostly not profitable in previous years too.  
- Dispersion between successful banks (large and small ones) and non-performing banks (small ones) is increasing.  
- The performance of small banks is much more volatile than that of larger ones.  
- Changes of business model in large banks seem to be successful.  
- A total of 53 percent of the banks reported negative net new money (NNM).

Small asset managers, many of them firms with less than 5 employee's, faced after the GFC's due to the regulatory and legal changes a cost and lack of knowledge problem. They failed to have legal and compliance know how and it was also not profitable to higher specialists in these fields. Similarly, they could not invest in new, scalable technologies for accounting, strategy construction, performance calculation and attribution. etc. Both factors led to platform-as-a-service (PaaS) innovations where the different services are outsourced and are bought by connecting via API technology.

Many of the regulatory initiatives launched in recent years are related to asset management and trading. We consider the eurozone. The Alternative Investment Fund Managers Directive (AIFMD) mainly acts in the hedge fund sector, whereas UCITS are key for the fund industry. EMIR regulates the OTC derivative markets, and PRIIPS initiative is responsible for the key information for retail investors in the eurozone. MiFID II provides harmonized regulation for investment services across the member states of the EU with one of the main objectives being to increase competition and consumer protection in investment services. In the US, the Dodd-Frank Act is the counterpart of many European initiatives.

Regulatory initiatives place greater demands on asset managers and their service providers. They force changes in the areas of customer protection, agreements with service providers, disclosure of regulatory and investor information, distribution channels, trade transparency, and compliance and risk management functions (PwC [2015]).

# 2.4.1 MiFID II

The MiFID II Directive implements the G20 Pittsburgh Summit Agreement in 2009 in the euro area and for all non-EU financial intermediaries offering investment products in the eurozone. It requires the adoption of 32 legal acts by the European Commission, 47 regulatory standards, 14 performance standards and 10 packages of measures.[2] MiFID

II has the following goals:

- The creation of a robust framework for all financial market players and financial instruments.  
- Improving the supervision of the various market segments and market practices, in particular OTC financial instruments.  
- Strengthening market integrity and competition through greater market transparency.  
- Harmonization and strengthening of regulation.  
- Improving investor protection.  
- Limiting the risks of market abuse in relation to derivatives on commodities, in particular for futures of essential goods.

Investor protection is based on four topics. First, inducements, i.e. the need to disclose independent versus non-independent status of advice and the prohibition for discretionary managers and independent advisers to be involved in inducements. Product governance means that the manufacturers' product approval process has to include the target market definition which has to be taken into account by the distributors and which has to be tracked by the asset managers. Suitability and appropriateness requires from all investment firms operating in EU countries to provide clients with adequate information for assessing the suitability and appropriateness of their products and services, and to comply with best execution obligations. Finally, client information requires that enhanced information is shared with clients, both regarding content and method such as in particular costs and charges for services or advice.

In the eurozone, suitability and appropriateness have to follow client segmentation and intermediation segmentation (see Figure 2.11). This segmentation applies to all EU and all non-EU banks offering investment products in the zone.

# Intermediation Channel Segmentation

- Execution only: Investors decide themselves and investment firms only execute orders.  
- Advisory: Investors and investment firm staff interact. While relationship managers or specialists advise the investor, the investment decision is finally made or approved by the investors themselves. Advisory was the traditional intermediation channel before the financial crisis of 2007.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/1af638af30fe873138f5daff6f9d1bc07e27531fa7feccf0a109bc662f619b45.jpg)  
Figure 2.11: Client segmentation and intermediation segmentation as per MiFID II.

- Mandate: The investor delegates the investment decision in a mandate. The mandate contract reflects the investor's preferences. The portfolio manager chooses investments within the contracted limits. Many banks and asset managers motivated their clients to switch from the advisory to the mandate channel after the GFC. The main reasons for this are lower business conduct risk and better opportunities for automatization. These reduce production costs and enhance economies of scale. Since the active portfolio managers are benchmarked against the CIO's TAA mandates they face the same problems as actively managed funds - most of them will turn out to be zero-alpha funds, see Section 4.6.6.3. This will motivate many customers to move back to the advisory or execution only channel.

Client Segmentation. Investment firms must define written policies and procedures according to the following categorization:

- Eligible counterparties such as banks, large corporates, and governments.  
- Professional clients. A professional client possesses experience, knowledge, and expertise with which to make his or her own investment decisions and properly assess the risks thus incurred.  
Retail clients (all other clients).

Wealth as the sole variable for the classification of customers is no longer applicable. Customers can both opt to opt up or down. So they can choose a less or stringent protection category. Suitability and appropriateness requirements are defined in each

cell of the  $3 \times 3$  segmentation matrix (Figure 2.11). Client suitability addresses the following six points:

1. Information on clients  
2. Information provided to clients  
3. Client knowledge and experience  
4. Financial circumstances of the client  
5. Investment objective  
6. Risk awareness and risk appetite

These six points reflect the parameters that define the optimization problem of a rational economic investor. To determine the preferences of an investor one needs to have general information about the investor (4.1) and specific risk attitudes (6), which both enter into the objective function (5). The optimization of the objective function leading to the optimal investment rule is carried out under various restrictions: the budget restriction (4) and restrictions of admissible securities due to their complexity or the experience of the investor (3). Tax issues, legal constraints, and compliance issues also enter into the restriction set and require information to be provided to the client (4.3). These six points are therefore sufficient for the investor to determine his or her optimal investment strategy.

Client product suitability consists of requirements that ensure that the product is suitable:

1. Specific service-/product-related restrictions  
2. Adverse tax impact  
3. Requirements for prospectuses  
4. Disclaimer

These requirements become less demanding the more experienced the client is. Suitability in advisory services requires qualified staff and an appropriate incentive structure in the asset management firm.

# 2.4.2 Investment Process for Retail Clients

How are the investor's preferences elicited, transformed into investment guidelines, and managed over time for retail clients? Figure 2.12 illustrates an investment process. Given the client's need, his or her preferences are compared with the CIO view and its transformation into CIO portfolios. This comparison defines the theoretical client portfolio. Using the securities from the producers the theoretical portfolio is transformed into the (real) client portfolio. Life-cycle management controls the evolution of the client portfolio

over its life cycle and compares the risk and return properties with the initially defined client profile. If necessary, this process sends warning or necessary activity messages to the client and/or advisor. A CIO view typically consists of several inputs such a quantitative model, research macro view and market view. Smaller institutions do not have the resources to provide all these inputs. They then buy the CIO view from another bank.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/900642bcac908b037f1ad1181a8e9f64454aed68338dcb51f9387c7369f95d85.jpg)  
Figure 2.12: An investment process. The three channels from left to right are the client - advisor channel, the investment office, and the producers of the assets or portfolios (trading and asset management).

Traditionally, intermediaries used questionnaires to reveal investors' preferences. This approach is fully replaceable by electronic end-to-end processes in wealth and asset management. Client risk profiling, preference and knowhow are one part in the process. The traditional questions are more and more replaced by decision problems which is closer to a game. This gamification in the customer journey is likely to produce more accurate investor preferences.

New trends in technology allow the process outlined in Figure 2.12 to be shaped. In extremis, there will be no need for an investor to disclose his or her investment preferences since the data already exist in the virtual world. If, furthermore, the investment views are formed in a fully automatized manner using publicly available data, then the function both of advisor's and of the CIO will become superfluous. Digital money managers are enticing with deep barriers to entry. Your performance is impressive. The greatest weakness is customer understanding.

# 2.4.3 Robos

Selma looks young and trendy. Her white-blond hair is formed into a casual bob hairstyle. The glasses are tinted, the lipstick is bright red. Selma keeps smiling and winking at you. She's with everyone right now by you. 'Hi! I'm Selma. Let's have a quick chat about your finances,' she writes. Selma is warm - but not a person of flesh and blood. She is the digital investment assistant for Selma Finance, a Robo Advisor. They have come to challenge traditional asset management and reinvent it with technical assistance. The idea is to take the complexity out of classic financial services in a playful way. Since the appearance of the iPhone 2008, little by little, all areas of everyday life are being digitized, driven by technological progress and the belief that computers not only perform tasks faster and cheaper, but also better with the help of artificial intelligence. This section is based on Gerbl (2019).

# 2.4.3.1 Markets

The digitization of wealth management initiated in the USA and Great Britain after the GFC: A retail customer practically no longer get investment advice in the UK - cost and compliance after the GFC forced banks to change their business model. A niche opened up that was quickly filled by financial service providers. Over 100 Robo Advisors are now active in the USA. Companies such as Vanguard, Charles Schwab, Betterment and Wealthfront dominate the market. ETF giant Vanguard's Robo alone is responsible for \$ 120 billion in investment money. In total, Robos is increasing more than 800 billion dollars. The Robos are forecast to manage around USD 2.2 trillion in 2023; one-third of Blackrocks 2018 AuM.

In Switzerland or Germany, investors are receiving better care. Every regional bank picks up the customer and covers him with products where technology supports the RM. Hence, a hybrid model applies so far. This evidently scales much less than the digital world in Anglo-Saxon or Scandinavian countries. But proponent of the hybrid model base their business approach on the assumption that wealth management is not bought, but sold. This does not usually happen with Robos, so there are no huge inflows in Switzerland or Germany so far. Currently, 200 million francs are being managed for end customers on its own platform in Switzerland (Gerbl (2019)). Is this cultural evidence strong enough to outweigh the advantages of the Robos

# 2.4.3.2 Advantages of Robos

Robos have brought a democratization of asset management in the sense that services are offered already for a few thousand dollars. But what is the quality of these services? Traditionally, Robos invests client funds in diversified exchange-traded ETFs that passively follow an index. Hence, meaningful Robos diversify client's wealth. The portfolio construction mostly follows traditional finance: Robust mean-variance optimization superimposed with some recommender system for more wealthy clients apply. Social

trading is also offered by some firms. In any case the information structure used to form the portfolios follows the EMH as an anchor (say mean-variance optimization using historical estimation of the input variables) and as an overlay individual views and preferences as well collective market participants views. They therefore do not engage in more expansive active management with its doubtful performance track record. So far there is not much intelligence in the Robos. But they follow the investment strategy of the customer and therefore rebalancing is a service which Robos offer.

Clients are offered visualizations to change the weights in the portfolio construction following their preferences. Anecdotal evidence states that second customer adapts such pattern strategies. Such patterns cannot be considered as passive investment any longer. In fact, more and more Robos are offering such active components for wealthier and more experienced investors. They can playfully simulate different strategies and compare them by backtesting. The programme decides whether the wishes are fulfilled or not. Costs are an important component whether or not it pays to use Robos. In comparison to traditional asset management mandates with costs usually well above one percent, Robos with flat fees of 0.68 percent are a cheaper alternative. In the USA, the average cost of Robos is less than 0.4 percent. How profitable are Robos? Agnesens (2019) state that 'Since the beginning of 2000, Robo strategies have yielded up to two percent better returns than mixed funds every year.' She compared strategy funds and different Robo-advisory model portfolios, see Figure 2.13.

The differences increase with increasing risk which is due to increasing costs for strategy funds facing increased risk. In Agnesens' comparison the Robos before costs are even slightly ahead of the strategy funds.

What are main critics against Robos? First it is claimed that many investors do not understand Robos, i.e. they are primarily concerned with the investment side and less with the client. Second, it is claimed that Robos don't know their customers well enough and don't explain to them what's going on in the markets and with their investments. There is no deeper understanding of the customer and his needs. A Robo Advisor is far from the personal advisor you ideally know for many years. If this holds true this can become a problem in turbulent markets. But one can also state that to know possibly customers better was not of any help in the financial crisis.

# 2.4.4 Mandate Solutions for Pension Funds

This section follows Lanter (2015). Figure 2.14 illustrates the investment decision process for a pension fund.

Asset Liability Management (ALM) is the first step, often involving external advice. This analysis provides a transparent picture of current assets and liabilities and how they may change in the future due to the various risk factors. Fulfillment of the Pension Fund's long-term objectives based on the analysis defines the strategic asset allocation, ie the allocation that should be stable through the possible future economic and financial market cycles. The tactical asset allocation is the next step. The pension funds must decide

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/fe497b69a72d040a5f80eb172267feecd8008a2eff53638019d0700d4698509a.jpg)  
Figure 2.13: Strategy funds versus Robo Advisory strategies after costs. The blue dots represent strategy funds. The red symbols Robo Advisors. The red circle are model portfolios with equity up to  $25\%$ , the diamonds are between  $25 - 50\%$  and the squares are for portfolios with more than fifty percent equity. (Agnesens [2019]).

whether to delegate the TAA to external portfolio managers in the form of a mandate or whether they will manage the assets within the fund. Furthermore, the benchmark and the definition of risk-based areas for tactical asset allocation have to be determined. It must also be decided whether the reporting, administration and risk controlling functions of the investment portfolios should also be outsourced. In case of outsourcing, request for proposal will be used. The entire investment decision outsourcing process is conducted with the involvement of external consultants. Goyal and Wahal (2008) estimate that 82 percent of US public pension funds use pension consultants.

We discuss in Section 2.3.2.4 that the extensive use of investment consultants raises is by no means free of conflicts for the performance of the delegated investments and for the selected asset managers. Critics for example often make them the accusation to be drivers of new investment strategies which turn out to be more complex (hence more difficult to handle, understand and also more expensive) than the actual used ones but where it is not clear whether they lead to a larger performance.

The other steps in the process, as illustrated and described in the last figure, are evident.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7f1f2fb89a86fc1d3d8a35e49ad52e1735176b4455702cd7e4943c9409794274.jpg)  
Figure 2.14: Process for a mandate in a pension fund (Lanter [2015]).

# 2.4.5 Conduct Risk

The largest risk for investment firms is conduct risk in the investment process. Conduct risk comprises a wide variety of activities and types of behavior that fall outside the other main risk categories. It refers to risks attached to the way in which all employees conduct themselves. A key source of this risk is the difficulty of managing information flows, their impact, their perception, and responsibilities in an unambiguous way. Consider an execution-only investor who does not understand a particular statement in a given research report. Can the relationship manager help the execution-only investor without entering into conflict with his or her 'execution-only' status - that is, help without advising? To hedge their conduct risk sources investment firms are forced to work out detailed and well-documented processes concerning the information flow between themselves and the customer. While this paper work may be effective as a hedge against conduct risk, its efficiency is questionable.

# Example

The Financial Stability Board (FSB) stated in 2013: One of the key lessons from the crisis was that reputational risk was severely underestimated; hence, there is more focus on business conduct and the suitability of products, e.g., the type of products sold and to whom they are sold. As the crisis showed, consumer products such as residential mortgage loans could become a source of financial instability. The FSB considers the

following issues key for a strong risk culture:

- Tone from the top: The board of directors and senior managers set the institution's core values and risk culture, and their behaviour must reflect the values being espoused.  
- Accountability: successful risk management requires employees at all levels to understand the core values of the institution's risk culture. They are held accountable for their actions in relation to the institution's risk-taking behaviour.  
- Effective challenge: a sound risk culture promotes an environment of effective challenge in which decision-making processes promote a range of views, allow for testing of current practices, and stimulate a positive, critical attitude among employees and an environment of open and constructive engagement.  
- Incentives: financial and non-financial incentives should support the core values and risk culture at all levels of the financial institution.

Conduct risk is a real source of risk for investment firms: fines worldwide amounted to more than USD 100 billion for the period 2009-2014. These fines and the new regulatory requirements raise serious profitability concerns for investment firms and banks (see Figure 8). But there is more than just financial costs at play for the intermediaries. A loss in trust in large asset managers and banks can prove disastrous. In particular if new entrants without any reputational damage can offer better services thanks to FinTech. Figure 2.15 shows the evolution of the fines imposed by the British regulatory authorities (Left Panel) and the global value of fines. One sees that it took about three years after the GFC to charge the fines to the banks, insurance companies and asset managers. The global figures now exceed USD 230 bn since the start of the GFC. The horizontal lines in the histogram show how large the individual fines were. It follows from example that there was a fine in 2014 of more than USD 15 bn to a single institution. In the US, enforcement statistics from the Securities and Exchange Commission (SEC) show an increase in enforcement actions in the category investment advisor/investment company of roughly  $50\%$  following the GFC. Compared to the pre-crisis figures of 76 and 97 cases per year, respectively, 2011-2014 returned respective figures of 130 and 147 cases.

Anti-tax-evasion and anti-money-laundering measures are driven by the OECD. After the Base Erosion and Profit Shifting (BEPS) report of 2013, asset managers operate in a world with country specific reporting of profits and tax paid. Therefore, offshore financial centers try to have access to double tax treaties (DTT) which motivates asset managers to use cross-border passports and reciprocities. But it also forces asset managers to decide in which location they want to be active and where they want to step back.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/188d720ac008df2f6ef32a7621bfc8acb6343227346988594e5f4163417978c2.jpg)  
Figure 2.15: Left Panel: Table of fines imposed in the UK (FSA and FCA web pages). Right Panel: Global value of fines (FT research, June 2015).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d22ae534bbbde46bbef0dae3408a29dff6f55b222448055c094d8f3c9a7fb198.jpg)

# Example - Hedge fund disclosure

Patton et al. (2013) show that disclosure requirements for hedge funds are not sufficient to protect investors. The SEC for example requires US-based hedge funds managing over USD 1.5 billion to provide quarterly reports on their performance, trading positions, and counterparties. The rule for smaller hedge funds are less detailed. Instead, one has to care seriously about the quality of the information disclosed.

We consider monthly self-reporting of investment performance where thousands of individual hedge funds provide data to one or more publicly available databases which are then widely used by researchers, investors, and the media.

Are these voluntary disclosures by hedge funds reliable guides to their past performance? The authors state:

… track changes to statements of performance in 'vintages' of these databases recorded at different points in time between 2007 and 2011. In each such 'vintage', hedge funds provide information on their performance from the time they began reporting to the database until the most recent period.

Vintage analysis refers to the process of monitoring groups and comparing performance across past groups. These comparisons allow deviation from past performance to be detected. The authors find

that in successive vintages of these databases, older performance records (as far back as 15 years) of hedge funds are routinely revised: nearly 40 percent of the 18,382 hedge funds in the sample have revised their previous returns by at least 0.01 percent at least once, and over 15 percent of funds have revised a previous monthly return by at least 1 percent. These are very substantial changes, given the average monthly return in the sample period is 0.64 percent.

Less than 8 percent of the revisions are attributable to data entry errors. About 25 percent of the changes were based on differences between estimated values at the reporting dates for illiquid investments and true prices at later dates. Such revisions can be reasonably expected. In total, 25 percent (50%) of the revisions relate to returns that are less than three months old (more than 12 months old). They find that negative revisions are more common, and larger when they do occur than positive ones. They conclude that on average initially provided returns signal a better performance compared to the final, revised performance. These signals can therefore mislead potential investors. Moreover, the dangerous revision patterns are significantly more likely revised for funds-of-funds and hedge funds in the emerging-markets style than for other hedge funds.

Can any predictive content be gained from knowing that a fund has revised its history of returns? Comparing the out-of-sample performance of revising and non-revising funds, Patton et al. (2013) find that non-revising funds significantly outperform revising funds by around 25 basis points a month.

# 2.5 Risk, Return, Diversification and Reward-Risk Ratios

The first step toward investment theory is to gain insights into the interplay between risk, return, and diversification without relying on a particular investment model. We:

- show on an ad hoc basis when a portfolio is more than the sum of the parts - that is, more return and less risk;  
- analyze the long-term performance of investments before and after costs;  
- consider risk scaling;  
- discuss two proposition from statistics concerning diversification;  
- introduce to diversity and concentration risk;  
show how fees impact long-term returns;

- introduce to the debate between active and passive management.

# 2.5.1 Long-term Risk and Return Distribution

Table 2.3 shows the risk and return distribution and the wealth growth for the period 1925-2013 for different asset classes (Kunz [2014]).  

<table><tr><td></td><td>Investment of CHF</td><td>Return</td><td>Risk</td></tr><tr><td></td><td>100 after 88 years gives</td><td>Average annual return</td><td>Standard deviation</td></tr><tr><td>Stocks USA</td><td>71,239</td><td>7.75%</td><td>23.50%</td></tr><tr><td>Stocks CHF</td><td>70,085</td><td>7.73%</td><td>19.30%</td></tr><tr><td>Stocks DEU</td><td>44,669</td><td>7.18%</td><td>41.30%</td></tr><tr><td>Stocks GBR</td><td>34,619</td><td>6.87%</td><td>25.30%</td></tr><tr><td>Stocks FRA</td><td>18,939</td><td>6.14%</td><td>29.20%</td></tr><tr><td>Stocks JPN</td><td>5,367</td><td>4.63%</td><td>29.80%</td></tr><tr><td>Stocks ITA</td><td>2,552</td><td>3.75%</td><td>28.30%</td></tr><tr><td>Bonds CHF</td><td>3,611</td><td>4.16%</td><td>3.70%</td></tr><tr><td>Bonds GBR</td><td>1,880</td><td>3.39%</td><td>12.70%</td></tr><tr><td>Bonds USA</td><td>1,196</td><td>2.86%</td><td>12.50%</td></tr><tr><td>Bonds FRA</td><td>212</td><td>0.86%</td><td>15.00%</td></tr><tr><td>Bonds ITA</td><td>195</td><td>0.76%</td><td>20.40%</td></tr><tr><td>Bonds JPN</td><td>57</td><td>-0.64%</td><td>21.20%</td></tr><tr><td>Deposit CHF</td><td>1,070</td><td>2.73%</td><td>1.20%</td></tr><tr><td>Gold</td><td>1,052</td><td>2.71%</td><td>15.80%</td></tr></table>

Table 2.3: Average annual returns and standard deviations of the asset classes and growth of capital after 88 years. The calculation logic being  $71,239 = 100(1 + 0.075)^{88}$ .

The Figure 2.16 shows the distribution of return and risk, measured by the standard deviation, over 88 years of investments.

In the long run equity had in most economies higher returns and risks than its bond counterparts. We discuss below why nevertheless an advice to invest in stocks only if the investor has a long-term horizon is not an optimal strategy. Furthermore, a small difference in the average return creates a large difference in wealth accumulation; the compounding effect. Finally, gold has in this long period a large risk component but only a small average return. This first analysis allows us to consider diversification next.

# 2.5.2 Diversification of Assets - Portfolios

Can we combine different investment classes to form a portfolio with higher return and lower risk than the individual asset classes above? This is the diversification question. If there is a positive answer, is there an optimal way of diversifying the investment? We apply diversification to the data in Table 2.3 using an ad hoc portfolio construction

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/548ae830aa5475af802152c27eedf067a9d590bba0992742bd67aac9c36db5fa.jpg)  
Figure 2.16: The distribution of return and risk, measured by the standard deviation, over 88 years of investments. The square marks represent equity, the diamonds bonds, the triangle is cash, and the circle is gold (data from Kunz [2014]).

approach: the weights are not optimally chosen using a statistical model but are fixed based on heuristics (experience). We form four portfolio strategies - called conservative, balanced, dynamic, and growth, see in Table 2.4.

<table><tr><td></td><td colspan="4">Strategy</td></tr><tr><td></td><td>Conservative</td><td>Balanced</td><td>Dynamic</td><td>Growth</td></tr><tr><td>Equity</td><td>25%</td><td>50%</td><td>75%</td><td>100%</td></tr><tr><td>CH</td><td>10%</td><td>20%</td><td>30%</td><td>40%</td></tr><tr><td>Rest of world total (six countries)*</td><td>15%</td><td>30%</td><td>45%</td><td>60%</td></tr><tr><td>Rest of the world per country</td><td>2.5%</td><td>5%</td><td>7.50%</td><td>10%</td></tr><tr><td>Bonds</td><td>75%</td><td>50%</td><td>25%</td><td>0%</td></tr><tr><td>CH</td><td>66%</td><td>44%</td><td>22%</td><td>0%</td></tr><tr><td>Rest of world total (six countries)*</td><td>9%</td><td>6%</td><td>3%</td><td>0%</td></tr><tr><td>Rest of the world per country</td><td>1.50%</td><td>1%</td><td>0.50%</td><td>0%</td></tr></table>

Table 2.4: Investment weights in four investment strategies (data from Kunz [2014]). *Investment in G, F, I, J, USA, UK.

Using data from Figure 2.16 for the different asset classes, we get the returns in Table 2.5.

Figure 2.17 shows that a combination of risk and return figures of basic asset classes

<table><tr><td></td><td>Investment</td><td>Return</td><td>Risk</td></tr><tr><td></td><td>100 CHF after 88 years gives</td><td>Average annual return</td><td>Standard deviation</td></tr><tr><td>Conservative</td><td>143,131</td><td>8.61%</td><td>19.80%</td></tr><tr><td>Balanced</td><td>76,949</td><td>7.84%</td><td>15%</td></tr><tr><td>Dynamic</td><td>33,318</td><td>6.82%</td><td>10.40%</td></tr><tr><td>Growth</td><td>11,702</td><td>5.56%</td><td>6.30%</td></tr></table>

Table 2.5: Average annual return, risk, and wealth growth for the four investment strategies.

can lead to a portfolio from which more return can be expected for the same risk or less risk for the same return. The green marks for the investment strategies form a virtual boundary line. In fact, the Markowitz model is an example that there is a efficient frontier such that there can be no portfolio construction with more return and lower risk than any portfolio on the efficient frontier within this model approach.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9a176fd71646960ea759210659383820f6872f3f35c0bd945d6b9e09c87dd588.jpg)  
Figure 2.17: Distribution of return and risk, measured by the standard deviation, over 88 years of investments. The square marks represent equity, the diamonds bonds, the triangle is cash, and the circle is gold. The dots represent the four investment strategies - conservative, balanced, dynamic, and growth (data from Kunz [2014]).

Two questions regarding diversification arise:

- What are the risks of not diversifying? Concentration risk.  
- When does diversification make little sense?

Consider the first question. Often employees own many stocks of their employer directly or indirectly in their pension scheme. Such stock concentration can be disastrous. Enron employees for example had over  $60\%$  of their retirement assets in company stock. They faced heavy losses when Enron went bankrupt. Diversification reduces such idiosyncratic risk.

Institutional investors also fail to diversify sufficiently. The University of Rochester's endowment in 1971 was USD 580 million, placing it fourth in the respective ranking of private universities. In 1992, it ranked twentieth and by 2011 had dropped to thirtieth place. A main reasons was the concentration held in Eastman Kodak, which filed for bankruptcy in February 2012. Boston University invested USD 107 million in a privately held local biotech company in the 1980s. The firm went public and suffered a setback. In 1997, the university's stake was worth only USD 4 million. The Norwegian sovereign wealth fund, in contrast, was created precisely to reap the gains from diversification. The fund swapped the highly concentrated oil revenues into a diversified financial portfolio. While anticipated events are incorporated into market prices, most of the return ultimately realized will be the result of unanticipated events. Investors do not know their timing, direction, or magnitude. Investment diversification is a mean to reduce these risks.

Considering the second question, Warren Buffet states: Diversification is protection against ignorance. It makes little sense if you know what you are doing.

Diversification also reduces complexity of portfolio risk management. If a portfolio is well diversified, the hope is that idiosyncratic risks compensate for each other leaving for management only market risk instead of many idiosyncratic risk factors. Figure 2.18 shows that dependence between asset classes strongly vary and also change sign. Diversification benefits vary over time and are difficult to predict.

To highlight these statements, consider the fraction of wealth  $\phi$  invested in asset 1 and the remainder in asset 2. Portfolio variance reads

$$
\sigma_ {p} ^ {2} = \sigma_ {1} ^ {2} \phi^ {2} + \sigma_ {2} ^ {2} (1 - \phi) ^ {2} + 2 \rho \sigma_ {2} \sigma_ {1} \phi (1 - \phi) \tag {2.1}
$$

with  $\rho$  the correlation between the two assets. Portfolio risk becomes additive only if the assets are not correlated. A negative correlation value reduces portfolio risk which motivates the search for negatively correlated risks. If correlation is  $-1$ , portfolio risk becomes a complete square and can be eliminated completely in two risky asset cases by solving  $\sigma_p^2 = 0$  w.r.t. the strategy. If correlation is  $+1$ , which is typical for many asset classes when markets are under stress, portfolio risk is maximal.

Example Needed Investment Amount for Diversification

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f7837b017ae033bad7b8a4c2809a22c7c05e9f1f4e765acf108cdae31b5b7ff6.jpg)  
Figure 2.18: Pair-wise correlations over time for different asset classes (Goldman Sachs [2011]).

Elton and Gruber (1977) show that the individual risk of stocks could be reduced from 49 percent to 20 percent by considering 20 stocks per market. Adding another 980 stocks only reduces risk further to 19.2 percent. The effect of adding more and more assets has a diminishing impact on risk diversification.

How much wealth is needed to achieve a diversification in 20 securities? Given the average price of stocks and bonds in Swiss francs the amount invested in one security should be around CHF 10,000. Lower investments are not efficient. Therefore, one needs CHF 200,000 for a pure equity portfolio of Swiss stocks. Diversifying this portfolio to US, European, and Asia-Pacific stocks requires an investment of CHF 0.8 million. If the portfolio should be an equal dollar mixture of bonds and equities the amount needed for diversified single security investments is CHF 1.6 million. Therefore, only wealthy individuals can invest directly in cash products to generate a sufficiently diversified portfolio. This is a rationale for the existence of ETFs, mutual funds, or certificates, which offer a similar diversification level to less wealthy clients as well.

# 2.5.3 Two Mathematical Facts About Diversification

The following propositions make precise how idiosyncratic and market risk behave if one increases the number of assets.

Proposition 4. Assume  $N$  uncorrelated asset returns and equally weighted (EW) investment, that is  $\phi_{k} = 1 / N$  for all assets. Increasing the number of assets  $N$  reduces portfolio risk  $\sigma_p^2$  arbitrarily and monotonically.

The EW-assumption is not necessary but facilitates the proof. To eliminate portfolio risk completely in an portfolio with uncorrelated returns, one only has to increase the number of assets in the portfolio. The proof reads:

$$
\sigma_ {p} ^ {2} = \mathrm {v a r} \left(\sum_ {j = 1} ^ {N} \frac {1}{N} R _ {j}\right) = \frac {1}{N ^ {2}} \mathrm {v a r} \left(\sum_ {j = 1} ^ {N} R _ {j}\right) \leq \frac {N c}{N ^ {2}}
$$

with  $c$  the largest variance. If assets are correlated to each other, which removes an unrealistic assumption in the last theorem, then:

Proposition 5. Consider an EW portfolio strategy  $1 / N$ . The portfolio variance is equal to the sum of market risk and idiosyncratic risk. Increasing  $N$ , the latter one vanishes while market risk can only be reduced to the level of average portfolio covariance  $\overline{\mathrm{cov}}$ .

The proof is only slightly more complicated than the former proof, and leads to:

$$
\sigma_ {p} ^ {2} = \frac {\overline {{\mathrm {v a r}}}}{N} + (1 - \frac {1}{N}) \overline {{\mathrm {c o v}}} .
$$

Hence, covariances prove more important than single asset variances in determining the portfolio variance. Taking the derivative of the portfolio variance w.r.t. the number of assets  $N$ , the sensitivity becomes proportional to  $-\frac{1}{N^2}$ . Adding to  $N = 4$  a further asset reduces portfolio risk by  $\frac{1}{25}$ , adding another asset to 9 assets the reduction is only  $\frac{1}{100}$ . Therefore, reducing portfolio risk by adding new assets becomes less and less effective the larger the portfolio is.

We show with that the two-asset intuition does not carry over to three or more assets. Consider an investor which wants to increase the return on investment by selling volatility and correlation of two stocks  $S_{1}$  and  $S_{2}$ . He sells the risk that any of the two stocks breaches a barrier level in specified time period. The price for this sold volatility and correlation risk is transformed into a fixed coupon which the investor receives. The sold option is a down-and-in put option since the barrier level is typically lower than the strike of the option and the option has a value different from zero only if the barrier is breached ('in'). Barrier reverse convertibles are a wrapper for such a payoff. An investor gets at maturity his invested amount plus the coupon if there was no breach or the the coupon plus the lowest stock value at maturity in case of a breach. The higher the probability of a breach, the higher the coupon to the investor.

Suppose that both stocks can move up and down with the same probability. If  $+1$ , the change of a barrier breach is  $50\%$  - either both move up or down and breach. If  $-1$ , the probability is 1 since one stock has to go down and breach the barrier. If they are

uncorrelated, the probability is  $75\%$  since there is only one state with both up where there is no breach in the four possible states. Hence, for two assets the more negatively correlated the assets are the higher the risk of breaching the barrier and therefore the higher the coupon.

Consider the same investment with 3 stocks. The intuition of the two asset case does not generalize. Given 3 assets there are 3 pairwise correlations. That all three correlations equal to  $-1$ , which would lead to the highest coupon, is not possible. If two correlations are  $-1$ , then the third one has to be  $+1$ . This shows that the 2-asset case logic does not extend to the three asset case.

# 2.5.4 Risk Model

A general risk model arises from the mapping of asset returns into a portfolio context.

Model Asset Return  $\rightarrow$  Portfolio Risk Analytics

A portfolio context is used since building a risk model on say 10'000 individual assets would mean to consider 10'000 models. Therefore, a risk model is built for all assets. Traditionally, risk is defined as the variance of returns. Most risk models in asset management are based on linear multi-factor return models. These models are simple, clear and tractable. The hope is to capture the dependency structure between the many assets by considering a much smaller number of factors. Factors should be independent of one another. If we have  $N$  assets, the dimension of the covariance matrix  $N(N - 1) / 2$  is reduced to  $K + N(K + 2)$ , if there are  $K$  factors. Formally, for asset  $i$  out of  $N$  assets, a generic linear models reads

$$
R _ {i, t} = \alpha_ {i} + \beta_ {i} ^ {\prime} F _ {t} + \epsilon_ {i, t} \tag {2.2}
$$

where there are  $K$  factors  $F$ ,  $R, F, \epsilon$  are IID Gaussian

$$
R _ {t} \sim \mathcal {N} (\alpha , C), F _ {t} \sim \mathcal {N} (0, \mathbf {I}), \epsilon_ {t} \sim \mathcal {N} (0, D ^ {2})
$$

with  $D^2$  the diagonal idiosyncratic covariance matrix with the variances of the idiosyncratic risks  $\epsilon$  as entries and  $\mathbf{I}$  the identity matrix. The  $(N\times K)$  matrix  $\beta$  is the loadings matrix. The dynamics (2.2) implies

$$
\sigma_ {i} ^ {2} = \beta_ {i} ^ {\prime} C _ {F} \beta_ {i} + D _ {i} ^ {2} C = \beta C _ {F} \beta^ {\prime} \tag {2.3}
$$

with  $C_F$  the factor covariance matrix.

Consider the following correlation matrix:

$$
\rho = \left( \begin{array}{c c c c} 1 & & & \\ 0. 0 9 & 1 & & \\ 0. 0 2 & 0. 1 2 & 1 & \\ 0. 0 1 & 0. 1 8 & 0. 9 4 & 1 \end{array} \right)
$$

The matrix indicates that the first and second assets as well the third and fourth assets are driven by the same risk factor. The other correlations are also of the same order of magnitude. Instead of considering  $(4 \times 3) / 2 = 6$  correlations, one would start with a two-factor model.

The linear factor model for the assets transform in the same functional form for portfolios. Let  $\phi_j$  be the portfolio weights (long or short) which add up to 1. Then the portfolio return  $R_p$  can be written:

$$
R _ {p, t} = \alpha_ {p} + \beta_ {p} ^ {\prime} F _ {t} + \epsilon_ {p, t} \tag {2.4}
$$

where all parameters are portfolio weighted, for example  $\alpha_{p} = \phi^{\prime}\alpha$  and portfolio risk reads

$$
\sigma_ {p} ^ {2} = \beta_ {p} ^ {\prime} C _ {F} \beta_ {p} + \sum_ {i} \phi^ {2} D _ {i} ^ {2}. \tag {2.5}
$$

Therefore, a risk model specification means to fix the factor covariance matrix  $C_F$ , the factor exposures  $\beta$  and the residual risks  $D^2$ .

The risk model hierarchy decision are as follow:

- First, factors or betas are not specified. Then a statistical factor model is used such as Asset Pricing Theory (APT) model. A model provider is Sungard. Principal Component Analysis (PCA) is used for the estimation. Statistical factor models are the best in-sample performing ones by construction. The resulting factors are difficult to interpret and they can vary strongly. The models are not meaningful in wealth management when portfolio risk has to be explained but they are used in trading thanks to the their precision for short time horizons to circumvent the instability problem.  
- Second, factors are defined and betas are estimated by a time-series regression. This set-up is used by UBS, Blackrock, swissQuant, Quantec, R-Squared.  
- Third, betas are defined and factors are estimated using a cross-sectional regression. Providers of this model are Barra, Axioma, Bloomberg.

The second and third model both lose information, i.e. estimation error enters the risk model either in the stock betas, factor returns and covariances. In the second method, the estimation error in the betas are diversified away on the portfolio level if  $N$  is large. This is not true for the third model: Estimation risk on the portfolio and individual asset level are the same. Both methods assume that the variables in the estimation are observable.

The time-series model (type 2) can only be used when the stock betas are stable over time. But style investing (factor investing) assumes that betas are not stable. In risk models where style factors enter, a hybrid approach is necessary - one part for the stable model (second model) and one part for the style part (third model).

# 2.5.5 When Diversification Fails

We saw that correlation is highly non-constant and it is known and documented that correlations increase for many asset classes in a crisis. But a correlation close to one means that assets move in the same direction, which we summarize that diversification disappears. This observation holds for individual stocks, country equity markets, global equity industries, hedge funds, currencies, and international bond markets. Basically, correlation seems to align in the left tail of the risk distribution over all assets. Hence, using full-sample correlations do not account for this tail behaviour and are misleading. Prudent investors therefore use additional risk figures such as downside risk measures and scenario analyses. Chua et al. (2009) documented significant undesirable correlation asymmetries for a broad range of asset classes: Correlations increase on the downside and significantly decreased on the upside. This is exactly the opposite of what investors want: Not all assets moving downwards in a crisis but all moving upwards in a boom. If diversification fails in a crisis, diversified portfolios may have greater exposure to loss than more concentrated portfolios. Leibowitz and Bova (2009) showed that during the GFIC a diversified portfolio underperformed a simple  $60\%$  US stocks/40% US bonds portfolio by 9 percentage points.

There are different ways of how to measure correlation in the tails. Longin and Solnik (2001) and Chua et al. (2009) used double conditioning, i.e. they isolate months during which both assets moved (up or down) by at least a given percentage. Page and Panariello (2018) condition only on a single asset:

$$
\rho (\theta) = \left\{ \begin{array}{l} \rho (x, y | x > \theta), \theta > 0 \\ \rho (x, y | x <   \theta), \theta <   0 \end{array} \right.
$$

where  $x, y$  represent the two assets,  $\theta$  is the return threshold which partitions the data. This anti-symmetric single asset conditioning measures differences in tail correlations based on which market drove the selloff.

Subsample correlations are expected to differ from full-sample estimates, a conditioning bias follow. Assuming normality, simulating the assets using a bivariate normal distribution where the simulation is used the full-sample empirical correlations, means, and volatilities any differences to the empirical tails indicate departures from normality. Furthermore, under normality downside and upside correlation profiles are symmetric and any departure indicates a departure from normality. Deep in the tails there are only few data and robustness is an issue. The authors augment the data in the tail using an exponentially weighted approach on the full data sample, i.e. estimating an exponential weighted function on the percentile of the returns.

Figure 2.19 shows for international portfolios that empirical correlation profiles differ substantially from their normally distributed counterparts. When US stocks rallied their correlation with non-US stocks dropped all the way to  $-17\%$ . During the worst  $1\%$  selloffs in US stocks their correlation with non-US stocks rose to  $+87\%$ . This is an asymmetry

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2d79ca43480f2869c0cca374841508218fff8697223dbb45b00094b1e151e26c.jpg)  
Figure 2.19: US equity correlation with international equity using monthly data Jan 1970 to Jun 2017. Shown are conditional correlations by percentile based on US stock returns between US stocks (MSCI US Total Return Index) and non-US stocks (MSCI EAFE Total Return Index). The dotted line shows the correlation profile that we would expect if both markets were normally distributed. Empirical conditional correlations are adjusted by the data-augmentation methodology. Page and Panariello (2018).

and the opposite an investor expects: Diversification sorks only in boom markets but not when they are under stress. This result holds not only for the US but studies were performed for many other pairs of countries, for pairs of asset classes, for hedge fund strategies and for risk factors all with similar results of asymmetry.

These facts have several implications. First, if a portfolio manager has a proven track record to forecast market and asset movements within a certain confidence then he should pick stocks in the upside and buy a protective put in the expected downside. These assumptions are in most cases not valid. Either market movements come as a surprise or stock picking capabilities are not existing. Then one approach is first to consider risk management serious, i.e. to analyze the tail behaviour if markets boom or are under stress, and to second to trade with discipline within the given risk governance framework.

# 2.5.6 Concentration and Diversity

The attentive reader remarked that we have not defined the notion of 'diversification'. There is not a single, widely accepted definition. We consider some concepts of con

centration risk and diversity: The diversification index of Tasche (2008), the concentration indices of Herfindahl (1950) and Gini (1921), and the Shannon entropy, which measures diversity; see Roncalli (2014) for a detailed discussion. We consider long-only non-leveraged portfolios.

# Tasche's diversification index

The diversification index of Tasche (2008) is the ratio between the risk measurement of a portfolio and the weighted risk measurement of the assets. If one specifies the risk measure to be the volatility, the Tasche diversification index  $TA$  reads

$$
\operatorname {T A} (\phi) = \frac {\sqrt {\langle \phi , C \phi \rangle}}{\langle \phi , D \rangle}, \tag {2.6}
$$

where  $D$  is the vector of volatilities. The numerator is equal to the portfolio risk term in the Markowitz model (4.1). The most-diversified-portfolio MDP portfolio minimizes the diversification index of Tasche, see Choueifaty and Coignard (2008). The diversification ratio is defined by

$$
\mathrm {D R} (\phi) = \frac {1}{T A (\phi)} , \tag {2.7}
$$

i.e. the ratio of the weighted average of volatilities divided by the portfolio volatility. This ratio is smaller than one and only equal to one if all wealth is invested in a single asset. Given a set of constraints  $\mathcal{M}$ , the MDP is the portfolio which maximizes the diversification ratio under the set of constraints. If the expected returns of the assets are proportional to the their volatilities, expected returns replace in DR the nominator  $\langle \phi, D \rangle$ . Then, maximizing DR is the same as maximizing the Sharpe ratio of the portfolio and MDP is the tangency portfolio.

Definition 6. [Sharpe Ratio] The Sharpe ratio SR is defined by

$$
\mathbf {S R} (R) = \frac {E (R) ^ {+}}{\sigma (R)} \geq 0 \tag {2.8}
$$

with  $R$  a general return (absolute, relative, net, gross) and  $A^{+} = \max(A, 0)$ .

Often the Sharpe ratio is not constrained to be positive. But this ratio is not very meaningful for negative values since the higher risk for a fixed negative return the higher the Sharpe ratio. Assuming log normal returns. Square-root scaling rule implies that the Sharpe ratio scales with  $\sqrt{T}$  for an increasing time horizon while the market price of risk (MPR) is time-scale invariant. While conceptually simple, there are many different interpretations and calculation methods for the Sharpe ratio: Should one use linear or log returns, how do we scale the Sharpe ratio properly from one time horizon to another one, what are the industry standards in the calculation of the ratio? The widely observed square-root scaling rule only holds in the IID case, see the Section Risk Scaling. For non-IID returns the situation is more complex and Lo (2003) is the reference to follow.

# Herfindahl's concentration index

Maximum concentration occurs if one weight has the value one and all other weights are zero. Risk concentration is minimal if the portfolio weights are equally weighted. The Herfindahl index which is similar to the Gini Index, is defined by

$$
\text {H e r f i n d a h l I n d e x} = \sum_ {k = 1} ^ {N} \phi_ {k} ^ {2}. \tag {2.9}
$$

It takes the value  $+1$  in the case of maximum concentration and  $1 / N = \frac{N}{N^2}$  in the EW portfolio case.

# Shannon entropy diversity measurement

The Shannon entropy  $S$  for a relative weight long-only portfolio vector  $\phi$  is defined by

$$
S (\phi) = - \sum_ {k = 1} ^ {N} \phi_ {k} \ln \phi_ {k}. \tag {2.10}
$$

To understand the entropy measurement, consider two dies - one symmetric and the other distorted. The outcome for the symmetric one is more uncertain than for the other die. Shannon axiomized this notion of uncertainty in the 1940s in the context of information theory. He proved that there exists only the function  $S(\phi)$  above, which satisfies his eight axioms describing uncertainty.

In finance, entropy measures how close different probability laws are to each other. The prior and the posterior distribution in the Black-Litterman model are an example. The space of probability laws is just a set and not a vector space. It is not trivial to find a reasonable measuring stick to measure nearness of say two normal distributions, one with mean 0.1 and variance 0.2 and the other one with mean 0.2 and variance 0.1. The relative entropy  $S(p,q)$ , the Kullback-Leibler divergence, for two discrete distributions  $p$  and  $q$ , defined by

$$
S (p, q) = - \sum_ {k} p _ {k} \ln \left(\frac {p _ {k}}{q _ {k}}\right), \tag {2.11}
$$

measures the similarity of two probability distributions.

Roncalli (2014) illustrates the different notions of diversification. There are 6 assets with volatilities  $25\%$ ,  $22\%$ ,  $14\%$ ,  $30\%$ ,  $40\%$ , and  $30\%$ , respectively, and the same returns. Asset 3 has the lowest volatility. The correlation matrix reads

$$
\rho = \left( \begin{array}{c c c c c c} 1 0 0 \% & & & & \\ 6 0 \% & 1 0 0 \% & & & \\ 6 0 \% & 6 0 \% & 1 0 0 \% & & \\ 6 0 \% & 6 0 \% & 6 0 \% & 1 0 0 \% & \\ 6 0 \% & 6 0 \% & 6 0 \% & 6 0 \% & \mathbf {2 0} \% \quad 1 0 0 \% \end{array} \right) .
$$

How will this local deviations - the lower volatility for asset 3 and the lower correlation between asset 5 and 6 - be perceived (it at all) and valued using different portfolio diversity

measures? The following portfolio are compared: the global minimum variance (GMV), the equal risk contribution (ERC), the most diversified (MDP), and the equal weights (EW) portfolios. The GMV portfolio is the Markowitz optimal solution in (4.1) with minimal risk. ERC is the portfolio in which the risk contribution of all six assets is set equal to 1/6 percent, see discussion following the example. Roncalli (2014) provides us with the results in Table 4.5 where  $\phi_j, RC_j$ , the risk contribution, are expressed in percentage values.

<table><tr><td rowspan="2">Asset</td><td colspan="2">GMV</td><td colspan="2">ERC</td><td colspan="2">MDP</td><td colspan="2">EW</td></tr><tr><td>φj</td><td>RCj</td><td>φj</td><td>RCj</td><td>φj</td><td>RCj</td><td>φj</td><td>RCj</td></tr><tr><td>1</td><td>0</td><td>0</td><td>15.7</td><td>16.67</td><td>0</td><td>0</td><td>16.67</td><td>16.18</td></tr><tr><td>2</td><td>3.61</td><td>3.61</td><td>17.84</td><td>16.67</td><td>0</td><td>0</td><td>16.67</td><td>14.08</td></tr><tr><td>3</td><td>96.39</td><td>96.39</td><td>38.03</td><td>16.67</td><td>0</td><td>0</td><td>16.67</td><td>8.68</td></tr><tr><td>4</td><td>0</td><td>0</td><td>13.08</td><td>16.67</td><td>0</td><td>0</td><td>16.67</td><td>19.78</td></tr><tr><td>5</td><td>0</td><td>0</td><td>10.86</td><td>16.67</td><td>42.86</td><td>50</td><td>16.67</td><td>24.43</td></tr><tr><td>6</td><td>0</td><td>0</td><td>14.49</td><td>16.67</td><td>57.14</td><td>50</td><td>16.67</td><td>16.86</td></tr><tr><td>Portfolio σ</td><td colspan="2">13.99</td><td colspan="2">19.53</td><td colspan="2">26.56</td><td colspan="2">21.39</td></tr><tr><td>Tasche index</td><td colspan="2">0.98</td><td colspan="2">0.8</td><td colspan="2">0.77</td><td colspan="2">0.8</td></tr><tr><td>Gini index</td><td>0.82</td><td>0.82</td><td>0.17</td><td>0</td><td>0.69</td><td>0.67</td><td>0</td><td>0.16</td></tr><tr><td>Herfindahl index</td><td>0.92</td><td>0.92</td><td>0.02</td><td>0</td><td>0.41</td><td>0.4</td><td>0</td><td>0.02</td></tr></table>

Table 2.6: Comparison of the global minimum variance (GMV), equal risk contribution (ERC), most diversified (MDP), and equal weights (EW) portfolios. All values are percentages (Roncalli [2014]).

Since correlation is uniform, but for one asset, it is 'overlooked' in the GMV allocation. Therefore, the GMV optimal portfolio picks asset 3 with the lowest volatility. The GMV portfolio is heavily concentrated. Portfolio risk measured by GMV is the smallest, which comes as no surprise.

The MDP, on the other hand, focuses on assets 5 and 6, which are the only ones that do not possess the same correlation structure as the others. Contrary to GMV, MDP is attracted by local differences in the correlation structure. The diversification index is lowest for the MDP. If we consider the concentration measures of Herfindahl, the EW should be considered if the investor wishes to have the broadest weight diversity and the ERC if risk concentration is the appropriate diversification risk measurement for the investor.

We consider in more detail ERC. The risk contribution of asset  $j$  to the portfolio risk is by definition the sensitivity of portfolio risk w.r.t. to  $\phi_j$  times the weight  $\phi_j$ . The Euler Allocation Principle states when the sum of all risk contributions equals portfolio risk.

Proposition 7. Let  $f$  be a continuously differentiable function on a open subset of  $\mathbb{R}^n$ .

If  $f$  is positive homogeneous of degree 1, this means  $tf(u) = f(tu)$  for  $t > 0$ , then

$$
f (u) = \sum_ {k = 1} ^ {n} u _ {k} \frac {\partial f (u)}{\partial u _ {k}}, u \in \mathbb {R} ^ {n}. \tag {2.12}
$$

Applying the Euler Theorem to risk measures means:

$$
R (\phi) = \sum_ {j} \phi_ {j} \frac {\partial R (\phi)}{\partial \phi_ {j}} =: \sum_ {j} R C _ {j} (\phi). \tag {2.13}
$$

Calculating say portfolio risk for  $1^{\prime}000$  positions in a portfolio is complicated. But using Euler's theorem, we need to calculate  $1^{\prime}000$  sensitivities, multiply them with their position and sum the result which is a much simpler task. For the volatility risk measure this means:

$$
R (\phi) = \sigma_ {p} (\phi) = \sum_ {j} \phi_ {j} \frac {\partial R (\phi)}{\partial \phi_ {j}} = \sum_ {j} \phi_ {j} \frac {(C \phi) _ {j}}{\sqrt {\phi^ {\prime} C \phi}} \tag {2.14}
$$

where  $(C\phi)_j$  denotes the  $j$ -th component of the vector  $C\phi$ . The Euler risk decomposition holds true for the volatility, VaR, and expected shortfall risk measurements.

Example - Euler allocation principle

Consider four assets in a portfolio with equal weights of 25 percent. The volatilities are  $30\%$ ,  $20\%$ ,  $40\%$ , and  $25\%$ . The correlation structure

$$
\rho = \left( \begin{array}{c c c c} 1 & & & \\ 0. 8 & 1 & & \\ 0. 7 & 0. 9 & 1 & \\ 0. 6 & 0. 5 & 0. 6 & 1 \end{array} \right) .
$$

The covariance matrix  $C$  is then calculated as (using the formula  $C_{km} = \rho_{km}\sigma_k\sigma_m$ )

$$
C = \left( \begin{array}{cccc}9\% & & & \\ 4\% & 4\% & & \\ 8.4\% & 7.2\% & 16\% & \\ 4.5\% & 2.5\% & 6\% & 6.25\% \end{array} \right)  .
$$

The portfolio variance

$$
\sigma_{p}^{2} = \sum_{i,j = 1}^{4}\phi_{i}\phi_{j}C_{ij} = 6.37\% .
$$

follows. Taking the square root, the portfolio volatility of  $25.25\%$  follows. Using (2.14), the marginal risk contribution vector

$$
\frac{C\phi}{\sqrt{\phi^{\prime}C\phi}} = \left( \begin{array}{c}26.4\% \\ 18.3\% \\ 37.2\% \\ 19\% \end{array} \right)
$$

follows. Multiplying each component of this vector with the portfolio weight gives the risk contribution vector  $\mathrm{RC} = (6.6\%, 4.5\%, 9.3\%, 4.7\%)$ . Adding the components of this vector gives  $25.25\%$  which is equal to the portfolio volatility. This verifies the Euler formula.

Table 2.7 shows that a seemingly well-diversified portfolio in terms of capital is in fact heavily equity-risk concentrated.  

<table><tr><td colspan="4">Asset class diversification</td><td colspan="2">Risk allocation</td></tr><tr><td>Cash</td><td>2%</td><td>Real estate</td><td>17%</td><td>Cash</td><td>2%</td></tr><tr><td>Domestic equities</td><td>14%</td><td>Hedge funds</td><td>10%</td><td>Equity</td><td>79%</td></tr><tr><td>IEQ</td><td>8%</td><td>Private equity</td><td>5%</td><td>Commodity</td><td>8%</td></tr><tr><td>EM equities</td><td>4%</td><td>Venture capital</td><td>9%</td><td>CCR</td><td>10%</td></tr><tr><td>Domestic govt bonds</td><td>9%</td><td>Natural resources</td><td>8%</td><td>Other</td><td>4%</td></tr><tr><td>ICB</td><td>10%</td><td>Distressed debt</td><td>4%</td><td></td><td></td></tr></table>

Table 2.7: Asset class diversification and risk allocation. The first two columns contain the diversification using the asset class view. The third column shows the result using risk allocation. While the investment seems to be well diversified using the asset classes the risk allocation view shows that almost  $80\%$  of the risk is due to equity. IEQ means international equities, ICB means international corporate bonds, CCR corporate credit risk.

This fact is often encountered in practice: Equity turns out to be the main risk factor in many portfolios. But then capital diversification is a poor concept from a risk perspective.

The asset allocation of European's asset managers was in 2013 (EFAMA (2015)):

$43\%$  bonds;  
$33\%$  equity;  

- $8\%$  cash and money market instruments;  
- $16\%$  other assets (property, private equity, structured products, hedge funds, other alternatives).

The allocation has been fairly stable in the past except in the GFC where equities lost massive value. This average allocation significantly differs for different countries. UK for example has investment in the equity class between  $46\%$  and  $52\%$  in the past while in France the same class is around  $20\%$ . This difference is due to differences in preferences of home-domiciled clients and the large differences in cross-border delegation of asset management. The ratio of AuM/GDP in UK is  $302\%$  which shows the importance of UK as the leading asset management center of Europe with a strong client basis outside

of the UK. Comparing the allocation for investment funds and discretionary mandates, the bond allocation is  $28\%$  in investment funds and  $58\%$  in the mandates and equities have a share of  $39\%$  in the funds and  $26\%$  in the mandates. Hence, self-deciders are less risk averse than those who delegate the investment decisions using mandates.

# 2.5.7 Risk Scaling

Is it possible given some assumptions to calculate risk for a new time horizon given its value on a different horizon without needing further data, running simulations or developing a new risk model? If one assumes IID normally distributed returns with zero mean, then the square-root of time rule can be used to scale volatilities. Consider investments with two different holding periods  $t < T$ . The volatility for the  $T$ -period follows from the  $t$ -period volatility by the square-root scaling law

$$
\sigma (T) = \sigma (t) \sqrt {T / t}. \tag {2.15}
$$

To prove this, consider  $n$  IID returns:

$$
\sigma^ {2} \left(R _ {1} + \dots + R _ {n}\right) = \sigma^ {2} \left(R _ {1}\right) + \dots + \sigma^ {2} \left(R _ {n}\right) = n \sigma^ {2} (R).
$$

For an asset with a one-day volatility of  $2\%$ , the monthly volatility - assuming 20 trading days - is equal to  $2\% \times \sqrt{20 / 1} = 8.9\%$ . The square-root rule provides a simple solution to a complex risk scaling problem. The method fails in any of the following situations:

- Modelling volatility at a short horizon and then scaling to longer horizons can be inappropriate since temporal aggregation should reduce volatility fluctuations, whereas scaling amplifies them.  
- Returns in short-term financial models are often not predictable but they can be predictable in longer-term models. Applying the scaling law one connects the volatility in two time domains that are structural different.  
- The scaling rule does not apply if jumps occur in the returns.  
- If returns are serially correlated, the square-root rule needs to be corrected (see Rab and Warnung [2011] and Diebold et al. [1997]).

# 2.5.8 Costs and Performance

We did not consider frictions in the risk, return, and performance analysis starting in Section 2.5.1. We add fees and taxes changing the results in Figure 2.17. We consider Swiss stocks with a gross average return of 7.73 percent and assume (Kunz [2014]):

- $25\%$  of the return arises from dividends, which face a taxation rate of  $30\%$ ,  
- The long-term inflation rate is  $2\%$ ,

<table><tr><td></td><td colspan="3">Return after …</td></tr><tr><td></td><td>… Fees</td><td>… Fees and taxes</td><td>… Fees, taxes, and inflation</td></tr><tr><td>Market index</td><td>7.73%</td><td>7.15%</td><td>5.15%</td></tr><tr><td>Investment fund</td><td>6.23%</td><td>5.65%</td><td>3.65%</td></tr><tr><td>Index fund</td><td>7.23%</td><td>6.65%</td><td>4.65%</td></tr></table>

- Investments can be via an investment fund (mutual fund, SICAV) with annual costs of 1.5 percent, or an index fund with annual costs of 0.5 percent.

The net returns using these figures are given in Table 2.8.

Given these net returns, an investment of CHF 100 takes after 25 years the values in Table 2.9.

Table 2.8: Returns after Fees (Kunz [2014]).  

<table><tr><td></td><td colspan="3">Value of CHF 100 after 25 years after…</td></tr><tr><td></td><td>… Fees</td><td>… Fees and taxes</td><td>… Fees, taxes, and inflation</td></tr><tr><td>Market index</td><td>643</td><td>562</td><td>351</td></tr><tr><td>Investment fund</td><td>453</td><td>395</td><td>245</td></tr><tr><td>Index fund</td><td>573</td><td>500</td><td>312</td></tr></table>

Table 2.9: Net growth of wealth (Kunz [2014]).

Fact 8. Using a cost and tax efficient wrapper for an investment amounts to an annual return gain of  $1.45\%$  compared to an investment fund.

Given the zero-sum game of active investment, see the next Section, that only  $0.6\%$  of 2,076 actively managed US open-end, domestic equity mutual funds generate a positive alpha after costs, see Section 4.6.6.3, and the possibility to wrap many investment ideas in cheap index funds or ETFs, it becomes clear why many investor prefer passive investments.

# 2.5.9 Passive versus Active Investment; a First Step

Let  $\mu_{m},\mu_{p},\mu_{a}$  be the expected returns of the fully diversified market portfolio, a passive portfolio, and an active investment, respectively. We assume that the fraction  $\lambda$  of investors is passively invested and  $1 - \lambda$  is invested in active vehicles. By definition, passive management means following an index, benchmark or another portfolio using quantitative techniques. Active investors are the non-passive ones. Since any investor is either an active or passive one and since the market return follows from the aggregate return of the active and passive investors, we have:

$$
\mu_ {m} = \lambda \mu p + (1 - \lambda) \mu_ {a}. \tag {2.16}
$$

Assuming that the return of the passive investment equals that of the market, (2.16) implies that the active return equals market return independent of the fraction  $\lambda$ .

Therefore, without any probabilistic or behavioural assumptions, before costs the three investments pay back the same return:

Proposition 9 (Sharpe). Before costs, the return on the average actively managed dollar will equal the return on the average passively managed dollar.

Because active managers bear greater costs than a passive investment:

Proposition 10 (Sharpe). After costs, the return on the average actively managed dollar will be less than the return on the average passively managed dollar.

These statements are strong and they are based on strong assumptions. Despite its beauty, the assumptions that lead to (2.16) trivialize the problem. Suppose all investor are active ones - who is on the other side of the trades? Returns are not independent of the demand and supply side but in fact follow in market equilibrium. Demand and supply matter. Pedersen (2018) extended the Sharpe arithmetic to cases where active management can on average be more profitable than passive one in an equilibrium context. He replaced the unrealistic assumption that an active investor's gain is the loss of another active investor, leading in the aggregate to a zero sum game. Next, the market portfolio is not constant. It changes over time since new shares are issued and corporate actions happen: Passive investors need also to trade regularly. If they have to trade at less favourable prices than the active investors do, then the logic of Sharpe is broken.

Roll pointed out that a true market portfolio is not observable since it would include any single asset. Market weighted indices are used as an approximation. In the US, the Wilshire 4'500 Index contains 4'500 stocks of approximately 5'000 listed stocks. In Switzerland, SPI Index contains 210 of 270 listed stocks. The global market portfolios also differ significantly depending who is calculating it. The major contributors are debt and equity where equity is split in global equity, EMMA equity, private equity and small cap equity and debt is split in government bonds, agency bonds, asset backed securities, EMMA bonds, corporate bonds. The assumption that passive investment means to be invested in the market portfolio is an approximation. Consider funds. US retail funds are different to US institutional funds and are also different to non-US funds. The one-fits-all argument of Sharpe does not consider the heterogeneity of investment wrappers across different asset classes, different geographical regions, different client segmentations. Finally, the result is based on average active managers. It does not account for the differences between skill and luck.

The goal of active asset management is to outperform benchmarks. The manager tries to beat the benchmark within a given Tracking Error (TE) limit. In fact proponents of active investment use argumentation following the work of Berk and Green (2004). They show that efficient markets not contradict the existence of skilled fund managers who beat the market consistently. The concept of benchmarking and hence relative performance has several advantages for the portfolio manager: Performance measurement is simple relative to the benchmark, benchmarking has a disciplining force acting on the

asset manager and the structuring of the investment portfolio is simplified.

Active management often has both a passive component, the long-term goals in a benchmark portfolio, and an active component, playing the views to exploit market opportunities (TAA). The passive portfolio stabilizes the whole investment.

Definition 11. A passive investment strategy tracks a market-weighted index or portfolio (the benchmark). The goal of an active investment strategy is to beat the market-weighted index by changing market weights (asset selection) at the right time (market timing) within a TE limit.

ETFs, trackers and index funds are examples of passive strategies. Mutual funds, opportunistic use of derivatives, and hedge funds are examples of active strategies. While the deviation of a strategy from a benchmark, the tracking error, should be as small as possible in passive investment, the tracking error in active investment describes how far away the active manager moves away from the benchmark.

Different types of benchmarks are used. Either the benchmark is used to compare the performance of a fund with its peers or the benchmark is a market index. While both methods are meaningful for active investment, in a passive investment only index benchmarking makes sense.

The main stock benchmark indices are MSCI World Index, FTSE, S&P 500 and some other well known stock market indices. Since bond securities do not trade on open exchanges there is less transparency about bond prices and the indexes used for benchmarking are those created by the largest bond dealers such as the Barclays Global Aggregate Bond Index, which tracks the largest bond issuers globally. Benchmark indexes for commodities are for example provided by S&P and Goldman Sachs (S&P GSCI) or by Bloomberg (Bloomberg Commodity Index). For credit risk of the Markit iTraxx indices reflect the creditworthiness of large corporates. A provider for real estate indices is MSCI. There are four different type of income-producing real estate assets: offices, retail, industrial and leased residential. Non-income producing assets are houses, vacation properties or vacant commercial buildings. These different types of real estates assets lead together with the geographical segmentation to many different real estate indices.

# 2.6 Market Figures

# 2.6.1 The Demand and Supply Side in Asset Management

The AM industry clients' are segmented into private and institutional clients. Institutional clients include pension funds, insurance companies, family offices, corporate treasuries, and government authorities. The two categories differ in many respects. Retail clients pay higher fees than institutional ones. Institutional investors ask for pure asset management services, while private clients often combine their asset management

demands with other banking services such as financial planning or mortgage lending. Private clients invest more heavily in wrappers of investment solutions such as mutual funds, ETFs or structured products. Institutional clients prefer to invest in cash products directly (bonds or stocks) and using overlays to cut and paste the return profile. Institutional clients have better or exclusive market access such as to alternative investments and regulation is more pronounced for private clients.

Trading units and asset management firms are the suppliers of assets for investment. Mutual funds or ETFs are often offered by non-banking firms such as BlackRock. These firms issue products but also provide other services.<sup>3</sup>

The largest asset management organizations in 2017 were BlackRock with USD 6.3 trillion AuM followed by the Vanguard Group.<sup>4</sup> The largest fund in 2014 was the SPDR ETF on the S&P 500 managed by State Street Global Advisors with assets of USD 224 bn; see the Appendix.

# 2.6.2 Asset Management Industry - the Eurozone

We follow EFAMA (2015). Asset management companies are one channel between providers and users of funds in the case where the parties do not exchange the assets directly by using organized market places. AM firms provide a pooling of funds for investment purposes. Banks, another channel, offer also non-asset management functions. Insurance companies or pension funds take savings from households or companies and invest them in money markets and capital markets. The main services of the AM industry to clients are savings management (diversification, reduction of risk by screening out bad investment opportunities), liquidity provision (providing liquid asset to clients while investing in not necessarily liquid assets) and reduction of transaction costs (size matters).

The AM firms also contribute to the real economy. Firms, banks and governments use AM firm to meet their short-term funding needs and the long-term capital requirements. The AM contribution to debt financing is  $23\%$  : European asset managers held this amount of all debt securities outstanding which also represents  $33\%$  of the value of euro-bank lending. The equity financing figures are similar. The AM industry held  $29\%$  of the market value of euro area listed firms and  $42\%$  of the free float.

From a corporate finance perspective, the valuation and market capitalization of asset management firms compared to banks and insurance companies between 2002 and 2015 is shown in Table 2.10 (McKinsey (2015)):

<sup>3</sup>BlackRock Solutions - the risk management division of BlackRock - was mandated by the US Treasury Department to manage the mortgage assets owned by Bear Stearns, Freddie Mac, Morgan Stanley, and other financial firms that were affected by the financial crisis in 2008. This gained expertise boosted the BlackRock Solutions to become more important than the asset management firm part.  
4The Vanguard Group 5.1 tr USD, Charles Schwar 3.4 tr USD, UBS 3.1 tr USD, State Street 2.8 tr USD.

<table><tr><td>Feature</td><td>Asset management firms</td><td>Banks</td><td>Insurance</td></tr><tr><td>Market Cap (100 in 2002)</td><td>516</td><td>313</td><td>231</td></tr><tr><td>P/E ratio</td><td>16.1</td><td>11.3</td><td>14.8</td></tr><tr><td>P/B value</td><td>3.2</td><td>1.2</td><td>1.6</td></tr></table>

Table 2.10: Key figures 2015 for asset management firms, banks and insurance companies. (McKinsey [2015])

The number of asset management companies in 2017 in Europe was approximately  $4^{\prime}200$  up from  $3^{\prime}300$  in 2014. Most companies are located in France, Ireland, Luxembourg, Germany, UK, Netherlands and Switzerland. The high number in Ireland and Luxembourg is due to their role played in the cross-border distribution of UCITS funds (see below). The main AM center where the investment management functions are carried out is London. The average AuM per asset manager range from EUR 9 billion in UK to less than one billion in Portugal and Turkey for example. The industry is highly concentrated in each country. The top 5 asset managers in Germany control  $94\%$  percent of all assets and in the UK the corresponding figure is  $36\%$ . In UK and France, less than  $20\%$  of the firms are owned by banking groups. In Germany  $(60\%)$  and Austria  $(71\%)$  of the asset management functions are part of a bank. Insurance companies play a significant role in Italy, UK, France and Germany (all  $13\%$ ) and in Greece  $(21\%)$ . Institutional investors represent the largest client category of the European asset management industry, accounting for  $71\%$  of total AuM at end 2016. Pension funds and insurance companies accounted for  $28\%$  and  $25\%$  of total AuM, respectively.

Total Assets under Management (AuM) in Europe increased by  $10\%$  in 2017 to EUR 25.2 trillion. Comparing the growth of investment funds versus discretionary mandates in Europe, both categories have increased in 2014 to a similar level of EUR 13.1(9.1) trillion in investment funds and EUR 12(9.9) trillion in discretionary mandates (EFAMA (2018) and (2015)). The share of investment funds compared to the mandates was falling from 2007 until 2011 but it then started to increase in the last three years. While mandates represented more than  $70\%$  of the AuM in the UK, Netherlands, Italy, Portugal, and more than  $70\%$  of the all AuM in Germany, Turkey or Romania were invested in investment funds. The dominance of either type of investment can have different causes. In the UK and the Netherlands pension funds play an important role in asset management and they prefer to delegate the investment decisions. The pool of professionally managed assets in Europe remains centered in the UK ( $37\%$  market share), France ( $20\%$ ), Germany ( $10\%$ ), Italy, Nordic countries and Switzerland.

The number of individuals directly employed (asset managers, analysts) in the industry is estimated 2017 (2013) at  $110'000(90'000)$  with one-third in the UK. The indirect employment such as IT, marketing, legal, compliance and administration is estimated to boost the total number of employees in the whole industry up to a half-a-million individuals.

# 2.6.3 Global Figures 2007-2014, Market Structure

The following figures in the period 2007-2014 are from McKinsey (2015).

- Per annum, global AuM growth between is  $5\%$ . The main driver was market performance. Typically, the net AuM flows are between  $0\%$  and  $2\%$  per annum.  
- The growth of AuM is  $13.1\%$  in Europe,  $13.5\%$  in North America and  $226\%$  in emerging markets which is largely due to the money market boom in China.  
- The absolute value of profits increased in Europe by  $5\%$ ,  $29\%$  in North America and  $79\%$  in the emerging markets.  
- Profit margins as the difference between net revenues margin and operating cost margin are 13.3 bps in Europe, 12.5 bps in North America and 20.6 bps in emerging markets. The observed revenue decline in Europe is due to the shift from active to passive investments, the shift to institutional clients and the decrease in management fees. The revenue margin in the emerging markets is only slightly lower in 2014 compared to 2007 (down to 68.1 bps from 70.6 bps) but the increase in operating cost margin from 33.8 bps to 47.4 bps in 2014 is significant.  
- The absolute revenues in some emerging markets such as China, South Korea, Taiwan are with values between USD 10.1 bn to USD 3.7 bn. They are almost at par with the revenues in Japan, Germany, France and Canada (all around USD 10 bn). The revenue pools of UK (USD 21.2 bn) and the US (USD 150.8 bn) are still leading the global league table.  
- The cost margins in Europe are stable between 21 bps and 23 bps. The split of the cost margin is in sales and marketing (around 5 bps), fund management (around 8 bps), middle/back office (around 3.5 bps) and IT/support (around 6 bps). There is a cost increasing trend for IT/support, decreasing costs for sales and marketing and middle/back office.  
- From a customer segment perspective, retirement/DC grew with a Compounded Annual Growth Rate (CAGR) of  $7.5\%$  is almost twice as strong as the retail sector with  $4\%$  between 2007 and 2014. The institutional customer's CAGR was  $5\%$ . These average global rates differ for different geographic regions. The retirement/DC CAGR dominates in Europe the retail one by a factor of 4 whereas in the emerging markets, the CAGR for institutional customers is  $13\%$  compared to  $11\%$  for retirement/DC.

By considering the above facts one should take into account the particular circumstances in the years after the GFC such as the decreasing interest rates level and stock market boom which were the main factors in the success of the asset management industry in this period.

<table><tr><td>Investment type</td><td>2003</td><td>2008</td><td>2012</td><td>22016</td><td>E2025</td></tr><tr><td>Passive /ETF</td><td>2</td><td>3.3</td><td>7.9</td><td>14.6</td><td>E36.6</td></tr><tr><td>LDIs</td><td>0.6</td><td>1.6</td><td>2.5</td><td>-</td><td>-</td></tr><tr><td>Active Core</td><td>24.8</td><td>28.1</td><td>30.9</td><td>60.1</td><td>E87,5</td></tr><tr><td>Active Solutions</td><td>8.2</td><td>10.8</td><td>15.1</td><td>-</td><td>-</td></tr><tr><td>Alternatives</td><td>1.9</td><td>3.9</td><td>6</td><td>10</td><td>21.1</td></tr></table>

Table 2.11: Global distribution of AuM by product and its dynamics in the last decade in trillion USD. Alternatives include hedge, private-equity, real-estate, infrastructure, and commodity funds. Active solutions include equity specialties (foreign, global, emerging markets, small and mid caps, and sector) and fixed-income specialties (credit, emerging markets, global, high yield, and convertibles). LDIs (liability-driven investments) includes absolute-return, target-date, global-asset-allocation, flexible, income, and volatility funds. Active core includes active domestic large-cap equity, active government fixed-income, money market, and traditional balanced and structured products (Valores Capital Partners [2014]).

The figure for 2016 and the projection to 2015 are from PwC (2018).

Table 2.11 illustrates the global distribution of AuM by product and its dynamics in the last decade.

The table indicates that the growth rate of passive investments is larger than for active solutions. McKinsey (2015) states for the period 2008-2014 that cumulated flows are  $36\%$  for passive fixed income and  $22\%$  for passive equity. Standard active management is decreasing for some asset classes and strategies: Active equity strategies lost  $20\%$  on a cumulated flow basis while active fixed income gained  $52\%$ . A next observation is that active management of less liquid asset classes, or with more complex strategies, is increasing. An increase of  $49\%$  cumulate flows for active balanced multi asset and of  $23\%$  for alternatives. The global figures vary strongly for different regions or countries. Swiss and British customers adopted the use of passive much faster than for example Spanish, French or Italian investors. Figure 2.20 shows the distribution of global investable assets by region and by type of investor.

Regulation imposes a great deal of complexity on the whole business of asset management and banking. On the other side of the fence, there is a so-called shadow banking sector with much less regulatory overview. Although the expression 'shadow bank' makes no sense at all - either an institution has a banking license or not - there is an incentive for banks to consider outsourcing their asset management units to these 'shadow banking' sector.

Traditional and non-traditional asset managers' (alternative asset class managers) roles are converging. Traditional asset managers have continuously lost market share to low-cost ETFs. They therefore consider liquid alternative products to stop the bleeding. This is one reason for the convergence. Non-traditional asset managers, on the other hand, want to expand into traditional segments since their non-traditional products are

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c9167d0b144ed2d472fcee8f94cd79d6a17c97045bde39c894d5f97661693678.jpg)  
Figure 2.20: Global investable assets by region in trillions of USD (Brown Brothers Harriman [2013]).

becoming more liquid and more transparent. This is the other reason for the coming together of the two, previously distinct, roles. The hedge fund AQR Capital Management opted for the Company Act Of 1940 (the 40-Act) mutual fund industry regulatory regime. This act requires much more transparency in reporting than hedge funds usually provide. This allowed AQR access to a new customer base. This business had grown to USD 19 billion AuM by 2014.

Forward looking estimates by PwC (2014, 2018) for the period 2014-2020 estimate that actively managed funds will grow at an CAGR of 5.4 percent and mandates with 5.7 percent (PwC [2014]). The actively managed funds growth driver is the growing global middle-class client base. Mandates growth factors are institutional investors (pension funds and SWFs) and HNWIs, see Table 2.12. Furthermore, the ratio active:passive =

<table><tr><td>Investment type</td><td>2014 - USD trillions</td><td>E2020 - USD trillions</td></tr><tr><td>Actively managed funds</td><td>30</td><td>41.2</td></tr><tr><td>Mandates</td><td>32</td><td>47.5</td></tr><tr><td>Alternative investments</td><td>6.9</td><td>13</td></tr></table>

Table 2.12: Actively managed funds, mandates, and alternative investment (PwC [2014]).

7:1 by 2012 and is estimated to fall to 3:1 by 2020. By the end of 2014, the AuM in actively managed funds are distributed as follows -  $60\%$  in the Americas,  $32\%$  in Europe, and  $12\%$  in Asia. Compared to 2010, there is a relative stagnation or decrease in Europe

and Asia whereas the proportion in the Americas is increasing.

The formation of four regional blocs in AM - South Asia, North Asia, South Asia, Latin America, and Europe - creates opportunities, costs, and risk. These blocks develop regulatory and trade linkages with each other based on reciprocity - AM firms can distribute their products in other blocs. The US, given the actual trends, will stay apart since it prefers to adhere to its regulatory model. But integration will not only increase between these blocs but also within blocs. There will be, for example, a strong regulatory integration inside the South Asia bloc. The ASEAN platform between Singapore, Thailand, and Malaysia will be extended to include Indonesia, the Philippines, and Vietnam. All these countries possess a large wealthy, middle-class of potential AM service investors. The global structure UCITS continues to gain attraction worldwide and reciprocity between emerging markets and Europe will be based on the European AIFMD model for alternative funds. By 2013, more than 70 memoranda of understanding for AIFMD had been signed.

The traditional AM hubs London, New York and Frankfurt will continue to dominate the AM industry. But new center will emerge due to the global shift in asset holdings. There will be a balance between global and local platforms. Whether or not a global or local platform is pushed depends on many factors: Time-to-market, regulatory and tax complexity, behavior and social norms in jurisdiction and the eduction level matter. AM firms recruit local teams in the key emerging markets - the people factor. The education of these local individuals started originally in the global centers but will diffuse more and more to the new centers in the emerging markets. Due to the positive brand identities that tech firms have, they can integrate part of the business layer into their infrastructure layer and offer AM services under tech firm brands instead of more traditional banking or AM company brands (Branding reversal). Finally, alternatives asset managers on one hand side offer new products - asset managers move in the space banks left vacated - and on the other hand side try that their alternative funds become mainstream. New products include primary lending, secondary debt market trading, primary securitizations, and off-balance-sheet financing.

# 2.6.4 Asset Management vs Trading Characteristics

Some key characteristics of asset management firms:

- Agency business model. Asset managers are not the asset owners, they act on a best effort basis for their clients and the performance is attributed to their clients.  
- Low balance sheet risk. Since asset managers to not provide loans, to not act as counter parties in derivatives, financing or securities transactions and they seldom borrow money (leverage) their balance sheet does not face the risk of a bank's balance sheet.  
- Protection of client assets. Asset managers are regulated and in mandated asset

management, the client assets are held separately from the asset management firm's assets.

- Fee based compensation. Asset managers generate revenue principally from an agreed-upon fee. There is no profit and loss as in the trading.

From a risk perspective, asset management is a fee business with conduct, business, and operational risk as the main risk sources.

Trading is contrary a market, counter party and liquidity risk business which needs a strong balance sheet of the intermediary. Trading is a mixture of a fee (agency trading) and a risk-taking business (principal and proprietary trading). Agency trading is a fee business based on client flow. Clients place their orders and the trading unit executes the orders on behalf of the client's account. For example, a stock order is routed by the trader to the stock exchange where the trade is matched. The bank receives a fee for this service. Principal trading already requires active market risk or counterparty risk taking by the bank since the bank's balance sheet is affected by the profits and losses from trading. Principal trading is still based on clients' orders but it requires the traders to take some trading positions in their market-making function or in order to meet future liabilities in issued structured products. This is a key difference to agency trading. Proprietary trading is not based on the client's flow at all. Proprietary traders implement trading ideas without any reference to a client activity. This type of trading puts the bank's capital at risk. New regulations limit proprietary trading by investment banks such as the The Volcker Rule in the US and 'ring-fencing' in the UK.

AM firms wrap the underlying assets into collective investment schemes ('funds') while the trading of a bank offers issuance and market making for cash products, derivatives, and structured products. Despite their differences, trading and asset management are linked. Portfolio managers in the asset management function execute their trades via the trading unit or a broker. The market making of ETF and listed fund trading takes place in the trading unit. Cash products are used by the asset management function in their construction of collective schemes and asset managers use in their portfolios derivative (overlay) to manage risk and return characteristics.

# 2.6.5 Institutional Asset Management versus Wealth Management

Investors are in institutional asset management (IAM) are legal entities such as pension funds and in wealth management WM private clients. The investment goal in IAM is often based on an non-maturing asset-liability analysis while in WM the goal is linked to the life cycle of the client. Although, this defines long-term investment horizons for both types of investors, we refer to Section 3.6 for difficulties of pension funds f to follow a long-term strategy. If WM clients use shortor mid-term investment horizons, opportunistic behavior is motivated. The performance of the investment for IAM is benchmarked while WM clients also prefer absolute returns. Therefore, for IAM beta is the first concern and alpha is added in a satellite form. The responsibility for the performance in IAM is

attached to investment boards, CFOs, board of trustees. In WM, the mandate manager is responsible for the performance. IAM companies use several mandates, often one for each asset class, to manage investments while WM either use a fewer number of mandates or even decide by their own in the advisory channel.

The size of investment is very huge for IAM and smaller for WM. The risk management for IAM is comprehensive and of the same quality as it is used by say banks for their own purposes. In WM risk management is often less sophisticated. Fees are typically lower for IAM than for WM. While IAM are highly regulated the regulation of WM was in the past much less strong. This changed after the GFC where MiFID II, Know-Your-Client, product information sheets, etc. heavily increases the WM regulation setup. Finally, the loyalty of IAM clients is decreasing while WM clients are more loyal. It will be interesting to observe in the future how loyalty of WM clients will change if technology will make investments not only more tailor-made but also more open platform oriented and therefore, less strongly linked to the home institution of the WM clients.

# 2.7 The Fund Industry

In 1774 Abraham van Ketwich, an Amsterdam broker, offered a diversified pooled security specifically designed for citizens of modest means. The security was similar to a present day closed-end fund. It invested in foreign government bonds, banks, and West Indian plantations. The word 'diversification' is explicit in the prospectus of this fund.

The 1920s saw the creation in Boston of the first open-end mutual fund - the Massachusetts Investors' Trust. By 1951 more than 100 mutual funds existed and 150 more were added in the following twenty years. The challenging 1970s - oil crisis - were marked by a number of innovations. Wells Fargo offered a privately placement, equally weighted S&P 500 index fund in 1971. This fund was unsuccessful and Wells created a successful value-weighted fund in 1973. It required huge efforts - tax and regulatory compliance, build up stable operations and education of potential investors. Bruce Bent established the first money market fund in the US in 1971 such that investors had access to high money market yields in a period where bank regulated interest rates. In 1975, John Bogle create a mutual fund firm - Vanguard. They launched 1976 the first retail index fund based on the S&P 500 Index. In 1993, Nathan Most developed an ETF based on the S&P 500 Index. The following table summarizes the worldwide market figures of investment funds without fund of funds. The fund industry is not free of scandals. In 2003 for example illegal late trading and market timing practices were uncovered in hedge fund and mutual fund companies. Late trading means that trading is executed after the exchanges are closed. Traders could buy mutual funds when markets were up at the previous day's lower closing price, and sell at the purchase date's closing price for a guaranteed profit.

There are different types of funds: Mutual funds, index funds, ETFs, hedge funds

<table><tr><td></td><td>Total</td><td>Equity</td><td>Bond</td><td>Balanced</td><td>MM</td><td>GP</td><td>RE</td><td>Other</td><td>ETF</td><td>IF</td></tr><tr><td>Net Assets</td><td>bn EUR</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>World</td><td>40&#x27;786</td><td>17&#x27;399</td><td>8&#x27;852</td><td>5&#x27;104</td><td>5&#x27;307</td><td>48</td><td>703</td><td>3&#x27;372</td><td>4&#x27;081</td><td>3&#x27;864</td></tr><tr><td>Americas</td><td>20&#x27;646</td><td>10&#x27;832</td><td>4&#x27;875</td><td>1&#x27;954</td><td>2&#x27;813</td><td>1</td><td>19</td><td>153</td><td>3&#x27;047</td><td>432</td></tr><tr><td>Europe</td><td>14&#x27;392</td><td>4&#x27;071</td><td>3&#x27;428</td><td>2&#x27;828</td><td>1&#x27;265</td><td>47</td><td>606</td><td>2&#x27;147</td><td>624</td><td>2&#x27;700</td></tr><tr><td>Asia</td><td>5&#x27;613</td><td>2&#x27;465</td><td>545</td><td>258</td><td>1&#x27;208</td><td>0</td><td>75</td><td>1&#x27;062</td><td>410</td><td>733</td></tr><tr><td>Africa</td><td>135</td><td>32</td><td>4</td><td>65</td><td>20</td><td>0</td><td>4</td><td>10</td><td>0</td><td>0</td></tr><tr><td>No. Funds</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>World</td><td>118&#x27;978</td><td>40&#x27;757</td><td>20&#x27;967</td><td>28&#x27;008</td><td>2&#x27;712</td><td>954</td><td>3&#x27;819</td><td>21&#x27;761</td><td>5&#x27;277</td><td>20&#x27;293</td></tr><tr><td>Americas</td><td>28&#x27;379</td><td>10&#x27;577</td><td>6&#x27;108</td><td>8&#x27;152</td><td>1&#x27;007</td><td>26</td><td>371</td><td>2&#x27;138</td><td>2&#x27;637</td><td>3&#x27;125</td></tr><tr><td>Europe</td><td>56&#x27;036</td><td>14&#x27;830</td><td>9&#x27;914</td><td>14&#x27;388</td><td>906</td><td>913</td><td>1&#x27;816</td><td>13&#x27;269</td><td>1&#x27;635</td><td>10&#x27;994</td></tr><tr><td>Asia</td><td>14&#x27;938</td><td>4&#x27;881</td><td>4&#x27;562</td><td>750</td><td>15</td><td>1&#x27;552</td><td>6&#x27;298</td><td>1&#x27;005</td><td>6&#x27;174</td><td></td></tr><tr><td>Africa</td><td>1&#x27;567</td><td>412</td><td>64</td><td>906</td><td>49</td><td></td><td>80</td><td>56</td><td></td><td></td></tr></table>

Table 2.13: MM means Money Markets, GP Guaranteed and Protection, RE Real Estate and IF Investment Funds. Data are end of Quarter Q4 2018. Sourceee: EFAMA, Investment Company Institute (ICI), International Investment Funds Association (IIFA). Statistics from 47 countries are included in this report.

and alternative investments. We note some broad characteristics:

- Index mutual funds and most ETFs are passively managed.  
- Index funds seek to match the fund's performance to a specific market index, such as the S&P 500, before fees and expenses.  
- Mutual funds are actively managed and try to outperform market indexes. They are bought and sold at the current day's closing price - the NAV (net asset value).  
- ETFs are traded real time at the current market price and may cost more or less than their NAV.

NAV is a company's total assets minus its total liabilities. If an investment company assets are worth USD 100 and has liabilities of USD 10, the company's NAV is USD 90. Since assets and liabilities change daily, NAV also changes daily. Mutual funds generally must calculate their NAV at least once every business day. An investment company calculates the NAV of a single share by dividing its NAV by the number of outstanding shares.<sup>5</sup>

Funds can be openor closed-end. Open-end funds are forced to buy back fund shares at the end of every business day at the NAV, see Table 2.14. Prices of shares traded during the day are expressed in NAV. Total investment varies based on share purchases, share redemptions, and fluctuations in market valuation. There is no limit on the number of shares that can be issued. Closed-end funds issue shares only once. The shares are listed and traded on a stock exchange: An investor cannot give back his or her shares

to the fund but must sell them to another investor in the market. The prices of traded shares can be different to the NAV - either higher (premium case) or lower (discount case). The vast majority of funds are of the open-end style.

<table><tr><td>Feature</td><td>Open-end fund</td><td>Closed-end fund</td></tr><tr><td>Number of outstanding shares</td><td>Flexible</td><td>Fixed</td></tr><tr><td>Pricing</td><td>Daily NAV</td><td>Continuous demand and supply</td></tr><tr><td>Redemption</td><td>At NAV</td><td>Via exchange</td></tr><tr><td>Market share</td><td>&gt;95%</td><td>&lt; 5%</td></tr><tr><td>US terminology</td><td>Mutual fund</td><td>Closed-end fund</td></tr><tr><td>UK terminology</td><td>Unit trust</td><td>Investment trust</td></tr><tr><td>EU terminology</td><td>SICAV</td><td>SICAF</td></tr></table>

Table 2.14: Features of open-end and closed-end funds. A SICAV (Société d'Investissement a Capital Variable) is an open-ended collective investment scheme. SICAVs are cross-border marketed in the EU under the UCITS directive (Undertakings for Collective Investments in Transferable Securities, see below). SICAFs are the closed-end fund equivalent of SICAVs.

The legal environment is crucial for the development of the fund industry. About three-quarters of all cross-border funds in Europe are sold in Luxembourg. Luxembourg offers favorable framework conditions for holdings/holding companies, investment funds, and asset-management companies. These companies are partially or completely tax-exempt; typically, profits can be distributed tax free. For private equity funds, two-thirds have the US state of Delaware as their domicile. For hedge funds one-third are in the Caymans; one-quarter in Delaware. As of Q3 2013, 48 percent of mutual funds had their domicile in the US, 9 percent in Luxembourg, and around 6 percent in Brazil, France, and Australia, respectively.

# 2.7.1 Mutual Funds and SICAVs

The Securities and Exchange Commission (SEC) defines mutual funds as follows:

Definition 12. A mutual fund is a company that pools money from many investors and invests the money in stocks, bonds, short-term money-market instruments, other securities or assets, or some combination of these investments. The combined holdings the mutual fund owns are its portfolio. Each share represents an investor's proportionate ownership of the fund's holdings and the income those holdings generate.

In Europe, mutual funds are regulated under the UCITS regime and mutual fund equivalents are called SICAVs. When we refer below to mutual funds, we always have US mutual funds in mind. Some characteristics of mutual funds are that investors purchase mutual fund shares from the fund and not via stock exchange, investors can sell their share any time, that they pay for mutual fund shares the NAV plus any shareholder

fees, that if there is a new demand, mutual funds create and sell new shares, and finally, investment portfolios are managed by separate entities (investment advisers) that are registered with the SEC. Mutual funds are non-listed public companies that neither pay taxes nor have employees.

The major benefits of mutual funds for investors are:

- Diversification and professional management.  
- Investor protection (regulation)  
- Affordability - the basic unit of a fund unit requires only little money from the investors and access to assets.  
- Partial transparency about the investment process, performance, the investment portfolio, and the fees.  
- Default remoteness. Fund capital is treated as segregated capital.  
- Liquidity. Mutual fund investors can redeem at any time their shares at the current NAV plus any fees and charges assessed on redemption.  
- Investment strategy. The investor can choose between active and passive investment, can have access to rule-based strategies, etc. But he cannot choose a guaranteed payoff as for structured products. Hence, investors in funds believe that the fund managers skills generate the performance.

Some disadvantages of mutual funds:

- Lack of control about the securities in the portfolios.  
- Price uncertainty. Pricing follows the NAV methodology, which the fund might calculate hours after the placement of an order.

The Investment Company Institute and US Census Bureau (2015) states that a total of  $43.3\%$  of US households with a median income of USD 85,000 own mutual funds. The median mutual fund holdings are USD 103,000 and the median of household financial assets is USD 200,000.  $86\%$  own equity funds,  $33\%$  hybrids,  $45\%$  bond funds, and  $55\%$  money-market funds. Only  $36\%$  was invested in global or international equity funds. The primary financial goal  $(74\%)$  for mutual fund investment are retirement goals.

# 2.7.2 US Mutual Funds versus European UCITS

Mutual funds and SICAVs are both collective investment schemes. But there are some major difference between the two types of wrapper and the entire industries. We follow Pozen and Hamacher (2015).

Cross-border distribution has been most successful within the European UCITS format. This is not only true for Europe. UCITS dominate global fund distribution in more than 50 local markets (Europe, Asia, the Middle East, and Latin America). This kind of global fund distribution is the preferred business model in terms of economies of scale and competitiveness. In 2016 around 80,000 registrations for cross-border UCITS funds exist. The average fund is registered in eight countries. Furthermore, UCITS are not required to distribute all income annually.

UCITS do not need to accept redemptions more than twice a month. Although the two previous points hold in general, many funds offer - for example - the option to distribute income annually or make redemptions possible on a daily basis. UCITS sponsors must comply with the EU guidelines on compensation for key personnel: the remuneration directive.

Both, UCITS funds and mutual funds originally were quite restrictive in their investment guidelines. Then UCITS (similar remarks apply to mutual funds) were allowed to use derivatives extensively. Using derivatives means, among other things, leveraging portfolios or creating synthetic short positions - UCITS are not allowed to sell physical assets short. The strategies of these funds - referred to as 'newCITS' - are similar to hedge fund strategies and they showed strong growth to USD 294 billion in 2013 according to Strategic Insight (2013).

But there are also differences between US mutual funds and European UCITS on a more fundamental level. US clients invest in existing funds while European investors are regularly offered new funds. That is, the number of US mutual funds has been decreasing in the last decade while the European funds have showed a strong increase in numbers; see Table 2.15. The stability of the US fund industry is due to the influence of US retirement plans (defined contribution), which do not change investment options often. The tendency to innovate permanently in Europe leads to funds which on average around six-times smaller than their US counterparts.

# 2.7.3 Functions of Mutual Funds

# 2.7.3.1 How They Work

Buying and selling mutual funds is not done via a stock exchange - the shares are bought directly from the fund. Therefore, the share price is not fixed by traders but is equal to the net asset value (NAV). Investors pay the NAV plus the sales load fee when they buy; if they sell, they get the NAV minus the redemption fee. While the calculation of the NAV is theoretically simple, the process of implementing the calculation is not since one has to accurately record all securities transactions, consider corporate actions, determine the liabilities for example. Digitization offers an opportunity to overcome present NAV calculation problems. If say the NAV can be calculated real-time, why should fund shares not be listed on a stock exchange?

<table><tr><td></td><td>2003</td><td>2013</td></tr><tr><td>US</td><td></td><td></td></tr><tr><td>Number of funds</td><td>8,125</td><td>7,707</td></tr><tr><td>Total Assets USD tr</td><td>7.4</td><td>15.0</td></tr><tr><td>Asset per fund USD mn</td><td>911</td><td>1,949</td></tr><tr><td>Europe</td><td></td><td></td></tr><tr><td>Number of funds</td><td>28,541</td><td>34,743</td></tr><tr><td>Total Assets USD tr</td><td>4.7</td><td>9.4</td></tr><tr><td>Asset per fund USD mn</td><td>164</td><td>270</td></tr><tr><td>Asia</td><td></td><td></td></tr><tr><td>Number of funds</td><td>11,641</td><td>18,375</td></tr><tr><td>Total Assets USD tr</td><td>1.4</td><td>3.4</td></tr><tr><td>Asset per fund USD mn</td><td>116</td><td>183</td></tr></table>

Table 2.15: Number of funds, average fund size and assets by region (Investment Company Institute [2010, 2014] and Pozen and Hamacher [2015]).

Mutual funds as companies pay out almost all of their income - dividend and realized capital gains - to shareholders every year and pass on all their tax duties to investors. Hence, mutual funds do not pay corporate taxes. Therefore, the income of mutual funds is taxed only once while the income of 'ordinary' companies is taxed twice.[6]

# 2.7.3.2 Organization of Mutual Funds

The fund's board of directors is elected by the fund's shareholders. It should govern and oversee the fund, see Figure 2.21. Mutual funds are required to have independent directors on their boards. The investment adviser manges the fund's portfolio following the guidance described in the prospectus. The fund administrator offers administrative services to the fund and ensures that the fund's operations comply with internal and external legal requirements. The fund's distributor or the principal underwriter sells fund shares. Mutual funds are required to protect their portfolio securities by placing them with a custodian. The largest custodians are Bank of New York Mellon, J.P. Morgan and State Street Bank and Trust Company (see the Appendix for a list of assets under custody).

# 2.7.3.3 Taxonomy of Mutual Funds

Money Market (MM) Funds

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d121c2c71b70ecbbd13d985f23ec59ae665a1c7f4b72a2e359146e7bbc4639b0.jpg)  
Figure 2.21: The organization of a mutual fund (Adapted from ICI Fact Book [2006]).

There are tax-exempt and taxable fund types. The former invest in securities backed by municipal authorities and state governments. Both securities do not pay federal income tax. Which fund to choose is only a question of the after-tax yield. Tax-exempt funds make sense for investors who face a high tax bracket. In all other cases, taxable funds show a better after-tax yield. Fund sponsors typically offer a retail and an institutional investor series of MM funds.

# Bond Funds

There are many types of bond funds. Bond funds can be tax-exempt or taxable, US and global bonds. In each possible category different factors matter: The creditworthiness of the bond, the maturity of the bonds, the segmentation of global bonds into emerging market bonds and general global bonds and the classification of bonds according to different economic sectors or specific topics. Finally, alternative bond funds use techniques from hedge funds to shape the risk and return profile.

Morningstar adopted in 2012 a new classification system to overcome the excessive number of dimensions that a bond fund can have. The system classifies bonds in the two dimensions creditworthiness (credit quality) and interest-rate sensitivity where each dimension has three classes such as high/medium or low credit quality and limited/moderate/extensive interest sensitivity. That is, each bond is classified in this  $3 \times 3$  matrix. The credit dimension indicates the likelihood that investors will get their invested money back. The interest-rate sensitivity states the impact of changing interest-rates on the value of the bonds.

# Stock Funds

For stock funds the difference between tax-exempt and taxable does not exist since most of their income comes from price appreciation and income from dividends is very low. Categories are US versus global funds, sectors, regions, style, etc. As for bond funds, a  $3 \times 3$  style box from Morningstar exists with size as one dimension and style the other one.

# 2.7.4 Fees for Mutual Funds

# 2.7.4.1 Definitions

The SEC (2008) defines the following components for mutual fund fees. (i) fees paid by the fund out of fund assets to cover the costs of marketing and selling fund shares … (ii) 'distribution fees', including fees that compensate brokers and others who sell fund shares and that pay for advertising, the printing and mailing of prospectuses to new investors,… (iii) 'shareholder service fees' - fees paid to persons who respond to investor inquiries and who provide investors with information about their investments.

The expense ratio is the fund's total annual operating expenses including management fees, distribution (12b-1) fees and other expenses. All fees are expressed as a percentage of average net assets. Other fees include fees related to the selling and purchasing of funds: Back-end sales load is a sales charge investors pay when they redeem mutual funds. Front-end sales is the similar fee when funds are bought. It is generally used by the fund to compensate brokers. Purchase and redemption fees are not the same as the backand front-end sales. They are both paid to the fund. The SEC generally limits redemption fees to 2 percent.

# 2.7.4.2 Share Classes

While different stock classes are used to express different voting rights, different mutual fund classes are used for different customers and different fees. The most prominent classes in the US are the A-, Band C-class.

Class-A shares for example charge a front-end load and have low 12b-1 (distribution)

fees. They are beneficial for long run investors. In Europe the type of share classes can define the client segmentation, specify investment amount and specify the investment strategy. For example:

- AA-class: Admissible for all investors, distribution of earnings.  
- AT-class: Admissible for all investors, blow back of earnings.  
- CA-class: Admissible for qualified investors only, distribution of earnings.  
D-class: Same as CA but blow back of earnings.  
- N-class: Only for clients which possess a mandate contract or an investment contract with the bank.

# 2.7.4.3 TER and Performance

The total expense ratio (TER) is a percentage ratio defined as the ratio between total business expenses and the average net fund value. TER expresses the total of costs and fees that are continuously charged. Business expenses are fees for the fund's board of directors, the asset manager, the custodian bank, administration, distribution, marketing, the calculation agent, audit, and legal and tax authorities.

The following approach is widely used for performance calculations. Consider a period starting at 0 with length  $T$ . The performance  $P$  is defined by:

$$
P \% = \frac {\mathrm {N A V} _ {T} \times f _ {1} \times \dots \times f _ {T}}{\mathrm {N A V} _ {0}} \times 100 \tag{2.17}
$$

with  $f$  the adjustment factor for the payout, such as dividends,

$$
f = \frac {\mathrm {N A V} _ {e x} + \mathrm {B A}}{\mathrm {N A V} _ {e x}},
$$

with  $BA$  the gross payout - that is to say, the gross amount of the earningand capital-gain payout per unit share to the investors, and  $\mathrm{NAV}_{ex}$  the NAV after the payout.

# Example

Consider a NAV at year-end 2005 of CHF 500 million, 2006 earnings of CHF 10 million, and a capital-gain payout of CHF 14 million. The NAV after payments is CHF 490 million and the NAV at the end of 2006 is CHF 515 million. The adjustment factor is

$$
f = \frac {4 9 0 + 1 0 + 1 4}{4 9 0} = 1. 0 4 8 9 8.
$$

This gives the performance for 2006

$$
P = \left(\frac{515\times 1.04898}{500} -1\right) = 8.045\%.
$$

There are several reasons why it is important to measure the performance of a fund correctly: Selection of the best fund, check whether the fund managers do what they promise and a correctly measured performance allows one to check whether the fund manager added value.

The performance formula (2.17) can be rewritten in the effective return form

$$
(1 + P) \mathrm {N A V} _ {0} = \mathrm {N A V} _ {T} \times f _ {1} \times \dots \times f _ {T} = \mathrm {N A V} _ {T} \prod_ {k = 1} ^ {T} \left(1 + \frac {\mathrm {B A} _ {k}}{\mathrm {N A V} _ {e x , k}}\right). \tag {2.18}
$$

If the gross payouts are zero in all periods, then the performance reads

$$
(1 + P) \mathrm {N A V} _ {0} = \mathrm {N A V} _ {T}
$$

with  $P$  the simple effective return. Contrarily, assume that in each period a constant fraction  $g = \frac{\mathrm{BA}}{\mathrm{NAV}_{ex}}$  is paid out. Then,

$$
(1 + P) \mathrm {N A V} _ {0} = \mathrm {N A V} _ {T} (1 + g) ^ {T} \geq \mathrm {N A V} _ {T}.
$$

Since  $(1 + g)^T$  is larger than one, with the same effective return  $P$ , the fund without any payouts achieves a larger final effective value than the fund with payouts.

# Example

The return calculation for funds can be misleading. Consider the following reported annual returns:  $5\%$ ,  $10\%$ ,  $-10\%$ ,  $25\%$ ,  $5\%$ . The arithmetic mean is  $7\%$ . The geometric mean is  $6.41\%$ . How much would an investor earn after 5 years if he or she starts with USD 100?

$$
1 0 0 \times 1. 0 5 \times 1. 1 \times 0. 9 \times 1. 2 5 \times 1. 0 5 = \mathrm {U S D} 1 3 6. 4.
$$

If the fund reports the arithmetic mean, the investor would expect

$$
1 0 0 \times 1. 0 7 5 = \mathrm {U S D} 1 4 0. 2.
$$

Using the geometric mean of  $6.41\%$ , the true value of USD 136.4 follows. Although it is tempting to report the higher arithmetic mean, such a report would be misleading. Some jurisdictions require funds to report returns in the correct geometric way.

# 2.7.5 The European Fund Industry - UCITS

Luxembourg attracts different kinds of funds by providing different vehicles with which to pool their investments. It offers both regulated and non-regulated structures. For regulated fund in Luxembourg, two options are available. First, an 'undertaking for collective investment' (UCI), a category which itself is divided into UCIs whose securities are distributed to the public and UCIs made up of securities that are reserved for institutional

investors. The most common legal form of UCI is a SICAV (Société d'Investissement à Capital Variable) - that is, an open-ended collective investment scheme that is similar to open-ended mutual funds in the US. A SICAV takes the form of a public limited company. Its share capital is - as its name suggests - variable and at any time its value matches the value of the net assets of all the sub-funds. Closed-end funds are referred to as SICAFs. Second, a Société d'Investissement en Capital à Risque (SICAR). These provide a complementary regime to that of UCIs. They are tailor-made for private equity and venture capital investment. There are no investment diversification rules imposed by law and a SICAR may adopt an open-ended or closed-ended structure.

Both schemes are supervised by the Luxembourg financial sector regulator. A main reason for Luxembourg's attractiveness is taxation. Both, SICAV and SICAF investment funds domiciled in Luxembourg are exempt from corporate income tax, capital gains tax, and withholding tax. They are only liable for subscription tax at a rate of 0.05 percent on the fund's net assets. Also, favorable terms apply with regards to withholding tax.

The UCITS - undertakings for collective investment in transferable securities - directives were introduced in 1985. They comprise the main European framework regulating investment funds. Their principal aim is to allow open-ended collective investment schemes to operate freely throughout the EU on the basis of a single authorization from one member state ('European Passport'). Their second objective is the definition of levels of investor protection (investment limits, capital organization, disclosure requirements, asset safe keeping, and fund oversight).

In summary, UCITS funds are open-ended, diversified collective investments in liquid financial assets and are 'product passported' in 27 EU countries.

Total UCITS funds' AuM grew from EUR 3.4 trillion at the end of 2001 to EUR 5.8 trillion by 2010 with a value of EUR 6.8 trillion at the end 2014. Roughly 85 percent of the European investment fund sector's assets are managed within the UCITS framework. On average, 10 percent of European households invest directly in funds: Germany,  $16\%$ ; Italy,  $11\%$ ; Austria,  $11\%$ ; France,  $10\%$ ; Spain,  $7\%$ ; and the UK,  $6\%$ .

There have been five framework initiatives - UCITS I (1985) to UCITS V (2016). Goals of UCITS IV:

- Reduce the administration burden by the introduction of a notification procedure.  
- Increase investor protection by the use of key investor information (KID). KID replaces the simplified prospectus.  
- Increase market efficiency by reducing the waiting period for fund distribution abroad to 10 days.

The Madoff fraud case and the default of Lehman Brothers highlighted some weaknesses in and lack of harmonization of depositary duties and liabilities across different

EU countries leading to UCITS V. It considers the following issues. First, it defines what entities are eligible as depositaries and establishes that they are subject to capital adequacy requirements, ongoing supervision, prudential regulation and some other requirements. Second, client money is segregated from the depositary's own funds. Third, the depositary is confronted with several criteria regarding the holding of assets. Fourth, remuneration is considered. A substantial proportion of remuneration, for example, and at least 50 percent of variable remuneration, shall consist of units in the UCITS funds and be deferred over a period that is appropriate in view of the holding period. Fifth, sanctions shall generally be made public and pecuniary sanctions for legal and natural persons are defined. Finally, measures are imposed to encourage whistle-blowing.

# 2.8 Index Funds and ETFs

The work of Fama on market efficiency was one reason for the rise in the 70s of low-cost and passively managed investing through index funds. Another theoretical milestone in the development of passive management was established by Jensen's (1968) work about the performance of 115 equity mutual funds:

The evidence on mutual fund performance indicates not only that these 115 mutual funds were on average not able to predict security prices well enough to outperform a buy-the-market-and-hold policy, but also that there is very little evidence that any individual fund was able to do significantly better than that which we expected from mere random chance.

A growth analysis of the top ten global asset managers over the past five years confirms this trend. Vanguard with its emphasis on passive products is the strongest growing AM, followed by BlackRock with its passive products forming the iShares family. Both index funds and ETF aim at replicating the performance of their benchmark indices as closely as possible. Issuers and exchanges set forth the diversification opportunities they provide - like mutual funds - to all types of investors at a lower cost as for mutual funds, but also highlight their tax efficiency, transparency, and low management fees. Although actively managed ETFs were launched around twenty years ago their importance remains negligible. One major reason is that actively managed ETFs lose their cost advantage compared to mutual funds. As of June 2012 about 1,200 ETFs existed in the US, including only about 50 that were actively managed.

# Example Core-satellite

Core-satellite approaches are common in many investment processes. They comprise a core of long-term investments with a periphery of more specialist or shorter-term investments. The core is then a passive investment style where index funds or ETFs are

used to implement the passive strategy at low costs (see the following sections for index funds and ETFs). Satellites are, conversely, often actively managed and the hope is that they are only weakly correlated with the core.

We next consider in some detail the construction of different types of indices.

# 2.8.1 Index Construction

Besides the member asset prices, there are four other main factors determining the index value. To calculate the index value the following factors have to be taken into consideration: member weighting, divisor, index return type and value fixing. The general formula for index calculation reads

$$
I = \frac {\sum_ {i = 1} ^ {M} w _ {i} S _ {i}}{D}
$$

where  $M$  is the number of assets in the index,  $S_{i}$  is the price of a tradable unit of asset  $i$ , e.g. the price of a stock,  $w_{i}$  is the weight assigned to the price of that asset and  $D$  is the divisor.

# 2.8.1.1 Weighting

Various methods are used for determining the weight of individual members in the index. Within the same category of members there can be subcategories.

- Market capitalization weighting: The members are weighted proportional to the total market value of the asset issuer, i.e.  $w_{i}$  is dependent on the size of the company for equity. In the equity case this would correspond to the number of outstanding free-floating shares multiplied by the share price. Subgroups of this weighting would be if weights were capped at some level, or that no consideration was taken into free float. This is the most common form of weighting for public indices and the rule for indices such as S&P, FTSE, MSCI and SMI.  
- Equal weighting 1 (Price Weighting): The weight assigned to different assets is the same. As a consequence the price of a tradable unit of the asset will have a determining effect on the weight of an asset in the index. Dow 30 and Nikkei 225 indices are calculated using the equal weighing scheme.  
- Equal weighting 2 (Currency Weighting): The CHF weight assigned to each asset is the same, i.e.  $S_{i}w_{i}$ , is the same for each asset. This means that if CHF 500 is to be invested in a basket of 10 assets, the amount bought of each asset would be CHF 50.  
- Share weighting: The members are weighted proportional to the total number of tradable units issued, i.e.  $w_{i}$  is dependent on the number of the shares outstanding for the equity asset class.
- Attribute weighting: The members are weighted according to their ranking score in the selection process. If our ranking is based on ethical and environmental criteria, and asset Y has a score of 75 and asset X 25, then weight ratio between asset Y and X will be Weight Y / Weight X = 3.  
- Hybrid or Custom weighting: The weighting scheme can be a combination of the above alternatives or be something totally new, maybe based on the request of client.

Free-floating is the portion of total shares held for investment purposes. This is opposite to shares held for strategic purposes, i.e. for control. Some indices are quoted using different weighting schemes, e.g. MSCI. However, the main quoted value is using the market capitalization weighting method.

# Remark:

The difference between the asset weighting scheme and the weight of an asset in the index is as follows. For a price weighted index  $w_{1} = w_{2}$  for asset 1 and asset 2. However if  $S_{1} / S_{2} = 3$  the weight of asset 1 in the index will be 3 times larger than the weight of asset 2.

# 2.8.1.2 Divisor

The divisor is a crucial part of the index calculation. At initiation it is used for normalizing the index value. For instance, the initial SMI divisor on June 1998 was chosen to a value, which normalized the index to 1500. However, the main role of the divisor is to remove the unwanted effects of corporate actions and index member change on the index value. It ensures continuity in the index value in the sense that the change in the index should only stem from the investor sentiment and not originate from "synthetic" changes. Corporate actions, which need to be accounted for by changing the divisor value, are dependent on the weighting scheme used for the index.

An example is the effect of a stock split for

- Market capitalization weighting: The price of stock will be reduced, but the number of free-floating shares will increase. These two effects will be offsetting and no change has to be made to the divisor.  
- Equal weighting 1 (Price Weighting): The stock price reduction will have an effect, but the number of free-floating share has no impact on such a weighting. Therefore, the divisor has to be changed, to a lower value, in order to avoid a discontinuity in the index value.

It is important to have a good understanding of the influence of common corporate actions such as splits, dividends, spin off, merger & acquisition, rights offering, bankruptcy, etc. on the index value so that the index value continuity can be ensured.

# 2.8.1.3 Return Type

How the dividends are handled in the index calculation determines the return type of the index. There are three versions of how dividends can be incorporated into the index value calculations:

- Price return index: No consideration is taken to the dividend amount paid out by the assets. The day-to-day change in the index value reflects the change in the asset prices.  
- Total return index: The full amount for the dividend payments is reflected in the index value. This done by adding the dividend amount on the ex-dividend date to the asset price. Thus, the index value 'acts' as if all the dividend payments were reinvested in the index.  
- Total return index after tax: The dividend amount used in the index calculation is the after tax amount, i.e. the net cash amount. In contrast, in the total return index case the gross dividend amount is used.

# 2.8.1.4 Value Fixing

Another set of rules that characterize an index calculation, is the data values and the frequency, which they are used. An index value is usually calculated in real time or once a day. The values that are needed for index value calculation can be quoted in various versions. For example, the most important value is the asset price. It has to defined weather the value uses is mid prices, bid or ask prices, last trade prices or any other price value provided.

In addition, if the index constituents have a wide geographical span, there are other issues that need to be taken into consideration. Some of the rules that need to defined are: index value quotation currency, source of currency rates, index opening and closing hours, and assets registered on multiple exchanges. For most major indices the quotation is real time and the currency rate used is also real time. The opening hour for the constructed index starts with the opening of the exchange of any index member, and the closing occurs when no index member exchange is open. Having a global index, with constituents from Japan to USA, would mean that the index would be "open" most hours of the day.

# 2.8.2 Capital Weighted Index Funds

Index funds are used to gain access to (global) diversified equity market performance. Traditionally, these indices are constructed using capitalization weights (CWs). In recent years, new types of weights have been considered. These alternative methods are often called smart beta approaches. The rationale for CW is the CAPM: all investors hold the CW market portfolio. The second theoretical input is the efficient market hypothesis (EMH). These two theoretical streams were the foundation for cost effective, passive investment in CW instruments: McQuown developed the first index fund - at Wells Fargo

-in 1970.

One must distinguish between the theoretical index and a strategy that replicates the theoretical index using securities. The theoretical index is not an investable asset or security. If we set  $\phi_{i,t}$  for the weight of asset  $i$  in the index at time  $t$ , with  $R_{i,t}$  the gross return of the asset in the period  $t - 1$  to  $t$ , the index value  $I_{t}$  satisfies the dynamics

$$
I _ {t} = I _ {t - 1} \left(\sum_ {k = 1} ^ {N} \phi_ {k, t} R _ {k, t}\right), I _ {0} = 1 0 0. \tag {2.19}
$$

The value of the index tomorrow is equal to the present value times the return of each stock generated until tomorrow weighted by the asset weight. The index fund  $F_{t}$  aims to replicate (2.19) by investing in the stocks. At each date  $t$  the fund has a number  $n_{k,t}$  of stocks  $k$  and  $F_{t}$  is equal to the sum of all stocks times their price  $P_{k,t}$ . The difference between the values  $F_{t}$  and  $I_{t}$  is the tracking error where the accuracy of the replication is often measured with the volatility of the tracking error.

# Example

The tracking error (TE) can be calculated directly or indirectly. Consider the following returns for a portfolio and its benchmark (market portfolio).

<table><tr><td>Period [month]</td><td>Portfolio</td><td>Market</td><td>Return difference</td></tr><tr><td>1</td><td>0.37%</td><td>0.53%</td><td>-0.16%</td></tr><tr><td>2</td><td>-1.15%</td><td>-1.36%</td><td>0.21%</td></tr><tr><td>3</td><td>-1.81%</td><td>-1.43%</td><td>-0.38%</td></tr><tr><td>4</td><td>-0.04%</td><td>-0.34%</td><td>0.30%</td></tr><tr><td>5</td><td>-1.22%</td><td>-1.59%</td><td>0.37%</td></tr><tr><td>6</td><td>0.08%</td><td>-0.30%</td><td>0.37%</td></tr><tr><td>7</td><td>1.18%</td><td>1.12%</td><td>0.07%</td></tr><tr><td>8</td><td>-0.52%</td><td>-0.39%</td><td>-0.13%</td></tr><tr><td>9</td><td>1.83%</td><td>1.94%</td><td>-0.11%</td></tr><tr><td>10</td><td>-0.70%</td><td>-0.36%</td><td>-0.33%</td></tr><tr><td>11</td><td>-0.66%</td><td>-0.60%</td><td>-0.06%</td></tr><tr><td>12</td><td>-1.60%</td><td>-1.85%</td><td>0.25%</td></tr><tr><td>σ</td><td>1.10%</td><td>1.14%</td><td>0.27%</td></tr><tr><td>σ1y = σ√12</td><td>3.80%</td><td>3.93%</td><td>0.92%</td></tr></table>

Table 2.16: Direct tracking error calculation. The TE is  $0.92\%$

The indirect method uses the following replication of the tracking error. The TE is equal to buying the portfolio and selling the benchmark. We can use the general variance formula for two random variables and choosing the weights  $\phi_1 = +1$  and  $\phi_2 = -1$ :

$$
\sigma^ {2} = \sigma_ {1} ^ {2} + \sigma_ {2} ^ {2} - 2 \rho \sigma_ {1} \sigma_ {2}.
$$

The TE is equal to  $\sigma$ . The covariance of the two time series is 0.011 percent. Dividing by the volatilities of the two time series the correlation factor  $\rho = 0.89$  follows. This gives the TE per period and scaling it with the square root law the annualized TE of  $0.92\%$  follows.

# Example

This example follows ZKB (2013). Examples of capital-weighted indices include the S&P 500, FTSO, MSCI, and SMI. Other indices use equal weighting (EW). Dow Jones 30 and Nikkei 225 are both equally weighted indices. Other types include share weighting and attribute weighting. In attribute weighting the weights are chosen according to their ranking score in the selection process. If our ranking is based on ethical and environmental criteria, and asset  $Y$  has a score of 75 and asset  $X$  of 25, then the weight ratio between asset  $Y$  and  $X$  will be 3.

The divisor is a crucial part of the index calculation. At initiation it is used for normalizing the index value. The initial SMI divisor in June 1998 was chosen as a value that normalized the index to 1,500. However, the main role of the divisor is to remove the unwanted effects of corporate actions and index member changes on the index value. It ensures continuity in the index value in the sense that the change in the index should only stem from investor sentiment and not originate from 'synthetic' changes. The impact of corporate actions depends on the weighting scheme used for the index. Consider a stock split for an index with:

- Market capitalization weighting - The price of the stock will be reduced and the number of free floating shares increases. These two effects will be offsetting and no change has to be made to the divisor.  
- Equal weighting (price weighting) - The stock price reduction will have an effect, but the number of free-floating shares has no impact on such a weighting. Therefore, the divisor has to be changed to a lower value in order to avoid a discontinuity in the index value.

How the dividends are handled in the index calculation determines the return type of the index. There are three versions of how dividends can be incorporated into the index value calculations:

- Price return index - No consideration is taken of the dividend amount paid out by the assets. The day-to-day change in the index value reflects the change in the asset prices.  
- Total return index - The full amount for the dividend payments is reflected in the index value. This is done by adding the dividend amount on the ex-dividend date to the asset price. Thus, the index value acts as if all the dividend payments were reinvested in the index.  
- Total return index after tax - the dividend amount used in the index calculation is the after tax amount; that is to say, the net cash amount.

The relative weights  $\phi$  are, for a CW index, defined by

$$
\phi_ {k, t} = \frac {M _ {k , t} P _ {k , t}}{\sum_ {j = 1} ^ {N} M _ {j , t} P _ {j , t}} \tag {2.20}
$$

with  $M$  the number of outstanding shares. The numerator is the market capitalization of stock  $k$  and the denominator is the market capitalization of the index. The weights  $\phi$  can change as follows, where we write MC for the index market capitalization:

$$
\Delta \phi_ {k, t} = \frac {\Delta M _ {k , t} P _ {k , t}}{M C} + \frac {\Delta P _ {k , t} M _ {k , t}}{M C} - \frac {\Delta M _ {k , t} P _ {k , t} \Delta M C}{(M C) ^ {2}}. \tag {2.21}
$$

The three possible changes of the weights reflect the changes in the outstanding shares, price changes and changes in the index market capitalization. The second change is the most important one. The two others are more constant in nature. If the market shares are constant over time, the same holds true for the number of shares  $N$  that are needed to construct the fund. This is one of the main reasons why CW is often used: the constancy of the shares implies low trading costs. This reason and the simplicity of the CW approach have made it the favorite index construction method.

# 2.8.3 Risk Weighted Index Funds

There are reasons why one searches for alternatives to the CW approach: The rejection of the CAPM and the procyclical behavior strategy of CW. Suppose that one single stock in the CW index formula (2.20) is outperforming all others at a very high rate. Then, the weights will be concentrated over time in this single stock. Diversification is lost and the index construction turned into a concentration of idiosyncratic risk with the respective large drawdown risk of such a construction in the past.

Alternative weighting schemes - smart beta approaches - weight the indices not by their capital weights but either by other weights, which should measure the economic size of companies better (fundamental indexation), or by risk-based indexation. Most

often, investors will use a mixture of CW and alternative schemes. A first requirement for such a mix is that the two approaches show a low correlation. Fundamental indexation serves the purpose of generating alpha to dominate the CW approach while risk-based constructions focus on diversification.

Examples of risk weighted allocations are EW, MV, MDP, ERC and MDP. Roncalli (2014) compares the different methods for the Euro Stoxx 50 index using data from December 31, 1992, to September 28, 2012. He computes the empirical covariance matrix using daily return and a one-year, rolling window; rebalancing takes place on the first trading date of each month and all risk-based indices are computed daily as a price index, see Table 2.17.

<table><tr><td></td><td>CW</td><td>EW</td><td>MV</td><td>MDP</td><td>ERC</td></tr><tr><td>Expected return p.a.</td><td>4.47</td><td>6.92</td><td>7.36</td><td>10.15</td><td>8.13</td></tr><tr><td>Volatility</td><td>22.86</td><td>23.05</td><td>17.57</td><td>20.12</td><td>21.13</td></tr><tr><td>Sharpe ratio</td><td>0.05</td><td>0.16</td><td>0.23</td><td>0.34</td><td>0.23</td></tr><tr><td>Information ratio</td><td>-</td><td>0.56</td><td>0.19</td><td>0.42</td><td>0.62</td></tr><tr><td>Max. drawdown</td><td>-66.88</td><td>-61.67</td><td>-56.04</td><td>-50.21</td><td>-56.85</td></tr></table>

Table 2.17: Statistics for the different index constructions of the Euro Stoxx 50. CW is capital weighting, EW is equal weighting, MV is mean-variance optimal, MDP is most diversified portfolio, and ERC is equal risk contribution (Roncalli [2014]).

# 2.8.4 ETFs

Exchange traded funds (ETFs) are a mixture of openand closed-end funds. The main source is Deville (2007). They are hybrid instruments which combine the advantages of both fund types. Mutual funds must buy back their units for cash, with the disadvantage that investors can only trade once a day at the NAV computed after the close. Furthermore, the trustee needs to keep a fraction of the portfolio invested in cash to meet the possible redemption outflows. Closed-end funds avoid this cash problem. Since it is not possible to create or redeem fund shares, there is no possibility to react to changes in demand for the shares in such funds: If there are strong shifts in demand, price reactions follow such as significant premiums or discounts with respect to their NAV.

ETF trade on the stock market and shares can be created or redeemed directly from the fund due to the in-kind creation and redemption process.

The in-kind process idea is due to Nathan Most. ETFs are organized as commodity warehouse receipts with the physicals delivered and stored, whereas only the receipts are traded, although holders of the receipt can take delivery. This 'in-kind' - securities are traded for securities - creation and redemption principle has been extended from commodities to stock baskets, see Figure 2.22.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/23b791044d55883c852f8cf4bb79217fc1b74407190f1eeec33925919a781eee.jpg)  
Figure 2.22: Primary and secondary ETF market structure where the 'in-kind' process for the creation and redemption of ETF shares is shownn. Market makers and institutional investors can deposit the stock basket underlying an index with the fund trustee and receive fund shares in return. These created shares can be traded on an exchange as simple stocks or later redeemed for the stock basket then making up the underlying index. Market makers purchase the basket of securities that replicate the ETF index and deliver them to the ETF sponsor. In exchange each market maker receives ETF creation units (50,000 or multiples thereof). The transaction between the market maker and the ETF sponsor takes places in the primary market. Investors who buy and sell the ETF then trade in the secondary market through brokers on exchanges. (Adapted from Deville [2007] and Ramaswamy [2011]).

It illustrates the dual structure of the ETF trading process with a primary market open to institutional investors (AP) for the creation and redemption of ETF shares directly from the fund. The ETF shares are traded on a secondary market. The performance earned by an investor who creates new shares and redeems them later is equal to the index return less fees even if the composition of the index has changed in the meantime. Only authorized participants can create new shares of specified minimal amounts (creation units). They deposit the respective stock basket plus an amount of cash into the fund and receive the corresponding number of shares in return. ETF share are not individually redeemable. Investors who want to redeem are offered the portfolio of stocks that make up the underlying index plus a cash amount in return for creation units.

Since ETFs are negotiated on two markets - primary and secondary market - it has

two prices: the NAV of the shares in the primary market and their market price in the secondary market. These two prices may deviate from each other if there is a pressure to sell or buy. The 'in-kind' creation and redemption helps market makers to absorb such liquidity shocks on the secondary market, either by redeeming outstanding or by creating shares. It also ensures that departures between the two prices are not too large since authorized participants in the primary market could arbitrage any sizable differences between the ETF and the underlying index component stocks. If the secondary market price is below the NAV, APs could buy cheap ETFs in the secondary market, take on a short position in the underlying index stocks and, then ask the fund manager to redeem the ETFs for the stock basket before closing the short position at a profit. Since ETF fund manager do not need to sell any stocks on the exchange to meet redemptions, they can fully invest their portfolio and the creations do not yield any additional costly trading within the fund. Finally, in the US, 'in-kind' operations are a nontaxable event.

Most ETFs track an index and are passively managed. ETFs generally provide diversification, low expense ratios, and the tax efficiency of index funds, while still maintaining all the features of ordinary stock, such as limit orders, short selling, and options. ETFs can be used as a long-term investment for asset allocation purposes and also to implement market-timing investment strategies. All of these features rely on the above described specific 'in-kind' creation and redemption principle. ETF are constructed by index providers, exchanges, or index fund managers (the originators).

The costs of an ETF have two components: transaction costs and total expense ratio (TER). Transaction costs are divided into explicit and implicit costs. Explicit transaction costs include fees, charges, and taxes for the settlement by the bank and the exchange. Implied costs are bid-ask spreads and costs incurred due to adverse market movements. ETFs can be constructed by direct replication (physical) or by using swap-backed construction (synthetic). Physicaal replication is a transparent approach with low counterparty risk (which occurs due to securities lending). Physical replication can be expensive for tracking broad emerging market equity or fixed income indices. Commodities ETFs and leveraged ETFs not necessarily employ full replication because the physical assets are either difficult to store or to leverage. Referring only to a subset of the underlying index securities for physical replication leads to a significant tracking error in returns between the ETF and the index. In a swap-backed construction, the performance of a basket is exchanged between the ETF and the swap counterparty.

Trends in ETF investment arise from regulation and investors' desire. From a regulatory perspective there has been barriers for active managers due to regulations by Retail Distribution Review (RDR) in UK and MiFID II in the euro zone. But growth in passive strategies will also be driven by cost transparency and the search for cheap investments. But also new uses for ETFs will emerge. Institutions will use them to get access to specific asset class or geographic exposures and retail investors will invest in ETFs as a lower-cost alternative to mutual funds and UCITS funds. Finally, trends in

the last year are to construct ETF not on an CW basis but on a risk weighted one using risk parity methods and to focus on risk factors instead of asset classes as underlying instruments.

# 2.8.4.1 Unfunded Swap-Based Approach

In the swap-based approach one invests indirectly in a basket by achieving the index performance via a total return swap (TRS), see Figure 2.23. The ETF sponsor pays cash to the swap counterparty and indicates which index should matter for the ETF. The swap counterparty is often the parent investment bank of the ETF sponsor. The TRS swaps the index return against a basket return - that is to say, the ETF sponsor receives the desired index return needed for the ETF and delivers a basket return to the swap counterparty. The basket should be close to the index; the closer it is the lower is the tracking error borne by the swap counterparty. The swap counterparty delivers a basket of securities to the ETF sponsor as collateral for the cash paid.

This approach minimizes the tracking error for the ETF investor and enables more underlyings to be accessed. The basket of securities used as collateral is typically not related to the basket delivered to the swap counterparty, which mimics the index. Why should an investment bank, as swap counterparty, enter into such a contract, see the next example.

# Example

Assume that three securities -  $S_{1}, S_{2}$ , and  $S_{3}$  - make up an Index  $I$ . The weights of  $S_{1}$  and  $S_{2}$  are each  $48\%$ , and  $S_{3}$  contributes  $4\%$  to the index. The ETF sponsor delivers the basket consisting of assets  $S_{1}$  and  $S_{2}$  only to the swap counterparty. The missing  $S_{3}$ -asset is the tracking error source. The swap counterparty (the investment bank (IB)) delivers to the ETF sponsor seven securities,  $C_{1}, \ldots, C_{7}$ , as collateral. These assets are in the inventory of the IB due either to its market-making activities or the issuance of derivatives, i.e. business that is not related to ETFs. When these securities  $C_{i}$  are less liquid, they will have to be funded either in unsecured markets or in repo markets with deep haircuts. The IB has, for example, to pay  $120\%$  for a security  $C_{i}$  that is worth only  $100\%$  at a given date. Transferring these securities to the ETF sponsor, the IB may benefit from reduced warehousing costs for these assets. Part of these cost savings may then be passed on to the ETF investors through a lower total expense ratio for the fund holdings. The cost savings accruing to the investment banking activities can be directly linked to the quality of the collateral assets transferred to the ETF sponsor. A second possible benefit for the IB is lower regulatory and internal economic capital requirements since the regulatory charge for less liquid securities  $C_{i}$  is larger than for the more liquid securities  $S_{1}$  and  $S_{2}$  in the basket delivered by the ETF sponsor. Summarizing, a synthetic swap has a positive impact on the security inventory costs of

the IB due to non-ETF business or regulatory capital or internal economic risk capital charges.

The drawbacks of synthetic swaps are counterparty risk and documentation requirements (International Swaps and Derivatives Association [ISDA]).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3009263bbd8172e1dd88b87122aab92b0e7c16cc96ca7670cdeddbac1d21d8b2.jpg)  
Figure 2.23: Unfunded swap ETF structure (Ramaswamy [2011]).

# 2.8.4.2 ETFs for Different Asset Classes

The first and most popular ETFs track broad stock indices, sector indices or specific niche areas like green power. The evolution of ETFs by region between 2010 and 2013 (World Federation of Echanges [2014]) shows the dominance of the Americas with around  $90\%$  of the traded ETF volumes, followed by Asia and Europe, both with  $5\%$  and  $6\%$ . The size in Europe declined in the period whereas the size in Asia doubled. The worldwide ETF assets in USD bn were 9.670 in 2010 and 11,893 in 2013.

Bond ETFs face typically face huge demand when stock markets are weak such as when recessions occur. An asset rotation from stocks to bonds is often observed in such cases. Figure 2.24 shows bond inflows of USD 800 billion and equity redemption in long-only equities (LO equities) after the GFC. In the last years an opposite rotation began due to close-to-zero interest rates.

Commodity ETFs invest in oil, precious metals, agricultural products, etc. The idea of a gold ETF was conceptualized in India in 2002. At the end of 2012 the SPDR Gold

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/21bd9d758eadb1b10998cc341a9c6265da798269a6fedc4455e47872d31cd71c.jpg)  
Figure 2.24: Bond inflows and equity redemptions (BoA Merill Lynch Global Investment Strategy, EPFR Global [2013]).

Shares ETF was the second-largest ETF. Rydex Investments launched 2005 the first currency ETF. These funds are total return products where the investor gets access to the FX spot change, local institutional interest rates, and a collateral yield.

Actively managed ETFs were offered in the United States since 2008. Initially, they grew faster than index ETFs did in their three years. But the growth rate was not sustainable: The number of actively managed ETFs is not growing since several years. Many academic studies question the value of active ETF management since they face the same skill and luck issue as mutual fund and much higher costs than static ETFs.

# 2.8.4.3 Leveraged ETFs (LETFs)

Leveraged ETFs (LETFs) or inverse leveraged ETFs use derivatives to seek a return that corresponds to a multiple of the unleveraged ETF. LETFs require financial engineering techniques in their construction and the life cycle management to achieve the desired return. Trading future contracts is a common way to construct leveraged ETFs. Rebalancing and re-indexing of LETFs can be costly in turbulent markets. LETFs deliver positive or negative multiples of a benchmark's return on a daily basis. Several empirical studies show that LETFs deviate significantly from their underlying benchmark. This tracking error has two main causes - a compounding effect and a rebalancing effect, Dobi and Avellaneda (2012).

# Example

Consider a LETF with positive leverage factor 2 (bullish leverage). We follow Dobi and Avellaneda (2012). There are three time periods 0, 1, 2 in the example (see Table 2.18). The index value of the ETF starts at 100, loses  $10\%$ , and then gains  $10\%$ .

<table><tr><td>Time Grid</td><td>t0</td><td>t1-</td><td>t1+</td><td>t2-</td><td>t2+</td></tr><tr><td>Index Value</td><td>100</td><td>90</td><td></td><td>99</td><td></td></tr><tr><td>AuM</td><td>1,000</td><td>800</td><td></td><td>960</td><td></td></tr><tr><td>TRS exposure needed</td><td>2,000</td><td>1,600</td><td></td><td>1,920</td><td></td></tr><tr><td>Notional TRS</td><td>2,000</td><td>1,800</td><td>1,6000</td><td>1,760</td><td>1,920</td></tr><tr><td>Exposure adjustment</td><td>0</td><td>-</td><td>-200</td><td>-</td><td>+160</td></tr></table>

Table 2.18: Data for the leveraged ETF example.  $t_{k, - }$  denotes the time  $t_k$  before adjustment of the TRS and  $t_{k, - }$  after the adjustment of TRS.

The initial AuM is USD 1,000 at day 0, and the AuM is USD 800 at day 1 due to the  $10\%$  drop on day 1:

$$
\mathrm {U S D} 8 0 0 = 1, 0 0 0 (1 - 2 \times 0. 1).
$$

This implies a required TRS exposure of  $2 \times 800 = \mathrm{USD1,600}$ . The notional value of the TRS from day 0 has become, at day 1,

$$
\mathrm {U S D} 2, 0 0 0 \times (1 - 0. 1) = 1, 8 0 0.
$$

This is the exposure before adjustment. Since the exposure needed at day 1 is USD 1,600, the swap counterparty must sell (short the synthetic stock) USD  $200 = 1,800 - 1,600$  of TRS. Doing the same calculation for day 2, the AuM is USD 960 and the exposure needed is USD 1,920 at day 2. Similarly, on day 2 the swap counterparty must buy a TRS amount of USD  $160 = 1,920 - 1,760$ , where USD  $1,760 = 1,600 \times (1 + 0.1)$  is the exposure before adjustment.

# Example

We consider the compounding problem for a LETF. Fix an index and a two-time LETF, both beginning at 100. Assume that the index first rises  $10\%$  to 110 and then drops back to 100, a drop of  $9.09\%$ . The LETF will first rise  $20\%$  and then drop  $18.18\% = 2 \times 9.09\%$ . But  $18.18\% 120 = 21.82$ . Therefore, while the index has value 100, the LETF is at 98.18, which implies a loss of  $1.82\%$ . Such losses always occur for LETF when the

underlying index value changes direction. The more frequent such directional changes are - hence it is a volatility effect - the more pronounced the losses.

These examples illustrate that a LETF always rebalances in the same direction as the underlying index, regardless of whether the LETF is a bullish one (positive leverage) or bearish one (negative leverage). The fund always buys high and sells low in order to maintain a constant leverage factor. A similar results hold for inverse LETFs.

# 2.8.5 Evolution of Expense Ratios

Figure 2.25 shows the evolution of expense ratios for actively managed funds and index funds.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b72a6a31cac58b86826d5813f7d965148ab7379a05ae090ad7ebeacad55de7c9.jpg)  
Figure 2.25: Expense ratios of actively managed (upper lines) and index funds (lower lines) - bps p.a. (Investment Company Institute and Lipper [2014]).

The trend of decreasing fees continues. But for the index funds a bottom level seems to be close. Table 2.19 also considers ETF fees.

# 2.9 Alternative Investments (AI) - Insurance-Linked Investments

AIs are often defined as investments in asset classes other than stocks, bonds, commodities, currencies, and cash. These investments can be illiquid. We only consider insurance

<table><tr><td></td><td>Equity</td><td>Bonds</td></tr><tr><td>Mutual funds (*)</td><td>0.74%</td><td>0.61%</td></tr><tr><td>Index funds (*)</td><td>0.12%</td><td>0.11%</td></tr><tr><td>ETFs (**, #)</td><td>0.49%</td><td>0.25%</td></tr><tr><td>ETF core (**, +)</td><td>0.09%</td><td>0.09%</td></tr></table>

Table 2.19: Fees p.a. in bps in 2013  $(^{*})$  Investment Company Institute, Lipper;  $(^{**})$  DB Tracker;  $(\sharp)$  Barclays;  $(+)$  BlackRock).

linked securities in the sequel. It is estimated that alternative investments will reach to USD 13 trillion by 2020 up from USD 6.9 trillion in 2014. One expects that more and more investors can access AIs as regulators begin to allow them access to specific regulated vehicles such as alternative UCITS funds in Europe and alternative mutual funds in the US.

This section is based on LGT (2014). Insurance-linked investments are based on the events of life insurers, and of non-life insurers such as insurers against natural catastrophes for example. The main products are insurance-linked securities (ILS such as CAT bonds) and collateralized reinsurance investments (CRI). The size, in global terms, of this relatively young market is USD 200 bn as of 2014. Regulation plays a significant role in the use of alternatives. The creditworthiness of the insurance and reinsurance company require large capital basis' from a regulatory perspective for the catastrophe cases. To reduce the capital charge under Solvency II, the catastrophe part of the risks is transferred to the capital markets using ILS and CRI.

# 2.9.0.1 ILS

Insurance buyers such as primary insurers, reinsurers, governments, and corporates enter into a contract with a special purpose vehicle (SPV). They pay a premium to the SPV and receive insurance cover in return. The SPV finances the insurance cover with the principal paid by investors. The principal is returned at the end of the contract if no event has occurred. The investor receives, in excess to the principal payback, the premium and a collateral yield.

An example is the catastrophe or CAT bond 'Muteki'. Muteki SPV provided the insurance buyer Munich Re with protection against Japanese earthquake losses. Central to ILS investing is the description of the events. The description has to be transparent, unambiguous, measurable, verifiable, and comprehensive. The parametrization in Muteki is carried out using parameters from the 1,000 observatories located in Japan that use seismographs. 'Ground acceleration' is used to calculate the value of the CAT bond index. This determines whether a payout from the investors to the insurance protection buyers is due.<sup>7</sup> Figure 2.26 shows the peak ground velocities measured during the 11

March, 2011 earthquake. The star indicates the epicenter; the regions with the highest ground velocities also experienced the related tsunami.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/df076c17040fd2e9ed156d87b26b93dc45c0a6565a31ed4e2417234c780ccf84.jpg)  
Figure 2.26: Ground velocities measured by the Japan's 1,000 seismological observatories during the earthquake of 11 March, 2011, which also caused a huge tsunami and almost 20,000 fatalities (Kyoshin [2011]).

The insurance industry lost an estimated USD 30-35 billion. The ground acceleration data became available on 25 March, 2015. Multiplying the ground velocity chart by the weight-per-station chart of Munich Re implied an index level for the CAT bond of 1,815 points. This index level led to a full payout from the investors to the insurance buyer since the trigger level - that is to say, the level of the index at which a payout starts to be positive - of 984 was exceeded and also because the exhaustion level of 1,420 points was breached. Hence, investors in this CAT bond suffered a 100 percent loss.

# 2.9.0.2 CRI

In collateralized reinsurance investments (CRIs) the same insurance protection buyers as for ILS buy insurance cover from an SPV in exchange for a premium. The SPV hands over the premium and collateral yield to the investor. The investor pays, in cases where he receives proof of loss, the loss payment to the SPV. Between the investor and the insurance buyer a letter of credit is set up to guarantee the potential loss payment. Table 2.20 summarizes ILS and CRI product specifications. The ILS pays out if an event is realized and triggers are met. Then the bond pays out. For the CRI, if and event is

<table><tr><td>Parameter</td><td>ILS</td><td>CRI</td></tr><tr><td>Wrapping</td><td>Fixed-income security</td><td>Customized contract</td></tr><tr><td>Return</td><td>Collateral yield + premium</td><td>Collateral yield + premium</td></tr><tr><td>Term</td><td>12 to 60 months</td><td>6 to 18 months</td></tr><tr><td>Size</td><td>USD 2 to 500 mn</td><td>USD 2 to 50 mn</td></tr><tr><td>Liquidity</td><td>Tradable asset; liquid</td><td>Non-tradable asset</td></tr><tr><td>Market size for non-life risk (2014)</td><td>USD 24 bn</td><td>USD 35 bn</td></tr></table>

Table 2.20: Comparison between ILS and CRI investments (LGT [2014]).

realized and triggers are met, the investor makes a loss payment.

ILS and CRI comprise 13 percent and 18 percent, respectively, of total reinsurance investments. The remainders are traditional uncollateralized reinsurance investments. The cumulative issuance volume of CAT bonds and ILS started in 1995, reached 20 bn in 2007, 40 bn in 2010 and 70 bn in 2015. Figure 2.27 shows the average catastrophe bond and ILS expected loss and coupon by year.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/113ca17095609b23cc2cebcc171025635fc9b2f0f52e58e798a75f8adbc0cb87.jpg)  
Figure 2.27: Average expected coupon and average expected loss of CAT bonds and ILS issuance by year (artemis.com [2015]).

The correlation with traditional asset classes are smaller than comparable correlations

<table><tr><td></td><td>ILS</td><td>Govt bonds</td><td>Corporate bonds</td><td>Equities</td></tr><tr><td>ILS</td><td>100%</td><td></td><td></td><td></td></tr><tr><td>Govt bonds</td><td>8%</td><td>100%</td><td></td><td></td></tr><tr><td>Corporate bonds</td><td>25%</td><td>35%</td><td>100%</td><td></td></tr><tr><td>Equities</td><td>23%</td><td>-22%</td><td>63%</td><td>100%</td></tr></table>

Table 2.21: Correlation matrix for different asset classes. Monthly data in USD from 31 Dec 2003 until 30 Nov 2014 (LGT [2014], Barclays Capital, Citigroup Index, Bloomberg).

between bonds and stocks, see Table 2.21. Nevertheless, correlation is weakly positive. This is due to the fact that catastrophe events always have an impact on firm value in both directions. The correlation with government bonds is much less affected and would become stronger if a catastrophe event had a significant impact on the entire economy of a nation.

# 2.10 Private Markets

Private markets (PM) compared to public markets are characterized as follows. First, the assets to invest are not publicly traded. Second, shares can only be bought and sold in large quantities. Third, information about the company where investment takes place is more detailed than in public markets but only accessible for shareholders. Fourth, shareholders are typically heavily involved and hold often a majority stake in the company. This means that a private equity firm such as The Blackstone Group not only buys shares for the investors but is heavily involved in the management of the company.<sup>9</sup> Fifth, PM transactions are characterized by significant access to capital and to networks with strong expertise.

The evolution of PM can roughly classified in three periods. In the area 1970-1990 private markets meant emergence of leveraged buyouts focused on the US and in the retail, chemical and manufacturing sectors. Such leveraged buyouts (LBO) mean to buy a company using a combination of equity and debt where the company's cash flow is used to repay the borrowed money. Debt is used since it costs of capital are lower than for equity. Interest payments reduce the corporate income tax liability but dividend payments based on equity do not. The use of leveraged buyouts led to several defaults of firms since their debt ratio was too high. This led banks to require lower debt-to-equity ratios. In the period 1990-2010 private equity became broader in the industries they invested in (healthcare, education) and PM became a global activity. In the last period starting after the GFC PM became broader with three pillars: Debt, real estate and infrastructure.

The low interest rate environments made private markets attractive for investors such as pension funds which before the GFC did not invest in these markets. A study of Towers Watson in 2017 highlighted that  $94\%$  of the actual PM investors will increase or maintain their private market allocations in the longer-term. The AuM in PM steadily increased from 2006 USD 1.5 tr to more than USD 4 tr in 2017. Dry powder however did not increase in the same period but dropped from around 40 percent before the GFC to values between 30 and 35 percent in the last years. Dry powder refers to highly liquid securities. If deal activity falls and dry powder accumulate a risky situation can emerge when investors adds pressure to the PM firm to deploy that capital, i.e. doing transactions they might not otherwise do.

A second observation related PM and public markets in the last 25 years. First, the number of publicly listed firms dropped from 7'322 in 1996 to 3'671 in 2016 (Credit Suisse, Doldge et al. (2016)) and second, private firms stay private longer or even forever. Facebook for example was founded 2004 and had its IPO in 2012.

The valuation of share in PM and public markets are in 2018 both at historic highs. The S&P 500 index increased by a factor of almost 2.5 in the last 6 years and EV/EBITDA in PM also increased around 40 percent in the same period for value 14x for large caps and 12x for small and mid caps (Sources: S&P and Partners Group (2018)).

Figure 2.28 shows that operational value creation drives performance more than financial development which is the opposite compared to the Leveraged Buyout period.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/e2384e7830f46d1026fe8149c3615792b5ee7101abc6e8c3fa2df598b809708b.jpg)  
Figure 2.28: Drivers of performance in PM. (Partners Group [2017]).

A further significant tendency of investor is abstain from excessive diversification but to search high conviction portfolios. Excessive diversification was a result of lack of transparency whereas high conviction is the result of experiences and successful selection of the investments. Typically, in the past institutional investor spread their PM investments among hundreds of assets. Today, the most successful PM firms see the investment spreads only across several dozen of assets.

Comparing return in PM after the GFC with public markets, roughly PM have a 3 to 4 percent average higher return than their public counter parts in the equity, debt, real estate and infrastructure investments and considering maximum drawdowns in the period 2000-2015, the figures for PM are between 20 and 30 percent lower in the above four classes compared to the public counter parts.

Some major players in the PM start to offer part of their PM offering to wealthy private clients or affluent clients. This requires to transform some of the PM offerings into public ones. Since many investors became familiar with PM in the last years they increased their allocations and invest globally. This requires PM firms to consider portfolio construction techniques on a more sophisticated level than in the past.

# 2.11 Hedge Funds

# 2.11.1 What is a hedge fund (HF)?

HFs allow for private placement collective investments for mostly qualified investors. HFs are an investment strategy and not an asset class in their own right since they often trade in common liquid asset classes. $^{10}$  HFs often use short positions, derivatives, and leverage in their strategies. From a regulatory and tax perspective, HFs were often offshore domiciled on certain islands/countries that offer tax advantages or have low regulation standards. But regulation of hedge funds is changing. But since 2012, HFs with assets exceeding USD 150 million have to register and report information to the SEC. $^{11}$  HFs have to satisfy less stringent disclosure rules than mutual funds.

HFs often have a limited number of wealthy investors. If a HF restricts the number of investors it is not a registered investment company. It is then in the US exempt from most parts of the Investment Company Act Of 1940 (the 40-Act). Most HFs in the US have a limited-partnership structure. The limitation of the number of investors automatically increases the minimum investment amount to USD 1 million or more. Many HFs do not allow investors to redeem their money immediately. The reason are short positions of the funds. To reduce this risk, HF needs to pay margins. If short positions

<sup>10</sup>The main sources are the hedge fund review of Getmansky, Lee, and Lo (2015) and Ang (2013).  
<sup>11</sup>Fatca, the Foreign Account Tax Compliance Act, is an US extraterritorial regime of hedge fund regulation. It requires all non-US hedge funds to report information on their US clients. Europe's Alternative Investment Fund Managers Directive (AIFMD) requires information by any fund manager independent where they are based if they sell to an EU-based investor.

increase, HFs need to add more and more margin and would then eventually face liquidity problems if at the same time investors redeem their money. Mutual funds are not allowed to earn non-linear fees, while most HFs do charge a flat management fee and a performance fee (rule 2/20 for  $2\%$  management fee,  $20\%$  performance fee). The business of running a hedge fund has become more expensive due to the increased regulatory burden. KPMG (2013) outline the following figures for the average set-up costs: USD 700,000 for a small fund manager, USD 6 million for a medium-sized one, and USD 14 million for the largest. In all, KPMG estimated hedge funds had spent USD 3 billion meeting compliance costs associated with new regulation since 2008 - equating to, roughly, a 10 per cent increase in their annual operating costs. KPMG (2013).

HFs can face losses due to their construction or the market structure even in cases when there are no specific market events. As Khandani and Lo (2007) state, quantitative HFs faced a perfect financial storm in August 2007 in a normal market environment. The Global Alpha Fund, managed by Goldman Sachs Asset Management, lost 30 percent in a few days although it claimed to be designed for low volatility and low correlated strategies. The HF received an injection of USD 3 billion to stabilize it.

# 2.11.2 Hedge Fund Industry

The first HF was set up by Jones in 1949. This fund was based on three principles. First, it was not transparent how Jones was managing the fund. Second, there was a performance fee of 20 percent, but no management fee. Third, the fund was set up as a non-public fund. This framework is still applied by most HFs today.

The largest HF in 2014, 2017, 209 are shown in Figure 2.22. Total HF size in 2014 was USD 2.85 trillion versus USD 2.6 trillion in 2013. The average growth in HF assets from 1990 to 2012 was roughly 14 percent per year. The decrease in AuM after the GFC was fully recovered six years later. The losses incurred during the GFC were around 19 percent, which is only around half the losses of some major stock market indices. In the period 2009 to 2012, HF performance was lower than the S&P 500, ranging between 4.8 percent and 9.8 percent on an annual basis.

The decreases in AuM during the GFC and the European debt crisis from USD 2.1 tr to 1.5 tr show that investors allocate money pro-cyclically to HFs, similar to mutual funds or ETFs. The following facts regarding the largest HFs are from Milnes (2014) (the number after the hedge fund's name is its ranking in the list of the world's largest HFs as of 2014).

- Bridgewater Associates (1). There was a relatively poor performance of the three flagship funds in 2012 and 2013 of  $3.5\%$ ,  $5.25\%$ , and  $4.62\%$ . The performance over ten years is  $8.6\%$ ,  $11.8\%$ , and  $7.7\%$ .  
- J.P. Morgan Asset Management (2). J.P. Morgan bought 2004 the global multi-strategy firm Highbridge Capital Management for USD 1.3 billion. Highbridge's assets have 2004 multiplied by nearly 400 percent to USD 29 billion.

<table><tr><td>Hedge Funds</td><td></td><td>USD bn 2014</td><td>USD bn 2017</td><td>USD bn 2019</td><td>Growth 14</td></tr><tr><td>Bridgewater Associates</td><td>USA</td><td>87.1</td><td>122.2</td><td>124.7</td><td></td></tr><tr><td>AQR Capital Management</td><td>USA</td><td>29.9</td><td>69.9</td><td>62</td><td></td></tr><tr><td>J.P. Morgan Asset</td><td>USA</td><td>59.0</td><td>45.0</td><td>47.7</td><td></td></tr><tr><td>Renaissance Technologies</td><td>USA</td><td>24.0</td><td>42.0</td><td>110</td><td></td></tr><tr><td>Two Sigma Investments/Advisers</td><td>USA</td><td>17.5</td><td>38.9</td><td>51</td><td></td></tr><tr><td>D.E. Shaw</td><td>USA</td><td>22.2</td><td>34.7</td><td>62</td><td></td></tr><tr><td>Millennium Management</td><td>USA</td><td>21.0</td><td>33.9</td><td>39</td><td></td></tr><tr><td>Man Group, London</td><td>UK</td><td>28.3</td><td>33.9</td><td>62 20</td><td></td></tr><tr><td>Och-Zif Capital Management</td><td>USA</td><td>36.1</td><td>33.5</td><td>32</td><td></td></tr><tr><td>Winton Capital Management</td><td>UK</td><td>24.7</td><td>32.0</td><td>22.1 30</td><td></td></tr><tr><td>Elliott Management Corporation</td><td>USA</td><td>23.3</td><td>31.3</td><td>35</td><td></td></tr></table>

Table 2.22: Largest hedge funds. (Barclays Hedge Fund Database)

- Brevan Howard Capital Management (3). This HF maintains both solid returns and asset growth - which is the exception of a HF. The flagship is a global macro-focused HF (USD 27 bn AuM), which - since its launch in 2003 - has never lost money on an annual basis.  
- Och-Ziff Capital Management (4) offers publicly traded hedge funds in the US with far greater disclosure than other HFs. Its popularity is mainly due to Daniel Och's conservative investing style.  
- BlueCrest Capital (5) was a spin-off from a derivative trading desk at J.P. Morgan in 2000. It has grown rapidly and is one of the biggest algo hedge fund firms. Its reputation boosted up in 2008 when it made large profits while most other HF facing losses.  
- AQR Capital Management (7), co-founded by Cliff Asness, gives retail investors access to hedge fund strategies. Asness is also well-known for his critique of the unnecessarily high fees charged by most HFs and his scientific contributions.  
- Man Group (9) was founded in 1783 by James Man as a barrel-making firm. It has 225 years of trading experience and 25 years in the HF industry. In recent years, its flagship fund AHL struggled due to its performance.  
- Baupost Group (11) is an unconventional, successful HF. Baupost avoids leverage, is biased toward long trades, holds an average of a third of its portfolio in cash and charges only 1 percent fee.  
- Winton Capital Management (13) has its roots in the quant fund AHL (founded 1987 and bought by Man Group in 1989). David Harding, like many in the quantitative trading field with a math or physics education was also a pioneer in the

commodity trading adviser (CTA) field. Winton is the biggest managed futures firm in the world.

- Renaissance Technologies (15). The famous mathematician Jim Simons founded Renaissance Technologies. Simons became the pioneer of quantitative analysis in the hedge fund industry. Renaissance mainly relies on scientists and mathematicians to write its moneymaking algorithms. It has been consistently successful over the years.

The largest loss a HF has suffered was the USD 6 billion losses of Amaranth in 2006. This loss, of around 65 percent of the fund's assets, was possible due to extensive leverage and a wrongheaded bet on natural gas futures.

# 2.11.2.1 HF Strategies

An important selling argument for HFs is that their investment only weakly correlates with traditional markets. Starting in 2000, correlation between MSCI World and the broad DJ CS Hedge Fund Index (HF Index) changed on a two-year rolling basis: Correlation was 0.16 (HF index) in the years 2000-2007 and jumped to 0.8 in 2007-2009 since a significant number of HFs' managers started 2007 to invest traditionally in stocks and commodities. Many HF use similar strategies as in factor investing. The main difference is transparency of the latter one, implementation of the factors as indices and construction of a cross-asset offering of factors. This main advantages make it attractive for investor to switch their investments from the more opaque and often more expansive HF to a factor portfolio.

# 2.11.3 CTA Strategy

CTA strategies are managed futures strategies where the HF invests in highly liquid, transparent, exchange-traded futures markets and foreign exchange markets. $^{12}$  Investments are made in different markets following a rule based investment strategy. The predominant investment strategy is market-neutral trend following: There is no need for any fundamental input nor for a forward looking market opinion. The portfolio construction is usually risk-weighted. Figure 2.29 shows the size evolution of the managed futures industry.

The figure shows the strong inflow in 2009 after the GFC where managed futures were successful and other investments in HF faced heavy losses. The last 4 years show stagnation in the growth of AuM. Many events in the recent past made trend following difficult: Euro Sovereign Debt Crisis, Greece, China Crisis 2015, etc. The zig-zag behaviour of markets due to such events is the natural enemy for trend models since trend reversal signals are 'too late'. The largest player as of end of 2017 with around USD 32 bn

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/618cef13e3d7b8936ab54fcc0e067cd5baede6f9b9ca44df87d0a1d78ef1abdf.jpg)  
Figure 2.29: Development of the managed futures industry. Data are from Barclay CTA index (Gmür [2015]).

is Wynton Capital, followed by MAN HL and Two Sigma Investments. Geographically, the London area dominates followed by the US and Switzerland. In the last two decades there has been a significant shift from the US to London and other European countries.

# 2.11.4 Fees and Leverage

Most hedge funds charge annual fees of a fixed percentage of AuM (1% - 2% of the NAV per year) and an incentive fee that is a percentage of typically 20% of the fund's annual net profit defined as the fund's total earnings above some minimum threshold such as the LIBOR return and net of previous cumulative losses (high-water mark).

Are HF fees justified? Titman and Tiu (2011) document that on average HF in the lowest  $R^2$  quartile charge 12 basis points more in management fees and 385 basis points more in incentive fees compared to hedge funds in the highest quartile. Feng et al. (2013) find that management fees act similar as a call option at maturity, and that HF managers can therefore increase the value of this option by increasing the volatility of their investments. For CTAs one observes that very professional investors in CTAs prefer to set the fixed management fee to zero and instead to share even more than  $20\%$  of the performance fee.

Fees are particularly opaque for double layer funds of funds, see Brown et al. (2004). They find that individual funds dominate funds of funds in terms of net-of-fee returns

and Sharpe ratios. The performance fee impacts compensation of HF managers or owner. While top hedge fund managers can earn billions of USD in one year. This dominates salaries of bluechip CEO by factors 10 to 30 times.

The fee discussion continues to damage the reputation of HF. California Public Employees' Retirement System (CalPERS) decided 2014 to divest itself of its entire USD 4 billion portfolio of HF.

Hedge funds often use leverage to boost returns. Since leverage increases both returns and risks, it is most relevant for low volatility strategies. Besides return volatility, illiquidity is another risk source for leveraged investments, i.e. the loans are linked to margin calls. This can force HFs to shut down in a crisis when the HF is unable to cover the large margin calls. Ang et al. (2011): … hedge fund leverage decreased prior to the start of the financial crisis in 2007 and was at its lowest in early 2009 when the leverage of investment banks was at its highest.

Leverage is not constant over time. Cao et al. (2013) find that HF are able to adjust their portfolios' market exposure as a function of market liquidity conditions. Several pitfalls exist in the context of leverage. Consider the use of futures for CTAs. Suppose that an investor invests USD 100 with a margin of 10 but he desires a leveraged exposure of USD 200 which requires a margin of USD 20. How much can the investor lose? In the worst case USD 100 when there is a margin call which exceeds USD 80. If the investor cannot comply with the margin call or if the investor is not able to pay the called amount, the positions are closed and the loss of the investor is USD 100.

# 2.11.5 Withdrawing Restrictions, Fund Flows and Capital Formation

Getmansky et al. [2015] state various restriction for investors to withdraw money from a hedge fund:

- a subscription process for investors,  
- the capacity constraints of a given strategy,  
- new investors are often forced into a one-year 'lockup' period during which they cannot withdraw their funds,  
- withdrawals that are subject to advanced notice,  
- temporary restrictions on how much of an investor's capital can be redeemed in a crisis.

Such restrictions protect against fire-sale liquidations causing extreme losses for the HF remaining investors. The discretionary right to impose withdraw gates can be very costly for investors if the losses accumulate during the period where withdrawing is not

possible, see Ang and Bollen (2010). Several studies document a positive empirical relationship between fund flows and recent performance. HF investors seek positive returns and flee from negative returns (Goetzmann et al. [2003], Baquero and Verbeek [2009], and Getmansky et al. [2015]). The relationship between fund flows and investment performance is often non-linear.[13]

# 2.11.6 Biases, Entries and Exits

Hedge fund managers report, voluntarily, their returns to databases. They are free to stop reporting at any time. Hence, a number of biases are possible in HF returns databases.

- Survivor bias and selection bias, i.e. there is a stronger reporting incentive if returns are positive. This bias increases the average fund's return, ranging between  $0.16\% - 3\%$ , see Ackermann et al. [1999], Liang [2000] and Amin and Kat [2003].  
- Backfill bias. The primary motivation for disclosing return data is marketing. HF start to report after they have been successful: They fill in their positive past returns; the 'backfill bias'. Fung and Hsieh (2000) estimate a backfill bias of 1.4 percent p.a. for the Lipper TASS database (1994-1998). Malkiel and Saha (2005) estimate that the return of HFs that backfill is twice the return figure for those not backfilling.

Backfilling means that part of the left tail loss return distribution are missing in HF databases. Since large, well-known HFs do not need to engage in marketing by reporting to commercial databases also part of the right-hand return tail is missing in the databases. We recall the findings of Patton et al. (2013) in Section 2.4.5 about the revision of previously reported returns.

Given these biases why do databases not correct in a transparent and standardized way these biases when publishing their data? Figure 2.30 shows that impact if one corrects for survivorship and backfill biases annualized returns half.

We consider entries and exits in HF. More than twice as many new funds entered Jan 1996-Dec 2006 the Lipper TASS database each year, despite the high attrition rates. This process reversed in the GFC period. After the peak number of new HF in 2007 - 2008, the attrition rate jumped to 21 percent, the average return was the lowest at  $-18.4$  percent, and 71 percent of all hedge funds experienced negative performance.

The survival rates of hedge funds is estimated by several authors, see Horst and Verbeek (2007). Summarizing,  $30 - 50$  percent of all HFs disappear within 30 months of entry and 5 percent of all HFs last more than 10 years. These rates differ significantly for different styles, see Getmansky et al. (2004).

<table><tr><td>From 1996 to 2014</td><td># funds-months</td><td>Annualized mean</td><td>Annualized Volatility</td><td>Skewness</td><td>Kurtosis</td><td>Max. Drawdown</td><td>Box p-value</td></tr><tr><td>Naive estimate</td><td>351364</td><td>12.6%</td><td>5.9%</td><td>-0.25</td><td>4.41</td><td>-14.9%</td><td>0.00003</td></tr><tr><td>Remove survivorship bias</td><td>927690</td><td>9.7%</td><td>5.6%</td><td>-0.22</td><td>4.96</td><td>-15%</td><td>0.00009</td></tr><tr><td>Remove backfill bias</td><td>195816</td><td>11.5%</td><td>8.1%</td><td>-0.54</td><td>9.02</td><td>-19.9%</td><td>0.00000</td></tr><tr><td>Remove both biases</td><td>505844</td><td>6.3%</td><td>6.3%</td><td>-0.50</td><td>5.72</td><td>-20,5%</td><td>0.00056</td></tr></table>

Figure 2.30: Summary statistics for cross-sectionally averaged returns from the Lipper TASS database from January 1996 through December 2014. The last value - box p-value - represents the p-value of the Ljung-Box Q-statistics with three reported legs (Getmansky et al. [2015]).

# 2.11.7 Investment Performance

We use the strategy categorization of the Lipper TASS database in 11 main groupings. $^{14}$

# 2.11.7.1 Basic Performance Studies

There are several facts that limit the alpha of the HF industry. The number of HF managers has increased from hundreds to more than 10,000 in the last two decades. Although the average fund manager today has higher technical skills than in the past, it is becoming increasingly difficult for the individual manager to beat the HF market: Take out the superstars, and you are left with an expensive, below-benchmark industry. A second limitation is the increased efficiency of some markets. The closer markets are to the EMH, the less possible it is to predict future returns. Finally, an increasing size of the fund typically lead to a weaker performance.

Asness (2014) plots the realized alpha of hedge funds over a period of 36 months. He takes the monthly returns over cash, subtracts 37 percent for the S&P 500 excess return

- which is the full-period, long-term beta - and looks at the annualized average of this realized alpha (see Figure 2.31).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/600a267f00012359e5fe10da9bf6e1058cfd47544ae34c6d353630af0b42d774.jpg)  
Figure 2.31: Average monthly returns (realized alpha) of the overall Credit Suisse Hedge Fund Index and the HFRI Fund Weighted Composite Index for a rolling 36 months (Asness [2014]).

We observe a decreasing alpha over time which ends up negative in the near past. Recent years seem to have been particular. Unlike for mutual funds, a number of studies document positive risk-adjusted returns in the HF industry before the GFC. Ibbotson et al. (2011) report positive alphas in every year in the period 1995-2009. While the alphas of the HF industry have been decreasing steadily in the last two decades, correlation with broad stock market indices shows the opposite evolution.

The performance of HF is often linked to specific circumstances. Gao and Huang (2014) report that hedge fund managers gain an informational advantage in securities trading through their connections with political lobbyists. They find that politically connected hedge funds outperform non-connected funds by between 1.6 percent and 2.5 percent per month on their holdings of politically sensitive stocks as compared to their less politically sensitive holdings.

# 2.11.7.2 Performance Persistence

There is mixed evidence regarding performance persistence.

- Agarwal and Naik (2000a), Chen (2007) and Bares et al. (2003) find performance

persistence for short periods.

- Brown et al. (1999) and Edwards and Caglayan (2001) find no evidence of performance persistence.  
- Fung et al. (2008) find a positive alpha-path dependency. Given a fund has a positive alpha, the probability that the fund will again show a positive alpha in the next period is 28 percent. The probability for non-alpha fund is only half of this value. The year-by-year alpha-transition probability for a positive-alpha fund is always higher than that of a non-alpha fund.

While performance persistence is sought out by investors, excessive persistence is a signal that something is wrong.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/74e583bceefea840db4a9d69e6da64e5c67bc5430ce92cc07d44c2a3c0fcea37.jpg)  
Figure 2.32: Monthly return distribution for Fairfield Sentry (line) and S&P 500 (dots) returns (Ang [2013]).

Figure 2.32 shows the extremely smooth return profile of Fairfield Sentry compared to the S&P 500. Fairfield Sentry was the feeder fund to Madoff Investment Securities.

We consider the performance of the CTAs Winton and Chesapeake. Starting with USD 1 of investment in October 1997 until the January 2013 (Quantica [2015]), the first CTA pays out around USD 9 ad the end of 2013 and the second one USD 18. Both CTAs had positive return until the GFC. Then Chesapeake's volatility started to increase and the positive past trend became essentially a flat one. This behaviour is typical for other CTAs too. For Winton, there is almost no suffering of return during and after the GFC.

The reason is risk. Winton takes much less risk than Chesapeake. Why can a CTA strategy work? Empirical evidence for the equity index market shows that skewness and the Sharpe-ratio are highly positively related in equity markets: Investors are compensated with excess returns for assuming excess skewness rather than excess volatility. Trend-following strategies which offer positive risk-premia with positive skewed returns. Market participants often believe that hedge funds are excessively using short strategies. This is not the case for CTAs - around  $80\%$  of the investments are long-only strategies and  $20\%$  use short strategies.

Figure 2.33 shows the attribution of the profit and loss to the different asset classes in the last decade. During the GFC, CTA did not produce a positive return by huge short positions in equity markets but by long positions in the trend model for fixed income: The decreasing rates in this period where a constant source of positive returns.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4b8d6bffbb67338b68ce571fb7b7d6f938cbbd6cc75e57168a3caf20b0c62157.jpg)  
Figure 2.33: Annual sector attribution of the profit and loss for the Quantica CTA (Quantica [2015]).

# 2.11.7.3 Timing Ability

Hedge funds are much less restricted compared to mutual funds to engage in several forms of timing. This includes market timing, volatility timing, or liquidity timing. The study of Aragon and Martin (2012) gives evidence that HF successfully use derivatives to profit from private information about stock fundamentals. Cao et al. (2013) find that HF managers increase (decrease) their portfolios' market exposure when equity market

liquidity is high (low), and that liquidity timing is most pronounced when market liquidity is very low.

# 2.11.7.4 Luck and Skill

Criton and Scaillet (2014) apply the false discovery methodology to hedge funds. They use a multi-factor model with time-varying alphas and betas. This means that they consider different risk factors for the different asset classes. For equity, one risk factor is the S&P500 minus the risk-free rate and for bonds one factor is represented by the monthly change in the 10-year treasury constant maturity yield.

They consider equity long/short strategy, emerging markets, equity market neutral, event driven, and global macro strategies. The main results are that the majority of funds are still zero-alpha funds (ranging from  $41\%$  to  $97\%$  for different strategies) similar to mutual funds. But there is a higher proportion of positive alpha funds compared to mutual funds  $(0\% - 45\%)$  and the proportion of negative-alpha funds ranges between  $2.5\%$  and  $18.6\%$ . The highest skilled funds are emerging market strategies, followed by global macro and equity long/short. The proportion of skilled or unskilled funds is different for different market stress periods. But there is not an uniform decline of skilled funds observed over the period from 1992 to 2006 as for mutual funds. This is some evidence that successful mutual fund asset managers moved to the HF and/or that markets are less efficient for HF strategies than for mutual fund ones.

# 2.11.7.5 Hedge Fund Styles

Hedge fund styles are highly dynamic and behave very differently from those used by mutual funds. Getmansky et al. (2015), see Figure 2.34, report correlations of monthly average returns of hedge funds in each Lipper TASS style category.

- High correlation. Correlations between Event Driven and Convertible Arbitrage categories are 0.77.  
- Negative correlation. Correlations between Long/Short Equity Hedge and Dedicated Short Bias are -0.74.  
- Virtually no correlation. Managed Futures have no correlation with other categories except for Global Macro.

Getmansky et al. (2015) use a factor model based on PCA to gain more insight into possible correlations. The size of the eigenvalues indicates that  $79\%$  of the strategies' volatility-equalized variances is explained by only three factors. This suggests that a large fraction of hedge funds' returns are generated by a very small universe of uncorrelated strategies. The largest estimated eigenvalue takes the value  $52.3\%$ . The authors simulate one million correlation matrices using IID Gaussian returns and they compute the matrices' largest eigenvalues. The mean of this distribution is  $13.51\%$ , while the minimum and maximum are  $11.59\%$  and  $17.18\%$ , respectively. These values are much

<table><tr><td rowspan="2">Category Correlations 1996-2014</td><td rowspan="2">Convertible Arbitrage</td><td rowspan="2">Dedicated Short Bias</td><td rowspan="2">Emerging Markets</td><td rowspan="2">Equity Market Neutral</td><td rowspan="2">Event Driven</td><td rowspan="2">Fixed Income Arbitrage</td><td rowspan="2">Global Macro</td><td rowspan="2">Long/Short Equity Hedge</td><td rowspan="2">Managed Futures</td><td rowspan="2">Multi-Strategy</td><td rowspan="2">Fund of Funds</td><td rowspan="2">All Single Manager Funds</td></tr><tr></tr><tr><td>Convertible Arbitrage</td><td>1.00</td><td>-0.41</td><td>0.63</td><td>0.55</td><td>0.77</td><td>0.69</td><td>0.23</td><td>0.61</td><td>-0.08</td><td>0.66</td><td>0.63</td><td>0.69</td></tr><tr><td>Dedicated Short Bias</td><td>-0.41</td><td>1.00</td><td>-0.57</td><td>-0.25</td><td>-0.60</td><td>-0.17</td><td>-0.15</td><td>-0.74</td><td>0.03</td><td>-0.53</td><td>-0.55</td><td>-0.66</td></tr><tr><td>Emerging Markets</td><td>0.63</td><td>-0.57</td><td>1.00</td><td>0.41</td><td>0.78</td><td>0.47</td><td>0.40</td><td>0.78</td><td>0.05</td><td>0.71</td><td>0.85</td><td>0.88</td></tr><tr><td>Equity Market Neutral</td><td>0.55</td><td>-0.25</td><td>0.41</td><td>1.00</td><td>0.59</td><td>0.46</td><td>0.18</td><td>0.49</td><td>0.04</td><td>0.54</td><td>0.46</td><td>0.52</td></tr><tr><td>Event Driven</td><td>0.77</td><td>-0.60</td><td>0.78</td><td>0.59</td><td>1.00</td><td>0.58</td><td>0.32</td><td>0.80</td><td>0.01</td><td>0.75</td><td>0.81</td><td>0.86</td></tr><tr><td>Fixed Income Arbitrage</td><td>0.69</td><td>-0.17</td><td>0.47</td><td>0.46</td><td>0.58</td><td>1.00</td><td>0.32</td><td>0.37</td><td>0.03</td><td>0.49</td><td>0.50</td><td>0.50</td></tr><tr><td>Global Macro</td><td>0.23</td><td>-0.15</td><td>0.40</td><td>0.18</td><td>0.32</td><td>0.32</td><td>1.00</td><td>0.33</td><td>0.55</td><td>0.43</td><td>0.54</td><td>0.51</td></tr><tr><td>Long/Short Equity Hedge</td><td>0.61</td><td>-0.74</td><td>0.78</td><td>0.49</td><td>0.80</td><td>0.37</td><td>0.33</td><td>1.00</td><td>0.09</td><td>0.74</td><td>0.84</td><td>0.94</td></tr><tr><td>Managed Futures</td><td>-0.08</td><td>0.03</td><td>0.05</td><td>0.04</td><td>0.01</td><td>0.03</td><td>0.55</td><td>0.09</td><td>1.00</td><td>0.23</td><td>0.29</td><td>0.24</td></tr><tr><td>Multi-Strategy</td><td>0.66</td><td>-0.53</td><td>0.71</td><td>0.54</td><td>0.75</td><td>0.49</td><td>0.43</td><td>0.74</td><td>0.23</td><td>1.00</td><td>0.83</td><td>0.83</td></tr><tr><td>Fund of Funds</td><td>0.63</td><td>-0.55</td><td>0.85</td><td>0.46</td><td>0.81</td><td>0.50</td><td>0.54</td><td>0.84</td><td>0.29</td><td>0.83</td><td>1.00</td><td>0.94</td></tr><tr><td>All Single Manager Funds</td><td>0.69</td><td>-0.66</td><td>0.88</td><td>0.52</td><td>0.86</td><td>0.50</td><td>0.51</td><td>0.94</td><td>0.24</td><td>0.83</td><td>0.94</td><td>1.00</td></tr></table>

Figure 2.34: Monthly correlations of the average returns of funds for the 10 main Lipper TASS hedge fund categories in the Lipper TASS database from January 1996 through December 2014. Correlations are color-coded with the highest correlations in blue, intermediate correlations in yellow, and the lowest correlations in red (Getmansky et al. [2015]).

smaller than  $52.3\%$ . This is strong evidence that the different HF returns, although they are claimed to be different in their styles and even unique, in fact are driven by few common factors. Since  $79\%$  of HF category returns are driven by three factors, the benefits of diversification are limited for HF.

The heterogeneity and commonality among HF styles is shown in Figure 2.35. Dedicated Short Bias underperformed all other categories. Multi-Strategy hedge funds outperformed Funds of Funds, Managed Futures funds' returns appear roughly IID and Gaussian. The returns of the average Convertible Arbitrage fund are auto-correlated and have fat tails. The styles Long/Short Equity, Event Driven, and Emerging Markets funds have high correlations with the S&P 500 total return index between  $0.64 - 0.74$ . Return volatility of the average Emerging Markets fund is three times greater than for the average Fixed Income Arbitrage fund.

The CTA Quantica shows a low correlation with the traditional asset classes inclusive the global hedge fund index: between  $10 - 15\%$  correlations to the S&P 500, USD Gov Bonds 3-5y and GSCI commodity index,  $24\%$  to the HFRX Global Hedge Fund Index and  $68\%$  to the Newedge CTA index. The large correlation with the CTA index indicates that many CTA are using similar models - trend-following models which are broadly

<table><tr><td colspan="2">From 1996 to 2014</td><td>monunusp- /</td><td>Mean</td><td>Annualized</td><td>Volatilitative</td><td>Annualized Ratio</td><td>Share</td><td>Ratio</td><td>Sortio</td><td>Swarmless</td><td>Keroses</td><td>Oasis</td><td>Mnempance</td><td>Constrol</td></tr><tr><td>Database Estimate</td><td>Convertible Arbitrage</td><td>14231</td><td>5.4%</td><td>7.3%</td><td>0.38</td><td>0.51</td><td>-3.37</td><td>28.94</td><td>-34.4%</td><td>0.51</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Dedicated Short Bias</td><td>2503</td><td>-1.1%</td><td>15.6%</td><td>-0.23</td><td>-0.41</td><td>0.62</td><td>5.23</td><td>-47.3%</td><td>-0.72</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Emerging Markets</td><td>47054</td><td>6.8%</td><td>14.2%</td><td>0.29</td><td>0.42</td><td>-1.43</td><td>9.94</td><td>-49.3%</td><td>0.64</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Equity Market Neutral</td><td>27459</td><td>4.7%</td><td>3.3%</td><td>0.61</td><td>0.99</td><td>-0.25</td><td>12.86</td><td>-14.6%</td><td>0.32</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Event Driven</td><td>39227</td><td>6.8%</td><td>5.9%</td><td>0.70</td><td>1.05</td><td>-1.64</td><td>8.97</td><td>-24.8%</td><td>0.65</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Fixed Income Arbitrage</td><td>18834</td><td>5.1%</td><td>4.4%</td><td>0.56</td><td>0.68</td><td>-4.35</td><td>32.93</td><td>-20.7%</td><td>0.29</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Global Macro</td><td>32034</td><td>4.9%</td><td>5.2%</td><td>0.44</td><td>0.81</td><td>0.48</td><td>4.93</td><td>-14.2%</td><td>0.28</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Long/Short Equity Hedge</td><td>178926</td><td>7.7%</td><td>9.0%</td><td>0.56</td><td>0.98</td><td>0.00</td><td>5.47</td><td>-24.7%</td><td>0.74</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Managed Futures</td><td>46204</td><td>4.8%</td><td>9.4%</td><td>0.23</td><td>0.44</td><td>0.26</td><td>3.13</td><td>-16.3%</td><td>-0.05</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Multi-Strategy</td><td>76233</td><td>5.8%</td><td>5.2%</td><td>0.62</td><td>0.93</td><td>-1.18</td><td>7.16</td><td>-21.5%</td><td>0.57</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>Fund of Funds</td><td>270369</td><td>3.8%</td><td>6.0%</td><td>0.20</td><td>0.31</td><td>-0.57</td><td>6.80</td><td>-21.9%</td><td>0.58</td><td></td><td></td><td></td><td></td></tr><tr><td>Database Estimate</td><td>All Single Manager Funds</td><td>505844</td><td>6.3%</td><td>6.3%</td><td>0.58</td><td>0.97</td><td>-0.50</td><td>5.72</td><td>-20.5%</td><td>0.71</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Convertible Arbitrage</td><td>228</td><td>7.3%</td><td>6.8%</td><td>0.69</td><td>0.95</td><td>-2.75</td><td>20.03</td><td>-32.9%</td><td>0.37</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Dedicated Short Bias</td><td>228</td><td>-6.4%</td><td>16.7%</td><td>-0.53</td><td>-0.95</td><td>0.78</td><td>4.65</td><td>-76.3%</td><td>-0.77</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Emerging Markets</td><td>228</td><td>8.4%</td><td>13.1%</td><td>0.44</td><td>0.65</td><td>-1.28</td><td>10.74</td><td>-45.1%</td><td>0.60</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Equity Market Neutral</td><td>228</td><td>4.8%</td><td>10.2%</td><td>0.21</td><td>0.23</td><td>-11.88</td><td>165.26</td><td>-45.1%</td><td>0.31</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Event Driven</td><td>228</td><td>9.2%</td><td>6.3%</td><td>1.03</td><td>1.52</td><td>-2.25</td><td>13.60</td><td>-19.1%</td><td>0.63</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Fixed Income Arbitrage</td><td>228</td><td>5.3%</td><td>5.6%</td><td>0.48</td><td>0.58</td><td>-4.64</td><td>36.20</td><td>-29.0%</td><td>0.32</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Global Macro</td><td>228</td><td>10.9%</td><td>8.9%</td><td>0.92</td><td>1.60</td><td>-0.06</td><td>8.01</td><td>-26.8%</td><td>0.24</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Long/Short Equity Hedge</td><td>228</td><td>9.7%</td><td>9.6%</td><td>0.72</td><td>1.29</td><td>-0.03</td><td>6.63</td><td>-22.0%</td><td>0.67</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Managed Futures</td><td>228</td><td>6.1%</td><td>11.4%</td><td>0.30</td><td>0.57</td><td>0.06</td><td>2.69</td><td>-17.4%</td><td>-0.05</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>Multi-Strategy</td><td>228</td><td>8.4%</td><td>4.9%</td><td>1.16</td><td>1.77</td><td>-1.99</td><td>11.52</td><td>-24.7%</td><td>0.43</td><td></td><td></td><td></td><td></td></tr><tr><td>CS/Dow Jones Index</td><td>All Single Manager Funds</td><td>228</td><td>8.6%</td><td>7.1%</td><td>0.82</td><td>1.44</td><td>-0.20</td><td>6.27</td><td>-19.7%</td><td>0.59</td><td></td><td></td><td></td><td></td></tr></table>

Figure 2.35: Summary statistics for the returns of the average fund in each Lipper TASS style category and summary statistics for the corresponding CS-DJ Hedge Fund Index from January 1996 through December 2014. Sharpe and Sortino ratios are adjusted for the three-month US treasury bill rate. The 'All Single Manager Funds' category includes the funds in all 10 main Lipper TASS categories and any other single-manager funds present in the database (relatively few) while excluding funds of funds (Getmansky et al. [2015]).

diversified. Although CTAs show a persistent upwards drift in the long run (see Figure 2.36), they may well suffer from temporary heavy losses.

It follows that the CTA index shows much less heavy drawdowns than an equity or a commodity index. The main reason is discipline in investment. This has two components. First, CTAs are fully rule based. If a stop-loss trigger is breached losses are realized. Second, CTAs allocations are risk-based where again, the risk attribution is carried out mechanically. CTAs therefore follow the investment advice of David Ricardo written in The Great Metropolis 1838: Cut short your losses, and let your profits run on.

# 2.12 AM Innovation - Views on Disruption

# 2.12.1 Replacement and Prices

At the root of disruption lies replacement. Existing successful goods and services are replaced by new ones: Automobiles replacing rail transport, high speed rail replacing short distance flights, word processing software replacing the typewriter, ultrasound re

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/1efbdd2ae1c8dcfbcd8859fc21aee79a3c40c914a3bf4f7e66e70c7e7115fba2.jpg)  
Figure 2.36: Drawdown periods for S&P500 total return, GS commodity total return index and Barclays US Managed Futures index BTOP 50. Data are from Dec 1986 to Mar 2013 (Bloomberg).

placing X-ray imaging, plastic replacing metals and wood, personal computers replacing workstations and Wikipedia replacing traditional encyclopaedias.

Disruption is considered uncontrollable - unlike a transformation. After the financial crisis in 2008, digital disruption for the financial intermediaris (FI) meant foremost replacing the semi-automated value chains by automating ones. Cost reductions and scalability were the drivers.

But digital disruption has a much broader meaning than efficiency. Innovation and the new entrants, FinTechs and the Tech Giants, can disrupt ownership of the FI both on the production and the customer side. FinTech innovation is driven from an end-customer perspective and customer will follow their business model. Hence FI have to adopt this view too and leave their bank centric approach. Since FI can integrate or copy the solutions of the many FinTechs they are not a real threat. But the few Tech Giants are. They already have a broad customer base, a technological advantage and almost unlimited resources. The Revised Payment Service Directive of the European Union, effective 2018, is an example. It has disruption potential since it is an important step towards an open finance system. That is a system where the end-costumers choose their best products and services from a platform. The FI deliver their services and products to the platform. Compared to the traditional business model in an open finance economy

the link end-costumer / FI is broken and the FI are in competition on the platform. Clearly, in an open economy business becomes much less profitable unless the FI owes the platform. The above directive is a regulatory driver for Tech Giants to offer their superior data analytic capabilities to end-customers.

Besides breaking the customer-FI link, new entrants can act disruptively by changing the topology of the financial architecture (Blockchain, cryptocurrencies, platforms). This means to redefine the market participants connections and to reallocate ownership rights in the architecture. Their broad assumption is that the action space of FI in the value chains can be largely reduced, sometimes even completely replaced. In fact, technology is able to replace monopolistic or oligopolistic ownership of key centralized FI functions by decentralized solutions based on game theory (aka blockchain). This defines the infrastructure channel of digital disruption in the financial industry.

The internet revolution in the 90s revolutionized the flow of information by sending information quickly and free of charge to many individuals. This is an efficient way to copy and distribute information. But financial intermediation is based on asset values and their distribution based on contracts. To revolutionize the existing generation and flow of values, the internet solution approach is useless: Copying a USD 10 bill for payment purposes is useless. In a digital value flow, someone has to validate that the payer owes USD 10, that he has not promised it to anyone else and that the millions of payments in the system are synchronized to prevent fraudulent actions. Formally, transaction feasibility, transaction legitimization and transaction consensus have to assured for each transaction at each date. In the current financial world, banks, central banks and exchanges are offering and owning these functions: They provide a payment system and they validate as third parties the transaction (consensus). Bitcoin based on the mutually distributed ledger technology proved that complete digitized payment systems and currencies are possible were code and mathematics replaces all functions of the FI in fiat money banking. Whether the thousands of cryptocurrencies survive is not clear. Each currency needs to reflect an economic value and not just a believe of investors, they need to be competitive (transaction fees, speed, security), ecological sound (energy consumption) and address the monetary perspective (stiff supply side).

The attack on the end-customer /FI link is different in nature. The iPhone method of integration makes it possible to integrate all FI activities in such a unique device. Furthermore, the methods to express and analyze customers needs will in the very near future replace the capabilities and quality of any relationship advisor. This sets the stage for an Open Finance system: They want to have a single access to an intelligent platform, where they can decide in a user experienced way. The FI, if they do not owe the platform, are reduced to product service providers and to running the accounts in the background. The quality of the digital services will ultimately create a time and location independent emotional relationship with the end-customers. At this stage definitively there will be no further need for a human FI interaction. Some FI have proven to be able to adapt

quickly to a new environment and they use their powerful resources to act as a shaper.

# 2.12.2 Market Entrants

There are start-ups (FinTechs) and Tech giants entrants. Start-up firms produce goods and services in a better way than traditional AM firms. 'Better' can mean cheaper, tailor-made to the customers, scalable, interconnected with other needs of the customers or an increased functionality or quality. Most FinTechs are mono-liners by offering a single service or product, they have no client base and they innovate mostly from a end-client perspective, i.e. at the end-client FI interface. This makes FinTechs vulnerable. The main strategy observed is to enter into a cooperation contract with FI. But cooperations are unlikely stable end states - the FI can break cooperation if they have caught up with the technological advantage of the FinTechs and FinTechs themselves can leave if they have access to customers.

The financial crisis 2008 can be considered a starting point for digital disruption in the financial sector. Of the 248 surveyed European FinTechs in the Roland Berger (2016) study, 15 were founded before 2008 and the rest after the financial crises. Three triggers cumulated in this period: The iPhone made it impossible to empower the end client, FI had to spend many their resources to meet the regulatory avalanche, and FI had to increase profitability by lowering costs. The survey of McKinsey (2015) for the sample of more than  $12'000$  FinTech start-ups states:

- Target clients:  $62\%$  of the start-ups target private customers,  $28\%$  SMEs and the rest large enterprises.  
- Function: Most start-ups work in the area of payment services (43%) followed by loans (24%), investments (18%) and deposits (15%).

Even FinTechs consider Tech Giants to be more dangerous for FI as they are themselves (Roland Berger (2016). The Big Four Amazon, Apple, Google and Facebook are examples for Tech Giant entrants in the financial sector. Our Western-centric view is to simplify the discussion. For each of the Big Four there is a comparable and equally successful Chinese counterpart.[15] While the Big Four are less agile than FinTechs, their almost unlimited resources, their strong client basis and their technological advantage make them a real threat for FI.

Although it has long been speculated that the Big Four will enter the banking business on a large scale so far this does not happen. Google has a banking license for Europe since 2011, Facebook requested one but nothing happened so far. One can speculate about the reasons: More profitable alternatives, to heavy regulatory costs or business

risk such as the program AdWords Business Credit which was discontinued? Facebook could offer banking services to its 1.5 billion users which are living in countries with a non-stable political, financial, social and legal system. Apple which is active with Apple Pay could do a lot more. It is meaningful what disruption could mean. One scenario is the the Big Four to become full FI. But they could also prefer to take over the end-customer interface due to their superior technology and data analytics methods. This latter model fits well into the so-called open finance paradigm where end-customers are self-decision makers, they are connected to a platform or a cloud where data analytics methods provide decision making services for portfolio management for example, where the data of the customers in different FI are aggregated in the platform, where the best FI is selected to deliver products and services once an end-customer made its decision. Hence, FI become pure product providers and lose the interface to their clients. Since 2018, the Revised Payment Service Directive (PSD2) from the European Union points in this direction and puts core banking functions under stress. PSD2 obliges banks which are active in payments to reveal customer data to third parties if the customers wishes to do so. Banks could then lose a main part of their value chain since the Tech Giants could use their excellent analytics to provide services to the end-clints. Banks will defend their value chain. Their main weapon is the existing payment infrastructure which they build up such as IBAN and SWIFT. They will price costs to the new entrants.

The four main channels for disruption are:

- Efficiency channel.  
- Customer-centricity channel.  
- Transaction values or verification channel, see Blockchain.  
- Data channel, see Big Data.

Disruptive efficiency is the classical view of financial intermediaries: All banks are looking at ways to cut costs and also generate more revenues. Ermotti (2016). Digital efficiency has a different meaning than past automation based efficiency which meant to digitize the information workflow in a value chain to reduce human activity and to reach scalability: Doing the same at lower costs, with fewer errors and using scalability. Disruption means to redesign the workflows and to eliminate humans to a before not seen degree using Bots, avaters or smart contracts. They are not only digitized legal documents - say trade confirmations - but they also contain code which make it possible that the documents manage themselves over the life cycle. Platforms are a second example of disruption. While platforms since ever changed the connectivity of the participants, present platforms possess two new features: Not only numerical information flows but any form of information gained from structured and unstructured data and platforms are using AI to analyze, manage, control and direct the information flow in the platform.

FinTech drive Customer-centricity by developing solutions starting with the end-customer in mind. The customers will have more bargaining power and autonomy to

decide. They can decide, value and compare say any investment advice in much deeper and intuitive way than in the past. The digital instruments also allow to take into account the customer's environment or his context. Customers expect tailor-made, convenient, affordable and integrated (smartphone) solutions for their asset and wealth management purposes.

How will asset protection considered in a digital world where cyber criminals, governments and bank defaults define risk sources? The FinTechs do not have the reputation and size for protecting accounts, insurance contracts and security deposits. The Tech Giants' reputation is decreasing, in particular in the US and Europe. In the FinTech study conducted by Roland Berger (2016), the European FinTechs mentioned customer trust to the financial intermediaries as the only success factor for financial intermediaries. Their protection function works since decades. So far there is no strong alternative to FI regarding safe keeping of money and financial assets.

Customer-centricity also affects regulation. It changes the interactions between regulation and innovation that have existed for decades: New regulation leads to innovations, which in turn trigger regulation. This occurred on a structural (Glass-Steagall Act) or a product level (Eurobonds). This cat-and-mouse game becomes less important due to the customer centricity where the interaction financial innovation/customer will dominate. This challenges regulators. How should they behave in the spotlight of this new dynamics and what is the best approach to any regulation? Evidently, in the new dynamic, complex interaction cannot be effectively and efficiently controlled with static, large regulatory frameworks as it was done in the past.

The WEF 2015 document The Future of Financial Services (2015) (FFS) summarizes and extends the discussion. The paper identified 11 clusters of innovation in six functions of financial services, see Figure 2.37.

The approach of considering six independent intermediary functions and identifying within these functions the eleven clusters is a silo business view. The clusters can be grouped into six themes that cut across traditional functions:

- Streamlined Infrastructure: Emerging platforms and decentralised technologies provide new ways to aggregate and analyse information, improving connectivity and reducing the marginal costs of accessing information and participating in financial activities.  
- Automation of High-Value Activities …  
- Reduced Intermediation: Emerging innovations are streamlining or eliminating traditional institutions' role as intermediaries, and offering lower prices and / or higher returns to customers.  
- The Strategic Role of Data …

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f87e0eddadd9335dbbd50341848723de6e236465ffa2d3f4e83784351348de33.jpg)  
Figure 2.37: The six functions (payments, market provisioning, investment management, capital raising, deposits and lending, and insurance) and the 11 innovation clusters (new market platforms, smarter & faster machines, cashless world, emerging payments rails, insurance disaggregation, connected insurance, alternative lending, shifting customer preferences, crowd funding, process externalization, empowered investors) (The Future of Financial Services [2015]).

- Niche, Specialised Products: New entrants with deep specialisations are creating highly targeted products and services, increasing competition in these areas and creating pressure for the traditional end-to-end financial services model to unbundle.  
- Customer Empowerment …

2017 the FFS paper was reconsidered and updated. Some expected trends materialized in the two years period while for others the expectations were revised due to lack of demand, technological immaturity or regulatory considerations.

Two years later in 2017 the working group of the WEF published a status report. The main findings are:

- Fintechs have seized the initiative - defining the direction, shape and pace of innovation across almost every subsector of financial services.  
- Fintechs have reshaped customer expectations, setting new and higher bars for user experience.  
- Failure: Customer willingness to switch away from incumbents has been overestimated.  
- Fintechs have struggled to create new infrastructure and establish new financial services ecosystems.

We close this section with sentiments of people about the digital disruption. On a broad scale, two-thirds of 400 CEOs in the US surveyed by KPMG in 2016 believed that the next three years will be more critical for the business performance of their companies than the past 50 years. Additionally, Grossman (2016) states in a CEO survey, based on Russel Reynolds Associates, that there are only three industry sectors, Health Care, Asset Management and Industries, where less than  $50\%$  of the CEOs expect massive or moderate digital disruption. For Media, Consumer Financial Services and Telecom more than  $60\%$  expect such a scenario. 34 percent of all 4.000 Chief Information Officer respondents surveyed in more than 50 countries note that digital disruption is already a reality in their companies, and further  $28\%$  say that this will happen in the next 1 to 2 years (Harvey Nash (2015)). Those responsible for information expect a much stronger disruption for the services industry due to the lack of physical components than for the processing, pharmaceutical or energy sector.

It is a scientific fact that financial literacy of the population is at a low level. Hence, any link to end-customers which is not based on a rational but an emotional paradigm is likely to win the end-customers connection battle. Although in principle an emotional link can be formed by using a human interaction with the end-customer this approach is not scalable: A client advisor has in Europe between 100 and 400 clients to serve. Therefore a digital link is a more promising solution. But how can a communication between a human and a software generate an emotional basis? The software needs to care and perform. This means to understand the customer's needs in his life cycle context and to give meaningful advice. AI is pointing in this direction. If this is possible why should end-customers bother that they do not communicate with a human?

# 2.12.3 Value Chain, Investment Process and Technology

Asset management is more than just investment theory. Roughly, by knowing an investment strategy we have not set up machinery that shows how the strategy can be implemented, priced, sold and managed for many investors efficiently, and we do not know how to export our AM capacity to other cultures and jurisdictions in a compliant

and profitable way. These issues define the value chain of AM, see Figure 2.41 where the production part of the value chain is shown.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c14a5cf95219c14a8236799a6714a30a072412bf50e3cdf41d06d5b9ce6757d0.jpg)  
Figure 2.38: Structure of the AM value chain.

The chain has two layers: the business and infrastructure level. The business layer has the following main functions (see Figure 2.41):

- The front-, middleand back office.  
- Product management.  
- Solution providers.

The front office consists of the distribution channel and the investment process. In this part of the chain the investor's preferences, risk capacity, and the type of investment delegation (execution-only, mandate, or advisory) are defined. All communication to end clients is made via this channel - new solutions, performance, risk reporting, etc. The investment process, headed by the CIO, starts with the investment view applied to the admissible investment universe. The view is then implemented by portfolio managers where different procedures can be followed. More precisely, the investment process has the following sub-processes for mandate clients:

- Investment view by the CIO.  
- Tactical asset allocation (TAA) construction.  
- Implementation of the TAA by asset managers.
- Matching of the eligible client portfolio to the implemented portfolios.

The middle office is responsible for reporting and for controlling the client portfolio with respect to suitability, appropriateness, performance, risk and it also constructs the eligible client portfolio. The back office is responsible for the execution and settlement of the trades.

The product management defines for the investor an eligible, suitable and appropriate offering. It is also responsible for overall governance, such as market access and regulatory requirements. The product management strategy tries to understand where the market is headed, how this compares with current products, client segments served, and firms' capabilities, and how competitors price their services in different channels. Product managers anticipate the people, process, and technology requirements for the product. They also assess gaps versus current capabilities and propose counter measures. A main function is the new-product-approval (NPA) process office. This office guarantees both an optimal time-to-market and an effective implementation of new products. Finally, product management also oversees outor insourcing opportunities in the business value chain. The solution providers in the investment process provide the building blocks for implementing the portfolios including funds, cash products, ETFs and derivatives.

The infrastructure layer naturally develops, maintains, and optimizes the IT infrastructure for the several functions of the business layer. The technology officer oversees the developments in technology and data management and considers the outor insourcing opportunities along the infrastructure value chain.

To deal with the digital disruption, many leading companies are looking at their businesses and operations anew, taking something of a 'blank sheet of paper' view of the world. Many outsource important parts of their back offices (NAV calculations, 'onboarding', investor statements, etc.), largely as a reaction to investor pressure following the scandals, see Section 2.4.5. According to PwC's recently released Alternative Administration Survey, 75 percent of alternatives fund managers currently outsource some portion of their back office to administrators and 90 percent of hedge funds behave in this way. While the initial experience has been mixed in many respects, it has helped to rethink business from scratch.

# 2.12.4 Some Innovations

Platforms are a synonym for technical connectivity. Novus is such a platform provider. Dec 2017, almost 200 of the world's top investment managers and investors - managing a combined total of approximately USD 3.5 trillion - are using Novus platform. At its essence, Novus is a platform via which the industry's top investors can collectively innovate. Novus aggregates funds' performance and position data. This defines a single point of access for asset managers. Using this platform, almost all worldwide funds and their performance are catalogued and analyzed based on an automated collection of regulatory

reporting data.

Externalization of processes is a key strategy for FI in the digital world. FFS classifies different innovations in process externalization:

- Advanced analytics. Using advanced computing power, algorithms and analytical models to provide a level of sophistication for the solutions.  
- Cloud computing to improve connectivity with and within institutions. This allows for simpler data sharing, lowers implementation costs. streamlines the maintenance of processes, and enables real-time processing.  
- Natural language leading to more intuitive processes for end users.

Kensho as an example models investment scenarios for fully automatized decision-making. The cost per generated scenario are much lower than those few manually generated scenarios. Using Kensho, institutions can shift their resources away from the management of processes to functions with higher value and where the asset management firm has comparative advantages. Kensho threatens the ability to model market projections and hypotheses by quant of large financial institutions by offering next-generation tools, application, technology and data bases. Common models of the process externalisation providers are:

- Platform, real-time databases or expert systems, leverage automation for the users and the solution providers.  
- As-a-service reduces infrastructure investments to a minimum level by externalization.  
- Capability sharing between institutions frees them to build up all possible capabilities and allows integration of different legal and technical standards.

Process externalization means for the AM industry:

- AM firms use advanced technologies to externalize, consolidate, and commoditize processes in a more efficient and sophisticated manner.  
- Winning AM activities shift from process execution to more 'human' factors.  
- External service providers give small and medium-size asset managers access to sophisticated capabilities that were not previously attainable due to lack of scale. This gives access to small and medium-size asset managers to top-tier processes and smaller players are able to compete with large incumbents.  
- Cross-border offering become profitable with well-controlled conduct and regulatory risk due to the platforms. But it could also amplify the risks of non-compliant activities and unclear liabilities when centralized externalization providers fail. Automation also increases the speed at which financial institutions implement regulatory changes. Therefore, regulators will receive faster consistent inputs from financial institutions.
- Since more capabilities, technologies, and processes are externalized, asset management firm becomes more dependent on third parties, lose negotiating power and continuity.

The constantly evolving regulation across geographies means an increase of compliance resources require solutions about regulation and its changes which is consistent within and across different jurisdictions. New entrants are able to interpret regulatory changes and translate them into rules. Such a rules based approach is scalable and allows asset managers responding fast to regulatory changes, see Figure ??

FundApps is such a FinTech firm. It organizes regulatory information from various sources, and delivers a cloud-based service that automates shareholding disclosure and monitors investment restrictions across over one-hundred regulatory regimes. FundApps partners with a global legal service provider to monitor and translate changes in relevant regulations into rules on a daily basis. If regulatory agencies partner firms such as FundApps in the future, they could ensure consistent compliance across financial institutions, make dissemination of regulatory changes in disclosure regimes faster, and reduce the compliance burden faced by the industry. FFS.

# 2.13 ESG Investing

Investors more and more consider not only the risk-adjusted return but also the extra-financial criteria such as environment, social and governance (ESG) scores. In the past, ESG investments were percived to underperform due to Sthe operational costs to achieve corporate social responsibility (CSR) objectives: Research costs, transaction costs and integration costs. But the work by Friede et al. (2015) synthesized more than 2000 studies concludes that ESG integration has a positive effect on business performance.

Nevertheless, the question of performance remains a controversial issue. Academic findings revealed a U-shape pricing of stocks in the equity market, meaning that both best-in-class and worst-in-class ESG stocks have been rewarded by the equity market in the past. These studies are based on long-term historical data.[16] But the tools for systematic and comprehensive extra-financial analysis of listed companies are much younger. Therefore, long time series can be misleading. Bennani et al. (2018) consider in their analysis data starting from the GFC; thereby avoiding the production of noisy and non-robust results that do not reflect the current behavior of how ESG is used nowadays.

They use the ESG metrics for each company provided by the Amundi ESG Research department which are not public available but the scoring system depends on the data of four external providers. The data are cleaned, normalized, checked by data analysts, and the

<table><tr><td>Environmental (E)</td><td>Social (S)</td><td>Corporate Governance (G)</td><td>Board of Directors/Board Functions</td><td>8%</td></tr><tr><td>E1. GHG Emissions</td><td>S1. CEO Pay Ratio</td><td>G1. Board Diversity</td><td>Board of Directors/Board Structure</td><td>24%</td></tr><tr><td>E2. Emissions Intensity</td><td>S2. Gender Pay Ratio</td><td>G2. Board Independence</td><td>Board of Directors/Compensation Policy</td><td>13%</td></tr><tr><td>E3. Energy Usage</td><td>S3. Employee Turnover</td><td>G3. Incentivized Pay</td><td>Integration/Vision and Strategy</td><td>76%</td></tr><tr><td>E4. Energy Intensity</td><td>S4. Gender Diversity</td><td>G4. Collective Bargaining</td><td>Shareholders /Shareholder Rights</td><td>60%</td></tr><tr><td>E5. Energy Mix</td><td>S5. Temporary Worker Ratio</td><td>G5. Supplier Code of Conduct</td><td>Margins /Performance</td><td>7%</td></tr><tr><td rowspan="3">E6. Water Usage</td><td rowspan="3">S6. Non-Discrimination</td><td rowspan="3">G6. Ethics &amp; Anti-Corruption</td><td>Profitability /Shareholder Loyalty</td><td>5%</td></tr><tr><td>Revenue /Client Loyalty</td><td>2%</td></tr><tr><td>Emission Reduction</td><td>89%</td></tr><tr><td rowspan="4">E7. Environmental Operations</td><td rowspan="4">S7. Injury Rate</td><td rowspan="4">G7. Data Privacy</td><td>Product Innovation</td><td>79%</td></tr><tr><td>Resource Reduction</td><td>87%</td></tr><tr><td>Customer /Product Responsibility</td><td>69%</td></tr><tr><td>Society /Community</td><td>48%</td></tr><tr><td rowspan="2">E8. Climate Oversight / Board</td><td rowspan="2">S8. Global Health &amp; Safety</td><td rowspan="2">G8. ESG Reporting</td><td>Society /Human Rights</td><td>91%</td></tr><tr><td>Workforce /Diversity and Opportunity</td><td>78%</td></tr><tr><td rowspan="2">E9. Climate Oversight / Management</td><td rowspan="2">S9. Child &amp; Forced Labor</td><td rowspan="2">G9. Disclosure Practices</td><td>Workforce /Employment Quality</td><td>31%</td></tr><tr><td>Workforce /Health &amp; Safety</td><td>39%</td></tr><tr><td>E10. Climate Risk Mitigation</td><td>S10. Human Rights</td><td>G10. External Assurance</td><td>Workforce /Training and Development</td><td>73%</td></tr></table>

Figure 2.39: Left Panel: ESG Classification of Nasdaq. Right Panel: Scoring of Vadofone using the Refinitiv scoring system.

final sector-neutral score is reviewed and validated by ESG analysts.

They consider five investment universes covered by MSCI indices North America, EMU, Europe ex EMU, Japan and World and three quarterly rebalanced strategies from Jan 2010 to Dec 2017: active management, passive management or optimized index portfolios and factor investing. Standardization means to eliminate geographical or sector biases. For each stock  $i$ , its corresponding ICB industry sector code is denoted by  $I(i)$  and its score at time  $t$  is denoted by  $S(i,t)$ . The Z-score is defined as:

$$
Z (i, t) = \frac {S (i , t) - \bar {S} (i , t)}{\sigma (i , t)}
$$

where the bar values are the average values of the sector.

A main result is that the impact of ESG is highly dependent on the time period. Before, the investment universe or the strategy. There is no evidence of a consistent reward of ESG integration in stock prices between 2010 and 2013 although in each period there is a variability between the five regions, see Figure ??. But for 2014 and 2017 most indicators are positive. In North America, buying the best-in-class stocks and selling the worstin-class generated an annualized excess return of 3.3 percent and 6.4 percent for the eurozone. We refer for the relative impacts of the three factors E, S and G to the paper.

# Annualized return of ESG sorted portfolios

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3ba089e7b81880f467ec2a6f9cfeb2a6a665fcea8144f9c70173570a1878c81d.jpg)  
North America

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/1ed420da01d75f2014517b08295a4e7cde3b75e55030f04ac54854b8e559d98e.jpg)  
Eurozone  
Figure 2.40: Annualized return of ESG sorted portfolios. Sorted portfolios following Fama and French (1992) are constructed. Stocks are quarterly ranked with respect to their score forming five quintiles  $Q_{1}$ , with the equally weighted portfolio Q1 corresponding to the 20 percent best-ranked stocks. Roncalli et al. (2018)

For institutional investors which prefer to implement ESG passively by using optimized tracking error between the benchmarking portfolios and a non-ESG based SAA. It follows that improving the normalized ESG score implies to accept an increase in tracking error. Being an ESG investor requires taking on a tracking error risk. This integration of ESG in passive management reduced performance between 2010 and 2013 but improved annualized return between 2014 and 2017.

The authors characterize the asset pricing implications in order to better identify and understand the drivers of performance. Figure ?? shows four possible hypothesis between the ESG score and return or risk, respectively.

The market confi

guration (b) is not observed in North America and the Eurozone whatever the score used. But a skewed-risk market confi

guration for the environmental pillar in North America is observed. Confi

guration (a) for ESG score is observed in North America but the most frequent market confi

guration is (c): ESG investing has only an impact on best and worst-in-class assets.

We conclude with some market figures.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4a15da40d9a97d68d9ce3a583adae5978b0e8774fdd353f38c04ed53f03689d9.jpg)  
Figure 2.41: Roncalli et al. (2018).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/54d7c82ebd04cdabdb073ed3e3f6c9894ccb8a59e1c787f80182b78719b837b7.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/a76633c1ef48e3d9d642ed484c8fa4bc1fab5fdbea33293fabd895f02c4f490f.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8d4e815ef509653c895943fef60a6e261e40cd2a5066d6da6990c23158f7df8d.jpg)

<table><tr><td>Region</td><td>2016</td><td>2018</td></tr><tr><td>Europe</td><td>12&#x27;040</td><td>14&#x27;075</td></tr><tr><td>US</td><td>8&#x27;723</td><td>11&#x27;995</td></tr><tr><td>Japan</td><td>474</td><td>2&#x27;180</td></tr><tr><td>Canada</td><td>1&#x27;086</td><td>1&#x27;699</td></tr><tr><td>AUS/NZ</td><td>516</td><td>734</td></tr><tr><td>Total</td><td>22&#x27;838</td><td>30&#x27;683</td></tr></table>

Table 2.23: Asset values in bn USD. Source: Global Sustainable Investment Alliance.

Sustainable investments extend across the range of asset classes. The majority of 51 percent of the assets were allocated to public equities, followed by fixed income with 36 percent. Real estate/property and private equity/venture capital each held 3 percent of global sustainable investing assets.

# 2.14 Green Investing

The climate change is one of the major threats and opportunities in this century. We first provide an overview about some key facts of the climate change including its potential impact on society, bio diversity and the economy. Different examples are given where the interplay of financial innovation and technological progress leads to ecological and economic meaningful solutions. The goal is to design solutions which do not rely on

government's command & control.

Data show that humankind is facing a climate change which largely will be irreversible. Global temperature anomalies of the recent past compared to the 1951-1980 show that the last years were the warmest one, see Figure 2.42.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9501d909252c541dfe15ac1bcd21ac58d95d5cdc71f18ddee93bcb97562c7e40.jpg)  
Figure 2.42: 2015 was the warmest year in the NASA/NOAA temperature record, which starts in 1880. It has since been superseded by the following years (NASA/NOAA; 20 January 2016).

Energy demand will further increase due to population growth, progressing industrialization and increasing wealthiness. This will without any countermeasures increase human made CO2 emissions. But keeping in line with the 2 degree goal a drastic reduction of CO2 emission is needed: For most countries 30 percent is ok but better would be 50 percent.

As stated above, we do not focus on governmental law or laisseur fair but we consider cases where it pays economically to reduce CO2 emission and to invest in energy efficiency.

The results depend on the following facts:

- There is enough clean energy, i.e. energy which can be used to replace CO2 emitting energy.  
- The technology to transport energy efficiently exists.  
- There exist financial market solutions which match investor's demand for sustainable investment with the demand for energy project finance.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/02395ffdc84f5c6e084b9636593f3971c45edaeb9323e0f3110e991ef576fad6.jpg)  
Figure 2.43 shows the impact of potential climate changes on different dimension of humanity and the ecosystem.  
Figure 2.43: Impact of potential climate change. Sources: Stern Review, IPCC, 4th Assessment Report, Climate Change 2007, WWF and Credit Suisse 2011.

The increase in CO2 over the last 100 years has lead to a measurable change in climate. The data from researchers show that climatic change less related to risk but more to uncertainty: There is lack of knowledge about the speed, the irreversibility, possible

feedback effects and some hidden non-linearities. The impact of the worst case scenarios on GDP forecasts a drop between 5 and 20 percent. Estimates of Credit Suisse and other institutions state that investment flows between USD 700 and 2000 billion per annum is required over the next decade to limit warming to 2 degrees Celsius.. This would mean around 2 percent of global GDP per annum. The majority of the required capital investment is concentrated in low carbon energy, energy efficiency, and low carbon transport infrastructure. Low carbon energy is primarily linked to investment in renewables, electricity infrastructure like grids and transmission and storage. The opportunity is concentrated in China, the US and the EU27. They represent nearly 60 percent of the mitigation cost. Figure 2.44 shows the distribution of the investments necessary to achieve the 2 percent pathways. The matrix has the dimensions geographical location and area of investment. The authora state different type of barriers affecting the current decarbonization efforts. Since regulatory mechanisms do not exist yet which price the externalities of carbon emissions technical and financial barriers exist: The economics of low carbon projects are often less attractive than those of their high carbon alternatives. Structural barriers include network effects (consumer will not buy electric cars unless there are workable and available charging solutions, but private investor hesitate to build a charging network unless there is sufficient demand), agency problems (the party making low carbon investment is under existing structures often not the one which will benefit from the savings) or the status quo bias (strong bias towards maintaining the status quo instead of making changes).

To highlight the challenges in setting up projects on a large scale we consider the DESERTEC concept. The bottom line of the project was that a 300 times 300 kilometer thermal solar energy plant in a desert is sufficient to generate enough energy to cover the world wide electricity demand. DESERTEC includes energy security and climate protection as well as drinking water production, socio-economic development, security policy and international cooperation. DESERTEC was founded 2009 in Germany and rapidly gained support from large cooperates and politics. The goal was to produce energy in the Sahara for Europe. To some extend similar projects on much lower scale have been implemented in the US and other countries. DESERTEC faced several risks.

- Political risk. Countries such as Algeria, Libya, Saudi Arabia given their natural oil resources have no interest in a solar energy project. But is not the case; in fact Saudi Arabia owes leading solar energy institutes. Furthermore, the solar energy project will be beneficial for employment and job creation in these countries to a far larger extent and due to the excess solar energy these states will be able to create new farming land.  
- Why should these countries produce energy for Europe given their own need? This point led also to heavy debates in Europe and to a standstill of the project.  
- Another risk factor is political instability. The events starting in 2011 demonstrate that this risk exists and that without the protection of an army the project

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/801327d7fa30867eb3b1e50468142429d4054d0b9a0ae792a0da152cbb859a27.jpg)  
Figure 2.44: Annual investment required to achieve 2 degrees Celsius pathway is USD 700 bn. Sources: Credit Suisse/WWF analysis based (2011) on McKinsey's Climate Desk tool.

cannot be sustainable. But which army should guarantee the functioning of the technology?

- A further political risk is that the middle and northern part of Europe will depend on a single point of entry in the Mediterranean region.  
- Technology and financing risk. Natural damage risks and energy losses in the transport are not material. But the need to construct a new powerful energy infrastructure in Europe triggers delicate financial issues.

Besides the DESERTEC example other examples show the risks of large scale environmental projects. The Lisbon Strategy, adopted in 2000, largely failed on its three pillars, where the environmental pillar recognized that economic growth must be decoupled from the use of natural resources. The overly complex structure with multiple goals and actions, an unclear division of responsibilities and tasks and a lack of political engagement from the member states let to its failure and GFC was then the final blow to the strategy. At the Spring Summit 2010 EU leaders endorsed the European Commission's proposal for a Europe 2020 strategy. This new strategy puts knowledge, innovation and green growth at the heart of the EU's blueprint for competitiveness and proposes tighter monitoring of national reform programmes, one of the greatest weaknesses of the Lisbon Strategy.

Another example is water pollution in Switzerland in the 60s of last century. Defining incentives and providing financial support by the Swiss government a new industry emerged (clarification plants) and treatment of farming land was changed. After some decades water from Swiss lakes or rivers is often potable. In the US, acid rain led to the implementation of the Clean Water Act which solved also the problem.

# 2.14.1 Green Bonds

When it comes to financial innovation, many different initiatives were raised since the 1980s. But most of them failed to be of sustainable success while so-called green bonds are proving to be the favourite wrapper.

Market-based solutions have proven consistently more effective in protecting the environment than government regulation alone. Project financing, public/private partnerships, and tradable permits have come to supplement or replace conventional regulation and purely tax-based instruments. This approach can minimize the aggregate costs of achieving environmental targets while providing dynamic incentives for the adoption and diffusion of greener technologies. The most practical solution for building a greener economy is to correct faulty pricing by making consumers and firms pay for the environmental damage they cause. Once these negative externalities are internalized, they will be incorporated in the prices of goods and services, creating real incentives for the creation and adoption of clean technologies. One of the most compelling examples of

using these principles to fix broken markets is that of cap-and-trade pollution markets. In such markets, the cap (or maximum amount of total pollution allowed) is usually set by government. Businesses, factory plants, and other entities are given or sold permits to emit some portion of the region's total amount. If an organization emits less than its allotment, it can sell or trade its unused permits to other businesses that have exceeded their limits. Entities can trade permits directly with each other, through brokers, or in organized markets.

The first green bond was issued 2007 by the European Investment Bank (EIB) and World Bank. For more details see www.climatebonds.net where the following data are taken from. In November 2013 the first corporate green bond was issued by a Swedish company. Tesla Energy issued the first solar ABS in November 2013. The biggest ABS issuer is Fannie Mae. ABS includes solar ABS, green MBS, green RMBS, green CMBS, and other types. The green bond market 2018 issuance reached USD 167.3 bn with over USD 500 bn currently outstanding.

Using debt capital markets to fund climate solutions

The majority of the green bonds issued are green 'use of proceeds' or asset-linked bonds. The following products fall in the category green bond, taken from www.climatebonds.net.

- 'use of proceeds' bonds. Proceeds from these bonds are earmarked for green projects. The same credit rating applies as issuer's other bonds. Barlays Green Bond are an example.  
- 'use of proceeds' Revenue Bond or ABS Earmarked for finance of green projects. Revenue streams from the issuers though fees, taxes etc are collateral for the debt. The Hawaii State ABS is backed by fee on electricity bills of the state utilities.  
- Project Bond. This is ring-fenced for the specific underlying green project. Recourse is only to the project's assets and balance sheet. Example is the Invenergy Wind Farm bond which is backed by Invenergy Campo Palomas wind farm.  
- Securitisation (ABS) Bond. They refinance portfolios of green projects or proceeds and they are earmarked for green projects. Recourse is to the asset pool such as a pool of green mortgages. Tesla Energy is for example backed by residential solar leases.  
- Covered Bond. They are earmarked for eligible projects included in the covered pool. Recourse is to the issuer and to the collateral pool. The Berlin Hyp green Pfandbrief is an example.  
- Loan. A loan is not a security. Loans are earmarked for eligible projects and full recourse to the borrower in the case of unsecured loans and in the case of covered bonds to the collateral. Examples are MEP Werke, Ivanhoe Cambridge and Natixis Assurances (DUO).

Benefits for issuers outweigh their additional costs compared to non-green bonds since issuers must track, monitor and report on use of proceeds. The benefits for the issuers are reputation, branding and build up of know about environmental investments.

Green bonds are flat and the same as for ordinary bonds, i.e. they are parti pasu to vanilla issuance. As an outlook, investors with \$ 45 tr of assets under management have made public 'commitments' to climate and responsible investment. This is around 50 percent of all AuM.

# 2.14.2 Energy Contracting and Structured Finance

We consider in some details how the tech and financing aspects are designed for energy contracting. Such contracts are defined between the following parties:

- Energy efficiency searching institution. An institution - public entity, a corporate - in our case wants to reduce energy costs in an existing building or a new project. To be specific we consider a large city administration.  
- Energy solution provider. A corporate provides the technology to realize the energy cost gains. The energy solution should lead to a substantial reduction in energy costs.  
- Financial solution provider. A FI offers different possibilities to finance the project. The financial solution should reflect the particular financial and political needs of the city administration.

As an overview the following figures hold as rough rules in case buildings are made energy efficient. The data are from Siemens (2015).

<table><tr><td>Type of Optimization</td><td>Energy Saving</td><td>Amortization Period</td></tr><tr><td>Measure &amp; Visualize</td><td>~ 10%</td><td>~ 1 - 2y</td></tr><tr><td>Optimizing Operations</td><td>~ 10 - 25%</td><td>~ 2 - 3y</td></tr><tr><td>Building Services Eengineering</td><td>~ 25 - 35%</td><td>~ 3 - 7y</td></tr><tr><td>Renew</td><td>~ 30 - 45%</td><td>~ 6 - 12y</td></tr></table>

Table 2.24: Rough figures for building energy efficiency measures.

Measure and Visualize means that a firm makes transparent its energy consumption at well-chosen location within the firm. Elevators are often used since most people in an elevator search for a fix point to focus on or the entrance lobby is also well suited. It has by now been reported in several studies that simple transparency or monitoring without any other actions leads to an approximate energy reduction of about 10 percent. It seems that such a transparency changes behavior of some employees leading to this reduction.

When it comes to financing the project a major requirement is that the project also makes economic sense. That is, we require  $\mathbf{Gain} > 0$ . The gain is a sum of investment costs  $I$  and the savings of energy costs over time. Saving of the energy costs has four risk sources:

- Investment risk. The amount  $I = \bar{I} + dI$  is equal to the expected costs  $\bar{I}$  and possible deviations  $dI$ .  
- Volume risk. I.e. the amount of saved energy  $c_t$  is given by

$$
c _ {t} = \bar {c} + d c _ {t}
$$

with  $\bar{c}$  the expected amount of saved energy once the project is finished and  $dc_{t}$  the risk of deviation from the expectation.

- Energy price risk. I.e. the price  $p_t$  of saved energy (oil, electricity, a mixture of them) is equal to

$$
p _ {t} = \bar {p} + d p _ {t}
$$

with  $\bar{p}$  the forward/futures prices and  $dp$  the deviation risk from the forward prices.

- The last risk is counter party risk of the energy solution user - here the city administration. Depending on type of financing the project the counter party risk matter for the investors or not, see below for details. We write default risk is in the form  $u = 1 - dk$  with 1 for not-defaulting and  $dk$  for the expected default rate.

The gain of the project can be written symbolically - i.e. without using summation and discounting notation, but focussing on the different parts in the gain function - as follow:

$$
\mathrm {G a i n} = \left\{ \begin{array}{l l} \bar {I}, & \text {e x p e c t e d i n v e s t m e n t c o s t s}; \\ d I, & \text {i n v e s t m e n t r i s k}; \\ \bar {c} \times \bar {p}, & \text {e s t i m a t e d s a v i n g s (c o s t s a n d v o l u m e)}; \\ d c \times \bar {p}, & \text {v o l u m e r i s k}; \\ \bar {c} \times d p, & \text {e n e r g y p r i c e r i s k}; \\ d c \times d p, & \text {c r o s s r i k}; \\ d k \times c \times p, & \text {d e f a u l t r i s k}. \end{array} \right.
$$

This defines the risk profile for the city without any structuring of risk. Therefore, the next question is: Who bears which risk? Professional technology provider keep the investment and volume risk due to their experience and their large project portfolio. That is variation in these two factors are absorbed in a large project portfolio. Consider an investor. The investor is willing to pay the expected investment costs  $\bar{I}$  in exchange of participating at the future energy saving. That is, the city and the investor share future energy savings: The city participates with  $\bar{c} \times \bar{p} \times a$  and the investor with  $\bar{c} \times \bar{p} \times (1 - a)$  at future energy savings. This defines the performance contract. The function  $a$  defines as function of time future participation. Since the investment has to be paid back to the investor, he will participate stronger at the beginning than the city. Else, the payback

time increases. In this set-up the whole investment is risk free for the city. The only risk which is not attributed is default risk of the city. Either it is passed and compensated to the investor or the bank keeps this risk. This type is a structured product solution. Other possible solutions are:

- City pays the project cash.  
- City issues a bond.  
- City issues a green bond.  
- Bank issues a structured product (solution above).  
- A special purpose vehicle is setup.

Before we consider some of these solutions we provide an example for the structured product. Assume a project which payback time 4y. Then the amount of saved energy  $\bar{c} = 25\%$ . Assume that the project costs 100 in a currency, that  $a$  increases linearly from 10 to 40 percent,  $1 - a$  decreases linearly from 90 to 60 percent, that energy price risk is  $\pm 2$  percent per annum, that default risk of the city is 10 bps, that fees in structuring the deal are 1 percent per annum and that interest rates are flat at 2 percent. Then,

- After 8y the whole energy savings belong to the city.  
- After 5 years the investment amount is amortized, i.e. the years 6-8 generate return for the investor.  
- The return for the investor is in case of constant energy prices equal to 6.3 percent, 5.3 percent if energy price fall by 2 percent each year and 7.1 percent in monotone increasing case. This return has to be corrected by the possible default of the city. If the investor does not want to take this default risk, the returns are lowered by the credit risk costs for the city.

Finally, if an investor wishes to get ride-off energy price risk the structuring delivers him fix energy prices or prices which are kept within a bandwidth.

From the other financing possibilities we only mention the green bond. This bond is issued by the city as an ordinary bond. The difference to such a bond is the coupon payment. The value of the coupon each year is determined by the price of the saved energy amount, i.e. it is a coupon derived from the underlying value 'energy price  $\times$  saved energy volume'.

Clearly such a construction requires strong legal and documentation work for and between the different parties. Furthermore, more hazard issues exist: The energy solution provider can change an excessive price  $I$  for the investment to cover possible price risk  $dI$  or the energy solution provider can predict biased low saved energy amounts to

reduce its energy volume risk. To avoid such potential disincentives, a simple solution is let the energy firm itself invest into the project, i.e. to take a part of the investor's stake. This then both reduces moral hazard related to the investment amount and also to the expected energy volume savings since systematic deviations reduce the return of investment.

# 2.15 Uniformity of Minds

Technology not only connects the different worldwide market places, it also allows information to spread about any given local event, without delay, to the rest of the world. This fact may also homogenize the way in which people think and make decisions in geographically and culturally different places. Is such an alignment of minds taking place, and - if so - what are the possible consequences? We follow Bacchetta and van Wincoop (2013) and Bacchetta et al. (2013), all of whom compare the GRF or 'Great Recession' of 2008 with the global economic recession (Great Depression) of the 1930s.

# 2.15.1 The Great Depression and the Great Recession

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d0f76f7b90439f7bb9cda7ff06f1a9d87b4be6d4a6e227e74ec13bd7f8d84a24.jpg)  
Figure 2.45: Comparing global GDP growth (pecent, annual, real) in the Great Recession and Great Depression for the US and developed non-US countries (Bacchetta and van Wincoop [2013]).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3244af9b767c50d783ae86133a6526f06c22a80a0228380180985d3a56d9ef2e.jpg)  
Figure 2.45 compares the economic impact on the US and non-US economies during the GFC and the Great Depression.

There was basically no difference during the Great Recession between the GDP growth in the US and that in the G20 states representing the main worldwide economy without the US. But in the Great Depression, the decline in US GDP growth did not spread with comparable intensity to the rest of the world. This indicates that while the Great Recession can be called a global crisis, the Great Depression was more local in nature. The authors show that the Great Recession was, in historical terms, the first global recession. The first question is: How could the crisis spread from the US financial sector to the US real sector? The second question is: Why did the Great Recession spread almost instantaneously from the US economy to the global economy - how did the recession become a global one?

# 2.15.2 Uniformity of Minds

Bacchetta and van Wincoop (2013) show that standard macroeconomic approaches fail to provide convincing explanations. Before we turn to the global issue, we reconsider the US. First, one can consider - for the US - direct effects of the financial sector on the real economy. Examples of these direct effects include broken financial intermediation leading to a credit crunch or stock market declines leading to negative wealth effects. While such explanations sound convincing, they are flawed due to the main methodical problem of the GFC not being exogenous but endogenous in the macroeconomic cycle. That is to say, the impact of the financial crisis is not a separated output variable acting on the economy but is part of the whole economy and must therefore impact the real economy.

As many authors have shown, the financial crisis was part of the so-called boom - bust cycle of the real economy. Of particular importance are real-estate boom - bust cycles. Reinhart and Rogoff (2008) illustrate the following pattern. Set T to be the date of a banking crisis. Consider the growth rate of the real-estate asset class some years before and after this date. One typically observes that before T prices increase and that they fall after or shortly before the banking crisis. In this sense, a financial crisis is part of a boom - bust cycle. The surprising aspect of the most recent crisis was not that it happened, but that such a crisis could be strong enough to destabilize the financial system of a developed economy (the US, here).

Given this US view, how could the recession become a global one? The standard channel for explaining global linkages is trade. But the US is not a very open economy, and imports - for many countries - to the US are relatively small. There is no empirical evidence of a link between openness in terms of trade and a decline in growth. Hence, the macroeconomic trade channel fails to provide an answer to the question of how the recession spread globally. Another possible channel is the financial channel. That is to say, the decline is asset prices and real-estate prices and changes to the credit supply channelled into the real economies outside of the US. But this hypothesis is not supported by empirical evidence either. While real-estate prices dropped in, say, Spain and Ireland, they did not in Germany or Switzerland. While Switzerland has a much stronger finan

cial link to the US than do most European countries, the European countries were much more affected by the Great Recession. While some countries faced a decline in credit supply, others did not. Although policy makers have often used the expression credit crunch', firms participating in surveys about the period have indicated that - during the Great Recession - lower demand was more important to them than reduced credit supply. Summarizing, standard macroeconomic models cannot explain the global recession.

Bacchetta et al. (2013) argue that there must have been other drivers that caused the global recession. They argue that it was not the globalization of the economy, as considered above, but rather the globalization of how individuals form expectations that was responsible for the recession spreading worldwide. This argument is, of course, linked to questions of information technology, information transmission, and information quality in worldwide terms. In contrast with the past, information today is spread almost in real time around the world, it is more difficult to control information distribution, and mainstream information is mostly costless to the consumer. Therefore, one can argue that - given a financial crisis and its related information flow - individuals around the world had access to similar information sets upon which to form their expectations. The authors claim that panic, by consumers and firms throughout the world, lead to declines in aggregated demand in most countries. Such panic must show a systemic component to have a worldwide impact. They assume therefore that such panic is rational or self-fulfilling:

- Agents first expect low future income due to the information available and uncertainty at play at the beginning of the financial crisis.  
- This leads to low current consumption.  
- This reduction in consumption lowers firms' current profits.  
- This leads to low future production and income, which matches the agents expectations as outlined in the first step.

# Chapter 3

# Fundamentals Theory

# 3.1 Returns and Performance Attribution

Returns are key in asset management for the calculation of risk and performance. The calculation of returns is not as straightforward as one might guess. One needs to calculate returns for arbitrary complicated cash flow profiles where cash can be injected or withdrawn at different time dates. Different assets possess different time scales for return calculations varying from intraday to months for illiquid assets. Returns often need to be aggregated for risk calculations to reduce the dimensionality and risk models are needed to value expected returns. Finally, the return for an investor can be the result of several money managers, i.e. returns should be decomposable to account for different contributors.

Why do we work with returns and not with prices? Price growth behaviour in price time series are statistically hard to manipulate. The mean value has little meaning if prices grow exponentially. One works with a scale free quantity; Returns. Why one does work with log-returns? The simple return over a period,  $\frac{S_t - S_{t - 1}}{S_{t - 1}}\in [-1,\infty)$ , is not useful if one tries to model returns assuming a normal distribution since simple returns range from  $-1$  (total loss) to  $+\infty$  while the normal distribution ranges over the reals. Furthermore, 10 days gross return is the product of ten one-days gross returns and not the sum. But the product of normal distributions is not normal. One therefore prefers to work with log-returns where the product of return aggregation is replaced by a sum and the sum of log-normals is log-normal.

# 3.1.1 Time Value of Money (TVM)

Since returns compare cash flows (CF) at different dates, the time value of money matters: CF at different dates cannot be added since the value of CHF 1 today is different from CHF 1 at any other date. The microeconomic assumption of impatience rationalizes why there is a time value of money. Consider consumption of the same good  $c$  at time  $t$  and

$T > t$ . If investors prefer consumption earlier to later,

$$
u \left(c _ {t}\right) \geq u \left(c _ {T}\right)
$$

with the utility function  $u$ . To make the investor indifferent, the consumption good at time  $T$  must be larger than at time  $t$ , i.e.

$$
u \left(c _ {t}\right) = u \left(c _ {t} + \Delta_ {t, T}\right) =: u \left(c _ {t} \left(1 + R _ {t, T}\right)\right)
$$

with  $\Delta$  the interest and  $R$  the interest rate to compensate for impatience.

The function which weights CFs at different dates  $T > t$  is the discount function  $D(t, T)$ . Discounting restores additivity which makes it possible to add CFs at different dates. Any two complicated cash flow profiles can be compared for investment purpose. Discounting is the necessary ingredient such that the price of a product can be written as the probability and a time weighted sum of future cash flows. Given the CF additivity, they can be mapped to a single point; the present value (PV) and future value (FV). It is irrelevant which date is chosen for mapping of all CFs in comparing two investment opportunities.

The discount function has the form  $D(t,T) = D(T - t)$ , i.e. the homogeneity of time or the irrelevance of the vista time. The inverse operation of discounting is compounding  $D(t,T)D(t,T)^{-1} = 1$ . If the discount factor is 1, interest rates are zero, if if is larger than one, interest rates are negative.

Consider CHF 1 at time  $T$  and two scenarios. First, discount the CHF back directly to  $t$ . Second, discount it first back to a time  $s$ ,  $t < s < T$ , and then from  $s$  to  $t$ . There is no risk. The value at  $t$  of the Swiss franc should be independent of the chosen discounting path. Else, by buying low and selling high generates a money machine (arbitrage in a risk free environment). Formally,

$$
D (t, s) D (s, T) = D (t, T), D (t, t) = 1. \tag {3.1}
$$

Cauchy proved that the exponential function is the unique continuous function which satisfies (3.1):

$$
D (t, T) = e ^ {- a (T - t)} , a > 0 .
$$

This motivates exponential discounting.  $a$  has the dimension inverse time and calculating the growth rate of the discount factor,  $\frac{\partial D}{\partial T} = -a$ , identifies  $a$  with the interest rate  $R$ . The discount function  $D(t,T)$  for different maturity dates  $T$  defines the spot rate term structure which we write  $\{D(t,T)\} \coloneqq \{D(t,T), T \geq 0\}$ . Assume that there exists interest rate risk. Then equation (3.1) makes no sense since  $D(s,T)$  is a random variable. To restore the identity, we have to fix the rate between  $s$  and  $T$  at time  $t$ , i.e. with the discount factor  $D(t,s,T)$  we again have that  $D(t,s)D(t,s,T) = D(t,T)$ . This defines the Forward Rate Term structure  $\{D(s,t,T)\}$ . Given one term structure, the other term structure follows by no arbitrage.

- The forward curve is a function  $t \to F(t, T)$ .  
- The zero or discount curve is a function  $T \rightarrow p(0, T)$  
- The par swap rate curve is vector of spot starting swap rates for all maturities.

<table><tr><td>Maturity</td><td>Swap Rate</td><td>Discount Factor</td><td>Spot Rates</td><td>Forward Rates</td></tr><tr><td>1y</td><td>4.50%</td><td>0.95638</td><td>4.5615%</td><td>-</td></tr><tr><td>2y</td><td>4.95%</td><td>0.90647</td><td>5.0324%</td><td>5.55%</td></tr><tr><td>3y</td><td>5.39%</td><td>0.85158</td><td>5.5015%</td><td>6.57%</td></tr><tr><td>4y</td><td>5.57%</td><td>0.80151</td><td>5.6872%</td><td>6.28%</td></tr><tr><td>5y</td><td>5.68%</td><td>0.75409</td><td>5.8071%</td><td>6.31%</td></tr></table>

Table 3.1: To obtain the discount factors from the swap rate we use (3.5). To get the spot rates from the discount factor we use  $R(0,T) = \left(\frac{1}{D(0,t)}\right)^{1 / T} - 1$  and the forward rates are calculated as  $F(0,S,T) = \frac{D(0,T)^T}{D(0,S)^S}$ . The day-count factor reads act/360/100 =1/36'000*365=0.0101388.

The absence of arbitrage implies that there exists exactly one discount factor for each currency and for each maturity; else build a money machine. But there are many different interest rate, profit and loss and performance calculations. The reasons are:

- The method of compounding - do investors reinvest their proceeds in future periods (compounding) or do they consume them (simple compounding)?  
- Do we use market rates for discounting or synthetic rates from an asset management perspective such as the yield-to-maturity (YtM) to value and compare different investments?  
- The calender and day-count-convention differ: The number of days within a year varies for different countries, exchanges and products.

Examples

# Compounding

Investing  $n$  years with compounding and simple compounding implies:

$$
F V _ {n} ^ {d} = P V \left(1 + R _ {d}\right) ^ {n}, F V _ {n} ^ {s} = P V \left(1 + n R _ {s}\right). \tag {3.2}
$$

Hence,  $FV_{n}^{d} \geq FV_{n}^{s}$ . The formulae can be generalized to the case with sub-annual periods and where  $R$  is not constant. The limit forward value is achieved for instantaneous interest rates which results in the exponential compounding formula as a limit how fast capital can grow.

# Unique discount factor

The continuous discount factor  $D_{c} = e^{-R_{c}(T - t)}$ , the discrete time  $D_{d} = (1 + R_{d})^{T - t}$  and the simple  $D_{s} = (1 + R_{s}(T - t))^{-1}$  all have to attribute the same PV to a future CHF 1. Therefore,  $R_{c}, R_{d}, R_{s}$  are in one-to-one relationship. Equating for example  $FV_{n}^{d} = FV_{n}^{s}$  implies  $R_{d} = (1 + nR_{s})^{1 / n} - 1$ . Continuous discounting:

$$
P V ^ {c} = D (0, 1) F V ^ {c} = e ^ {- R _ {c}} F V ^ {c}
$$

implies  $R_{c} = \ln \left(\frac{FV}{PV}\right)$ . If we consider short time periods (say daily return calculations), the logarithm can be approximated up to first order by the gross simple return:  $\ln \left(\frac{FV}{PV}\right) \sim \frac{FV}{PV} - 1 \eqqcolon R$ .

# Remarks:

- Interest rates are quoted on a p.a. basis.  
- Typically, nominal interest rates are quoted in financial markets.  
- Simple discounting is used for LIBOR rates, products with maturity less than a year, discrete compounding for bonds and continuous compounding for derivatives or Treasury Bills.

The discount function is a simple function of the interest rate. But the interest rate itself is a complicated function of a risk free rate, the creditworthiness of counter parties, liquidity in the markets etc. The discount function construction is the key object in financial engineering.

# Example Zero-Coupon Bond and Discount Factor

Let  $p(t,T)$  the price of a zero-coupon bond (ZCB) at time  $t$  paying USD 100 at maturity  $T$  if there is no default. Except from counter party risk, a ZCB is the same as a discount factor. ZCB are the most simple interest rate products. More complex products such as coupon paying bonds can be written as a linear combination of ZCBs. Consider a coupon bond with a yield  $R$ , i.e. the rate needed such that the PV of the bond is equal to its present price is  $R$ . The slope of the price-yield graph is negative since a bond issued today will have a lower price tomorrow if the interest rates increase (opportunity loss). The relation is non-linear since  $p(t,T) = D(t,T)\times 1 = \frac{1}{(1 + R(t,T))^{T - 1}}\times 1$ .

# Example Effective rate of return and Yield-to-Maturity (YtM)

The effective simple rate  $R_{e,s}$  is the gross return needed to reach from the PV value the FV value:

$$
\left(1 + R _ {e, s}\right) P V := F V.
$$

Consider  $R_{e,s}$  for a  $n$ -year investment in a stock  $S$  (where  $\mathrm{PV} = S_0$ ,  $\mathrm{FV} = S_n$ ):

$$
1 + R _ {e, s} = \frac {S _ {n}}{S _ {0}} := \frac {S _ {n}}{S _ {n - 1}} \frac {S _ {n - 1}}{S _ {n - 2}} \dots \frac {S _ {1}}{S _ {0}} = \prod_ {k = 0} ^ {n} (1 + R _ {k, k - 1})
$$

where  $R_{j,j-1}$  is the sub-period return. The effective, simple gross return is equal to the product of the period returns. The compounded effective rate  $R_{e,d}$  follows by taking a square root  $n$  in the above formula. If compounding is continuous, the effective return is equal to the arithmetic sum of period returns since the log of a product is a sum. This is one reason why continuous compounding is preferred.

A particular decision problem for an investor is to choose between two bonds:

- Bond 1: Price 102, coupon  $5\%$ , maturity 5 years.  
Bond 2: Price 98, coupon  $3\%$ , maturity 5 years.

Bond 1 has more attractive future CFs but bond 2 is cheaper. Which one to prefer? If maturity would increase then bond 1 should become more profitable and the opposite holds if the price of the bond 2 becomes more cheaper compared to the bond 1. The yield-to-maturity (YtM)  $y$  is a decision criterion which assumes that products are kept until maturity. The YtM  $y$  solves by definition the equation:

$$
\mathrm {P r i c e} = \sum_ {j = 1} ^ {n} \frac {c}{(1 + y) ^ {j}} + \frac {N}{(1 + y) ^ {n}}.
$$

The bond with the higher  $y$  is the preferred one. This equation can be solved easily numerically. YtM, which has a flat term structure, is the most important example of a Money-Weighted Rate of Return (MWR), see below.

# 3.1.2 Interest Rate Swaps

Discount factors are derived from prices of liquid financial instruments together with mathematical interpolation for maturities where no observable asset prices exist. For maturities up to one year, the money markets, futures or forward rate agreements (FRA) are used. For longer maturities, the capital markets, bonds or swap rates are used. We consider interest rate swaps (IRS) and FRA. Both instruments are OTC derivatives.

Vanilla interest rate swaps (IRS) $^{1}$  are bilateral contracts contracted over-the-counter (OTC), i.e. not via a stock exchange where typically fixed versus floating rates are exchanged. The reference rate for the floating leg is typically LIBOR or EURIBOR. The notional amount is not exchanged. It serves only as a calculation figure. In USD or Euro maturities range between 2-30 years. To enter such a contract an ISDA agreement and counter party risk limits are needed. Minimum contract size in Swiss Francs is CHF 2 Mio. $^{2}$  The counter party paying the fixed rate is the 'payer', the other one the 'receiver'. The payer (receiver) is by convention long (short) the swap.

Originally, IRS were introduced for interest arbitrage reasons. Consider two firms  $A$  and  $B$ .  $A$  has a high creditworthiness,  $B$  a low one. Both firms can borrow at a fixed or floating rate given in Table 3.2.

<table><tr><td></td><td>A</td><td>B</td><td>Difference</td></tr><tr><td>Fixed</td><td>5%</td><td>6%</td><td>1%</td></tr><tr><td>Floating</td><td>LIBOR</td><td>LIBOR + 0.75%</td><td>0.75%</td></tr></table>

Table 3.2: Rates for firms  $A$  and  $B$  .

The two firms can both benefit if they enter into a IRS, since the difference in fixed rate borrowing differs from the floating rate one by  $0.25\%$ . Both parties can realize and divide this amount using an IRS. To lock in the profit, each party borrows where it has an advantage:  $A$  borrows fixed and  $B$  floating.  $B$  agrees to pay  $A$  floating rate LIBOR plus 0.75 percent and  $A$  agrees to pay  $B$  fixed 5.9 percent.  $A$  gets floating rate funding at LIBOR minus 0.15 percent and  $B$  gets an advantage in fixed funding of 0.1 percent.

The first swap was designed 1981 between the World Bank and IBM, see Figure 3.1. IBM received DM from its funding program and used this money to finance project in the US. That for IBM needed to change periodically USD in DM to serve the coupon payments. Since USD became stronger in that period compared to DM, IBM made currency gains. To realize these gains IBM needed to get ride of its DM-liabilities. The World Bank borrowed in the capital markets and lent to developing countries for project finance. The costs of the loans were the same than the financing cost of the World Bank in the markets. US interest rates were at 17 percent in this period and in Germany and Switzerland they were  $12\%$  and  $8\%$ . World Bank preferred raising all funds in lower interest rate currencies. But it was constraint to borrow in these countries and had to use also USD. It searched for party which owed DM and wanted to exchange them against USD. An investment banker at Salomon Brothers realized that a currency swap would

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/94daf491b8b6e9daf28be9f2e1e7a1ee161ad594edda8c8c06718b02ee4a610c.jpg)  
Figure 3.1: Swap between the World Bank and IBM.

solve the problems of both parties: IBM could change their DM-liabilities into USD and the World Bank could buy DM at favourable rates. The World Bank lent IBM over notional amounts and coupons denominated in DM and received notional and coupons in USD in exchange. Such a direct swap without involvement of the banks balance sheet is a back-to-back swap.

Banks started in the 80's and 90's to enter into own-name transactions. The swap counter parties discussed directly with the bank as intermediary their desired risk and return profile. Entering in-between the two swap parties the bank faced counter party risk. One also stared to develop standardized documentation documents which allowed to process customized transaction effectively, the ISDA agreements. The third period was characterized by beginning market making. Banks started to trade swaps with several counter parties. Market and counter party risk increased due to this wider activities - large investment in risk management followed. Market risk was often compensated with transactions in other markets.

# 3.1.2.1 Swap Pricing

We fix swap initiation date 0 and maturity date  $T$ . The fixed rate at which the swap can be executed is the constant par swap rate  $s_{0,T}$ . This rate by definition sets the value of the swap at initiation to zero, i.e.

$$
\mathrm {P V} _ {\text {S w a p}} (0, s _ {0, T}) = 0
$$

since at initiation no cash flows are exchanged. Fixed payments  $s_{0,T}(0)$  are made annually, floating ones quarterly. Figure 3.2 shows replication of a swap into a par fixed bond and a floating rate note (FRN). We prove that the PV of FRN must be worth par at each quarterly LIBOR reset date. Since the initial value of a swap is zero, the initial value of the fixed leg must also be worth par.

Solving for the swap rate and using  $\mathrm{PV}(\mathrm{Float}) = 1 - p(0,T)N$  we get

$$
s _ {0, T} = \frac {1 - p (0 , T)}{A _ {0 , T} (0)} = \frac {\mathrm {P V F l o a t i n g}}{\text {A n n u i t y}} \tag {3.3}
$$

where  $A_{0,T}(0) = \sum_{j=1}^{T} p(0,j)$  is the present value of an annuity and  $p(0,t)$  is the price of a zero coupon bond; the level of the swap.

Proposition 13. The  $PV$  of a floating rate note is equal to the notional.

Since  $D(0,0) = 1$ , the PV of the floating leg equals

$$
\mathrm {P V} (\mathrm {F l o a t}) = (1 - p (0, T)) N.
$$

To prove the claim, we set  $L_{j} = L(t_{j - 1},t_{j})$  for the LIBOR forward rate fixed at  $t_{j - 1}$  with payment at  $t_j$ . At time 0 only  $L_{0}$  is known. To replicate a random cash flow  $L_{j} = L(t_{j - 1},t_{j})$  we need one unit of a currency at time  $t_{j - 1}$ , which can be invested at the rate  $L_{j}$  such that we get in  $t_j$  the payoff  $1 + L_{j}$ : Buy a zero coupon bond  $p(0,t_{j - 1})$  and sell a zero coupon bond  $p(0,t_j)$ . The balance of both bonds at  $t_j$  is  $L_{j}$ . Replication is accomplished. Consider the next cash flow  $L_{j + 1}$ . Then the short bond  $p(0,t_j)$  for the former cash flow will enters as a long bond: The bond cancels. Considering a series of cash flows  $L_{j}$ , the replicating bonds cancel but the last one. This proves the claim.

Consider a 2y FRN with reset date each  $6\mathrm{m}$ , notional  $1^{\prime}000$  and given spot rates. Setting the day count fraction to  $1/2$ , we get the values in Table 3.3:

<table><tr><td>Maturity</td><td>Spot Rate</td><td>Forward Rate</td><td>Cash Flow FRN</td><td>PV FRN</td></tr><tr><td>0.5</td><td>2.45%</td><td>2.45%</td><td>12.25</td><td>-</td></tr><tr><td>1</td><td>2.62%</td><td>2.76%</td><td>13.78</td><td>-</td></tr><tr><td>1.5</td><td>2.80%</td><td>3.08%</td><td>15.40</td><td>-</td></tr><tr><td>2</td><td>3%</td><td>3.45%</td><td>1017.37</td><td>-</td></tr><tr><td>-</td><td>-</td><td>-</td><td>-</td><td>1000</td></tr></table>

Table 3.3: Valuation of a FRN. The forward rates are calculated using simple compounding  $F(0,S,T) = \frac{\frac{1 + T \times R(0,T)}{1 + S \times R(0,S)} - 1}{T - S}$ . The FRN cash flows are derived from  $\mathrm{CF}(T) = 1'000 \times \frac{F(0,S,T)}{2}$  and the PV follow from  $\mathrm{PV}(\mathrm{CF}(T)) = \frac{\mathrm{CF}(T)}{1 + T \times R(0,T)}$ .

We close with some OTC market figures. Figure 3.3 shows notional and gross amounts in OTC markets. Notional amounts are USD 600 tr which is 8 times worldwide GDP. The gross amount is more than a factor 10 smaller. The markets cover OTC foreign exchange, interest rate, equity, commodity and credit derivatives.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/134fa08966b0d28b8b34e4777bee89e5fd80f4e929824200375bf79d11b9e475.jpg)  
Figure 3.2: Graphical representation of a payer swap replication (payer means the party which pays the fixed rate and obtains the floating one). Dotted lines represent floating cash flows. Replication is obtained by virtually adding and subtracting notional amounts at the beginning and maturity of the swap. We assume for simplicity the same periodicity for the floating and fixed leg. The figure shows an important property of risk structuring: To obtain the cash flow profile of a new product one can add to an existing profile new products and add them vertically.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/841a3b836cab88678550053c01916d4bd631eb80c96ad2795e0d259ab3f17083.jpg)  
Figure 3.3: OTC market figures. The statistics on the country level is based on data reported every six months by dealers in 12 jurisdictions (Australia, Canada, France, Germany, Italy, Japan, the Netherlands, Spain, Sweden, Switzerland, the United Kingdom and the United States) plus data reported every three years by dealers in more than 30 additional jurisdictions. (Source: BIS, 2018)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c327f5e0ddaa411ceb5b0a1e3fd9b392e857273fc72f460099cafaacd4e5a1e6.jpg)

The gross positive market values is the sum of the replacement values of all contracts that are in a current gain position to the reporter at current market prices and similar for gross negative market value. The gross positive market value is the sum of the two absolute values. Gross means that there is no netting or offsetting. Gross market values supply information about the potential scale of market risk in derivatives transactions and it is a measure of comparable economic significance across markets and products.

# 3.1.3 Forward Rate Agreements

IRS can be considered as a sequence of forward rate agreements (FRAs): A FRA is a swap with a single floating and single fixed leg. Consider a client which would like to obtain a loan of CHF 10 Mio. starting in 6m with 6m maturity. LIBOR spot  $L(6m,6m)$  is fixed in 6m. The client believes that 6m LIBOR starting in 6m will be higher than present 6m LIBOR. He would like to freeze the loan term on the actual interest rate level, i.e. on the fixed forward LIBOR rate  $K = F(0,6m,6m)$ : He wants to swap the floating rate  $L(6m,6m)$  against the fixed rate  $F(0,6m,6m)$ . A FRA contract achieves this client's need:

- At initiation time 0 no cash flows are exchanged.  
- At time  $12\mathrm{m}$  the client has to pay  $\mathrm{CHF} - 10(1 + L(6m,6m))$  Mio. without an FRA. But the client would like to pay  $\mathrm{CHF} - 10(1 + F(0,6m,6m))$  Mio.  
- An FRA contract pays/receives an amount  $A$  in 6m and  $A(1 + F(6m, 6m))$  in 12m such that  $A$  balances the payments in 12m between the unwanted risky payment without a FRA and the wanted fixed payment:  $A$  solves in 12m the equation:

$$
\underbrace {A (1 + L (6 m , 6 m))} _ {\text {B a l i n c e}} - \underbrace {1 0 (1 + L (6 m , 6 m))} _ {\text {W i t h o u t F R A}} = \underbrace {- 1 0 (1 + F (0 , 6 m , 6 m))} _ {\text {D e s i r e d P a y m e n t}}.
$$

Solving for  $A$ , inserting the year-fraction  $\alpha = \frac{\text{Hedging period}}{360}$  and  $K = L(0, 6m, 6m)$  we get:

$$
A = \frac {1 0 \alpha (L (6 m , 6 m) - K)}{1 + \alpha L (6 m , 6 m)}.
$$

The no arbitrage relation between spot rates  $R(s,t)$  and forward rates  $F(s,t,u)$

$$
\left(1 + R (0, 6 m) \frac {1 8 3}{3 6 0}\right) \left(1 + K \frac {1 8 2}{3 6 0}\right) = \left(1 + R (0, 1 2 m) \frac {3 6 5}{3 6 0}\right) \tag {3.4}
$$

implies

$$
K = F(0,6m,6m) = 7.26\% .
$$

Returning to swap pricing and using the no arbitrage relationship between zero bonds and forward rates we get

$$
s _ {0, T} = \sum_ {j = 1} ^ {T} w _ {j} L (0, T _ {j - 1}, T _ {j}), w _ {j} = \frac {p (0 , j)}{A _ {0 , T} (0)}.
$$

The sum over all weights  $w_{j}$  equals 1. This shows that a IRS is a weighted sum of FRA's.

# 3.1.4 Constructing Discount Factors

We construct the discount function  $\{D(0,T)\}$  starting from the par swap rates  $\{s_{0,T}\}$ , i.e. the mapping

$$
\left\{s _ {0, T} \right\}\rightarrow \left\{D (0, T) \right\}.
$$

We start with a  $1y$  par swap rate  $s_{0,1}$  and  $6m$  LIBOR for the floating leg. Proposition 13 implies

$$
N (D (0, 1) - 1) = N s _ {0, 1} (0) D (0, 1) \alpha_ {0, 1}
$$

with  $\alpha$  the day count convention. Solving for the first discount factor:

$$
D (0, 1) = \frac {1}{1 + s _ {0 , 1} \alpha_ {0 , 1}}.
$$

To obtain  $D(0,2)$  we consider a 2y swap with swap par rate  $s_{0,2}$ . From

$$
N (D (0, 1) - 1) = N s _ {0, 2} \left(D (0, 1) \alpha_ {0, 1} + N D (0, 2) \alpha_ {1, 2}\right)
$$

$D(0,2)$  follows as a function of  $D(0,1)$  (Bootstrapping, curve stripping). Solving,

$$
D (0, 2) = \frac {1 - s _ {0 , 2} \alpha_ {0 , 1} D (0 , 1)}{1 + s _ {0 , 2} \alpha_ {1 , 2}}.
$$

An immediate recursion gives

$$
D (0, T) = \frac {1 - s _ {0 , T} (0) \sum_ {i = 1} ^ {t - 1} \alpha_ {i - 1 , i} D (0 , i)}{1 + s _ {0 , T} . \alpha_ {T - 1 , T}}. \tag {3.5}
$$

Table 3.1 shows how different rates are derived from the given swap rates. Using these rates we price  $5y$  swap with a notional of 50 Mio. in a given currency. Table 3.4 summarizes the floating leg pricing. The PV of the floating leg, see Proposition 13, is

$$
- 1 2 ^ {\prime} 3 9 5 ^ {\prime} 1 5 9 = - 5 0 ^ {\prime} 0 0 0 ^ {\prime} 0 0 0 (1 - 0. 7 5 4 0 9).
$$

We price the fixed leg using  $1\%$  as an ad hoc fixed rate.

The PV using  $1\%$  fixed is  $2'135'015$ , hence the fixed swap rate  $s$  follows:

$$
s = -\frac{\mathrm{PV}_{\text{Floating}}(0)}{\mathrm{PV}_{\text{fix at} 1\%}(0)} = 5.806\%.
$$

So far, we assumed that necessary input rates exist. What if there are holes, i.e. times were no observable instrument exists? Then we have to to interpolate. Such a construction should satisfy several requirements:

<table><tr><td>Floating Leg</td><td>1y</td><td>2y</td><td>3y</td><td>4y</td><td>5y</td></tr><tr><td>Rates</td><td>4.5615%</td><td>5.5518%</td><td>6.5750%</td><td>6.2827%</td><td>6.3128%</td></tr><tr><td>Cash flows</td><td>-2&#x27;280&#x27;743</td><td>-2&#x27;775&#x27;921</td><td>-3&#x27;287&#x27;486</td><td>-3&#x27;141&#x27;361</td><td>-3&#x27;156&#x27;409</td></tr><tr><td>PV of cash flows</td><td>-2&#x27;181&#x27;246</td><td>-2&#x27;516&#x27;291</td><td>-2&#x27;799&#x27;551</td><td>-2&#x27;517&#x27;843</td><td>-2&#x27;380&#x27;228</td></tr><tr><td>Fix Leg 1%</td><td>1y</td><td>2y</td><td>3y</td><td>4y</td><td>5y</td></tr><tr><td>Fix 1%</td><td>1%</td><td>1%</td><td>1%</td><td>1%</td><td>1%</td></tr><tr><td>Cash flows</td><td>500&#x27;000</td><td>500&#x27;000</td><td>500&#x27;000</td><td>500&#x27;000</td><td>500&#x27;000</td></tr><tr><td>PV of cash flows</td><td>478&#x27;188</td><td>453&#x27;235</td><td>425&#x27;789</td><td>400&#x27;757</td><td>377&#x27;047</td></tr></table>

Table 3.4: Floating leg pricing. Up to 1y spot rates are used for longer maturities forward rates apply. Lower Panel: Pricing with a fixed  $1\%$  rate.

- Liquid Mark-to-market. The value of a dollar at a future date should be determined by liquid securities. This minimizes the risk that cash flows, are misspecified.  
- Stability. The constructed term structures should be stable when switching from one structure to another one. Switching from a meaningful discount curve to a forward curve should also provide a meaningful forward curve.  
- Smoothness. Curves should not be ragged unless a sound economic explanation exists.  
- Consistency. Estimated term structures today should be consistent with the dynamics of interest rate models. More precisely which parameterized families used to estimate the forward rate curve are consistent with arbitrage free interest rate models? We do not consider this issue and refer to Filipovic (2009).

# Table 3.5 shows CHF money and capital market instruments.

There are several methods to find a curve which interpolates observed data. Linear interpolation leads to jagged curves. Suppose the zero rate curve is constructed linearly. The forward rate is basically a derivative of the zero rate curve and hence the kinks in linear interpolation lead to jumps. Errors and kinks in the linear approximation of the zero rates lead then to jagged forward rate curves. We need therefore higher order polynomials. Approaches are the so-called B-splines or cubic splines, smoothing splines and the exponential-polynomial approach (Nelson-Siegel, Svensson). The last approach is used by most central banks. We consider an interpolation by 3rd order polynomials. The spot rate  $R(0,t)$  is given by

$$
R (0, t) = a t ^ {3} + b t ^ {2} + c t + d
$$

such that the curve matches known rates at specific dates  $t_k = ky$  for  $k = 1,2,3,4$  with values 4, 4.5, 5, 5.3 percent, respectively. We search for the intermediate rate  $R(0,2.5y)$ :

$$
R (0, 2. 5) = a (2. 5) ^ {3} + b (2. 5) ^ {2} + c (2. 5) + d.
$$

<table><tr><td>Period
o/n</td><td>SARON
-0.745</td><td>Period</td><td>LIBOR %</td><td>Period</td><td>Swiss Gov.</td><td>Bonds</td></tr><tr><td></td><td></td><td>1m</td><td>-0.817</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>3m</td><td>-0.768</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>6m</td><td>-0.748</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>12m</td><td>-0.634</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>2y</td><td>-0.896</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>3y</td><td>-0.923</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>4y</td><td>-0.992</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>5y</td><td>-1.006</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>7y</td><td>-0.892</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>8y</td><td>-0.798</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>10y</td><td>-0.654</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>20y</td><td>-0.248</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>30y</td><td>-0.012</td><td></td></tr></table>

Table 3.5: CHF interest rates as of July 2019. Note that all rates are negative. SARON (Swiss Average Rate Overnight) is an overnight interest rates average referencing the Swiss Franc interbank repo market. The data in the table are blended: if several possibilities exist to construct the table, the most convenient instruments are used to fill out the table. Source: Swiss National Bank.

That this unknown rate matches the 4 given ones is equivalent to a linear system:

$$
M x = y  ,   x = (a, b, c, d) ^ {\prime}  ,   y = (4 \%, 4.5 \%, 5 \%, 5.3 \%,  ) ^ {\prime}  ,   M = \left( \begin{array}{c c c c} 1 & 1 & 1 & 1 \\ 8 & 4 & 2 & 1 \\ 2 7 & 9 & 3 & 1 \\ 6 4 & 1 6 & 4 & 1 \end{array} \right)
$$

where the matrix  $M$  has the time index powers as entries. Using the inverse matrix  $M^{-1}$  implies for  $x = (-0.00033, 0.002, 0.00133, 0.037)$  the rate

$$
R (0, 2.5) = - 0. 0 0 0 3 3 (2. 5) ^ {3} + 0. 0 0 2 (2. 5) ^ {2} + 0. 0 0 1 3 3 (2. 5) + 0. 0 3 7 = 4. 7 6 2 \%.
$$

# 3.1.5 Return Bookkeeping

Given a single return calculation, how are returns of portfolios calculated? We always consider a finite economy: A finite number of dates  $0, 1, 2, \ldots, T$ ,  $S_0$ , a risk-less asset  $S_0$ , normalized to  $S_0(0) = 1$ ,  $N$  risky assets  $S_j(t) \geq 0, j = 1, \ldots, N$  in all future states and no frictions (tax, spreads, etc.).

The value or wealth process measures position times price (we often neglect the superscript  $\psi$ ):

$$
V ^ {\psi} (t) = \psi_ {0} S _ {0} (t) + \sum_ {j = 1} ^ {N} \psi_ {j} S _ {j} (t) =: \langle \psi (t), S (t) \rangle , \tag {3.6}
$$

with  $\psi_0$  the amount invested in the risk-free asset,  $\psi_j$  the number of units of the risky security  $j$  held in a period  $[t,t + 1)$  and  $\langle \psi ,S\rangle$  the scalar product. The vector  $\psi (t)$  is a portfolio or a strategy. Dividing (3.6) by the value leads to a normalized portfolio:

Definition 14. A normalized portfolio  $\phi(t)$  is defined by

$$
\phi_ {0} (t) = \frac {\psi_ {0} (t) S _ {0} (t)}{V ^ {\psi} (t)}, \phi_ {k} (t) = \frac {\psi_ {k} (t) S _ {k} (t)}{V ^ {\psi} (t)}, k = 1, \dots , N. \tag {3.7}
$$

If all positions are positive, i.e. a long-only portfolio, and there is no leverage, then the normalized weights are probabilities and add up to one.

Asset managers are interested in self-financing portfolios. The change in value in any period is due only to changes in asset values and not by an external money inor out-flow. Writing  $\Delta X_{t} \coloneqq X_{t} - X_{t - 1}$ , the change in portfolio value  $V = \psi S$  with one asset  $S$  reads in general:

$$
\Delta V _ {t} = (\Delta \psi_ {t}) S _ {t} + \psi_ {t} \Delta S _ {t}.
$$

In the first term on the RHS a change in portfolio value between two dates is due to external money added or withdrawn. Self-financing rules out such strategies:  $(\Delta \psi_{t})S_{t} = 0$ . We summarize some immediate facts:

Proposition 15. 1. The normalized portfolio components without leverage adds up to 1.

2. The return of a portfolio is equal to the weighted sum of the portfolio constituent's return:

$$
R ^ {\phi} = \sum_ {j = 1} ^ {N} \phi_ {j} R _ {j} =: \langle \phi , R \rangle . \tag {3.8}
$$

3. If the portfolio is self-financing, then

$$
V (t) = V (0) + \sum_ {s = 1} ^ {t} \sum_ {j = 1} ^ {N} \psi_ {j} (s) \Delta S _ {j} (s). \tag {3.9}
$$

The last fact states that the portfolio value at a future date is given by the sum of all portfolio profit and loss over time. Each intermediate P&L is determined by the investment decision at the beginning of the period times the random P&L in the period. The simple return of a portfolio is invariant of the size of the portfolios: Scaling the portfolio value by a factor, the factor cancels out in the return calculation. Hence, without loss of generality we set  $V(0) = 1$ .

The proposition implies for the growth rate of wealth  $R_{[0,t]}^{\phi}$  from 0 to  $t$ :

$$
\begin{array}{l} 1 + R _ {[ 0, t ]} ^ {\phi} := \frac {V _ {t}}{V _ {0}} = \frac {V _ {t}}{V _ {t - 1}} \frac {V _ {t - 1}}{V _ {t - 2}} \dots \frac {V _ {1}}{V _ {0}} \tag {3.10} \\ = \left(1 + R ^ {\phi} (t)\right) \left(1 + R ^ {\phi} (t - 1)\right) \dots \left(1 + R ^ {\phi} (1)\right) \\ = \left. (1 + \langle \phi (t), R (t) \rangle) (1 + \langle \phi (t - 1), R (t - 1) \rangle) \dots (1 + \langle \phi (1), R (1) \rangle), \right. \\ \end{array}
$$

i.e.

$$
V _ {t} = V _ {0} \prod_ {s = 1} ^ {t} ((1 + \langle \phi (s), R (s) \rangle).
$$

Wealth growth follows from a geometric rate and not an arithmetic one.

# 3.1.6 Returns and Rebalancing

. We define two basic investment strategies:6

Definition 16.  $\psi(t)$  is a buy-and-hold (BH) or static portfolio if  $\psi(t) = \psi(0)$  for all  $t \geq 0$ .

$\psi(t)$  is a constant rebalanced (RB) portfolio if  $\psi_j(t-)S_j(t) = c_j$  for all positions  $j$  and all  $t$  with  $c$  given.  $t-$  denotes a prior time arbitrary close to  $t$  where the asset value of the period is realized and the portfolio weight  $\psi_j(t-1)$  chosen at  $t-1$  is changed to  $\psi_j(t)$  such that the position value equals the predefined position  $c_j$ .

We consider a portfolio value  $V$  which consists of two asset  $S$  and  $B$  where at each date the weight of the  $S$ -asset is  $60\%$  of the total portfolio value. If  $\phi$  represents the number of shares  $S$  in the portfolio and  $\psi$  those of  $B$ , we have at time 0 (by abusing our notation):

$$
V _ {0} = \phi_ {0} S _ {0} + \psi_ {0} B _ {0} = 0. 6 V _ {0} + 0. 4 V _ {0}.
$$

To achieve the weights, the investor has to buy at time  $0\phi_0 = \frac{V_0}{S_0}\times 0.6$  of asset  $S$  and similarly, for asset  $B$ . After one time step the absolute portfolio value before rebalancing reads:

$$
V _ {1} = \phi_ {0} S _ {1} + \psi_ {0} B _ {1} \neq 0. 6 V _ {1} + 0. 4 V _ {1}
$$

where a change in portfolio value is entirely due to changes in asset values and not in changing the positions (self-financing investment strategy). Then the required values are restored by rebalancing. It follows that the weight of the asset with a price increases is reduced and vice versa for the other asset.

The market portfolio is a buy-and-hold portfolio. Rebalancing to constant wealth levels keeps a constant dollar mix in the positions but not a constant risk mix. We only

consider this type of rebalancing unless otherwise stated. The proportion on capital in stock  $j$  just before rebalancing is given by

$$
\psi_ {k} (t + 1) _ {-} = \frac {\psi_ {k} (t) (1 + R _ {k} (t + 1))}{\sum_ {j = 1} ^ {N} \psi_ {j} (t) (1 + R _ {j} (t + 1))}.
$$

the weights  $\psi_{k}(t + 1)_{-}$  are the drifted weights. In a buy-and-hold portfolio drifted weights equal rebalanced weights at each date.

Given that wealth growth is at a geometric rate we state:

Proposition 17. The geometric return  $R_{BH}$  of a BH long-only portfolio in  $T$  periods for  $N$  assets is given by

$$
(1 + R _ {B H}) ^ {T} = \sum_ {j = 1} ^ {N} \phi_ {j} (1 + g _ {j}) ^ {T}
$$

where  $\sum_{j}\phi_{j} = 1$  and  $(1 + g_j)^T = \prod_{k = 1}^T (1 + R_j(k))$ .

The geometric return  $R_{RB}$  of a fixed-weight RB portfolio in  $T$  periods for  $N$  assets is given by

$$
(1 + R _ {R B}) ^ {T} = \prod_ {k = 1} ^ {T} \left(1 + \sum_ {j = 1} ^ {N} \phi_ {j} R _ {j} (k)\right)
$$

where  $\sum_{j}\phi_{j}R_{j}(t) = R_{RB}(t)$  is the fixed-weight return of the portfolio in period  $t$ .

Comparing BH and RB strategies faces two difficulties. First, the expressions are of a different algebraic form. How to compare them? Second, for RB strategies volatility matters. The first problem can approached by comparing the two geometric returns with a third, fictitious return  $\bar{G}$ . It is fictitious since it is not the geometric return of any actual portfolio. The second problem is solved by using the volatility drag relationship between geometric and arithmetic returns, see below.

Consider an investment problem of the mean-variance type. That is, the optimal policy follows by solving an optimization problem. Expected return and variance are inputs in this model. The expected return input of a single asset is typically the arithmetic mean return over  $T$  periods. Then the expected return of the portfolio becomes the arithmetic mean of the returns of a portfolio which is rebalanced to the mix specified by the optimal investment policy for each asset. Such an analysis of the Markowitz model implies that long term return of an asset with returns is given by the arithmetic mean but we have seen that the effective growth rate is geometric. Since the arithmetic mean of any return series is always greater than the geometric mean, the return predicted by the Markowitz analysis is always greater than the true long term return that would have been obtained by using the actual rebalanced allocation. The next proposition makes this precise.

Proposition 18. For numbers  $x_{i}$ ,

$$
\sum_ {x _ {i} = 1} ^ {N} x _ {i} \geq \left(\prod_ {i = 1} ^ {N} x _ {i}\right) ^ {1 / N}. \tag {3.11}
$$

Equality holds only if all  $x_{i}$  are the same.

If one therefore inputs the geometric asset return a non optimal situation occurs since this always underestimates the true return of the rebalanced portfolio - the volatility drag.

We write GM for the geometric mean and AM for the average arithmetic mean for  $T$  periods:

$$
\mathrm {G M} = \left(\prod_ {k = 1} ^ {T} \left(1 + R _ {k}\right)\right) ^ {1 / T} - 1. \tag {3.12}
$$

Taking logarithm,

$$
\log (1 + \mathrm {G M}) = \frac {1}{T} \sum_ {k = 1} ^ {T} \log (1 + R _ {k})
$$

with  $R_{i}$  the return of the portfolio between time  $i - 1$  and  $i$ . Writing  $\mu$  for the expected mean return of the portfolio we get:

$$
\begin{array}{l} E (\log (1 + \mathrm {G M})) = \frac {1}{T} \sum_ {k = 1} ^ {T} E (\log (1 + R _ {k})) \\ = \frac {1}{T} \sum_ {k = 1} ^ {T} \left(\log (1 + \mu) + E \left(\frac {R _ {i} - \mu}{1 + \mu}\right) - E \left(\frac {(R _ {i} - \mu) ^ {2}}{2 (1 + \mu) ^ {2}}\right)\right) + o (\mu) \\ = \log (1 + \mu) + 0 - \frac {\sigma^ {2}}{2 (1 + \mu) ^ {2}} + o (\mu). \\ \end{array}
$$

If  $\mu$  is small  $\log (1 + \mu) = \mu +o(\mu)$ , using the Neumann series in the portfolio volatility term and approximating the log in GM implies the volatility drag equation:

$$
E (G M) = \mu - \frac {\sigma^ {2}}{2} + o (\mu) = \mathrm {E} (\mathrm {A M}) - \frac {\sigma^ {2}}{2} + o (\mu). \tag {3.13}
$$

The equation also holds if there exists no risk and for individual assets. The volatility drag defines strategies to harvest volatility. by exploiting that volatility impacts the growth of wealth follows. Strategies which take volatility into account such as rebalancing strategies are expected to outperform pure buy-and-hold or equal market weighted strategies.

# 3.1.7 Rebalancing Example

We illustrate rebalancing for the following indices: Swiss Market Index SMI, MSCI World, UCITS ETF, JPM Global Aggregate Bond Index, equal-weighted index of 1,600 hedge

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c933f704339d06604fdf923ddc763884a168d08463afe69841bc9befe6b6f718.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f7a58f36affc643de0541d78da31b6ee2a69e0edeab56907ce64de9c3762439b.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/6d2642f504aad32ff3a662c1dcd495423e9ca124b08a809ed97a0d7c117bd895.jpg)  
Figure 3.4: Rebalancing example for SMI, MSCI World UCITS ETF (MXWO), JPM Global Aggregate Bond Index (SZG2TR), equal-weighted index 1,600 hedge funds (JAGGUSD), FTSE NAREIT All Equity REITs Index (BCOMT), gold dollar price (AU Currency) and the S&P 500 Index (SPX).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d3fbb0f8d19d6e1cfea018a8d99513318e44e42e9a19459e4538b6900def9811.jpg)

funds, FTSE NAREIT All Equity REITs Index, gold dollar price and the S&P 500 Index using weekly data from Sept 2 1993 to Mar 27 2015, see Figure 3.4. The top left panel shows the index or price evolution. The dot.com and GFC crisis are visible. The bottom left panels show the rebalancing strategy. Basically, winners are sold and losers are bought. This panel is a mirror image of the price chart. The panels on the right hand side show performance of different investment strategies. On the top right, the rebalanced strategy and the equal weighted buy-and-hold strategy are shown. Both strategies fail to provide protection if markets are under stress although the rebalancing strategy suffers from a lower shortfall. But it also cuts the upside potential which leads to overall underperformance. The red line assumes transaction costs of 10 bps per rebalancing.

In the lower right panel, the rebalanced to EW strategy is compared with the inverse volatility strategy IV and two momentum strategies. In the IV strategy, the rebalancing update of the strategies is adjusted by the past volatility of the indices - the more volatile an index was, the less weight it will have in the next period (negative leverage). With this strategy the large market stress periods are neutralized but the strategy also annihilates the growth potential. In the momentum approach, strategies are updated according to whether a strategy belonged to the winner or looser strategy over the past month. More precisely, the average last month return of all strategies are calculated. Each strategy

is compared to this average: If the performance is higher (lower) than the average, the strategy is a winner (looser) one and the updated rebalancing strategy is updated by adding/subtracting a constant number, respectively. The strategy is a long only strategy which is atypical for momentum strategies which are implemented as long-short portfolios (buy the winners, sell the losers). The momentum strategy shows boost and crash before and during the GFC. These two effects typically are reinforced in a long-short set-up.

# 3.1.8 Rebalancing  $=$  Short Volatility Strategy

A short volatility strategy means that investors sell out-of-the-money call and put options. Since the price of an option is in  $1:1$  relation with the volatility, shorting a call is the same as shorting volatility. Therefore, 'Rebalancig = Short Volatility Strategy' means that the investor is effectively selling rewarded options by rebalancing which leads to the additional growth rate. We follow Ang (2013).

Consider a single risky asset  $S$  and a risk-free bond that pays 10 percent each period in a two-period binomial model. The stock starts with a value of 1 and can go up or down in each period with the same probability of 50 percent (see the data in Figure 3.5). If an up state is realized, the stock value doubles; otherwise the stock loses half of its value.

Using these assumptions, wealth projections for the buy-and-hold strategy follow at once. The value in the node 'up - up' - that is, 2.884 follows from

$$
2. 8 8 4 = 1. 6 4 (0. 7 3 1 7 \times 2 + 0. 2 6 8 3 \times 1. 1),
$$

where 1.64 is the wealth level of the former period node; 2 and 1.1 are the returns of the risky asset (up) and the risk-free asset, respectively; and  $0.7317 = 0.6 \times 2 / 1.64$  is the holding in equity after the first period. The rebalancing dynamics are calculated in the same way but with fixed proportions in the two assets.

The payoffs after period 2 show that rebalancing adds more value to the sideways paths but less value to the extremes (up - up or down - down) compared to the buy-and-hold strategy. This transforms the linear strategy of buy-and-hold - that is, payoff is a linear function of the stock value, in a non-linear way. Precisely, consider a European call option with a strike value 3.676 at time 2 and a European put option with a strike of 0.466. The option prices at date0 and date 1 follow from no-arbitrage pricing.

Consider the following two strategies:

- A rebalancing strategy.  
- A short call + short put + long bond + long buy-and-hold strategy. The first two positions are the short volatility strategy.

A calculation - see Ang (2013) - shows that:

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7016d6ca52f0902f65803a841fea8ea0ebb9872bb6aad6d63ecd7c6019c5f077.jpg)  
Figure 3.5: Rebalancing as a short volatility strategy in a binomial tree model. Left are the risky asset's dynamics, in the middle are the wealth values if a buy-and-hold strategy (60/40) is used, and right are the wealth levels for a rebalancing strategy to fixed (60/40) weights. Note that up and down is the same as down and up. Therefore, there are two paths for the stock value after period 2, both with the result of 1 (Ang [2013]).

- Both strategies start with the same value 1 at time 0.  
- Both strategies attain the same values in all 3 states at time 2.

Therefore the two strategies are identical. This shows that a short volatility strategy, financed by bonds and the buy-and-hold strategy, is the same as a rebalancing strategy. Since volatility is a rebalancing means short volatility, the investor automatically earns the volatility risk premium. The short volatility strategy makes the payoff in the center of the probability distribution larger at the costs of the extreme payoffs. Short volatility or rebalancing underperforms buy-and-hold strategies if markets are either booming or crashing, but it performs well if markets are showing time reversals.

# 3.1.9 Optimal Investment Strategy and Rebalancing

How is rebalancing related to optimal multi-period investment theory? Merton laid the foundations in his works from 1969 and 1971 (Merton [1969, 1971]). The rational agents optimize their lifetime expected utility of consumption by choosing their optimal consumption path and optimal investment portfolio, see Section 4.3.2 for the model. The work of Merton triggered a myriad of academic papers. These papers differ from one another in many respects, including the innovation risk sources, the agents preferences, information asymmetries. The main lessons learned from dynamic models is how risk is best distributed over time and in the cross-section (diversification), while static models only consider the latter one. Hence, dynamic investment matters for pension funds and personal finance for example.

Fortunately, for most models the optimal investment strategy have the same structural form.

The optimal strategy  $\phi(t)$ , for time separable expected utility maximizing models, consists of two parts:

$$
\phi (t) = \text {S h o r t - T e r m W e i g h t} + \text {O p p o r t u n i s t i c W e i g h t} \tag {3.14}
$$

The short-term weight is also called the myopic investment demand, and the opportunistic weight the hedging demand or long-term weight. This general rule follows from the the 'Principle of Optimality' of R. Bellman, see Section 4.2.1.

We write (3.14) more explicitly:

$$
\phi (t) = \mathrm {M P R} \times \mathrm {R R A} ^ {- 1} + (1 - \mathrm {R R A} ^ {- 1}) \Delta Y \times \mathrm {R I R A} ^ {- 1} \tag {3.15}
$$

where:

The Market Price of Risk (MPR):  $\mathrm{MPR} = \frac{\alpha_t - r_t}{\sigma_t^2}$ .  

- RRA $^{-1}$  the inverse relative risk aversion - the investor's risk tolerance.  
- RIRA $^{-1}$  the inverse relative innovation risk aversion.  
- $\Delta Y$  the hedge of innovation risk factors.

If the opportunity set is constant,  $\Delta Y = 0$ , then optimal investment is equal to myopic investment. The myopic component  $\mathrm{MPR} \times \mathrm{RRA}^{-1}$  is equal to a the optimal solution of a one-period model. The second component  $(1 - \mathrm{RRA}^{-1})\Delta Y \times \mathrm{RIRA}^{-1}$  represents the desire to hedge against future opportunity changes.

# Definition 19. Equation (3.15) defines the theoretical TAA.

The myopic part corresponds to the one-period TAA used in practice, see Section 4.3.4.6. The theoretical one is the more difficult to handle due to the long-term part.

We comment on the optimal strategy formula (3.15). First, the optimal investment strategy is time-varying; buy-and-hold is not optimal from a dynamic investment point of view. But there is nothing in the optimal formula which states that it is optimal to rebalance say to constant weights too.

Second, rebalancing is countercyclical. Consider the two asset case. If an asset price increases, the market price of risk for this asset increases (larger return, lower risk). The rule states to sell this asset.

Third, which of the two components in (3.14) is more important? In the extreme case where returns are not predictable or stochastic opportunities are not changing over time or the investor has a logarithmic utility function, then the long-term investment strategy part in (3.14) vanishes. It is optimally to invest myopically. Else, research results are ambiguous about the relative strength. The result depends on size of the opportunistic weight which is driven by two factors: predictability and investment opportunity. The closer asset returns are to predictability and/or the less stochastic opportunity set variations matter, the less important is the opportunity component.

Fourth, the MPR keeps its form for many assets but the division by the variance is replaced by a multiplication with the information matrix  $C^{-1}$ , the inverse covariance matrix:

$$
\mathrm {M P R} = C ^ {- 1} \left(\mu_ {t} - r _ {t}\right). \tag {3.16}
$$

Comparing this with the solution of the Markowitz problem with no risk-free asst (4.3),  $\phi = \frac{1}{\theta} C^{-1}\mu$ , shows that the first component of the optimal investment strategy (3.14) defines a mean-variance efficient portfolio. The MPR is proportional to the Sharpe ratio. In this sense, portfolio theory without innovation risk factors rationalizes the Sharpe ratio and the Markowitz model to many period investing.

Fifth, the inverse relative risk aversion measures the curvature of the utility function as a function of wealth: If the investor is risk neutral,  $\mathrm{RRA}^{-1} = 1$ . The more risk averse an investor is, the lower  $\mathrm{RRA}^{-1}$  is and the more is optimally invested in the risk-free asset. The notion of relative risk aversion raises two delicate issues. First, there is a calibration result by Rabin (2000) that shows that expected-utility theory is an utterly implausible explanation for appreciable risk aversion over modest stakes. Second, the measurement of RRA is, in itself, a delicate matter.

Six, the opportunistic weight consists of three different terms: First, if the investor is getting more risk averse,  $\mathrm{RRA}^{-1}$  decreases, then the myopic component in the optimal portfolio becomes less important. Second, the aversion to innovation risk sources. Third, a hedging demand against innovation risk. This is proportional to  $\operatorname{cov}(R^e,R_I)$  in (3.14) - that is to say, the hedging demand follows from the correlation pattern of the innovation's portfolio return with the overall portfolio return. Investors will increase their holding of the risky asset given by the first term if it covaries negatively with state variables, that matter in the value function to the investor. A bond is such a hedge against falling

interest rates.

Seventh, if liabilities matter such as in goal based investment, then in both expressions in (3.15) functions of time differences  $f(T - t)$  enter where  $T$  is a realization time of a liability. These functions take into account the 'way to go' effect. It is for example optimal to take more risk given a positive drift if there is 5 years left to finance, given an actual financing degree, a liability than if only one month is left until maturity of the liability.

Logarithmic utility facilitates calculations but is behavioral specific. Log investors always act optimally myopic (one-period view) independent of the dynamic context. Their demand for hedging long-term risks is zero. To understand why, a log investor maximizes log returns. Assuming normality of the returns, the log return over a long time horizon is equal to the sum of one-step returns. Long-term return is therefore maximized if the sum over the one-period returns is maximized which is the same that each one-period return is maximal.

To see how the optimal investment formula fail to be applied in reality, consider the Great Financial Crisis (GFC). Pick an investor with a relative risk aversion of 1, a normal market return of  $6\%$  in stocks, a risk free rate of  $2\%$  and volatility of  $18\%$ . The investor assumes that returns are IID; he is a myopic investor. From the optimal portfolio formula (3.15):  $\phi = \frac{0.06 - 0.02}{0.18} = 0.6$ . That means the investor holds  $60\%$  in equities and  $40\%$  in a risk-less asset. In the GFC, volatility (both realized and implied one) increased to levels around  $70\%$ . The optimal myopic formula implies  $\phi = 0.04$ , i.e., a  $4\%$  equity position or a reduction by  $93\%$  from the pre-crisis investment. But stock market participation was not reduced by  $93\%$ . Since the average investor holds the market, he did not show the same behavior as our theoretical.

We compare three well-known strategies:

- Do nothing (buy-and-hold) [In (3.15) all parameters are constant];  
- Buy falling stocks, sell rising ones (constant-mix  $60/40$  rebalancing strategies) [Contrarian view to the myopic part in (3.15)];  
- Sell falling stocks, buy rising ones (portfolio insurance strategies) [In-line with the myopic part of (3.15)].

We follow Perold and Sharpe (1988) and Dangel et al. (2015). They consider buy-and-hold, constant mix (say 60/40 strategies), constant-proportion portfolio insurance and option-based portfolio insurance. We start with the first two strategies with a risky asset  $S$  and a risk-free asset  $B$ . In th payoff diagrams value of the assets is a function of the value of the stock and in th exposure diagrams the relation between dollars invested in stocks to the total assets is calculated.

The payoff diagram for the  $60/40$  rule is a straight line with a slope of 0.6, the maximum loss is  $60\%$  of the initial investment and the upside is unlimited, see Figure 3.6. The exposure diagram is also a straight line in the space where the value of the assets

are related to the stock position. For a buy and hold strategy, the slope is 1 and the line intersects the  $x$ -axis of the value of the assets at USD 40. If the portfolio is less than 40 USD, the demand to invest in the stock is zero, for the constant mix strategy there is always a demand.

If there is no volatility in the market, either stocks rise or fall forever. Then the buy-and-hold payoff always dominates the constant mix portfolio. But with volatile markets, the success of the strategy depends on the paths of asset prices, see volatility drag and volatility harvesting. A constant mix portfolio tends to be a superior strategy if markets show reversal behavior instead of trends.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/41e33529669d47d152845bd7de3283bdd806e4c792d445ca4c9e7c8fc574f4ac.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/293db59233f33c39e905a136211912fa89fdee88a24016eb0f21273e44c12828.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/fe246f052a4513a7f2eb90644e1536d914399c4c2ad42184dd9add23fc87b42c.jpg)  
Figure 3.6: Payoff and exposure diagrams for constant mix and buy-and-hold strategies (Adapted from Perold and Sharpe [1988]). The left panels show the payoff diagram for the  $60/40$  buy and hold strategy and the exposure diagrams for the  $60/40$  strategy once buy-and-hold or dynamic, that is assuming a constant mix. The upper right panel shows the superiority of the buy-and-hold strategy when there are only trends and the lower diagram shows that constant mix strategy can dominate the buy-and-hold one if there is volatility depending on the stock asset path which is represented by the thickness of the asset value line.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7a28b22daad0574264c182185fe9c739f3561263b9e48d64411c3409b7f370ee.jpg)

This shows that the performance of rebalancing depends on the investment environment: different economic and financial market periods lead to different results. Ang (2013) compares the period 1926-1940 with the period 1990-2011. He compares buy-and-hold investments in US equities and US Treasury bonds and pure investments in the two asset classes with the rebalanced (60/40) investment portfolio in the two assets. The

countercyclical behavior of rebalancing smooths the individual asset returns. It leads to much lower losses after the stock market crash in 1929 but it was not able to follow the strong stock markets before the crash compared to the static strategy. The rebalancing strategy also leads to much less volatile performance than the single asset or bond strategy.

We consider portfolio insurance. Maximizing expected return with constant absolute risk aversion implies that optimal static sharing rules are linear in the investment's payoff: It is optimal to hold a certain fraction of a risky investment rather than negotiating contracts with nonlinear payoffs. This also holds in some dynamic models such as the Merton model (1971). If investment opportunity sets are not changing, the proportions of risky and risk-free assets are kept unchanged over time. But this requires portfolio rebalancing: Buying/selling the risky asset when it decreases/increases in value and selling it with increasing prices - the constant mix strategy holds. Theoretically, with this strategy investors invest in risky assets even in market stress situations. In practice, however, there is a strong demand for portfolio insurance since investors have a considerable downside-risk aversion. Therefore, a rebalancing method 'opposite' to the constant mix is required: selling stocks as they fall.

Returning to the tree alternatives the payoffs of the strategies are linear, concave or convex. The last strategy is called convex since the payoff function is increasing with an increasing rate if the stock values increase. Hence, rebalancing has an impact on the payoff. Concave strategies, such as the constant mix strategies, are the mirror image of convex strategies such as portfolio insurance. The buyer of one strategy is also the seller of the other one.

Summarizing, buying stocks as they fall leads to concave payoffs. These are good strategies in market with no clear trend since the principle 'buy low, sell high' applies. In markets under stress, losses are aggravated since more and more assets are bought. The convex payoff of portfolio insurance strategies limits the losses in stressed markets while keeping he upside intact. But if markets oscillate, their performance is poor.

There are many ways to construct convex payoffs:

- Stop-loss strategies. The investor sets a minimum wealth target or floor that must be exceeded by the portfolio value at the investment horizon. This strategy is simple but once the loss is triggered the portfolio will no longer be invested in the risky asset and hence participation in a risky asset recovery is not possible.  
- In the option based approach one buys a protective put option. While simple, this strategy has several drawbacks. First, it acts against many investor's behavior that one should buy portfolio insurance when it is cheap - stock markets boom. Second, buying an option at the money is expensive compared to the expected risky asset return and since one has to roll the strategy costs multiple. Therefore,

such option based strategies are often used in long-short combinations (buying out-of-the-money put and sell an out-of-the-money call).

- Constant Proportion Portfolio Insurance (CPPI). This strategy is a simpler version of the protective put strategy.

# 3.1.10 Stochastic Portfolio Theory (SPT)

Stochastic portfolio theory (SPT) was introduced by Fernholz (2002). Its goal is to construct investment strategies that outperform a certain reference portfolio such as the market portfolio. We work in discrete time and follow Pal and Wong (2016). We have seen that rebalancing can but must not outperform a benchmark return. SPT makes precise under which conditions such a outperformance is possible. This means SPT gives a precise and model independent meaning for example to volatility harvesting. The conditions are variants of the Fernholz master equation. The original equation depends on the assumed dynamics of the underlying asset prices. Pal and Wong showed in the discrete time set-up that the master equation does not depend on the asset dynamics. It allows a return decomposition for each path without relying to the asset stochastic law.<sup>7</sup>

We start with a classic example with two assets. Asset 1 earns  $-50\%$  return for all odd periods and  $100\%$  return for all even periods. Asset 2 is a risk-free asset whose return is always  $0\%$ . Table 3.6 shows different portfolio returns for a buy-and-hold (BH) portfolio and a rebalanced portfolio (RB) to equal weights in each period. Initial wealth is USD 1.

<table><tr><td>Period</td><td>BH 1</td><td>BH 2</td><td>RB 1+2</td><td>RB 1</td><td>RB 2</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>0.5</td></tr><tr><td>1-</td><td>1</td><td>0.5</td><td>0.75</td><td>0.25</td><td>0.5</td></tr><tr><td>1+</td><td>1</td><td>0.5</td><td>0.75</td><td>0.375</td><td>0.375</td></tr><tr><td>2</td><td>1</td><td>1</td><td>1.125</td><td>0.756</td><td>0.375</td></tr><tr><td>Total Return</td><td>0%</td><td>0%</td><td>12.5%</td><td>+51.5%</td><td>-25%</td></tr></table>

Table 3.6: Buy-and-hold versus equal-weight rebalanced portfolios. 1means the time before rebalancing and  $1+$  is the portfolio and position value after rebalancing.

Investing the dollar BH in either of the two assets leads to zero growth of wealth. Rebalancing to equal weights in each period leads to a portfolio growth of  $0.75 \times 1.5 = 1.125$ . Systematic rebalancing is capable of capturing profit from volatility even when the underlying assets experience zero growth. If we extend the model to many periods a sequence of alternating return products  $0.75 \times 1.5 = 1.125$  determines excess return of RB relative to BH. The order of the return products does not matter but the number of such pairs

of of matchings. If we can form  $N$  pairs, the growth is boosted as  $(1.125)^{N}$ .

To formalize the discussion, consider a binomial tree with two risky asset prices  $S_{1}, S_{2}$ . Then

$$
X (t) = \log \frac {S _ {1} (t)}{S _ {2} (t)}
$$

is a measure of relative price. We set  $\Delta X(t) \coloneqq \pm \sigma$  where  $\sigma^2$  is instantaneous variance of relative prices. For a strategy  $\phi = (\phi_1, \phi_2)$ ,

$$
W ^ {\phi} (t) := \frac {V ^ {\phi} (t)}{S _ {2} (t) / S _ {2} (0)} = \left(\frac {S _ {1} (t) + S _ {2} (t)}{S _ {1} (0) + S _ {2} (0)}\right) \frac {S _ {2} (0)}{S _ {2} (t)}
$$

is the value of the portfolio  $\phi$  relative to asset 2. It satisfies the dynamics (using the same arguments as for (3.21)):

$$
\frac {W ^ {\phi} (t + 1)}{W ^ {\phi} (t)} = 1 + \phi_ {1} (t) \left(e ^ {\Delta X (t)} - 1\right) =: A (t).
$$

Iterating this equation implies

$$
W ^ {\phi} (t) = \prod_ {s = 0} ^ {t - 1} A (s).
$$

Assume that  $\phi$  is constant, then a volatility matching pair of up and down moves generates the growth factor which is larger than 1, i.e.  $A(s)A(s - 1) > 1$ . It is maximal for the equal weighted portfolio  $\phi = 0.5$ . The recursive form of wealth implies that wealth growth of the constant weighted portfolio dominates the benchmark growth rate of asset 2 if the number of matching pair dominates the moves in the price paths which do not match. In a perfect zig-zag price path all moves match, in a monotone increasing or decreasing path there is no matching at all and volatility harvesting is a loser strategy.

We use these ideas to develop the formal set-up of SPT starting with some notations. The market weights  $\mu_j(t)$ , where  $X_{j}(t)$  is the market capitalization at time  $t$  of asset  $j$ , read:

$$
\mu_ {j} (t) := \frac {X _ {j} (t)}{\sum_ {k = 1} ^ {N} X _ {k} (t)}. \tag {3.17}
$$

Investing in each period according to the market weights, the investment portfolio is the market portfolio  $V^{\mu}$ . The temporal update of the market weights, if only asset returns lead to capital changes, reads

$$
\mu_ {j} (t + 1) = \frac {\mu_ {j} (t) \left(1 + R _ {j} (t + 1)\right)}{\sum_ {k = 1} ^ {N} \mu_ {k} (t) \left(1 + R _ {k} (t + 1)\right)}. \tag {3.18}
$$

and:

$$
V ^ {\mu} (t) = \frac {\sum_ {j} X _ {j} (t)}{\sum_ {j} X _ {j} (0)}. \tag {3.19}
$$

Let  $V^{\mu}$  be the market portfolio value and  $V^{\phi}$  any other portfolio value. We define the relative portfolio

$$
V ^ {\phi / \mu} (t) := \frac {V ^ {\phi} (t)}{V ^ {\mu (t)}}. \tag {3.20}
$$

The time evolution of the relative portfolio depends only on the market weights for all  $t > 0$ :

$$
\frac {V ^ {\phi / \mu} (t + 1)}{V ^ {\phi / \mu} (t)} = \sum_ {k = 1} ^ {N} \phi_ {k} (t) \frac {\mu_ {k} (t + 1)}{\mu_ {k} (t)} \tag {3.21}
$$

and  $V^{\phi /\mu}(0) = 1$

After these preparations, we write

$$
\begin{array}{l} \Delta \log V ^ {\phi / \mu} (t) \tag {3.22} \\ = \log \left(\sum_ {k = 1} ^ {N} \phi_ {k} (t) \frac {\mu_ {k} (t + 1)}{\mu_ {k} (t)}\right) \\ { = } { \sum _ { k = 1 } ^ { N } \phi _ { k } ( t ) \log \left( \frac { \mu _ { k } ( t + 1 ) } { \mu _ { k } ( t ) } \right) + \log \left( \sum _ { k = 1 } ^ { N } \phi _ { k } ( t ) \frac { \mu _ { k } ( t + 1 ) } { \mu _ { k } ( t ) } \right) - \sum _ { k = 1 } ^ { N } \phi _ { k } ( t ) \log \left( \frac { \mu _ { k } ( t + 1 ) } { \mu _ { k } ( t ) } \right) } \\ =: \sum_ {k = 1} ^ {N} \phi_ {k} (t) \log \left(\frac {\mu_ {k} (t + 1)}{\mu_ {k} (t)}\right) + \gamma^ {\phi / \mu} (t). \\ \end{array}
$$

The expression  $\gamma^{\phi/\mu}$  is always non-negative by Jensen's inequality and it strictly positive if  $Y := \log\left(\frac{\mu_k(t+1)}{\mu_k(t)}\right)$  is not constant, i.e. if there is temporal volatility which we assume to hold true. $^9$  We write  $\Gamma^{\phi/\mu}(t) = \sum_{s=0}^{t} \gamma^{\phi/\mu}(s)$  for the cumulated excess growth rate. Since  $\gamma^{\phi/\mu} > 0$ ,  $\Gamma \to \infty$  if time goes to infinity, Gamma is called the energy term.

The second transformation for the log return in (3.22) is to rewrite the first term using relative entropy:

$$
\sum_ {k = 1} ^ {N} \phi_ {k} (t) \log \left(\frac {\mu_ {k} (t + 1)}{\mu_ {k} (t)}\right) = \sum_ {k = 1} ^ {N} \phi_ {k} (t) \log \left(\frac {\mu_ {k} (t + 1)}{\phi_ {k} (t)}\right) - \sum_ {k = 1} ^ {N} \phi_ {k} (t) \log \left(\frac {\phi_ {k} (t)}{\mu_ {k} (t)}\right).
$$

With the relative entropy notation  $S(p,q) = \sum_{j}p_{j}\log (p_{j} / q_{j})$  for two probability distributions we get:

$$
\sum_ {k = 1} ^ {N} \phi_ {k} (t) \log \left(\frac {\mu_ {k} (t + 1)}{\mu_ {k} (t)}\right) = S (\phi (t), \mu (t + 1)) - S (\phi (t), \mu (t)).
$$

Summarizing, relative log return for any strategy can be decomposed into:

$$
\Delta \log V ^ {\phi / \mu} (t) = \gamma^ {\phi / \mu} (t) + S (\phi (t), \mu (t + 1)) - S (\phi (t), \mu (t)). \tag {3.23}
$$

If rebalancing takes place to constant weights, then  $\phi$  is constant and the decomposition reads:

$$
\Delta \log V ^ {\phi / \mu} (t) = \gamma^ {\phi / \mu} (t) + S (\phi , \mu (0)) - S (\phi , \mu (t)). \tag {3.24}
$$

Figure 3.7 shows the decomposition of a log portfolio value, rebalanced to constant weights, into its energy and entropy decomposition. Gamma measures the amount of

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9cec7a0fe139bda89a4d0807c125f02da74cf3b5ff6705bd1c0749e15983dabe.jpg)  
Figure 3.7: Decomposition of a constant weight rebalanced portfolio in the energy and entropy paths.

market volatility captured by the portfolio - the number of matched factors in the introductory examples. The relative entropy term measures how much the relative performance deviates from Gamma. This term depends only on the initial and current positions of the market weight vector, i.e. how the change in capital distribution affects the performance of the portfolio. There is no volatility effect. The fluctuations of the log return are dominated in the short run by the entropy part and long term growth comes from the cumulated excess growth rate.

For constant weighted portfolios the following theorem characterizes log return growth.

Theorem 20. Consider a constant weighted strategy  $\phi$ . Assume that the market returns  $\mu(t)$  for all  $t$  are element of a compact set  $K$  and that  $\Gamma(t)$  is increasing to infinity for  $t$  to infinity. Then, portfolio value  $V^{\phi/\mu}(t)$  also tends to infinity.

The statement is a pathwise one and free of any stochastic modeling assumptions. Long term outperformance follows whenever the two path properties are satisfied. The validity of these two conditions can be evaluated by a portfolio manager at each date. The authors extend Pam and Wong extend the discussion to non-constant rebalancing strategies.

# 3.1.11 Return Attribution

The attribution of returns is key in AM to understand the return drivers. We consider the Arithmetical Relative Return (ARR). It is defined as the difference between a portfolio return  $R^V$  and a benchmark return  $R^b$

$$
A R R = R ^ {V} - R ^ {b} = \sum_ {j} \left(\phi_ {j} R _ {j} ^ {V} - \mathbf {b} _ {j} R _ {j} ^ {b}\right) \tag {3.25}
$$

with  $\mathbf{b}$  the benchmark portfolio weights. Figure 3.8 shows how this return difference can be split into three different rectangles for each  $j$ :

$$
\mathrm {A R R} _ {j} = 1 + 2 + 3 = \underbrace {(\phi_ {j} - \mathbf {b} _ {j}) R _ {j} ^ {b}} _ {=: A} + \underbrace {(R _ {j} ^ {V} - R _ {j} ^ {b}) \mathbf {b} _ {j}} _ {=: S} + \underbrace {(\phi_ {j} - \mathbf {b} _ {j}) (R _ {j} ^ {V} - R _ {j} ^ {b})} _ {=: I}. \tag {3.26}
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3ea8337a4b9db3917ceba23027e88884c6daad6f5fa8ac2179d5428f265cea69.jpg)  
Figure 3.8: Arithmetic return decomposition. Source: Adapted from Marty (2015)

$A$ , a difference arising in portfolio weights, represents the tactical asset allocation (TAA) (the Brinson-Hood-Beebower (BHB) effect),  $S$  the stock selection effect and  $I$  the interaction effect. BHB invented this decomposition in 1986. It is often used as a

starting point in performance attribution.

Figure 3.9 shows the performance attribution tree for the MSCI World ESG Quality Index. The total return  $R^T$  can be written in the form  $R^T = R^T - R^b + R^b = \mathrm{ARR} + R^b$ . Since fees are not available, total return is a gross return. The figure shows that the ARR has several levels.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b91af95ae6093a3dfc74017e49c8602ce7f83fad66122046bcc36f89995a7cfc.jpg)  
Figure 3.9: Performance attribution tree for the MSCI World ESG Quality Index where the information written in red comes from me (Adapted from MSCI [2016]).

The ARR is first decomposed in asset classes. Then the asset class equity is further decomposed into three types: Sector and geographical diversification  $G$ , the selection part  $S$  and a part which invests into a portfolio of factor risk premia. In the return attribution, return numbers add up in the hierarchy but non-linear risk figures to not add up.

Given the return attribution, how do we calculate returns? This is trivial if no cash inflows or outflows need to be considered. Two methods to calculate investment return are distinguished:

- Time-Weighted Rate of Return (TWR).

# - Money-Weighted Rate of Return (MWR)

We refer to Marty (2015) for a detailed discussion. The TWR measures the return of an investment where inor outflows do not affect the return of the investment. Its reflects the return due to the asset managers decisions taken in the past. As an example, start with USD 100 in period one, where another USD 200 are added at the beginning of period two and portfolio value at the end of period two is USD 300. The net gain of the portfolio is zero, but calculating the linear return results in a 200 percent return if do not take into account intermediate cash flows. TWR controls for these cash flows in return calculations. MWR reflect the return from an investor's perspective: In and out cash flows as well as the profit and loss matter in this perspective. The MWR method is based on the no arbitrage principle. Both, the MWR and TWR can be applied on an absolute or relative return basis.

The TWR  $R_{0,T}^{TWR}$  of an investment starting in 0 and ending in  $T$ , with  $T - 1$  time points in between (not-necessarily equidistant) is defined by:

$$
1 + R _ {0, T} ^ {T W R} = \prod_ {i = 0} ^ {T - 1} (1 + R _ {i, i + 1}) = \prod_ {i = 0} ^ {T - 1} \left(1 + \frac {V _ {i + 1} - V _ {i}}{V _ {i}}\right) = \prod_ {i = 0} ^ {T - 1} \left(\frac {V _ {i + 1}}{V _ {i}}\right) \tag {3.27}
$$

Writing out the second product it follows that  $1 + R_{0,T}^{TWR}$  maps  $V_{0}$  into  $V_{T}$  - all intermediate steps cancel. The following properties hold for TWR:

Proposition 21. 1. Adding or subtracting any cash flow  $c_{\widehat{t}}$  at any time  $\widehat{t}$  does not change TWR.

2. If  $\phi_i(j) = \lambda_i\phi_{i-1}(j)$  for all assets  $j$  and all time points  $i$ , then TWR equals the return of the final portfolio value relative to its initial value. Hence, all intermediate returns cancel in (3.27).

The TWR method is used by most index providers since cash inor out-flows do not impact the return of the index. To prove the first property, fix a time  $\hat{t}$  and let  $c_{\hat{t}}$  be an arbitrary cash flow. The relevant terms in the TWR with this additional cash flow are:

$$
\left(1 + \frac {V _ {\hat {t} + 1} - V _ {\hat {t}}}{V _ {\hat {t}}}\right) \left(1 + \frac {V _ {\hat {t}} - V _ {\hat {t} - 1}}{V _ {\hat {t} - 1}}\right).
$$

Assuming that  $V_{\widehat{t}} = V_{t} + c_{\widehat{t}}$ , i.e. the additional cash flow is added, and inserting this in the last expression implies

$$
\frac {V _ {t + 1}}{V _ {t - 1}}
$$

which is the same result as simplifying the two terms in the TWR without any additional cash flows.

In the MWR cash flows  $c_{j}$  are reinvested at the internal rate of return (IRR), i.e.  $R^{MWR}$  solves:

$$
P V (\mathbb {C}, R ^ {M W R}) = \sum_ {j = 1} ^ {T} D (0, j; R ^ {M W R}) c _ {j} \tag {3.28}
$$

where the discount factor  $D$  depends explicitly on the  $R^{MWR}$ . Since  $R^{MWR}$  enters the denominator of the discount factor, (3.28) is solved numerically. Using the first order approximation  $D \sim \frac{1}{1 + R}$  transforms (3.28) into a linear equation for  $R$ -the so-called Dietz Return (with AIC the Average Investment Capital):

$$
R ^ {D i e t z} = \frac {P \& L}{A I C} := \frac {S _ {T} - S _ {0} - \sum_ {j = 1} ^ {T - 1} c _ {j}}{S _ {0} + \frac {1}{2} \sum_ {j = 1} ^ {T - 1} c _ {j}}. \tag {3.29}
$$

This approximation implies simple compounding and assumes that the CF are realized in the middle of the respective periods.

# 3.1.12 Returns and Leverage

We consider two assets, see Anderson et al. (2014). The return of this portfolio without leverage  $R^0$  in a single period reads

$$
R ^ {0} = \langle \phi , R \rangle , \sum_ {i} \phi_ {i} = 1 \tag {3.30}
$$

with  $\phi, 1 - \phi$  the invested amounts in asset 1 and 2, respectively. Consider a leveraged position with leverage ratio  $\lambda \geq 1$ . The portfolio value in absolute terms reads at any date

$$
V ^ {\lambda} = \lambda \left(\psi_ {1} S _ {1} + \psi_ {2} S _ {2}\right) + (1 - \lambda) \psi_ {3} B \tag {3.31}
$$

where the first part represents the levered portfolio and the last term represents borrowing costs for the leveraged position which is an investment in the borrowed asset  $B$ . Note that this term is negative. In relative terms,

$$
1 = \lambda (\phi_ {1} + \phi_ {1}) + (1 - \lambda) \phi_ {3}
$$

which shows that for  $\lambda = 1$  we are back in the unlevered case.

As an example, consider two assets  $S_{1}, S_{2}$  both with prices 100 CHF at date 0, one unit of each asset in the portfolio and leverage  $\lambda = 3$ . Hence,  $600 = \lambda (\psi_{1}S_{1} + \psi_{2}S_{2})$  CHF. Therefore,  $\psi_{3}B = 400$  and  $V_{0} = 200$  CHF. Assume that the return of the borrowing asset  $B$  is  $2\%$ . If the  $S$ -asset's return is  $10\%$ , then the leveraged portfolio return is  $22\% = 3 \times 10\% - 4 \times 2\%$ . But if the  $S$  assets falls by  $10\%$ , then the leveraged portfolio return is  $-38\%$ . This means that after costs for leveraging, a boost of positive returns is

smaller than the comparable negative return boost if asset prices drop.

Calculating the return of the leveraged portfolio:

$$
R ^ {\lambda} = \lambda \langle \phi , R \rangle + (1 - \lambda) \phi_ {3} R _ {B}. \tag {3.32}
$$

Setting  $\phi = (\phi_1, \phi_2)$  and  $\phi_3 = 1 - \phi_1 - \phi_2$ . Inserting this, implies

$$
\frac {\lambda}{2 \lambda - 1} = \phi_ {1} + \phi_ {2}.
$$

If there is no leverage,  $\phi_3 = 0$  or  $\lambda = 1$ . Calculating the excess return relative to a risk free rate  $R_{f}$  and to the borrowing rate  $R_{B}$  we get:

$$
\begin{array}{l} R ^ {\lambda} - R _ {f} = \lambda \langle \phi , R - R _ {f} \rangle + (1 - \lambda) \phi_ {3} \left(R _ {B} - R _ {f}\right) \\ R ^ {\lambda} - R _ {B} = \lambda \langle \phi , R \rangle . \tag {3.33} \\ \end{array}
$$

The excess return relative to the borrowing rate scales linearly in the leverage ratio. But for the excess return relative to the risk free rate, if  $R_{B} > R_{f}$ , increasing of the leverage ratio reduces the gains in the original portfolio.

The leverage ratio  $\lambda$  is in many investment strategy applications not a constant over time but a random variable. Rewriting the second equation in (3.33) and taking expectations we get:

$$
E (R ^ {\lambda}) = \lambda \langle \phi , E (R) \rangle + E (1 - \lambda) E (R - R _ {B}) + \operatorname {c o v} (\lambda , R - R _ {B}). \tag {3.34}
$$

Anderson et al. (2014) call the first two terms on the right hand side the magnified source terms due to leveraging. How important is the covariance correction in the last term? To quantify it we need to consider the volatility drag. Formula (3.34) summarizes that the expected return of a leverage portfolio also contains a covariance reduction term between the random leverage ratio and the excess return. Summarizing, in a multi period investment, there are three factors which matter:

- The covariance correction present in leverage portfolios.  
- The volatility drag which is present in any multi-period investment.  
- Transaction costs.

Anderson et al. (2014) consider these three factors in a 60/40 target volatility investment with US equity and US Treasury bonds. They consider monthly returns from Jan 1929 to Dec 2012. The target volatility is set equal the fixed  $11.59\%$  realized volatility in the observation period. Since volatility is not known ex ante, the leverage ratio is a random variable. The borrowing for the leverage is done at the 3m Eurodollar deposit rate and trading costs are proportional to the traded volume.

The authors find that the magnified source return in equation (3.34) dominates all other components. But his portfolio is not realizable. The gross return of the source portfolio, i.e. the risk parity portfolio with 60/40 target (gross of trading costs) and 3m Eurodollar financing (net of trading costs) is  $5.75\%$  in the period. The magnified source term contributes  $9.72\%$ . This implies that  $3.97\%$  is due to the leverage and excess borrowing return. The total levered arithmetic return is  $6.84\%$ . The difference to  $0.72\%$  is the covariance correction  $-1.84\%$  and the trading costs of  $-1.04\%$ . Finally, the variance drag value is  $-0.4\%$  which implies the total geometric levered return of  $6.37\%$ . Summarizing, the three effects - transaction costs, covariance correction and variance drag - reduced the positive leverage return impact of  $3.97\%$  by  $82\%$  to  $0.69\%$  ( $3.97 - 1.84 - 1.04 - 0.4 = 0.69\%$ ).

# 3.2 Basics of No Arbitrage

We consider in this and the following sections relative or derivative asset pricing. This is used for pricing derivatives and options. It is based on the no arbitrage principle,

To motivate the arbitrage approach, we consider a minimal market with two dates, 0 and  $T$ , one state at 0 and two states  $\omega_{1}, \omega_{2}$  at time  $T$ .

- There is a stock  $S$  with price  $S_0 = 100$  at time 0. Research estimates that
- the stock raises to a value of  $S_{T}(\omega_{1}) = 120$  with a probability of  $p = 90\%$  in the state  $\omega_{1}$  and  
- that the stock drops with a probability of  $1 - p = 10\%$  to a price of  $S_{T}(\omega_{2}) = 80$ .
- The investor can buy the following contract - a call option  $C_0$  at time 0 with the payoffs  $C_T$  at time  $T$
- 20, if the stock rises,  
- 0, if the stock drops.

Summarizing, the payoff of call at time reads  $C_T = \max(S_T - 100, 0)$ .

- There is a risk-less instrument  $B$  with price 1 today and which pays 1.1 at time  $T$  independent whether the stock rises or falls.

How much is the investor willing to pay at time 0 for the derivative  $C$ ? This defines the pricing problem.

We show that there is a unique, fair answer to this question in complete markets. We start with the motivations of a seller (writer or trader of a bank) and of a buyer of the derivative.

The writer of the derivative would like to obtain a price from the buyer at time 0 such that he can buy a portfolio  $V_{0}$  at 0 which will have a value  $V_{T}$  at time  $T$  which is always worth at least the liability value of the derivative  $C_{T}$  at time  $T$ , i.e.

$$
V _ {T} (\omega) \geq C _ {T} (\omega), \mathrm {i n a l l s t a t e s} \omega .
$$

The price at time 0 should be high enough that the writer can pay the liability at time  $T$  using the price change of the portfolio  $V_{0}$  up to time  $V_{T}$  without additional money<sup>10</sup> and using the three instruments  $S, B, C$  only. The buyer of the derivative does not want to pay a price at 0 for the derivative such that the writer can buy a portfolio  $V$  at time 0 which is worth more than the derivative value at time  $T$ :

$$
V _ {T} (\omega) \leq C _ {T} (\omega), \mathrm {i n a l l s t a t e s} \omega ,
$$

is the buyer's intention. The price, if it exists, where both motivations are met

$$
V _ {T} = C _ {T}, \mathrm {i n a l l s t a t e s} \omega .
$$

is called the fair price of the replication portfolio (we skipped the state variable  $\omega$ ). There are no restrictions on the portfolio positions, i.e. we can be long or short any instrument.

What is a state? It represents everything that is relevant for the value of the firm, including firm-specific variables such as earnings and leverage, industry-specific variables such as product demand and input prices, and macroeconomic variables such as interest rates and exchange rates. The state includes everything that we are not going to model explicitly. Sometimes it includes the stocks price, so that, even though we are ultimately interested in deriving the stock price as a function of more primitive variables, the distinction between the state and the price becomes blurred.

Replication is not always possible. This leads to the following definitions.

Definition 22. Complete Market:  $V_{T} = C_{T}$  holds in all states. This is the case of replication or a perfect hedge.

- Incomplete Markets:  $V_{T} = C_{T}$  not always holds true. The portfolio value at time  $T$  can be smaller or larger than the liability value in some states. A portfolio is called a hedge in such a setup and there exists always hedging risk.

To find the replication portfolio  $V$  we buy or sell an amount  $\phi_2$  of the risky asset and trade  $\phi_1$  riskless products. The condition  $V_{T} = C_{T}$  is equivalent to two linear equations for  $\phi_2$  and  $\phi_1$ :

$$
\begin{array}{l} \phi_ {2} * 1 2 0 + \phi_ {1} * 1. 1 = 2 0 \\ \phi_ {2} * 8 0 + \phi_ {1} * 1. 1 = 0. \tag {3.35} \\ \end{array}
$$

The problem with a risky asset is expressed in terms of linear algebra where no entry is risky. Whether or not a (unique) replication exists is therefore reduced to the questions when does a linear system has no, many or a single solution. By solving the system we get

- $\phi_{2} = 0.5$ , i.e. buy  $1/2$  risky asset.  
- $\phi_{1} = -36.36$ , i.e. long a loan with value 36.36.

Choosing  $\phi_2, \phi_1$  in this way, there are no hedge risks.

How do we get the fair price  $C(0)$ ? To answer this we calculate the portfolio value at time 0 using the above strategy:

$$
V _ {0} = 0. 5 * S _ {0} - 3 6. 3 6 = 0. 5 * 1 0 0 - 3 6. 3 6 = 1 3. 6 4. \tag {3.36}
$$

This is the fair derivative price, i.e.  $V_{0} = C_{0} = 13.64$ . Indeed we apply the Law of One Price which is a weaker formulation than the no arbitrage principle:

Definition 23 (Law of One Price). Consider a perfect market. Two assets with identical cash flows must trade at the same price or if the replication price of an option exists, then this price is unique.

One often states the law of one price as follows: If we have three payoffs  $x, y, z$  at a given date with

$$
z = x + y.
$$

Then the prices  $p(\cdot)$  at any date of these equal payoffs also agree:

$$
p (z) = p (x) + p (y).
$$

If this is not true, one constructs money machines.

Since  $V_{T} = C_{T}$  we must have  $V_{0} = C_{0}$ . If a different price follows, the writer can make risk less profits in a risky environment. For  $V_{0} < C_{0}$ , the writer invests the difference in the risk less asset. If  $C_{0} < V_{0}$  the writer buys the derivative from the investor and sells it to the fair price. Again the difference is looked in and invested in the risk less asset. The law of one price is the most important special cases of no arbitrage.

How does the Law of one Price fits into the no arbitrage relation (3.1) in a riskless environment, i.e.  $D(t,s)D(s,T) = D(t,T)$ ,  $D(t,t) = 1$ ? Take USD 1 at time  $T$ . Discounting this dollar back to time  $t$  using two different paths has to give the same value at time  $t$  by the Law of one price. This exactly what (3.1) states.

The probabilities  $P$  assumes that the risky asset goes up with 90 percent and down with 10 percent. This probabilities are derived from historical data using econometric

methods. They do not matter explicitly in the pricing of derivatives. The fair price in a complete market is independent on individual belief's of the market participants or real (historic) probabilities. This is a major reason for the success of derivative pricing since it liberates buyers and sellers to estimate these probabilities which in a multi period set-up turn out that one has to guess the drift of the risky asset price processes. Given this observation people are tempted to state that the belief is of no importance at all. This is not true. Suppose that the common belief is that Google's stock price will raise by  $10\%$  in one week. Then the belief does not enter a derivative contract of Google but it clearly affects the level of the stock. Therefore, beliefs matter in derivative pricing by affecting the underlying's price level.[12]

In the replication approach a portfolio of bonds and stocks was set up to replicate the derivative payoff. In the hedging approach one considers an unknown amount of the stock and the derivative. This portfolio is then specified by requiring that the portfolio has the same value in all states of the world as the risk less bond. Therefore, using the option and the stock one derives the bond property. A portfolio with this property is hedge position. The same value for  $\phi_{2}$  follows as under the replication approach. One could equally take the last combination - the derivative and the bond - as a portfolio combination an replicate the stock.

What happens if the two asset payoffs are linearly dependent (redundant assets)? Then, the replication system has no solution. Similar if there is only one asset, the option cannot be replicated.

We change our market in the initial example as follows: The time  $T$ -values of the risky asset are 80 and 105 and the derivatives pays 10 in the upper state and 0 in the lower one. Forming the replication portfolio and solving the equations we get  $A = 0.4$ ,  $B = -29.1$  and  $V_0 = 10.9$ . This price makes no sense. Why should anybody pay 10.9 for a contract which pays 10 or 0 at time  $T$ ? The replication portfolio was setup correctly. Therefore something must be wrong in the market structure. We show that the market is not free of arbitrage. To see this, we write the risky asset price moves using the up ('u') and down ('d') notation, i.e.  $120 = 100u$  and  $80 = 100d$ .

Proposition 24. Arbitrage is not possible in the above one period market if and only if

$$
u > 1 + r > d \tag {3.37}
$$

holds

To explain the result, we note that  $u > d$ . Suppose  $1 + r > u > d$ . Then the risk less investment always dominates the risky one - in all possible stated tomorrow. Therefore, go short the risky asset and long the risk less one. In the case  $u > d > r + 1$  a similar argument applies. We obtain for the example at the beginning of the section:

$$
1. 2 > 1. 1 > 0. 8 \Rightarrow u > 1 + r > d.
$$

The above proposition gives us a simple criterion to check whether no arbitrage is possible or not in a binomial model.

We consider risk neutral pricing. We have seen that historical probabilities or beliefs about the risky asset price dynamics do not matter for fair option pricing in the replication approach. But there is a pricing approach where probabilities matter. These probabilities are different from the empirical or subjective ones. We define

$$
q := \frac {R - d}{u - d}, R = 1 + r. \tag {3.38}
$$

Proposition 25. Suppose that there are no arbitrage possibilities. Then  $q$  is a probability, the so-called risk neutral probability.

To prove this we show  $0 \leq q \leq 1$ . Since  $r - d > 0$  and  $u - d > 0$ , we have  $q > 0$ . Assume  $q > 1$ . This is equivalent to  $R - d > u - d$ , i.e.  $R > u$ . This contradicts the assumption of no arbitrage.

If we calculate  $q$  in the original setup we get  $q = 0.75$ . In the variant with an arbitrage opportunity we have  $q = 1.25$ . The RNP has the form of a Sharp Ratio:

$$
q = \frac {\mathrm {R e t u r n r e l a t i v e t o r i s k f r e e}}{\mathrm {V o l a t i l i t y}}.
$$

We can  $q$  to characterize no arbitrage. The definition of  $q$  is equivalent to  $qu - qd + d = R$ . Multiplying the last equality with  $S_0$  we get (using the notation  $S_T^u = S_0 u$ )

$$
\underbrace {q S _ {T} ^ {u} + (1 - q) S _ {T} ^ {d}} _ {\text {E x p e c t e d v a l u e u n d e r Q}} = E ^ {Q} \left[ S _ {T} \right] = R S _ {0}.
$$

Dividing by  $R$ :

$$
E ^ {Q} \left[ \frac {S _ {T}}{R} \right] = S _ {0}.
$$

In an arbitrage free market, the expected value of discounted risky assets under the risk neutral probability equals today's discounted asset value (note that  $S_0 / 1$  is the discounted value in 0). The First Fundamental Theorem of Finance states that converse also holds. The existence of a martingale measure implies no arbitrage. Since martingales have no drift, the expected value of the discounted price process is constant.

We relate the replicating approach to the risk neutral one. The solution of the general replication equations

$$
\phi_ {2} * S _ {0} * u + \phi_ {1} * R = C ^ {u}
$$

$$
\phi_ {2} * S _ {0} * d + \phi_ {1} * R = C ^ {d} \tag {3.39}
$$

is

$$
\phi_ {2} = \frac {C ^ {u} - C ^ {d}}{S _ {0} u - S _ {0} d} =: \Delta , \phi_ {1} = \frac {C ^ {u}}{R} + \frac {C ^ {u} (d - u - 1) - C ^ {d} u}{R (u - d)}.
$$

$\phi_{2}$ , the Delta, measures the price sensitivity of the derivative given a price change of the underlying risky asset.  $\phi_{1}$  is negative. We have at time 0:

$$
V _ {0} = \phi_ {2} S _ {0} + \phi_ {1} B _ {0} = \Delta S _ {0} + \phi_ {1} B _ {0}. \tag {3.40}
$$

Transforming this expression we get after some algebra:

$$
{V _ {0}} = {\frac {1}{R} \left(C ^ {u} q + C ^ {d} (1 - q)\right) = E ^ {Q} \left[ \frac {1}{R} C _ {T} \right],}
$$

i.e. the fair option price is equal to the discounted payoff under the RNP. The price of a call is long the underlying times its delta and long a loan since  $\phi_{1}$  is negative. From a balance sheet perspective buying a call asset is equivalent to add an asset, the delta part, and adding a liability the loan part. Since the delta is not larger than one, if the call is bought by selling the underlying asset, the asset side of the balance gets shorter and a liability is added: Leverage of the balance sheet increases.

From

$$
V _ {0} = C _ {0} = \Delta S _ {0} + \mathrm {C a s h}
$$

we get

$$
1 - \mathrm {C a s h} / C _ {0} = \underbrace {S _ {0} \times \Delta / C _ {0}} _ {\mathrm {L e v e r a g e R a t i o} L}.
$$

$L > 1$  represents a loan (cash is negative) and  $L < 1$  the lending case. For  $L = 5$ , we gain with the costs for the option an exposure in the underlying value which is 5 times larger. To achieve this, we borrow  $4/5$  of the costs and invest  $1/5$  of the costs from our own money.

Theorem 26. Consider a complete and perfect market.

- Fair derivative prices are expected values of discounted terminal payoffs under the risk neutral probability.  
- The discounted derivative process is a martingale under the risk neutral probability.  
- The existence of a synthetic probability  $Q$  leads to an arbitrage free market structure.
- The objective or empirical probabilities  $P$  do not enter explicitly in derivative pricing formulae.

If markets are incomplete our statements hold true with the exception, that  $Q$  is not unique or equivalently, the price of the derivative is not uniquely determined using no arbitrage.

We consider a more general setup with two risky assets:

$$
\phi_ {2} * S _ {T} ^ {u} + \phi_ {1} * X _ {T} ^ {u} = C _ {T} ^ {u}
$$

$$
\phi_ {2} * S _ {T} ^ {u} + \phi_ {1} * X _ {T} ^ {d} = C _ {T} ^ {d}. \tag {3.41}
$$

with  $S$  and  $X$  two assets and  $C(S)$  the derivative. Using  $X$  as numeraire, the discounted option  $C / X$  and risky asset  $S / X$  are both martingales. A numeraire is by definition a positive random variable.  $X = 1 / (1 + r)^T$  is a deterministic numeraire. Indeed, it follows that  $C / X$  or the replicating portfolio  $V / X$  is a martingale if and only if  $S / X$  is a martingale:

$$
\frac {C _ {0}}{X _ {0}} = E ^ {Q ^ {X}} \left[ \frac {C _ {T}}{X _ {T}} \right] \text {i f a n d o n l y i f} \frac {S _ {0}}{X _ {0}} = E ^ {Q ^ {X}} \left[ \frac {S _ {T}}{X _ {T}} \right]. \tag {3.42}
$$

The probability  $Q^{X}$  depends on the choice of the numeraire:

$$
q ^ {X} = \frac {\frac {S _ {0}}{X _ {0}} - \frac {S _ {T} ^ {d}}{X _ {T} ^ {d}}}{\frac {S _ {T} ^ {u}}{X _ {T} ^ {u}} - \frac {S _ {T} ^ {d}}{X _ {T} ^ {d}}}.
$$

If we set  $X$  equal to a risk-free asset,  $q^{X}$  becomes the well-known  $q = \frac{R - d}{u - d}$ .

We summarize. First, the advantage of relative pricing w.r.t.  $X$  is that the probability  $Q^{X}$  is independent of the derivative, the replicating portfolio and the pricing equation (3.42) holds for all derivatives  $C$ . Second, both the derivative and the relative asset price are martingale measures, i.e. the measure related to the numeraire. Third, we could choose  $S$  as a numeraire instead of  $X$ . This leads to a new measure  $Q^{S}$  such that  $X / S$  and  $C / S$  are martingales under this new measure: The choice of a numeraire does not alter the price of the derivative  $^{13}$ . One can chose the most convenient numeraire for calculations. Fourth, if we would consider absolute pricing (pricing using a general equilibrium model) instead of relative one, the martingale measure for a derivative depends on the specific derivative payoff  $V_{T}$ . This is a main reason why one uses relative no arbitrage pricing in practice much more often than a fully fledged general equilibrium model. We summarize:

Theorem 27. Under no arbitrage pricing the pricing formula holds for all types of payoffs or derivatives.

- The risk neutral probability in the linear pricing formula depends only on the asset's characteristic (numeraire and other assets).  
- In absolute pricing (General Equilibrium) the probability entering in the linear pricing formula depends on the assets and payoff/derivative.

# 3.3 No Arbitrage and Derivative Pricing

We generalize no arbitrage pricing to one period models with many states and many assets. We assume that there are  $N$  risky assets in a single period with a finite number of states  $s > 1$ .  $S^j (k)$  is the asset price of asset  $j$  in state  $k\coloneqq \omega_{k}$ .  $\mathbb{R}^N$  is the space of portfolios where each component represents an amount of an asset hold. The linear payoff map  $\mathbb{P}:\mathbb{R}^N\to \mathbb{R}^S$  associates to a portfolio  $\phi$  a payoff  $\mathbb{P}\phi$ . In the simplest market structure each payoff can be reached by a portfolio given a payoff map. Every risk in the economy can be perfectly replicated. But typically, the space of payoffs which can be reached is smaller than the state space. This smaller vector space is called the asset span  $\langle \mathbb{S}\rangle \subset \mathbb{R}^S$ .

We impose the weak internal consistency condition of no arbitrage in the market: We exclude portfolios which allow to make no losses in all future states and gains in some states in a risky environment. No arbitrage is equivalent to the Law of One Price if we consider an economy with a finite number of assets and a finite number of states, i.e. we consider the set-up:

Definition 28. Consider a one-period model with  $\mathbb{S} = s > 1$  states at time  $T$  and  $N - 1$  risky assets  $S$  and a riskless asset  $B$ . The price of asset  $j$  at time  $T$  in state  $k := \omega_{k}$  is given by  $S^{j}(k)$ . The payoff matrix  $\mathbb{P}$  is defined by<sup>14</sup>

$$
\mathbb {P} = \left( \begin{array}{c c c c} B ^ {1} (1) & S ^ {2} (1) & \dots & S ^ {N} (1) \\ \vdots & \vdots & \ddots & \vdots \\ B ^ {1} (s) & S ^ {2} (s) & \dots & S ^ {N} (s) \end{array} \right). \tag {3.43}
$$

A portfolio (strategy) is a vector  $\phi = (\phi_1, \ldots, \phi_N)'$ .

The matrix  $\mathbb{P}$  has the dimension  $\mathbb{S} \times N$ . The payoff or portfolio value  $X$  at time  $T$  is

$$
X = \mathbb {P} \phi . \tag {3.44}
$$

Definition 29. A payoff  $X$  is attainable given  $\mathbb{P}$  if a portfolio  $\phi$  exists such that  $X = \mathbb{P}\phi$ . The portfolio  $\phi$  is called a replication portfolio. The space of attainable payoffs, the asset span, is denoted  $\langle \mathbb{S} \rangle \subset \mathbb{R}^S$ .

Investors are interested to find  $\phi$  given the payoff, i.e. to solve

$$
X = \mathbb {P} \phi
$$

with the solution

$$
\phi = \mathbb {P} ^ {+} X + N (\mathbb {P}) \tag {3.45}
$$

with  $A^{+}$  the Moore-Penrose Pseudo Inverse $^{15}$  and  $N$  the kernel of  $\mathbb{P}$ . If  $\mathbb{P}$  is invertible, the pseudo inverse equals the inverse and the kernel space is empty. The pseudo inverse matters if the payoff matrix is not onto; the kernel is not empty. If the kernel is not empty, the pseudo inverse minimizes  $||\mathbb{P}\phi - X||^2$  which in the invertible case is given by the inverse matrix. If  $N = s$  and  $\mathbb{P}$  onto, the inverse exists. For  $N = s$  the sources of randomness can be spanned in all state by the assets. If there are more states than assets,  $\mathbb{S} > N$ , the replication problem has no solution. In the case  $\mathbb{S} < N$  an infinite number of solutions is the generic case. The 'perfect' market set-up is defined as follow:

Definition 30. A market with payoff  $\mathbb{P}$  is complete if each claim  $X$  is attainable.

For  $\mathbb{P}$  invertible, market completeness follows. Given a market with payoff matrix  $\mathbb{P}$  and an asset price vector  $S_0 \coloneqq (B_0, S_0^1, \ldots, S_0^N)$ , we define arbitrage:

Definition 31. Consider a market with payoff matrix  $\mathbb{P}$  and asset price vector  $S_0$ . An arbitrage is a portfolio  $\phi = (\phi_1, \ldots, \phi_N)$  such that

- the initial portfolio value  $V_{0} = \langle S_{0},\phi \rangle \leq 0$  
$\mathbb{P}\phi \geq 0$  
- and there exists at least a single state  $\tilde{k}$  where  $x(\tilde{k}) > 0$  holds.

If there is arbitrage, a zero costs portfolio today and ends up with no loss tomorrow in all states and with the chance of a profit in at least one state. Consider a single asset which prices  $S^{+}$  and  $S^{-}$  and  $B$  the risk free asset price. In a risky environment  $S^{-} < B < S^{+}$  is the market structure leading to the absence of arbitrage. If  $B < S^{-} < S^{+}$ , you borrow a large amount by selling the risk free asset and invest the whole amount in the risky one such that  $V_{0} = \langle S_{0},\phi \rangle = 0$ , i.e.  $0 = \phi_{1}B_{0} + \phi_{2}S_{0}$ . Whatever the realized future state is you will make a certain profit since

$$
\mathbb {P} \phi = \left( \begin{array}{c c} B (1) & S (1) \\ B (2) & S (2) \end{array} \right) \phi = B (1) \phi_ {1} + S (1) \phi_ {2} = B (2) \phi_ {1} + S (2)) \phi_ {2} = B _ {0} \phi_ {1} (r + d) > 0 \tag {3.46}
$$

where we inserted  $\phi_{2}$  from  $0 = \phi_{1}B_{0} + \phi_{2}S_{0}$  and  $S^{+} = S(1) = uS_{0}, S^{-} = S(2) = dS_{0}$ . We never make a loss starting with zero net worth.

When is a market free of arbitrage? Using state prices  $\psi$  the First Fundamental Theorem of Finance (FFTF) answer the question.

Proposition 32 (First Fundamental Theorem of Finance (FFTF)). There is no arbitrage opportunity in a finite discrete market model if and only if there exists a vector of state prices  $\psi \in \mathbb{R}^S$ ,  $\psi_j > 0$  for all  $j$ , such that

$$
\mathbb {P} ^ {\prime} \psi = S _ {0}. \tag {3.47}
$$

The FFTF states that the price of asset  $i$  at time 0 is given by

$$
S _ {0} ^ {i} = \sum_ {j = 1} ^ {S} \psi_ {j} \mathbb {P} ^ {i} (j) .
$$

To interpret state prices, consider a risk less asset:

$$
B (0) =: B _ {0} = \sum_ {j = 1} ^ {S} \psi_ {j} B ^ {1} (j) = \sum_ {j = 1} ^ {S} \psi_ {j} \times 1 = \sum_ {j = 1} ^ {S} \psi_ {j} =: \psi_ {0}
$$

since the risk less asset pays 1 in all possible states. We define the probabilities with values  $(0,1)$

$$
q _ {i} := \psi_ {i} / \psi_ {0}, \forall i.
$$

The risk less asset can be rewritten

$$
B _ {0} / \psi_ {0} = \sum_ {j = 1} ^ {S} q _ {j} B ^ {1} (j) = E ^ {Q} (B ^ {1}) = E ^ {Q} (1) = 1.
$$

Therefore,  $\psi_0$  is the discount on a riskless borrowing. If  $r$  is the riskless annual interest rate, we write

$$
B _ {0} = \psi_ {0} = \frac {1}{(1 + r) ^ {T}}.
$$

This implies for all other risky assets:

$$
S _ {0} ^ {i} = \sum_ {j = 1} ^ {S} \psi_ {j} S ^ {i} (j) = \frac {1}{(1 + r) ^ {T}} \sum_ {j = 1} ^ {S} q _ {j} S ^ {i} (j) = E ^ {Q} \left[ \frac {S ^ {i}}{(1 + r) ^ {T}} \right] = E ^ {Q} [ M S ^ {i} ] \tag {3.48}
$$

with  $M$  the Stochastic Discount Factor SDF.. This factor is in this model deterministic and does not depend on consumption as it is the case in more general models. We will consider the SDF in more detail below. That means that in the pure finance set-up with a given market structure and no-arbitrage the Fundamental Asset Pricing in (3.48) follows. The sum of the  $q_{i}$ 's is equal to 1,  $q_{i} > 0$  and  $S_0^i = \frac{1}{(1 + r)^T}\sum_{j = 1}^{S}q_jS^i (j) = E^Q\left[S^{i,*}\right]$ , where  $S^{i,*}$  is the discounted asset price. Then the  $q$ 's are the risk neutral probabilities (RNP). This shows the equivalence of risk neutral probabilities and state prices:

$$
\frac {q _ {i}}{(1 + r) ^ {T}} \leftrightarrow \psi_ {i}. \tag {3.49}
$$

State prices are Arrow-Debreu securities  $e(j), j = 1, \ldots, S$  where the security  $e(m)$  pays 1 CHF if the state  $m$  is realized and zero otherwise. The FFTF implies

$$
\left( \begin{array}{c} 1 \\ e (1) \\ \dots \\ e (S) \end{array} \right) = \left( \begin{array}{c c c c} (1 + r) ^ {T} & \dots & \dots & (1 + r) ^ {T} \\ 1 & 0 & 0 & 0 \\ \dots & \dots & \dots & \dots \\ 0 & \dots & 0 & 1 \end{array} \right) \left( \begin{array}{c} \psi_ {1} \\ \psi_ {1} \\ \dots \\ \psi_ {S} \end{array} \right) .
$$

Hence,  $e(j) = \psi_j$  follows. We summarize.

Corollary 33. State-price densities are the prices of the Arrow-Debreu securities. State price densities and risk neutral probabilities are equivalent.

Each payoff can be written as a linear combination of the Arrow-Debreu securities. In practice one often prefers to work with risk neutral probabilities instead with state prices. We state the FFT using risk neutral probabilities.

Proposition 34 (First Fundamental Theorem of Finance). There is no arbitrage opportunity if and only if a risk neutral probability exists.

Consider the RNP condition for a single asset  $S_0 = E^Q [S^*]$ . This is equivalent to (note that  $S_0^* = S_0$  since discounting at a single date is 1)

$$
1 = E ^ {Q} \left[ S ^ {*} / S _ {0} \right] \longrightarrow E ^ {Q} \left[ S ^ {*} / S _ {0} - 1 \right] = E ^ {Q} \left[ R _ {0} ^ {*} \right] = 0,
$$

i.e. the expected return of the risky asset under RNP is zero: The asset has no trend under this probability. If we consider several investment periods, the risky asset condition for a RNP reads

$$
S _ {t} = E _ {t} ^ {Q} \left[ S _ {t + 1} ^ {*} \right]
$$

with the conditional expectation at time  $t$  given the information set at this date. Interpreting conditional expectation as best guess, the condition states that under a RNP the best guess of future discounted prices is today's price. Such price processes are called martingales, see below. The absence of arbitrage does not imply that the risk neutral probability is unique. The second Second Fundamental Theorem of Finance considers this question.

Proposition 35 (Second Fundamental Theorem of Finance). Consider an arbitrage free market. The risk neutral probability is unique if and only if the market is complete.

Proof. To show that completeness implies uniqueness of the state vector, assume that there exist two state vectors  $\psi_{1},\psi_{2}$  which both solve the equation  $S_0 = \mathbb{P}\psi$ . This implies  $0 = \mathbb{P}(\psi_1 - \psi_2)$ , i.e. the vector difference is orthogonal to all rows of the payoff matrix. Therefore, the difference is not attainable. This contradicts that the two vectors are state price vectors. The other direction is proven with a similar argument.

# 3.4. APPLICATION

The theorem is equivalent to the uniqueness of SDF or risk neutral probabilities.

Following this structural representation of arbitrage free markets we consider derivative asset pricing in such markets. We assume  $r > 0$  and the assets

$$
\left(B _ {t}, S _ {1} ^ {*} (t), \dots , S _ {N} ^ {*} (t)\right) _ {t = 0, T}
$$

where  $S_1^*(t) = S_j(t) / B(t)$  are the discounted asset prices. A derivative is a contract signed at  $t = 0$  which leads to a state contingent non-negative reward  $X_1(\omega)$  at  $T$ . How do we price  $X$  fair, i.e., what is the price  $X_0$ ?

Definition 36.  $X_0$  is a fair price for the contingent claims  $X_T$ , if the enlarged market

$$
(B _ {t}, S _ {1} ^ {*} (t), \ldots , S _ {N} ^ {*} (t), X _ {t} ^ {*}) _ {t = 0, T}
$$

is free of arbitrage opportunities.

If the enlarged market is free of arbitrage, there exists a RNP  $Q$  with  $S_{i}(0) = E_{Q}[S_{i}^{*}(T)]$  since the initial market was by assumption arbitrage free and the fair price is  $X_0 = E_Q[X_T^*]$ . The next theorem summarizes the pricing of derivatives by extending what we already know from the introduction to this topic.

Proposition 37 (Risk-neutral Valuation Principle). In arbitrage free markets, the fair price of attainable contingent claims  $X_{T}$  is uniquely given by

$$
X _ {0} = E _ {Q} [ X _ {T} ^ {*} ] = \frac {1}{1 + r} E _ {Q} [ X _ {T} ].
$$

We apply this to put and call option. A Call-Option gives the buyer the right to buy the underlying asset  $S$  at time  $t = 1$  to the Exercise Price  $K$  (or Strike-Price) and a put option gives her the right to sell the underlying asset to the price  $K$ . For a call option this contingent claim is formally given by

$$
C _ {T} := (S - K) _ {+} := \max  \{0, S - K \},
$$

and for a put  $P_T \coloneqq (K - S)_+$

Then, the fair price  $C_0$  of an attainable call option in a arbitrage free market is

$$
C _ {0} = E _ {Q} [ (S - K) _ {+} ^ {*} ] = \frac {1}{1 + r} E _ {Q} [ (S - K) _ {+} ]
$$

and for the put:

$$
P _ {0} = E _ {Q} [ (K - S) _ {+} ^ {*} ] = \frac {1}{1 + r} E _ {Q} [ (K - S) _ {+} ].
$$

<table><tr><td>Country</td><td>FX</td><td>Position</td><td>Benchmark ISV</td><td>ISV TAA Weight</td><td>ISV TAA Duration</td><td>Implementation ETF</td><td>Weight ETF</td><td>Duration ETF</td></tr><tr><td>CH</td><td>CHF</td><td>Liquidity</td><td>Libor 1 Monat</td><td>4.50</td><td>Pictet CH Short-Term Money Market CHF</td><td>4.50</td><td>0.14</td><td></td></tr><tr><td>CH</td><td></td><td>Govis</td><td></td><td>14.00</td><td>4.78</td><td>14.00</td><td>4.78</td><td></td></tr><tr><td>CH</td><td>CHF</td><td>Bonds 1 - 5</td><td>SBI Domestic AAA-BBB 1-5y TR</td><td>9.66</td><td>CS ETF (CH) on Swiss Bd Idx Dom Govt 1-3</td><td>8.76</td><td>1.82</td><td></td></tr><tr><td>CH</td><td>CHF</td><td>IG</td><td>SBI Domestic Non-Gov AAA-BBB TR</td><td>14.00</td><td>ZKB-CIF Swiss Bd TM Idx AAA-BBB Dom E</td><td>14.00</td><td></td><td></td></tr><tr><td>EU</td><td>EUR</td><td>Govis</td><td>JPM EMU Government Xy TR</td><td>2.50</td><td>4.90</td><td>2.50</td><td>4.90</td><td></td></tr><tr><td>EU</td><td>EUR</td><td>Bonds 5 - 10</td><td>JPM EMU GOV 5-7/7-10y</td><td>1.13</td><td>iShares Barclays Cap Euro Gov Bd3-5</td><td>1.64</td><td>3.60</td><td></td></tr><tr><td>EU</td><td>EUR</td><td>IG</td><td>Citigroup EUROBIG Corporate TR</td><td>2.25</td><td>ZKB-CIF EUR Corp. Bond Index E</td><td>2.25</td><td></td><td></td></tr><tr><td>EU</td><td>EUR</td><td>HYCB</td><td></td><td>0.25</td><td>iShares Markit iBoxx Euro Hi-Yld Bd (IE)</td><td>0.25</td><td></td><td></td></tr><tr><td>UK</td><td>GBP</td><td>Govis</td><td>JPM GBI UK Xy GBP TR</td><td>1.00</td><td>5.06</td><td>1.00</td><td>5.06</td><td></td></tr><tr><td>USA</td><td>USD</td><td>Govis</td><td>JPM GBI US Xy USD TR</td><td>1.00</td><td>5.00</td><td>1.00</td><td>5.00</td><td></td></tr><tr><td>USA</td><td>USD</td><td>Bonds &gt; 10</td><td>JPM GBI US 10y+ USD TR</td><td>0.05</td><td>iShares Barclays Cap $ Trsy Bd7-10</td><td>0.55</td><td>7.53</td><td></td></tr><tr><td>USA</td><td>USD</td><td>IG</td><td>Citigroup USBIG Corporate TR</td><td>0.80</td><td>ZKB-CIF USD Corp. Bond Index E</td><td>0.80</td><td></td><td></td></tr><tr><td>USA</td><td>USD</td><td>HYCB</td><td>BoA Merrill Lynch US High Yield TR</td><td>0.20</td><td>iShares iBoxx $ High Yield Corporate Bd</td><td>0.20</td><td></td><td></td></tr><tr><td>CAN</td><td>CAD</td><td>Govis</td><td>JPM GBI Canada Xy CAD TR</td><td>1.00</td><td>4.85</td><td>1.00</td><td>4.85</td><td></td></tr><tr><td>J</td><td>JPY</td><td>Govis</td><td>JPM GBI J Xy JPY TR</td><td>0.00</td><td>0.00Swisscanto (CH) Inst BF-JPY I</td><td>0.00</td><td>4.81</td><td></td></tr><tr><td>AUS</td><td>AUD</td><td>Govis</td><td>JPM GBI Australia Xy AUD TR</td><td>1.00</td><td>4.64UBS (Lux) BF AUD P Acc</td><td>1.00</td><td>4.90</td><td></td></tr><tr><td>EM</td><td>USD</td><td>EM Bonds</td><td>JP Morgan EMB+ TR</td><td>3.00</td><td>iShares JPMorgan $ Emerging Markets Bond</td><td>3.00</td><td></td><td></td></tr><tr><td>CH</td><td>CHF</td><td>Stocks</td><td>MSCI Switzerland NR</td><td>11.00</td><td>Amundi ETF MSCI Switzerland A</td><td>11.00</td><td></td><td></td></tr><tr><td>EU</td><td>EUR</td><td>Stocks</td><td>MSCI Europe ex Switzerland NR</td><td>9.50</td><td>Amundi ETF MSCI Europe Ex Switzerland</td><td>9.50</td><td></td><td></td></tr><tr><td>N-Americas</td><td>USD</td><td>Stocks</td><td>MSCI North America USD NR</td><td>8.50</td><td>iShares MSCI North America</td><td>8.50</td><td></td><td></td></tr><tr><td>Asia / Pacific</td><td>USD</td><td>Stocks</td><td>MSCI Pacific USD NR</td><td>6.50</td><td>ComStage ETF MSCI Pacific</td><td>6.50</td><td></td><td></td></tr><tr><td>EM</td><td>USD</td><td>Stocks</td><td>MSCI Emerging Markets USD NR</td><td>4.50</td><td>db x-trackers MSCI Emerg Mkts TRN 1C</td><td>4.50</td><td></td><td></td></tr><tr><td>Global</td><td>CHF</td><td>Hedge Funds</td><td>HFRX Global Hedge Fund CHF Index</td><td>4.50</td><td>db x-trackers db Hedge Fund 5C</td><td>4.50</td><td></td><td></td></tr><tr><td>Global</td><td>USD</td><td>Commodities</td><td>DJ UBS Commodity TR Hedge to CHF</td><td>3.00</td><td>ZKB-CIF Commodity Index hedged CHF E</td><td>3.00</td><td></td><td></td></tr><tr><td>Global</td><td>USD</td><td>Gold</td><td>Spotpreis USD/Unze CHF Hedged</td><td>3.00</td><td>ZKB Gold ETF CHF Hedged</td><td>3.00</td><td></td><td></td></tr><tr><td>CH</td><td>CHF</td><td>Real Estate CH</td><td>SXI Real Estate Funds Index</td><td>4.00</td><td>UBS-IS - SXI Real Estate Funds I</td><td>4.00</td><td></td><td></td></tr><tr><td>Total</td><td></td><td></td><td></td><td>100.00</td><td></td><td>100.00</td><td></td><td></td></tr></table>

Figure 3.10: Inputs in a TAA. The table shows the different asset classes, their volatility adjusted benchmark, the implementation when using ETFs, the weights and durations of the benchmark and ETF portfolio. Source: ZKB (2013)

# 3.4 Application

# 3.4.1 TAA Construction, Forwards and Futures

We consider the construction of the TAA for a Swiss intermediary (Source: ZKB [2013]). Figure 3.10 shows the inputs in the TAA construction. The asset classes are cash, bonds, stocks, hedge funds, commodities, gold and real estate CH. Bonds are split in three time buckets, 1-5y, 5-10y and more than ten years, into government bonds and corporate investment grade (IG) and high yield (HYCB) bonds. The list of ETF represents a possible implementation of the benchmarks. The weights of the portfolio are the result of an optimization such as a mean-variance optimization. The weights of the different asset classes are volatility weighted (the ISV notation) which will be explained below.

The positions in the TAA are replicated using liquid and cheaper instruments than ETF: futures, forwards and swaps which we call REP instruments, see Table 3.7. Equity, foreign bonds, commodities are replicated using futures, currency using forwards and swaps are used for CHF bonds. This means that asset class  $A_{j}$  is written as a linear combinations of the REP instruments. Say the  $11\%$  allocation of Swiss stocks is equal to  $9\%$  in SMI Fut and  $2\%$  in SMIM Fut. The splitting of the individual assets classes into the REP experiments is done by minimizing the tracking error of the REP instruments towards the benchmark. Hence, a given REP instrument can contribute to several asset

classes. The allocation of the REP instruments is shown in the table Allocation  $100\%$ . Hedge funds and real estate cannot be attributed to the liquid REP instruments. Their allocation weights are therefore zero.

<table><tr><td>Instrument</td><td>Allocation 100%</td><td>Allocation Index</td><td>Instrument</td><td>Allocation 100%</td><td>Allocation Index</td></tr><tr><td>Liquidity CHF</td><td>4.5%</td><td>4.5%</td><td>AUS 10 YR Bond Future</td><td>0.6%</td><td>1.2%</td></tr><tr><td>SMI Fut</td><td>10.7%</td><td>20.7%</td><td>Natural Gas Future</td><td>0.3%</td><td>0.5%</td></tr><tr><td>SMIM Fut</td><td>1.2%</td><td>2.3%</td><td>Crude Oil Future</td><td>0.2%</td><td>0.4%</td></tr><tr><td>FTSE Fut</td><td>4.1%</td><td>7.9%</td><td>Brent Oil Future</td><td>0.4%</td><td>0.8%</td></tr><tr><td>Euro-Stoxx 50 Fut</td><td>6.2%</td><td>12%</td><td>Live Cattle Future</td><td>0.2%</td><td>0.3%</td></tr><tr><td>S&amp;P 500 E-mini Fut</td><td>8.4%</td><td>16.4%</td><td>Wheat Future</td><td>0.2%</td><td>0.4%</td></tr><tr><td>TSX 60 Fut</td><td>0.7%</td><td>1.4%</td><td>Corn Future</td><td>0.2%</td><td>0.4%</td></tr><tr><td>SPI 200 Fut</td><td>1.8%</td><td>3.5%</td><td>Soybean Future</td><td>0.4%</td><td>0.8%</td></tr><tr><td>TOPIX Fut</td><td>4.2%</td><td>8.2%</td><td>Sugar Future</td><td>0.2%</td><td>0.3%</td></tr><tr><td>Hang Seng Fut</td><td>0.6%</td><td>1.2%</td><td>Aluminum Future</td><td>0.2%</td><td>0.4%</td></tr><tr><td>MSCI Singapore Fut</td><td>0.4%</td><td>0.7%</td><td>Copper Future</td><td>0.4%</td><td>0.8%</td></tr><tr><td>MSCI EM Fut</td><td>4.8%</td><td>9.4%</td><td>Gold Future</td><td>3.8%</td><td>7.3%</td></tr><tr><td>Swap CHF 3 YR</td><td>24.1%</td><td>46.8%</td><td>EUR/CHF Fw</td><td>11.5%</td><td>22.4%</td></tr><tr><td>Swap CHF 7 YR</td><td>6.2%</td><td>12.1%</td><td>GBP/CHF Fw</td><td>5.1%</td><td>10%</td></tr><tr><td>Swap CHF 10 YR</td><td>1.7%</td><td>3.2%</td><td>USD/CHF Fw</td><td>18.7%</td><td>36.2%</td></tr><tr><td>Euro-Schatz Fut</td><td>1.6%</td><td>3.2%</td><td>CAD/CHF Fw</td><td>1.8%</td><td>3.5%</td></tr><tr><td>Euro-Bobl Fut</td><td>2.4%</td><td>4.7%</td><td>AUD/CHF Fw</td><td>2.9%</td><td>5.6%</td></tr><tr><td>Euro-Bund Fut</td><td>1.3%</td><td>2.6%</td><td>JPY/CHF Fw</td><td>4.2%</td><td>8.2%</td></tr><tr><td>Short Gilt Fut</td><td>0.6%</td><td>1.2%</td><td>HKD/CHF Fw</td><td>0.6%</td><td>1.2%</td></tr><tr><td>Long Gilt Fut</td><td>0.5%</td><td>0.9%</td><td>SGD/CHF Fw</td><td>0.4%</td><td>0.7%</td></tr><tr><td>US 2 YR Note Fut</td><td>1.2%</td><td>2.3%</td><td>Total Cash</td><td>4.5%</td><td>4.5%</td></tr><tr><td>US 5 YR Note Fut</td><td>2.4%</td><td>4.7%</td><td>Total Futures</td><td>95.5%</td><td>185.5%</td></tr><tr><td>US 30 YR Note Fut</td><td>1.8%</td><td>3.4%</td><td>Total Forwards</td><td>45.2%</td><td>87.8%</td></tr><tr><td>Can 10 YR Bond Fut</td><td>1.1%</td><td>2.1%</td><td>Volatility 60d</td><td>4.1%</td><td>8%</td></tr><tr><td>Mini JGB 10 YR Bond Fut</td><td>0%</td><td>0%</td><td>Investment Degree</td><td>100%</td><td>194.2%</td></tr><tr><td>AUS 3 YR Bond Fut</td><td>0.5%</td><td>0.9%</td><td></td><td></td><td></td></tr></table>

Table 3.7: Futures, forwards and swaps in the TAA replication. The allocation to  $100\%$  is scaled to the allocation index which takes into account that the total volatility of the TAA should be equal to  $8\%$ , see text for explanations.

The next step is to consider volatility. For each instrument, calculate the daily returns for one year. Then form the sum of the products of the returns at each date. This gives the return of the allocation index time series. The volatility of this index is the standard deviation multiplied by the square root of return days within one year (square root rule). This implies the volatility  $4.12\%$ . Given the target volatility of  $8\%$ , the investment degree of  $194.2\%$  follows, see the Allocation Index. Such a model TAA is an input for the CIO which makes pairwise bets of dollar value each at inception.

Consider an index of forwards, futures and swaps replicating a TAA. The index value  $I_{t}$  at time  $t$  is updated as follows from a index value at a prior time  $s < t$

$$
I _ {t} = \left(1 + \sum_ {k} \phi_ {s} ^ {k} \frac {F X _ {t} ^ {k}}{F X _ {s} ^ {k}} R _ {F u t, t} ^ {k} + \sum_ {l} \phi_ {s} ^ {l} \mathrm {S w a p} _ {s, t} ^ {l} + \sum_ {m} \phi_ {s} ^ {m} \mathrm {F o r w} _ {s, t} ^ {m}\right) I _ {s} = G _ {s, t}
$$

where  $R_{Fut,t}$  is the simple futures return and the FX component only matters for the futures since the swaps and the forwards are in CHF.  $\phi$  is the allocation vector arising from an optimization problem.  $FX_{t}^{k}$  is the exchange rate of the currency of the future  $k$  against the Swiss franc. francs at time  $t$  where 1 currency unit is equivalent to  $FX_{t}^{k}$  of Swiss francs. The value of the futures  $k$  is calculated as the price of the futures  $k$  at the time  $s$  in local currency multiplied by the contract unit of the futures. An oil future with contract unit 1,000 and USD 108 local currency has value USD 108,000.  $\mathrm{Swap}_{s,t}^{l}$

is the value of the swap  $l$  at time  $s$  with final date  $t'$  at fair value interest rate and with nominal CHF 1.00. The value of the currency forwards  $\mathrm{Forw}_{s,t}^{m}$  at time  $t$  in Swiss francs is given by a fair value forward rate fixed at time  $s$  with a nominal value of CHF 1.00. The maturity of the forward corresponds to the next planned roll date. The above formula shows that interest exposure follows from the chain rule.

Iterating the index updating rule we get

$$
I _ {t} = \prod_ {k = 1} ^ {t} G _ {k - 1, k} I _ {0}.
$$

Hence, gross return  $R^g 0, t \coloneqq I_t / I_0$  is given by the product of one-step adjustments. Gross return can also be written as a product of one-step gross returns:

$$
R _ {0, t} ^ {g} = \frac {I _ {t}}{I _ {0}} = \frac {I _ {t}}{I _ {t - 1}} \frac {I _ {t - 1}}{I _ {t - 2}} \dots \frac {I _ {1}}{I _ {0}} = \prod_ {k = 1} ^ {t} R _ {k - 1, k} ^ {g}.
$$

Therefore,

$$
R _ {0, t} ^ {g} = \prod_ {k = 1} ^ {t} R _ {k - 1, k} ^ {g} = \prod_ {k = 1} ^ {t} G _ {k - 1, k}.
$$

# 3.4.1.1 Forwards and Futures

A forward contract is an obligation for the buyer (seller) to buy (sell) a specified quantity of an underlying asset at a specified price at specified future date. The terms date of exchange  $T$ , underlying asset  $S$ , quantity to exchange  $N$  and delivery price  $K$  are all fixed at conclusion  $t$  of the contract. Contrary to futures contract, all terms of a forward can be freely fixed by the two counter parties. They are OTC contracts and the parties face counter party risk of the opponent.

Forwards can be used to hedge risks. Consider a German based firm which wants to buy goods in the US. The firm could buy the goods at a future date at the spot rate USDEUR  $S(t)$ . To avoid this risk the firm can enter today into a forward contract. The forward price  $F(t,T)$  is fixed such that no cash flows exist at spot date  $t$ ; the PV of a forward is zero. The delivery price  $K$  is set equal to  $F$  at  $t$ , i.e.  $K = F(t,T)$ . The equality  $K = F(t,T)$  does not hold any longer after  $t$ . If at maturity  $S(T) = K$ , then the German buyer of the contract faces neither losses nor gains. If  $S(T) > K$ , the German firm makes a profit since USD can be bought at the cheaper price  $K$  than spot price.

Summarizing, a forward contract  $V$  has the following value for the buyer at maturity:

$$
V (T) = N \cdot (S (T) - K),
$$

with  $N$  the notional amount. The payoff is a linear function of  $S(T)$  contrary to options, where the payoff is non-linear: The price of a forward does not depend on

# 3.4. APPLICATION

(spot) volatility since the probability of making a gain or a loss at maturity is symmetric. No arbitrage leads to a unique forward price. Taking risk neutral expectation  $V(t) = N \cdot e^{-r(T - t)}E^{Q}((S(T) - K))$  implies

$$
V (t) = N \cdot e ^ {- r (T - t)} E ^ {Q} (S (T)) - N \cdot e ^ {- r (T - t)} K.
$$

Since  $E^{Q}(S(T)) = e^{r(T - t)}S(t)$  we get

$$
V (t) = - N S (t) - N \cdot e ^ {- r (T - t)} K.
$$

Since at contract initiation  $V(t) = 0$ , the initial forward  $F(t,T)$  has to be chosen as follows:

Proposition 38. The unique arbitrage free forward price  $F(t,T)$  given a risk free rate  $r$  is under continuous compounding:

$$
F (t, T) = S (t) \cdot e ^ {r (T - t)} \tag {3.50}
$$

This price only holds for forward where no dividends, no cost of storage, no interest rate differential costs and no convenience yield apply. The growth rate of the future price  $F$  is equal to  $r$ . If  $r \neq 0$  then  $F(t,T) > S(t)$  or  $F(t,T) < S(t)$  with  $F(T,T) = S(T)$ . For simple compounding, using the approximation  $e^x \sim 1 + x$ :

$$
F (t, T) \sim S (t) \cdot (1 + r (T - t)). \tag {3.51}
$$

We generalize to forwards with stocks paying dividends with a continuous rate  $d$ , commodities with storage cost rate  $s$ , bonds with coupon payment rate  $c$ , FX-transaction with different interest rates foreign and domestic  $i$  (interest rate differential) and commodities with a convenience yield  $y$ . These extensions are captured by the net cost-of-carry yield  $q$ :

$$
q = r + s - y - d - c \pm i.
$$

Proposition 39. The unique arbitrage free forward price  $F(t,T)$  given  $q$  is given under continuous compounding by:

$$
F (t, T) = S (t) \cdot e ^ {q (T - t)} \tag {3.52}
$$

If  $q > 0$ , the costs to possess the underlying value are larger than its value. This happens if storage costs are very high for a commodity forward. The buyer of the forward therefore compensates the seller for these costs.

We next consider the valuation of a forward at intermediate dates. We recall that the forward contract has value 0 at initiation time  $t$ . For  $s$  an intermediate date  $t < s < T$ , the value  $V(s)$  of the forward contract is defined by

$$
V (s) := e ^ {- r (T - s)} E ^ {Q} (S (T) - F (s, T)).
$$

The PV of  $S(T)$  equals  $S(s)$  if no dividends are paid and

$$
E ^ {Q} (F (t, T)) = D (s, T) F (t, T)
$$

which implies

$$
V (s) = S (s) - D (s, T) F (t, T).
$$

Using the no arbitrage relation  $S(s) = F(s,T)D(s,T)$ :

Proposition 40. The value of forward contract at time  $s$  is given by

$$
V (s) = \left(F (s, T) - F (t, T)\right) D (s, T). \tag {3.53}
$$

Setting  $s = t$  or  $s = T$  shows that the known initial and final values follow.

Consider a stock with  $S(0) = 25$  CHF and a  $6\mathrm{m}$  forward contract. The  $6\mathrm{m}$  interest rate is  $r = 7.12\%$ . Using simple compounding we get

$$
F (0, 0. 5) = 2 5 (1 + 0. 0 7 1 2 / 2) = 2 5. 8 9 \mathrm {C H F}
$$

After  $3\mathrm{m}$  the stock price is  $S(t + 3m = 0.25) = 23$  CHF and  $3m$  interest rates are  $r = 8.08\%$ . The forward price of a new contract with the same maturity reads

$$
F (0. 2 5, 0. 5) = 2 3 (1 + 0. 0 8 0 8 / 4) = 2 3. 4 6 \mathrm {C H F}.
$$

The value of the old contract is

$$
V (0. 2 5) = \left(F (0. 2 5, 0. 5) - F (0, 0. 5)\right) D (0. 2 5, 0. 5) = - 2. 3 8 \mathrm {C H F}.
$$

If the buyer (long) wants after 3m leave the original contract he has to pay 2.38 CHF to the seller.

The difference between the forward and spot price is called the basis  $b$ :  $b(t) = F(t, T) - S(t)$ . When the underlying  $S$  of the futures market and the cash market are identical, the basis converges to zero on the maturity date. **Basis risk** arises if either there is a mismatch of underlying asset or mismatch of maturity. Consider a forward  $F(t, T) = e^{-q(T - t)}S(t)$ . If  $q$  is known at time 0, we set  $h = e^{-q(T - t)}$ . Then, the payoff at time  $t$  of  $h$ -forwards  $h(F(t, T) - F(0, T)) = S(t) - S(0)e^{qt}$  is the same as for a forward entered at time 0 with maturity  $t$ . Then there is no basis risk.

Forwards offer full flexibility to the two involved parties. But forwards also possess some drawbacks. Each seller needs to find a buyer and both parties face counter party default risk. These two drawbacks are eliminated using futures instead of forwards. Futures are traded at a future exchange. Each future exchange has a clearinghouse. A clearinghouse is a well-capitalized financial institutions. It acts as an intermediary between the two parties. The house guarantees contract performance to both parties. The

two parties have an obligation to the clearinghouse and no longer to each other. To reduce default risk of the clearinghouse, the buyer and seller must deposit funds with their broker; the margins. The form of the margin must be eligible such as cash or specified securities. Since the initial margin is typically a one digit fraction of the goods represented in the future contract potential losses are much higher than the margin deposit. To counteract this risk the potentially large gains or losses in future contracts are not left to grow over time but they are realized on a daily basis. Values of futures positions are daily settled by marking-to-market of the contracts. Besides the initial margin, the maintenance margin reflects the necessary minimum amount on the margin account and the variational margins is payable if a shortfall of the margin account is considered.

Futures contracts are standardized contracts w.r.t. to delivery date  $T$ , the underlying value and the quantity to deliver. The two parties only have to agree about the delivery price  $K$  and the number of contracts.

Since a futures initial price is zero, to buy a future is equivalent to buy the underlying value financed by borrowing (leveraging). Futures allow for the same exposure than the underlying value but at lower costs - lower fees and smaller bid-ask spreads. Since future price can vary heavily during its life time it requires enough liquidity for the potential margin calls. At the Chicago Mercantile Exchange the minimum amount is 250 thousand US dollar. The largest future exchanges are CME, CBOT, Eurex.

We consider an example:

- Monday
- Investor buys futures USDEUR with a notional amount EUR 125'000.  
- The underlying value is  $0.7 \frac{\text{USD}}{\text{EUR}}$  and maturity is 1 year.
- Tuesday
- Price underlying:  $0.5 \frac{\text{USD}}{\text{EUR}}$  
- 0.2 USD EUR × EUR 125'000 = USD 25'000 are taken away from the margin account.

Wednesday

- Price underlying:  $0.8\frac{\mathrm{USD}}{\mathrm{EUR}}$  
- $0.3\frac{\mathrm{USD}}{\mathrm{EUR}} \times \mathrm{EUR}125'000 = \mathrm{USD}35'500$  are credited to the investor's margin account.

In a Dax future the notional amount is equal to the Dax index value times 25 Euro. For Dax at 3'900 points the notional amount of a future contract is 97'500 Euro. The initial margin for a Dax Future is Euro 3'850. With Euro 10'000 on the margin account one can enter into at most 2 futures contracts. The maturity of Dax futures is typically

3 months. The tick for the futures is 0.5 Dax index points. Since the value of a single Dax point is Euro 25, the value of a tick is 12.5 Euro. The exchange fees are Euro 50 cents per contract.

Proposition 41. (Valuation Futures) If there is no interest rate risk, default risk of the counter parties and no arbitrage holds, then the valuation of futures is the same as the valuation of corresponding forward contracts.

Table 3.8 proves the proposition where  $r$  is the fixed one-period interest rate: If we

<table><tr><td>Time</td><td>Forward</td><td>Future</td></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>+ r(VF(1) - VF(0))rT-1</td></tr><tr><td>2</td><td>0</td><td>+ r2(VF(2) - VF(1))rT-2</td></tr><tr><td>3</td><td>0</td><td>+ r3(VF(3) - VF(1))rT-3</td></tr><tr><td>·</td><td>·</td><td>·</td></tr><tr><td>T-1</td><td>0</td><td>+ rT-1(VF(T-1) - VF(T-2)r1</td></tr><tr><td>T</td><td>rT(S(T) - F(t,T))</td><td>+ rT(S(T) - VF(T-1))</td></tr></table>

Table 3.8: Equivalence of forwards and futures for deterministic interest rates

price futures in a market without any frictions, the pricing of futures is given by the cost-of-carry model, i.e. no arbitrage is the driver. If  $C$  represents the expected cost-of-carry, i.e. the costs which are necessary to carry the good forward from  $t$  to delivery date  $T$ , the no arbitrage relations

$$
F (t, T) = S (t) (1 + C), \text {o r} F (t, T) = S (t) e ^ {q (T - t)} \tag {3.54}
$$

relate the costs  $C$  uniquely to the cost-of-carry yield  $q$ .

We illustrate (3.54) for  $S$  an equity index,  $D$  the value of the dividends before maturity and  $r$  the annualized financing rate or money market yield. The fair futures prices read

$$
F (t, T) = S (t) \left(1 + r \frac {T - t}{3 6 0}\right) - D. \tag {3.55}
$$

Next, let  $B(t,T)$  be the market price of a bond including accrued interest rate (dirty price). The fair futures price is given by

$$
F (t, T) = \text {B o n d P r i c e} + \text {I n t e r s t C o s t - C o u p o n I n c o m e}
$$

where the interest cost are the interest opportunity cost and the coupon payments are those up to expiration of the futures contract. Let  $c$  be the annualized coupon rate,  $A$  the days of accrued interest rate, then

$$
F (t, T) = B (t, T) \left(1 + r \frac {T - t}{3 6 0}\right) - c B (t, T) \frac {T - t + A}{3 6 0}.
$$

This formula assumes that the bond can be bought and delivered at any data. But this needs not to be true. Consider US Treasury bond futures which are traded on the Chicago Board of Trade (CBOT). These bonds have quarterly expiration dates. The size of one futures contract is equal to USD 100'000 face value of a eligible Treasury bonds having at least 15 years to maturity and which are not callable for at least 15 years. Therefore  $B(t,T)$  in the second bond expression in the last formula is replaced by a tradeable bond for the short seller - the cheapest to deliver bond  $B_{cd}(t,T)$ . Since different bonds have different characteristics, standardization is lost at this stage. To give the short seller flexibility in choosing which bond is actually delivered the actual Treasury bond selected by the short seller for delivery is price adjusted by a delivery factor  $f$  such that the bond reflects a standardized 8 percent coupon rate:

$$
F (t, T) = \frac {B (t , T) \left(1 + r \frac {T - t}{3 6 0}\right) - c B _ {c d} (t , T) \frac {T - t + A}{3 6 0}}{f}. \tag {3.56}
$$

Delta hedging is used to hedge the risk of futures. Consider gold with spot price 400 in a currency, net cost-of-carry  $6\%$  p.a. and time-to-maturity one year, i.e.  $F(t,T) = 400e^{0.06} = 425$ . In a static hedge an investor's is short futures and long spot. Table 3.9 summarizes the profit and loss for two spot price scenarios ( $N = 1$ ). A gain or loss

<table><tr><td colspan="3">Scenario 1</td><td colspan="3">Scenario 2</td></tr><tr><td></td><td>today</td><td>tomorrow</td><td></td><td>today</td><td>tomorrow</td></tr><tr><td>Spot</td><td>400</td><td>600</td><td>Spot</td><td>400</td><td>200</td></tr><tr><td>Future</td><td>425</td><td>637</td><td>Future</td><td>425</td><td>212</td></tr><tr><td>1:1 Hedge</td><td>-25</td><td>-37</td><td>1:1 Hedge</td><td>-25</td><td>-12</td></tr><tr><td>P&amp; L</td><td></td><td>-12</td><td>P&amp; L</td><td></td><td>12</td></tr></table>

Table 3.9: Static approach which is not a hedge.

follows which is not what we expect in a hedged position. The reason is that spot and futures move only 1:1 if the cost-of-carry is zero.

A Delta hedge  $\Delta_{\mathrm{Spot}}^{\mathrm{Fut}}$  restores the 1:1 relation where

$$
\Delta_ {\mathrm {S p o t}} ^ {\mathrm {F u t}} = \frac {\mathrm {C h a n g e S p o t}}{\mathrm {C h a n g e F u t u r e s}}.
$$

If  $x$  is the change in the futures price and  $\tau = T - t$ , no arbitrage between spot and futures price implies

$$
\Delta_ {\text {S p o t}} ^ {\text {F u t}} = \frac {e ^ {- q \tau} x}{x} = e ^ {- q \tau}, \tag {3.57}
$$

i.e. the Delta is determined by the cost-of-carry. Hence, a Delta hedged portfolio  $W$  is short  $\Delta$  times the futures and long spot:

$$
W (t) = S (t) - \Delta_ {\mathrm {S p o t}} ^ {\mathrm {F u t}} F u t (t).
$$

If the futures price changes, the portfolio changes are zero:

$$
\Delta W (t) = \Delta S (t) - \Delta_ {\mathrm {S p o t}} ^ {\mathrm {F u t}} \Delta F u t (t) = \Delta S (t) - \Delta S (t) = 0
$$

which proves the hedging property.

# 3.4.2 Currency Forward and Futures

For a portfolio invested in multiple currencies there is currency risk from exchange rates fluctuation. Foreign exchange forward and futures contracts futures and options can be used to mitigate risk. Considering forwards, the relationship between the spot rate and the forward rate is determined by the difference in the interest rates earned on the respective currency pairs; the cost of carry. To understand this, forwards and futures imply in the absence of no arbitrage the Covered Interest Rate Parity which relates interest rates and FX rates.

- Covered Parity (CIP): The return of a domestic risk free investment equals the return of a foreign risk free investment if the FX risk is hedged using a forward contract.  
- Uncovered Parity (UIP): The interest differential between two countries is compensated by the expected FX changes.

We consider the covered parity for the Japanese yen (JPY) and Brazilian Real (BRL). If JPY are exchanged against BRL there is no guarantee that BRL does not de-evaluates. Using a FX forward we eliminate this risk. We assume

- Interest rates Yen  $R_{JPY} = 1\%$  p.a., Real  $R_{BRL} = 10\%$  p.a. and spot rate  $S(t) = 0.025$  BRLJPY.

We consider two dates 0 and  $T = 1y$  for a Japanese investor. He acts as follow at 0:

He borrows JPY 1000 at  $1\%$  for 1y.  

- He changes the JPY into BRL at the spot rate which gives BRL 25.  
- He invests the BRL 25 at  $10\%$  for 1y: he receives at  $T$  BRL 27.50.

In  $T$ , the investor changes the BRL 27.50 into JPY at spot  $S(T)$  which is not known at 0. The above strategy is risky. To choose a risk-free FX strategy he replaces today unknown spot rate  $S(T)$  by the known forward price  $F(0,T)$ . The forward price is determined with the following no arbitrage argument. We write  $R_{d}$  for the nominal interest rate in the domestic currency JPY and  $R_{f}$  for the interest rate in the foreign currency BRL. Table 3.10 illustrates the strategy where borrowing is in the foreign currency. At 0:

- The investor borrows BRL for one year. He exchanges the BRL at the spot  $S(0)$  in JPY and invests the JPY for  $1y$ .

# 3.4. APPLICATION

- He buys a forward  $F(0, T)$  to exchange in one year JPY against BRL.

At  $T$

- The investor exchanges  $(1 + R_d) \times F(0, T)$  JPY in BRL.  
- He pays back the borrowed BRL amount and pays  $(1 + R_{f})\times$  BRL.

$$
\begin{array}{l} t: \quad 1 \text {B R L b o r r o w} \rightarrow \quad S (t) \text {J P Y r e c i e v e} \\ \begin{array}{c c} \downarrow & \downarrow \\ \hline \end{array} \\ \end{array}
$$

$$
T: \quad (1 + R _ {f}) \mathrm {B R L} \quad \rightarrow \quad (1 + R _ {d}) S (t) / F (t, T) \mathrm {B R L}
$$

Table 3.10: Representation of the forward strategy to hedge the FX risk.

To avoid arbitrage at time  $T$  the amount received in foreign must equal the amount of foreign currency paid back. This implies the Covered Interest Rate Parity Theorem (CIP)

$$
F (t, T) = S (t) \frac {\left(1 + R _ {d}\right)}{\left(1 + R _ {f}\right)} \tag {3.58}
$$

with

$$
R _ {d} - R _ {f}
$$

the interest rate differential. CIP states that the difference between domestic and foreign interest rate determines the forward price.

Consider next an USD-based investor with a 5 bn yen equity investment. He wishes to fully hedge the currency risk for the next year. The current spot rate is 96.50 JPYUSD, one-year interest rates are  $5.63\%$  in the US and  $0.7\%$  in Japan. The one-year forward rate is

$$
\frac{(1 + 0.70\%)}{(1 + 5.63\%)}\times 96.50 = 92.00 \mathrm{JPYUSD}.
$$

Since interest rates in Japan are significantly lower than in the US, the forward price of yen is at a significant premium to the current spot price (92.00 vs. 96.50). To hedge the investment, the investor enters into a forward contract to sell 5 billion yen at 92.00 JPYUSD one year from today. If the JPYUSD exchange rate ends the year lower (higher) than the forward rate, the investor will realize a loss (gain) on the contract. Consider a falling yen scenario. The initial Yen investment 5,000,000,000 is worth initially USD 34,722,722. Initial spot is 144.0 and after one year, assumed spot is 156.7. The forward rate is 136.8, the spot return is  $8.1\%$ , the forward premium on Yen is  $5.0\%$  and the currency surprise is  $13.3\%$ . The spot P&L is USD 2,810,847, hedging P&L is 4,551,885 which results in a total P&L of 1,741,039.

What is the difference between the uncovered (UIP) and the covered parity? UIP replaces the forward price in the CIP procedure by expected spot price, i.e.  $F(t,T)$  by

$$
E _ {t} [ S (T) ] \colon :
$$

$$
\operatorname {U I P}: E _ {t} [ S (T) ] = S (t) \frac {\left(1 + R _ {d}\right)}{\left(1 + R _ {f}\right)}. \tag {3.59}
$$

Which view enters the expectation? Carry trades are bets that expectations formation differs from the e forward rate view:

$$
E _ {t} [ S (T) ] \neq F (t, T) = S (t) \frac {\left(1 + R _ {d}\right)}{\left(1 + R _ {f}\right)}. \tag {3.60}
$$

Consider a Swiss investor which needs in 30d JPY. He buys the 30d JPY CHF forward which fixes the exchange rate for 30d in CHF. This is a covered position, i.e. there is no FX risk. A different strategy is to exchange the CHF in JPY at the spot rate  $S(t)$ , to invest the amount in the Japanese money market for 30d and to pay the debt in JPY back. This leads to the CIP. Finally, a third strategy is to invest the CHF amount and to exchange it in 30d into JPY. This investment is not covered. FX risk is only zero if realized 30d spot rates equals the forward price. If the forward is lower than indicated by the CIP one borrows money in the foreign currency, exchange it in domestic currency at the spot price and lend in the domestic currency.

Given the uncovered interest rate parity (UIP), arbitrage implies that the change of a FX rate is equal to the nominal interest rate differential between the two currencies. Hence monetary policy (fixing interest rates) and exchange rates are dependent. The so-called Trilemma or Impossible Trinity. holds. A country cannot simultaneously choose three policies: 1) a fixed exchange rate (exchange rate stability), 2) open capital markets (financial integration) and 3) monetary policy autonomy. It can pick two; the third follows by no arbitrage. If a country chooses open capital markets, uncovered interest parity must hold: Arbitrage equalizes expected returns at home and abroad; the domestic interest rate must equal the foreign interest rate plus the expected appreciation of the foreign currency. If a country chooses open capital markets and fixed exchange rates, domestic interest rates have to equal the base-country interest rate, ruling out monetary policy autonomy. If a country chooses open capital markets and wishes to set domestic interest rates at levels suitable to domestic conditions, then exchange rates can no longer be fixed.

Since 2014, the CIP between USD and major other countries is broken. Borio et al. (2016) analyze reasons for this fact. We show how one can exploit this arbitrage opportunity. Consider a firm which denominates its income and balance sheet in CHF - a currency where the CIP with USD in the period since 2014 is broken. Although CHF interest rates are negative up to several years of maturity the firm cannot take a profit out of this fact since interest rates are floored, deposits pay zero interest rates, and loans are shifted upwards. The broken CIP makes it possible that the firm participates at the negative interest rate environment. The firm asks for the loan in USD. Together with an USDCHF swap FX risk is hedged and participation at the negative CHF interest rates follows.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2061a5e1960da0d7f05e229e9cc64fe65cf10d4f9dc954877465266f08dbf8e4.jpg)  
Figure 3.11: Left Panel: If a nation adopts position  $a$ , then it would maintain a fixed exchange rate and allow free capital flows, the consequence of which would be loss of monetary sovereignty. Sweden for example decided to have control over the interest rate and the free international capital flows and accepts that the exchange rate follows, i.e. they cannot be controlled. Source: Wikipedia. Right Panel: Monetary policy selections for four countries. Source: J.P. Danthine, Swiss Finance Institute (2011).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/e432cf4b53ae57cf3e1ba00d452972dbac8f994b6bdd7b5c7f69fba983716ac8.jpg)

With market rates as of June 12, 2017, the mechanics is the following:

- At  $t = 0$ , a FX USDCHF swap is fixed, the USD loan is received, the amount is changed into CHF at the spot rate and the  $3\mathrm{m}$  forward USDCHF is fixed. Consider a loan value in CHF  $10\mathrm{mn}$  and spot USDCHF 0.9730. The firm gets USD 10.277.490 for a CHF loan of  $10\mathrm{mn}$ .  
- At  $t = 3m$ , the USD are bought back at the forward rate  $3\mathrm{m}$  USDCHF 0.9670 which implies a pay-back USD amount:

$$
\mathrm {C H F} 9. 9 7 9. 6 6 0 = 1 0. 2 7 7. 4 9 0 (1 + 1. 5 8 / 4) * 0. 9 6 7 0
$$

where a margin of 0.4 percent is added to the USD 3m LIBOR rate  $1.18\%$ . Hence, a P&L in 3m of CHF 20.340 which means a return p.a. of 0.81 percent follows.

The strategy can be rolled-over until the CIP is eventually restored in the future.

For a portfolio that invests in different countries, its value is affected by asset prices changes, interest-bearing incomes and by P& L from exchange rates. Investment in each country is a composition of exposures in asset markets and in exchange rates. A currency overlay modifies the currency positions such that FX risk becomes acceptable. We restrict to linear overlays, i.e. forwards.

The general set-up to currency overlays is a straightforward generalization of the following example using linear algebra. Consider the 3 assets bond, equity and cash with four currencies USD, EUR, GBP and JPY defining an international portfolio. The structure of the portfolio is given in Table 3.11.

<table><tr><td></td><td>US</td><td>D</td><td>UK</td><td>J</td></tr><tr><td>Bond</td><td>a11</td><td>a12</td><td>a13</td><td>a14</td></tr><tr><td>Equity</td><td>a21</td><td>a22</td><td>a23</td><td>a24</td></tr><tr><td>Cash</td><td>a31</td><td></td><td></td><td></td></tr><tr><td>Forward USDEUR</td><td>F1</td><td>-F1</td><td>0</td><td>0</td></tr><tr><td>Forward USDGBP</td><td>F2</td><td>0</td><td>-F2</td><td>0</td></tr><tr><td>Forward USDJPY</td><td>F3</td><td>0</td><td>0</td><td>-F3</td></tr><tr><td>Forward EURGBP</td><td>0</td><td>F4</td><td>-F4</td><td>0</td></tr><tr><td>Forward EURJPY</td><td>9</td><td>F5</td><td>0</td><td>-F5</td></tr><tr><td>Forward GBPJPV</td><td>0</td><td>0</td><td>F6</td><td>-F6</td></tr><tr><td>Overlay Exposures</td><td>F1+F2+F3</td><td>-F1+F4+F5</td><td>-F2-F4+F6</td><td>-F3-F5-F6</td></tr></table>

Table 3.11: The structure of international portfolio investing in four countries with two asset classes.

We write  $a_{ij}$  for the exposure to asset class  $i$  of country (=currency)  $j$  and  $F$  represents the respective forward position of a contract on a given currency. That is, in a given currency  $j$  the currency exposure is equal to the sum of asset exposures of the investor in a currency  $j$  plus the overlay position consisting of all forward contracts  $F$  in that country or currency. For each forward contract, a minus sign indicates selling and a plus sign indicates buying. The goal of the investor is to find the optimal asset exposure weights  $a$  and the optimal forward contracts  $F$ . This optimization, using for example a mean-variance framework, is done under several restrictions. Besides usual transaction cost constraints, of interest are overlay position constraints. Let  $L$  be the total overlay limit allowed on a portfolio and  $L_{m}$  the total overlay of a portfolio equal to  $\frac{1}{2}\sum_{j}|\sum_{i}F_{ij}|$  with Forwards position of contract  $i$  on currency  $j$ . If  $L = 1$ , then the total currency exposure can deviate from total asset exposure up to 100% of a portfolio. If  $L_{m} = 0$ , then the portfolio is unhedged and forward contracts are not allowed to shift from less-performing to better-performing currencies which hence better improve the risk-return profile of the portfolio.

Entering into forward contracts incurs the cost of carry, i.e. the interest rate differential. For an investment in any country  $j$ , the total return  $R_{j}$  is given by:

$$
R _ {j} = a _ {r} R _ {j} ^ {a} + c _ {j} R _ {j} ^ {c} + v _ {j} i _ {j}
$$

where  $a_{j}, c_{j}$  and  $v_{j}$  are respectively asset exposure, currency exposure and overlay position on country  $j$  and the other variables are expected asset return, expected currency return and expected interest rate of country  $j$ . Since overlay position is defined as the

difference in currency and asset exposures, we can write

$$
R _ {j} = a _ {j} (R _ {j} ^ {a} - i _ {j}) + c _ {j} (R _ {j} ^ {c} + i _ {j}).
$$

Hence, the portfolio total return is equal to the product of adjusted returns times asset exposure and currency exposure, respectively. Therefore, the expression of overlay positions is not explicitly required to calculate total returns of a portfolio. For more details see Chatsanga and Parkes (2017).

# 3.4.3 Call-Put-Parity

Consider an extended arbitrage free market with a call and a put option. There exists a RNP  $Q$  such that

$$
E _ {Q} [ \frac {1}{1 o + r} S ] = S _ {0}, E _ {Q} [ \frac {1}{1 + r} C _ {1} ] = C _ {0}, E _ {Q} [ \frac {1}{1 + r} P _ {1} ] = P _ {0}.
$$

From the definition of the call and put follows  $(S - K) = (S - K)_+ - (K - S)_+$  and therefore

$$
E _ {Q} [ S - K ] = E _ {Q} [ S ] - K = E _ {Q} [ C _ {1} ] - E _ {Q} [ P _ {1} ].
$$

Inserting the expressions above implies the Put-Call parity

$$
C _ {0} - P _ {0} = S _ {0} - \frac {1}{1 + r} K.
$$

The parity is useful, since once knowing the price of say a call, the corresponding put price follows: A call is a put and a put is a call. The parity holds for more general markets too.

# 3.4.4 Market Structure

We next consider the market structure:

$$
\mathbb {P} = \left( \begin{array}{c c c} 4 & 6 & 2 \\ 1 2 & 3 & 9 \end{array} \right)  ,   S _ {0} ^ {\prime} = (7, 3, 5)
$$

The equation for the state price density reads

$$
\mathbb {P} _ {T} ^ {\prime} \psi = S _ {0}.
$$

A solution of the linear system is:

$$
\psi^ {\prime} = (1 / 4, 1).
$$

The market is free of arbitrage. The existence of a unique solution is an exception since there are 3 equations and 2 unknowns. Typically, the payoffs of the three non-redundant securities are conflicting.

Consider a market with a riskless asset with zero interest rate and a risky asset with 3 states:

$$
\mathbb {P} = \left( \begin{array}{c c} 1 & 1 8 0 \\ 1 & 1 5 0 \\ 1 & 1 2 0 \end{array} \right)  ,   S _ {0} = (1, 1 5 0) ^ {\prime}  .
$$

This market is incomplete. Solving  $\mathbb{P}\psi = S_0,\psi_j > 0$  and the set of state prices is parametrized by:

$$
\psi = \left\{\left(a, 1 - 2 a, a\right), a \in (0, 1 / 2) \right\}.
$$

This incomplete market is free of arbitrage within the given parametrization set. Given the incompleteness, there exist self-financing portfolios  $\phi$  such that there are claims  $X \notin \langle \mathbb{S} \rangle$ :  $X \neq \mathbb{P}\phi$  for some states. Consider a call option which payoff  $(30,0,0)$ . This call option is not attainable. Since  $X - \mathbb{P}\phi$  is not zero in all states, hedge risk exist. No arbitrage alone does not lead to a unique price in this case. A second criterion is needed to enforce uniqueness. There are many possible criteria. One is that the market chooses the single RNP  $Q$  which is used for pricing. The derivative price is then fixed by mapping the parametrized theoretical prices to observed market prices. This approach is used in interest rate modelling ('inverting the yield curve').

# 3.4.5 Incomplete Market

We consider an incomplete market with two securities  $S$  (risky) and  $B$  (risk less) with  $r$  the interest rate. The risky security  $S$  can achieve three states:  $S^u = S_0 u > S^m = S_0 m > S^d = S_0 d$  with  $S_0$  the initial price and the up/mid/down parameters  $\mathrm{u / m / d}$ . This trinomial model is incomplete since the payoff matrix has the dimension  $3 \times 2$ . Since there is a risk less asset, we know that the three state prices add up to the risk less discounting factor:

$$
\frac {1}{1 + R} = \psi_ {1} + \psi_ {2} + \psi_ {3}. \tag {3.61}
$$

The second condition  $S_0 = \sum_j \psi_j S^j$  follows from no arbitrage. Since  $S^j = S_0 \times x$ ,  $x = u, m$  or  $d$ , this condition reads:

$$
1 = u \psi_ {1} + m \psi_ {2} + d \psi_ {3}. \tag {3.62}
$$

The two equations (3.61) and (3.62) should determine the three dimensional state price vector. The solution of the two equations, which are two planes, is in general a line or arbitrage free prices - and not a point as in a complete market. The state price vector is not unique. Despite the incompleteness the no arbitrage condition is the same as in the well-known binomial model: There is no arbitrage if and only if

$$
d <   1 + r <   u.
$$

The line is bounded by the requirement that state prices are positive. Each vector on the line segment used to price derivatives leads to arbitrage free prices. Solving the two

# 3.4. APPLICATION

equations, the boundary points of the line segment follow: For  $m \geq 1 + r$

$$
\psi_ {1} = \frac {1 + r - d}{(1 + r) (u - d)} , \psi_ {2} = 0 , \psi_ {3} = \frac {u - 1 - r}{(1 + r) (u - d)} ,
$$

and

$$
\psi_ {1} = 0, \psi_ {2} = \frac {m - 1 - r}{(1 + r) (m - d)}, \psi_ {3} = \frac {1 + r - d}{(1 + r) (m - d)}.
$$

A similar corner solution holds for  $m < 1 + r$ .

The boundary values do not lead to arbitrage free prices since some components of the state price densities are zero. If  $m \to d$  or  $m \to u$ , the trinomial model collapses to the binomial one with the state prices:

$$
\psi_ {1} = \frac {1}{1 + r} q, \psi_ {2} = \frac {1}{1 + r} (1 - q), \psi_ {3} = 0.
$$

# 3.4.6 Multi Period Derivative Pricing

So far we considered single period pricing and hedging. The extension to multi period and discrete states modelling is discussed next. We assume that the price of risky assets follows a recombining binomial tree: At each date the stock price can go up or down with constant steps across the periods and an up-down moves is the same as down-up move starting from any node in the tree. This defines the Cox-Ross-Rubinstein model structure where there is one risky asset living on the tree and a risk less asset. The ideas of the one period option pricing model transfer to the multi period modelling: The existence of a martingale measure is equivalent to the absence of arbitrage and the uniqueness of such a measure defines a complete market.

The risk less interest rate describing the risk less asset is  $r > 0$  and the dynamics of the risk less asset is  $B_{t} = (1 + r)^{t}$  with  $B_{0} = 1$ . The initial price of the risky asset is  $S_{0}$ . The price in period  $t + 1$  can go up  $(u)$  or down  $(d)$  with constant rates  $d$  and  $u$  starting from the  $t$ -price. The dynamics reads under an objective probability measure  $P = (p, 1 - p)$

$$
S _ {t + 1} = \left\{ \begin{array}{l l} S _ {t} (1 + u), & \mathrm {w i t h p r o b a b i l i t y} p; \\ S _ {t} (1 + d), & \mathrm {w i t h p r o b a b i l i t y} 1 - p. \end{array} \right. t = 0, 1, \ldots , T - 1.
$$

The price at time  $k$  is then

$$
S _ {k} = S _ {0} (1 + u) ^ {N _ {k}} (1 + d) ^ {k - N _ {k}}
$$

with  $N_{k}$  the random number of upwards moves in  $k$  time steps. The values of a portfolio  $V_{t}$  reads

$$
V _ {t} = \phi_ {t} B _ {t} + \psi_ {t} S _ {t}, \Delta V _ {t} = \phi_ {t} \Delta B _ {t} + \psi_ {t} \Delta S _ {t}
$$

where  $\Delta V_{t} = V_{t} - V_{t - 1}$ ,  $\phi_t$  the amount of CHF invested in risk less asset at time  $t$  and  $\psi_t$  the number of shares held at time  $t$ . The number of shares  $\psi_t$  has to be known before  $t$ , that is a time  $t - 1$ . This property of random variable sequences (stochastic processes) is called predictability. We only consider self-financing strategies., see Section 3.1.5. If  $\phi_t$  is self-financing, the portfolio value reads

$$
V _ {t} = V _ {0} + \sum_ {j = 0} ^ {t} \phi_ {j} \Delta X _ {j}.
$$

The final portfolio value is equal to the initial value plus the cumulative gains and losses from the price changes of the asset  $X$  over time weighted by the investment strategy. If we recall that replication means  $V_{t} = C_{t}$  in all states and at all time points, the above equation transforms to

$$
C _ {t} = C _ {0} + \sum_ {j = 0} ^ {t} \phi_ {j} \Delta X _ {j}.
$$

$\phi_{j}$  is the replication strategy which given the initial option price  $C_0$  generates the random option claims  $C_t$ . The martingale representation theorem states when such a strategy exists. The notion of an arbitrage strategy carries over from the one-period case. Formally:

Definition 42. A self-financing strategy  $\phi$  is an arbitrage strategy, if the portfolio value under this strategy satisfies:  $V_{0} = 0$ ,  $V_{t} \geq 0$  for all  $t = 1, \ldots, T - 1$ ,  $V_{T} \geq 0$  for all states and  $V_{T} > 0$  for one state.

In a dynamic context we have to define how information evolves. The information set  $\mathcal{F}_t$  at time  $t$  is not a vector space. Consider a 3-period recombining stock price model. In each period stock prices can move up or down with given probabilities. We can observe 8 possible path realizations  $\omega_{k}$  after there periods, see Figure 3.12:

$$
\omega_ {1} = (u, u, u), \omega_ {2} = (u, u, d), \omega_ {3} = (u, d, u), \omega_ {4} = (u, d, d)
$$

$$
\omega_ {5} = (d, u, d), \omega_ {6} = (d, d, u), \omega_ {7} = (d, u, d), \omega_ {8} = (d, d, d).
$$

The set of all observable outcomes  $\omega_{j}$  is the sample space  $\Omega$ . To understand information dynamics, suppose that the first move was up. Then four paths are still possible after this step, the others are impossible. After say a down move in the second step, only two paths remain possible. After the last price move, a single realized path is left. This allows to introduce possible events. For 8 observable events, the power set  $\mathcal{A} = 2^{8}$  defines all possible events.

Filtrations  $(\mathcal{F}_t)$  describe the possible event structure dynamics.  $\mathcal{F}_t \in \mathcal{A}$  represents the possible information up to time  $t$ : Only past information generated by all possible price paths enter into the filtration. We require

$$
\mathcal {F} _ {t} \subset \mathcal {F} _ {t + 1}, \mathcal {F} _ {t} \in \mathcal {A} \forall t.
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9a17c1f19faeb41d9400d872af422b796a453f9105820feb978580f141dd03d8.jpg)  
Figure 3.12: Illustration of the information and filtration structure for the three period CRR.

Intuitively, increasing time means information resolution increases (there are more sets). At  $t = 0$ ,  $\mathcal{F}_0 = \{\emptyset, \mathcal{A}\}$  everything is possible, i.e. all future information is random. $^{16}$  At  $t = 1$ , we define the sets

$$
A _ {1} = \left\{\omega_ {1}, \omega_ {2}, \omega_ {3}, \omega_ {4} \right\}, A _ {2} = \left\{\omega_ {5}, \omega_ {6}, \omega_ {7}, \omega_ {8} \right\}.
$$

$A_{1}\left(A_{2}\right)$  is the set of all events where the first price move is 'up' ('down'). We set

$$
\mathcal {F} _ {1} = \{\emptyset , \mathcal {A}, A _ {1}, A _ {2} \}.
$$

This assures that  $\mathcal{F}_0\subset \mathcal{F}_1$ .  $\mathcal{F}_2$  is the power set of all eight observable states. The information sets were generated by the evolution of the asset prices only. This is the standard information structure set-up in asset and derivatives pricing.

The FFTF transforms to the CRR model case. The theorem is based on the notions of RNP or equivaiet martingale measures.

Definition 43. n Consider a price process under a probability  $P$ . A probability  $Q$  is equivalent to  $P$ , written  $Q \sim P$ , if they have the same impossible sets. A probability  $Q \sim P$  is a risk neutral probability if the discounted price process  $\tilde{S} \coloneqq S / N$  is  $Q$ -martingale with  $N > 0$  the numeraire, i.e.

$$
\tilde {S} _ {t} = E ^ {Q} \left[ \tilde {S} _ {s} | \mathcal {F} _ {t} \right] =: E _ {t} ^ {Q} \left[ \tilde {S} _ {s} \right],
$$

holds for all  $t$  and  $s \geq t$ .

Equivalence means, that  $P(\text{State } k) > 0$  for all states implies  $Q(\text{State } k) > 0$  for all states and vice versa. Then, as in the static case, the CRR model is free of arbitrage if and only if a RNP  $Q$  exists.

It is useful to introduce the random variable

$$
X _ {t + 1} := S _ {t + 1} / S _ {t}.
$$

This price ratio takes only the values  $(1 + u)$  or  $(1 + d)$ . Since  $Q$  is strictly positive, both values are attained with a positive probability. This implies  $d < R = 1 + r < u$ , else the equation  $E^{Q}[S_{t + 1} / S_{t}] = 1 + r$  does not hold true. The last inequality is the no arbitrage condition of the one period model. If the inequality is violated, arbitrage is possible.

We construct the measure  $Q$ ?

Proposition 44. Assuming  $0 < d < 1 + r < u$ . The following statements are equivalent:

1. $\tilde{S}_k$  is a  $Q$ -martingale.  
2. The random variables  $X_{k + 1}$  are i.i.d. under  $Q = (q,1 - q)$  with

$$
Q \left[ X _ {k + 1} = 1 + u \right] = q = \frac {R - d}{u - d}
$$

$$
Q \left[ X _ {k + 1} = 1 + d \right] = 1 - q = \frac {u - R}{u - d}.
$$

The risk neutral probability is unique, i.e. the CRR market is complete. If the underlying instrument pays a dividend yield  $\delta \geq 1$ , the risk neutral probability and the no arbitrage condition are:

$$
u > R / \delta > d, q = \frac {R / \delta - d}{u - d}.
$$

We show how to price an European call option in the CRR model. Such a contract pays at maturity  $C(S_{T}) = \max (S_{T} - K,0)$  with  $K$  the strike value. The following proposition is proven in Appendix ??

Proposition 45. The arbitrage free price of a call option in the  $n$ -period CRR model is:

$$
C (S, t) = \sum_ {k = 0} ^ {n} \binom {n} {k} q ^ {n} (1 - q) ^ {n - k} \max  \left(S _ {0} u ^ {k} d ^ {n - k} - K, 0\right). \tag {3.63}
$$

Separating the two terms in the payoff formula $^{17}$ , the price of a call option shows the same form as in the one period model. The price is proportional to the underlying value and the present value of the strike. Since this last expression has negative sign

# 3.4. APPLICATION

it represents a loan. The difference to the one period model are the more complicated factors in front of  $S$  and  $K$ . They are probabilities. The formula states in words that the price of a call (or put) option in the CRR model at a date  $t$  with maturity  $T$  is given by:

$$
C (S, t) = \sum_ {\text {p a t h s}} \text {P a t h P r o b a b i l i t y} \times \text {N o .} \text {o f p a t h s} \times \text {P a y o f f E n d N o d e} T \tag {3.64}
$$

where the path probability equals  $q^{k_u}(1 - q)^{k_d}$  with  $q$  the risk neutral probability  $k_{u}$  the number of 'up' moves on the given path from  $t$  to  $T$  and similarly  $k_{d}$  the number of 'down' moves, 'No. of paths' the number of paths connecting the node at time  $t$  with the end node at  $T$ .

We compare the accuracy of the binomial CRR model with observed option prices. Consider a call on ABB Ltd. with strike CHF 31 and expiration June, 20 2008. The bid and ask prices where at CHF 0.33 and 0.34 respectively and the actual ABB share price was CHF 29.9, see Figure 3.13. The figures are calculated using (3.64).

Figure 3.13: Data for the ABB call. Source: Swissquote.

The first step is to calculate the tree  $u, d, r$  from the real world data. If  $R$  is the annual rate,  $r$  the rate on the tree,  $n$  the number of periods in the tree and  $\tau = T - t$  time to maturity, we have the relationship  $(1 + r)^n = R^\tau$ . The number of periods in the CRR model is  $n = 11$ , time to maturity is  $\tau = 0.917$ . This implies  $1 + r = R^{\tau / n} = 1.00327$ . The discount factor is  $D = e^{-\tau (1 + r) / n} = 0.920$ . We need the up and down values. A standard approach is to set  $u = e^{\sigma_{1y}\sqrt{\tau / n}}$ ,  $d = 1 / u$ , we comment about this choice at the end of the example. Using ABB closing data we get a daily volatility of  $\sigma_{1d} = 0.0150983$ . To obtain an annualized volatility we use the square-root rule, i.e.

$$
\sigma_ {1 y} = \sqrt {\mathrm {d a y s}} \sigma_ {1 d} = \sqrt {2 5 0} \sigma_ {1 d} = 0. 2 8 8 2
$$

where we assumed that there are 250 days in a year. We also need to know the risk less rate for one period. This gives  $u = 1.087$ ,  $d = 0.92$ . These values imply for the risk neutral probability  $q = 0.499$ . The table shows the pricing result.

The sum of the path weights over all end nodes is 1 and the sum of the payoffs over all nodes, i.e. the last column, is CHF 3.41205. Discounting this value back to time zero gives 3.1383. Using the ratio  $1:10$  gives the theoretical price of 0.31 CHF compared to the actual bid-ask prices of  $0.33 - 0.34$ .

We relate the discrete and continuous time variables. Consider a continuous time model for the risky asset where the mean and variance of the asset ratio  $S_{t + dt} / S_t$  are given by

$$
E (S _ {t + d t} / S _ {t}) = e ^ {r d t}, \mathrm {v a r} (S _ {t + d t} / S _ {t}) = e ^ {2 r d t} (e ^ {\sigma^ {2} d t} - 1)
$$

<table><tr><td>Node</td><td>S0uk-10dk</td><td>max(ST-K,0)</td><td>No. of Paths</td><td>qk-10(1-q)k</td><td>S.P.</td><td>Sum Payoff</td></tr><tr><td>11</td><td>74.541</td><td>43.541</td><td>1</td><td>0.0004</td><td>0.0004</td><td>0.020</td></tr><tr><td>10</td><td>63.114</td><td>32.114</td><td>11</td><td>0.0004</td><td>0.0052</td><td>0.168</td></tr><tr><td>9</td><td>53.440</td><td>22.440</td><td>55</td><td>0.0004</td><td>0.0264</td><td>0.593</td></tr><tr><td>8</td><td>45.248</td><td>14.248</td><td>165</td><td>0.0004</td><td>0.0796</td><td>1.134</td></tr><tr><td>7</td><td>38.312</td><td>7.312</td><td>330</td><td>0.0004</td><td>0.1600</td><td>1.170</td></tr><tr><td>6</td><td>32.440</td><td>1.440</td><td>462</td><td>0.0004</td><td>0.2250</td><td>0.324</td></tr><tr><td>5</td><td>27.467</td><td>-</td><td>462</td><td>0.0004</td><td>0.2260</td><td>0.000</td></tr><tr><td>4</td><td>23.257</td><td>-</td><td>330</td><td>0.0004</td><td>0.1622</td><td>0.000</td></tr><tr><td>3</td><td>19.692</td><td>-</td><td>165</td><td>0.0004</td><td>0.0814</td><td>0.000</td></tr><tr><td>2</td><td>16.673</td><td>-</td><td>55</td><td>0.0004</td><td>0.0272</td><td>0.000</td></tr><tr><td>1</td><td>14.118</td><td>-</td><td>11</td><td>0.0004</td><td>0.0054</td><td>0.000</td></tr><tr><td>0</td><td>11.954</td><td>-</td><td>1</td><td>0.0005</td><td>0.0005</td><td>0.000</td></tr><tr><td></td><td></td><td></td><td></td><td>Sum</td><td>1</td><td>3.41205</td></tr></table>

Table 3.12: Valuation of the call option in the 11 period model with ABB as underlying value. 'S.P.' means 'sum of path weights'.

with  $\sigma$  the volatility of the continuous time price process of the risky asset. Using a Taylor approximation we get

$$
E \left(\frac {d S / d t}{S}\right) = r,
$$

i.e. the expected risky asset growth rate equals the risk free rate. In the one period model the mean and variance of the same asset ratio are

$$
E \left(S _ {t + 1} / S _ {t}\right) = q u + (1 - q) d
$$

and

$$
\operatorname {v a r} \left(S _ {t + 1} / S _ {t}\right) = q u ^ {2} + (1 - q) d ^ {2} - (q u + (1 - q) d) ^ {2} = q (1 - q) (u - d) ^ {2}.
$$

Equating the moments in the models we get:

$$
q u + (1 - q) d = e ^ {r d t}, q (1 - q) (u - d) ^ {2} = e ^ {2 r d t} (e ^ {\sigma^ {2} d t} - 1).
$$

Matching expected values implies the RNP formula  $q = \frac{e^{rdt} - d}{u - d}$ . Making the symmetric choice  $u = 1 / d$  from the variance matching condition a complicated expression for  $u$  follows. Using a Taylor approximation (dt is small) one gets

$$
u = 1 / d = 1 + \sigma \sqrt {d t} + \frac {\sigma}{2} d t + \dots .
$$

The first terms agree with the power series expansion of  $u = e^{\sigma \sqrt{dt}}$  - this justifies the approach in the above pricing of the ABB call option.

# 3.4.7 Black and Scholes

Given multi period dynamic models in discrete time the next generalization is to consider derivative pricing in continuous time and with continuous state space. The seminal work of Fischer Black and Myron Scholes is the starting point and in fact it was published before the CRR model. We could introduce stochastic calculus and develop the model from scratch using no arbitrage. This would take us to far away and therefore, we state the Black and Scholes model as a limit model of the CRR.

We have to consider a two-fold limit: Discrete time spacing and discrete states become continuous. We fix time  $T$  of the continuous model. We to make sure in the limit procedure that (i) the value of one dollar in  $[0, T]$  is the same in the CRR model and in the Black and Scholes model and (ii) that the CRR-price process  $S_{t}$  converges towards a continuous price process which is log-normally distributed. This is the assumed distribution in Black and Scholes; assuming a different distribution different continuous time models follow.

To satisfy (i), divide  $[0,T]$  in  $m$  equidistant binomial model in  $m$  periods. We have  $(B_{k},S_{k})_{k = 0,\dots,m}$  with  $B_{m} = B_{T}$ ,  $S_{m} = S_{T}$ . We adjust the parameters  $r_m,u_m,d_m$  such that they can be compared with the parameters of the CRR model. Let  $R = \ln (1 + r)$  be the risk free interest rate in the time unit [0,1]. Setting  $r_m\coloneqq \frac{RT}{m}$  and  $B_{m} = (1 + r_{m})^{m}$  we have in the limit

$$
\lim _ {m \to \infty} (1 + r _ {m}) ^ {m} = \lim _ {m \to \infty} \left(1 + \frac {R T}{m}\right) ^ {m} = e ^ {R T} = (1 + r) ^ {T}.
$$

Hence,  $B_{m}$  converges towards the same value as in the  $T$ -maturity continuous model.

We consider (ii) and define relations between  $r_m, u_m, d_m$ :

$$
\ln (1 + u _ {m}) = \ln (1 + r _ {m}) + \sigma \sqrt {\frac {T}{m}}
$$

$$
\ln (1 + d _ {m}) = \ln (1 + r _ {m}) - \sigma \sqrt {\frac {T}{m}}
$$

with a constant  $\sigma > 0$ , which is independent of  $m$  and we set as in the  $T$ -model

$$
\hat {p} _ {m} := \frac {r _ {m} - d _ {m}}{u _ {m} - d _ {m}}.
$$

The above parametrization implies  $u / d = 1$ . The definitions guarantee that  $\log X_{i}$  is normally distributed with a mean and variance that reduces to the same one as in the Black and Scholes model. Formally:

Proposition 46. Let  $r_m, u_m, d_m$  defined as above. Then

$$
\lim  _ {m \to \infty} \ln \left(\frac {\tilde {S} _ {T}}{S _ {0}}\right) \sim \mathcal {N} (- \frac {\sigma^ {2} T}{2}, \sigma^ {2} T).
$$

That is, the random variable  $\ln \frac{\tilde{S}_T}{S_0}$  converges for  $m\to \infty$  in probability to a normally distributed random variable with mean  $-\frac{\sigma^2T}{2}$  and variance  $\sigma^2 T$ .

We apply this result to price call and put options in Black and Scholes model.

Proposition 47 (Black-Scholes Formula). Let  $u_{m}, d_{m}, r_{m}, \hat{p}_{m}$  be given as above. The prices of European call and put options in the Black and Scholes model are given by:

$$
\lim  _ {m \rightarrow \infty} C _ {0} ^ {(m)} = S _ {0} \Phi (d _ {1}) - K e ^ {- R T} \Phi (d _ {2}) \tag {3.65}
$$

$$
\lim _ {m \rightarrow \infty} P _ {0} ^ {(m)} = K e ^ {- R T} \Phi (- d _ {2}) - S _ {0} \Phi (- d _ {1})
$$

with  $d_1, d_2$  given by:

$$
d _ {1} = \frac {\ln (S _ {0} / K) + R T}{\sigma \sqrt {T}} + \frac {\sigma \sqrt {T}}{2}
$$

$$
{d _ {2}} = {d _ {1} - \sigma \sqrt {T} = \frac {\ln (S _ {0} / K) + R T}{\sigma \sqrt {T}} - \frac {\sigma \sqrt {T}}{2}}
$$

Although the formulae look complicated, they share the same logic and properties as in the single period model. First, they are expected values of the discounted call payoff under the RNP which is not visible since we took the limits in the CRR model. Second, a call is proportional to the stock times its Delta minus cash. We work on these comments.

Consider an out-of-the-money call option with price

$$
C (S = 90, K = 100, r = 2 \%, \sigma = 20 \%, t = 0, T = 6 \mathrm {~m}) = 1.99 \sim 2.
$$

This positive price cannot be due to interest rates only since investing CHF 90 for  $6\mathrm{m}$  gives  $90 \cdot e^{r(T - t)} = 90.90 < 1005$  CHF. The reason for a price of 2 is due to the fact the underlying  $S$  random variable has a potential to grow above the strike value in the next  $6\mathrm{m}$ . The returns of the underlying is normally distributed, i.e.

$$
\ln (S _ {T} / S _ {t}) \sim N (\mu , \sigma_ {T})
$$

This implies that the stock price at  $T$  is log-normal distributed:

$$
S _ {T} \sim S _ {t} L N (\mu , \sigma_ {T}) = L N (\ln (S _ {t}) + \mu , \sigma_ {T}).
$$

Since we know the distribution, we can price the call using the no arbitrage principle. The price is given

$$
C (S, K, r, \sigma , t, T) = E ^ {Q} \left[ \max  \left(S _ {T} - K, 0\right) \right]. \tag {3.66}
$$

How do we find the risk neutral probability? No arbitrage implies that the discounted price process  $S$  is a martingale with the risk free interest rate as numeraire. But this means that the expected value  $S$  has to grow like the risk less asset - else the drifts are

# 3.4. APPLICATION

not the same. But if the drift of  $S$  and the drift  $r$  of the riss less asset are not the same, their ratio -  $S$ /risk less asset - cannot be driftless. Summarizing, we must have at  $T$

$$
E \left[ S _ {T} \right] = S _ {t} \exp (r (T - t)). \tag {3.67}
$$

But the expectation of log normal distributed random variable with mean  $\mu$  and volatility  $\sigma$  is given by

$$
E \left[ S _ {T} \right] = S _ {t} \exp \left(\mu + \sigma_ {T} ^ {2} / 2\right). \tag {3.68}
$$

Equations (3.67) and (3.68) imply:

$$
\mu + \sigma_ {T} ^ {2} / 2 = r (T - t) \quad \Rightarrow \quad \mu = r (T - t) - \sigma_ {T} ^ {2} / 2 \tag {3.69}
$$

The volatility  $\sigma_T$  from  $t$  to maturity is determined from the annual maturity by the square-root rule:

$$
\sigma_ {T} = \sigma \sqrt {T - t}
$$

with  $\sigma$  the annualized volatility. Summarizing

$$
\ln \left(S _ {T} / S _ {t}\right) \sim N \left(r (T - t) - \frac {1}{2} \sigma^ {2} (T - t), \sigma \sqrt {T - t}\right) \tag {3.70}
$$

or

$$
S _ {T} / S _ {t} \sim L N \left(r (T - t) - \frac {1}{2} \sigma^ {2} (T - t), \sigma \sqrt {T - t}\right)
$$

All these expressions enter  $d_{1}$  and  $d_{2}$  in the Black and Scholes formula. How can we calculate the probability that we exercise the call? The option is exercised if  $S_{T} > K$ . This reads for the continuous return  $r_{S} = \ln (S_{T} / S_{t})$

$$
r _ {S} = \ln \left(S _ {T} / S _ {t}\right) > \ln \left(K / S _ {t}\right).
$$

But we know from (3.70) the distribution of  $r_S$ :

$$
r _ {S} = \ln \left(S _ {T} / S _ {t}\right) \sim N \left(r (T - t) - \frac {1}{2} \sigma^ {2} (T - t), \sigma \sqrt {T - t}\right)
$$

A calculation shows

$$
P \left(S _ {T} > K\right) = P \left(r _ {S} > \ln \left(K / S _ {t}\right)\right) = \Phi (d _ {2}).
$$

The probability to exercise the option is equal to  $\Phi(d_2)$  which is the Delta.

# 3.4.8 Hedging and Greeks

Risk management for options is based on the Greeks, i.e. sensitivities or partial derivatives of option prices with respect to parameters. Since derivatives are linear; a Greek of a portfolio is equal to the sum of the position Greeks time the quantity. Since there are many parameters in the pricing formula, several Greeks exist.

We define the Delta  $(\Delta) = \frac{\partial C}{\partial S}$ . A Delta of  $+0.5$  implies that if an underlying stock rises by CHF 1, the theoretical option price increases by CHF 0.5. Consider an investor which is long 10 option contracts 50-calls (i.e. strike 50) on Nestle stock with a Delta of 0.5 with 70 shares of the stock per option contract and he is short 200 Nestle stocks. The position Delta :

$$
- 2 0 0 + 0. 5 \times 1 0 \times 7 0 = + 1 5 0.
$$

Gamma  $\Gamma$  states how much the Delta of an option changes when the price of the stock moves. A large Gamma means that the Delta changes strongly even for a small move in the stock price.

Theta  $\Theta$ , or time decay, is an estimate of how much the theoretical value of an option decreases when 1 day passes. The Thetas for same-parameter calls and puts are not equal. The difference depends on the cost-of-carry for the underlying stock. When the dividend yield is less than the interest rate - the cost-of-carry for the stock is positive - Theta for the call is higher than for the put. The difference between the extrinsic value of the option with more days to expiration and the option with fewer days to expiration is due to Theta. Therefore, long options have negative Theta and short options have positive Theta. If options are continuously losing extrinsic value, a long option position will lose money because of Theta. Theta value does not decrease linearly over time since the value is not linear distributed between OTM, ATM and ITM. If Gamma is highest for a long call position, negative Theta is also largest.

We consider Delta and Gamma hedging in for the portfolio  $V$ :

- Short  $1^{\prime}000$  calls, Time-to-Maturity (TtM) 90 days, strike 60, volatility  $30\%$ , risk less rate  $8\%$ . The currency is irrelevant.  
- The fair option price using Black and Scholes is 4.14452 with Delta 0.581957. We therefore receive a premium of 4144.52 by selling the options.  
- To hedge the position we buy 581.96 stocks at the price 60. That for we borrow (cash)

$$
5 8 1. 9 6 \times 6 0 - 4 1 4 4. 5 2 = 3 4 ^ {\prime} 9 1 7. 3 9 - 4 1 4 4. 5 2 = 3 0 ^ {\prime} 7 7 2. 8 8.
$$

The portfolio value today is zero. We consider the portfolio value after 1 day, i.e. TtM is 89 days. In the Scenario 'unchanged' the underlying value remains at 60. Using Black and Scholes, the option is worth 4.11833, i.e. Theta acts. This lower option liability value is partly off-set by the increased cash liability:

$$
3 0 ^ {\prime} 7 7 9. 6 2 = 3 0 7 7 2. 8 8 \times (1 + 0. 0 8 / 3 6 5).
$$

A gain 19.44 follows, see Table ??. The result for the two other scenarios 'up' and 'down' are reported in Table ??

# 3.4. APPLICATION

<table><tr><td></td><td colspan="3">Value</td></tr><tr><td></td><td>unchanged</td><td>up</td><td>down</td></tr><tr><td>Underlying</td><td>34&#x27;917.39</td><td>35&#x27;499.35</td><td>34&#x27;335.44</td></tr><tr><td>Cash</td><td>-30&#x27;779.62</td><td>-30&#x27;779.62</td><td>-30&#x27;779.62</td></tr><tr><td>Option</td><td>-4&#x27;118.33</td><td>-4&#x27;721.50</td><td>-3&#x27;559.08</td></tr><tr><td>Sum</td><td>19.44</td><td>-1.77</td><td>-3.26</td></tr></table>

This shows that the Delta hedge is effective for small changes in the underlying value.

Can we additionally hedge the Gamma? Since one option is used for the Delta hedge, we need a second option to achieve also Gamma neutrality. The data of this option are:

- Call, TtM 60 days, strike 65.  
- All other parameters are the same as for the first option, see Table 3.14.

Table 3.13: Value of the portfolio  $V$  after 1 day for different scenarios.  

<table><tr><td></td><td>TtM</td><td>Strike</td><td>Option Price</td><td>Delta</td><td>Gamma</td></tr><tr><td>Option 1</td><td>90/365</td><td>60</td><td>4.14452</td><td>0.581957</td><td>0.043688</td></tr><tr><td>Option 2</td><td>60/365</td><td>65</td><td>1.37825</td><td>0.312373</td><td>0.048502</td></tr></table>

Table 3.14: Option data.

Delta and Gamma neutrality means to choose a number of stocks  $z$  of option  $z$  such that:

$$
\Delta V = x - 1 ^ {\prime} 0 0 0 \Delta_ {\mathrm {O p t} 1} + z \Delta_ {\mathrm {O p t} 2} = 0
$$

$$
\Gamma V = - 1 ^ {\prime} 0 0 0 \Gamma_ {\mathrm {O p t 1}} + z \Gamma_ {\mathrm {O p t 2}} = 0.
$$

Solving these two linear equations gives

$$
x = 3 0 0. 5 8, z = 9 0 0. 7 6
$$

To fix cash, one solves  $V = 0$  at time 0:

$$
V = x S + \operatorname {C a s h} - 1 0 0 0 * \operatorname {O p t} 1 + z * \operatorname {O p t} 2 = 0 \Longrightarrow \operatorname {C a s h} = - 1 5 ^ {\prime} 1 3 1. 7 7.
$$

To be Delta and Gamma neutral we are long in the underlying, long in option 2 and short cash. Table 3.15 compares the hedge effectiveness between Delta and Delta & Gamma hedging.

Vega is an estimate of how much the theoretical value of an option changes when volatility changes by 1 percent. Option prices and volatility are in a 1:1 relation in the Black and Scholes model. You can quote option in CHF or in volatility points. Vega is highest for ATM options. Rho  $\rho$  is an estimate of how much the theoretical value of an option changes when interest rates move 1.00 percent. The Rho for a call and put at the same strike price and the same expiration month are not equal.

<table><tr><td>Underlying after 1d</td><td>Delta &amp; Gamma</td><td>Delta</td></tr><tr><td>58</td><td>-2.04</td><td>-71.35</td></tr><tr><td>58.5</td><td>0.3</td><td>-31.56</td></tr><tr><td>59</td><td>1.07</td><td>-3.26</td></tr><tr><td>59.5</td><td>0.81</td><td>13.69</td></tr><tr><td>60</td><td>0.02</td><td>19.45</td></tr><tr><td>60.5</td><td>-0.79</td><td>14.22</td></tr><tr><td>61</td><td>-1.11</td><td>-1.77</td></tr><tr><td>61.5</td><td>-0.49</td><td>-28.24</td></tr><tr><td>62</td><td>1.52</td><td>-64.93</td></tr></table>

Table 3.15: Delta & Gamma vs. Delta Hedge.  

<table><tr><td>Sensitivity w.r.t.</td><td>Math</td><td>Finance</td><td>Expression</td></tr><tr><td rowspan="2">Underlying S</td><td>\(\frac{\partial C(S)}{\partial S}\)</td><td>Delta Δ</td><td>\(\Delta_{\mathrm{C}}=\Phi(d_{1})&gt;0\)</td></tr><tr><td>\(\frac{\partial P(S)}{\partial S}\)</td><td></td><td>\(\Delta_{\mathrm{P}}=\Phi(d_{1})-1&lt;0\)</td></tr><tr><td rowspan="2">Time-to-maturity τ</td><td>\(\frac{\partial C(\tau)}{\partial \tau}\)</td><td>Theta Θ</td><td>\(\Theta_{\mathrm{C}}=-S \sigma \phi(d_{1})/(2 \sqrt{\tau})-r K e^{-r \tau} \Phi(d_{2})&lt;0\)</td></tr><tr><td>\(\frac{\partial P(\tau)}{\partial \tau}\)</td><td></td><td>\(\Theta_{\mathrm{P}}=-S \sigma \phi(d_{1})/(2 \sqrt{\tau})+r K e^{-r \tau} \Phi(-d_{2})&lt;0\)</td></tr><tr><td rowspan="2">Risk free rate r</td><td>\(\frac{\partial C(r)}{\partial r}\)</td><td>Rho ρ</td><td>ρC=Ke-rττΦ(d2)&gt;0</td></tr><tr><td>\(\frac{\partial P(r)}{\partial r}\)</td><td></td><td>ρP=-Ke-rττΦ(-d2)&lt;0</td></tr><tr><td rowspan="2">Vola σ</td><td>\(\frac{\partial C(\sigma)}{\partial \sigma}\)</td><td>Vega ω</td><td>ωC=φ(d1)S√τ&gt;0</td></tr><tr><td>\(\frac{\partial P(\sigma)}{\partial \sigma}\)</td><td></td><td>ωP=ωC</td></tr><tr><td rowspan="2">Underlying S</td><td>\(\frac{\partial^{2}C(S)}{\partial S^{2}}\)</td><td>Gamma Γ</td><td>ΓC=φ(d1)/(Sσ√τ)&gt;0</td></tr><tr><td>\(\frac{\partial^{2}P(S)}{\partial S^{2}}\)</td><td></td><td>ΓP=ΓC</td></tr></table>

The sensitivities are linked by the Black and Scholes pricing equation:

$$
\sigma^ {2} S ^ {2} \Gamma + r S \Delta - r C = - \Theta . \tag {3.71}
$$

This equation follows by the assumed market structure and the assumption of no arbitrage - no further economic assumptions are needed. Adding the specific option contract as a terminal condition, the solution  $C$  of the equation is the Black and Scholes formula for the option under consideration - a second method to price options beside calculating expected values under a RNP.

We consider the creation of an option trading book in a liquid market. Consider the liquid stock Lafargeholcim (LH). We start with a short position of 1000 calls on LH with price 7.232 CHF (Step 1). The option price is theoretically calculated. If LH stock moves, up to first order  $\frac{\partial C}{\partial S} =: \Delta$ , a loss of CHF  $-587$  on the derivative position follows, see Table 3.16.

<table><tr><td>Step 1</td><td>Product</td><td>Size</td><td>B &amp; S</td><td>Tr.Pr.</td><td>Pos.Val.</td><td>Delta</td><td>P &amp; L</td></tr><tr><td></td><td>Option LH</td><td>-1000</td><td>7.232</td><td></td><td>-7232</td><td>-587</td><td></td></tr><tr><td></td><td>Position</td><td></td><td></td><td></td><td>-7232</td><td>-587</td><td>0</td></tr><tr><td>Step 2</td><td>Product</td><td>Size</td><td>B &amp; S</td><td>Tr.Pr.</td><td>Pos.Val.</td><td>Delta</td><td>P &amp; L</td></tr><tr><td></td><td>Option LH</td><td>-1000</td><td>7.232</td><td></td><td>-7232</td><td>-587</td><td></td></tr><tr><td></td><td>Stock LH</td><td>620</td><td>80</td><td>80</td><td>49600</td><td>620</td><td></td></tr><tr><td></td><td>Position</td><td></td><td></td><td></td><td>42368</td><td>33</td><td>0</td></tr><tr><td>Step 3</td><td>Product</td><td>Size</td><td>B &amp; S</td><td>Tr.Pr.</td><td>Pos.Val.</td><td>Delta</td><td>P &amp; L</td></tr><tr><td></td><td>Option LH</td><td>-1000</td><td>7.232</td><td>7.5</td><td>-7232</td><td>-587</td><td>268</td></tr><tr><td></td><td>Stock LH</td><td>620</td><td>80</td><td>80</td><td>49600</td><td>620</td><td>0</td></tr><tr><td></td><td>Position</td><td></td><td></td><td></td><td>42368</td><td>33</td><td>268</td></tr><tr><td>Step 4</td><td>Product</td><td>Size</td><td>B &amp; S</td><td>Tr.Pr.</td><td>Pos.Val.</td><td>Delta</td><td>P &amp; L</td></tr><tr><td></td><td>Option LH</td><td>-1000</td><td>7.232</td><td>7.5</td><td>-7232</td><td>-587</td><td>268</td></tr><tr><td></td><td>Stock LH</td><td>620</td><td>81</td><td>81</td><td>50220</td><td>620</td><td>0</td></tr><tr><td></td><td>Delta</td><td></td><td></td><td></td><td></td><td></td><td>33</td></tr><tr><td></td><td>Position</td><td></td><td></td><td></td><td>42988</td><td>33</td><td>268</td></tr></table>

Table 3.16: Positions in the option portfolio construction. Tr.Pr. means Trading Price, B & S the theoretical Black and Scholes model price and Pos.Val. Position Value.

Step 2: To reduce Delta risk, we buy 620 LH stocks at the price 80. To generate P&L different possibilities exist. First (Step 3) one sells the options slightly at a higher price than their values are. This gives a P&L of CHF 268. Second, price movements as described above lead to P&L (step four where LH gains 1). Step 5 describes how volatility movements generate P&L. We assume that the portfolio  $V$  is Delta neutral. Volatility is  $20\%$ . If volatility increases by 1 volatility point, the bank loses 304 CHF. If the trader hedges the Vega exposure he needs to trade in different options. Step 6 shows that if he trades in a second option, the Vega of the position is reduced but Delta increases moves from zero. As we seen above, both Greeks can be controlled.

calculated reference volatility curve, e.g. the Eurex curve: Volatilities of the warrants are larger than the corresponding reference values and vice versa for the

# 3.4.9 Structured Products (SP) and Structured Investments

18 Consider markets which are disrupted unpredictably by certain events and investors want to choose an investment in response of the event. Investments should hence be fast deployed and not capturing any diversification needs but being bets due to the market disruption and hence the belief, that markets will drift back to normal levels.

<table><tr><td>Step 5</td><td>Product</td><td>Size</td><td>Price</td><td>Pos. Val.</td><td>Delta</td><td>Vega in CHF</td></tr><tr><td></td><td>Option Holcim</td><td>-1000</td><td>7.232</td><td>-7232</td><td>-587</td><td>-304</td></tr><tr><td></td><td>Stock Holcim</td><td>588</td><td>80</td><td>47040</td><td>588</td><td></td></tr><tr><td colspan="3">Position</td><td>39808</td><td>1</td><td>-304</td><td></td></tr><tr><td>Step 6</td><td>Product</td><td>Size</td><td>Price</td><td>Pos. Val.</td><td>Delta</td><td>Vega in CHF</td></tr><tr><td></td><td>Option Holcim</td><td>-1000</td><td>7.232</td><td>-7232</td><td>-587</td><td>-304</td></tr><tr><td></td><td>Stock Holcim</td><td>588</td><td>80</td><td>47040</td><td>588</td><td>0</td></tr><tr><td></td><td>Option Holcim 2</td><td>400</td><td>7.232</td><td>2893</td><td>235</td><td>122</td></tr><tr><td colspan="3">Position</td><td>42701</td><td>236</td><td>-182</td><td></td></tr></table>

Table 3.17: Position in the option portfolio construction. The figure Delta is expressed in numbers of Holcim shares.

There are different causes for these events - macroeconomic, policy interventions, break down of investment strategies, or firm-specific events (for example, Lehman Brothers). While some events are isolated and affect only single corporates, events at the political or market level often lead to broader investment opportunities. Policy interventions can trigger market reactions that in turn can lead to new policy interventions. The Swiss National Bank's announcement, in January 2015, that it would remove the EURCHF cap and introduce negative interest rates had an effect on Swiss stock markets, EURCHF rates, and fixed-income markets.

Such events can impact financial markets for a short period of time (a flash crash), a medium time period (the GFC), or a long time (the Japanese real-estate shock of the 1990s). Making a bet when markets are under stress is simpler than in normal times where it is uncertain if an event happens at all. We stress that a general requirement for investments based on events is the fitness of all parties involved - investors, advisory, and the issuer.

If an event occurs, the time-to-market to generate investment solutions and to make an investment decision are key. Wrappers of such solutions such as funds or ETFs take too much time to be constructed. The wrappers used are derivatives and structured products (SP). Both are manufactured and issued by trading units or derivative firms - not by traditional asset management firms. SPs are a combination of traditional investment instruments and at least one derivative. SP define payoff liabilities for the issuer and hence affect the balance sheet of the issuer. The investor faces issuer risk.

The replication of the payoff of an SP with cash products and vanilla options is central to the pricing and hedging of the SP. The price of the SP is equal to the sum of the prices of the building blocks. The no arbitrage paradigm applies. The hedge corresponds to the position of the dealer of the bank, which must generate the promised payoff of the SP. Theoretical equivalent replications can be different in practice if components have

SP are in some sense an opposite investment vehicle to funds since most of them do not rely on the discretionary power of an asset manager but the final payoff is promised ex ante to the investor. The issuer has to generate with the initial investment amount the final payoff in any market circumstances: Trading, structuring, pricing and hedging are key disciplines for SP.

different liquidity or if taxation differs. The buyer of a SP faces only claims but no obligations unlike in a swap contract for example. The only counter-party for the investor is the issuer whose creditworthiness enters in the pricing of the SP.

Table 3.18 compares mutual funds with structured products.  

<table><tr><td>Mutual funds</td><td>Structured Products</td></tr><tr><td>Mass products</td><td>Taylor made, starting from CHF 10&#x27;000</td></tr><tr><td>No issuer risk</td><td>Issuer risk (but COSI, TCM)</td></tr><tr><td>Long time-to-market</td><td>Short time-to-market</td></tr><tr><td>Performance promise</td><td>Payoff promise</td></tr><tr><td>Large setup costs</td><td>Low setup costs</td></tr><tr><td>Liquid and illiquid assets</td><td>Liquid assets</td></tr><tr><td rowspan="3">Strong legal setup, standards, market access</td><td>No legally binding definition of Structured Products</td></tr><tr><td>High-quality secondary markets</td></tr><tr><td>On balance sheet</td></tr></table>

Table 3.18: Mutual funds vs. structured products. COSI are structured products with a minimal issuer risk thanks to collateralization vis SIX exchange. Triparty Collateral Management (TCM) serves the same purpose.

How are SPs defined? The definition varies for different jurisdictions, sometimes a proper definition is missing but only a description exists. In the UK for example they differentiate between capital-at-risk and non-capital-at-risk products. In the former one conditional on the issuer non-defaulting the investor gets paid back a fixed amount of his initial investment at maturity as a minimum amount. A capital-at-risk product is defined as … a product, other than a derivative, which provides an agreed level of income or growth over a specified investment period and displays the following characteristics:

- (a) the customer is exposed to a range of outcomes in respect of the return of initial capital invested;  
- (b) the return of initial capital invested at the end of the investment period is linked by a pre-set formula to the performance of an index, a combination of indices, a 'basket' of selected stocks (typically from an index or indices), or other factor or combination of factors;  
- (c) if the performance in (b) is within specified limits, repayment of initial capital

invested occurs but if not, the customer could lose some or all of the initial capital invested.' Source: FSA Handbook.

Point (c) defines that capital repayment is contingent on realization of events. A typical event are breaches of barriers by the underlying value.

SP should not be confused with structured finance products such as MBS, CDO or CLN. The latter one arise as products by pooling illiquid assets whereas SP are defined for liquid assets.

# 3.4.10 Pricing of Structurd Products

Using the SP definition of last section, we consider risk structuring for an investor with the following preferences and views: He wishes capital protection at maturity of the contract and participation in the performance of an underlying asset:

- Redemption of the investment capital at a minimum guaranteed percentage of the invested capital at maturity of the investment contract.  
- Participation in the performance of an underlying asset.

The main economic idea to structure a Capital-Guaranteed Product (CP) is to present the value of say CHF 100 in 5 years is a lower amount today - the difference is used for participation. Then the seller of the guarantee, i.e. the issuer of the structured product, acts as follows:

- Suppose that the annual interest rates are  $2\%$ . The PV of the guaranteed CHF 100 in 5 is

$$
9 0 = (1 - 5 \times 0. 0 2) \times 1 0 0 \mathrm {C H F}
$$

using linear compounding. If the issuer invests today CHF 90 in a zero-bond, then the capital guarantee promise in 5 years can be satisfied - if the issuer does not defaults.

- The amount of  $10\%$  is used to define participation for the investor.

Therefore, the investment product  $\mathrm{SP} V_{t}$  consists of a zero bond with price  $p(t,T)$  at time  $t$  and maturity  $T$  and a participation product whose price depends on the price of the underlying asset  $S_{t}$ . In the simplest variant, the value of the product  $V_{T}$  at maturity  $T$  is determined as the product of the face value and the participation in the underlying asset's price return:

$$
V _ {T} = N \times \left(1 + \max  \left(0, b \frac {S _ {T} - S _ {0}}{S _ {0}}\right)\right)
$$

with  $N$  the face value and  $b$  the participation rate. Rewriting, we get

$$
V _ {T} = N + \frac {b N}{S _ {0}} \max  \left(0, S _ {T} - S _ {0}\right). \tag {3.72}
$$

We note that a  $+ + -$  sign in a payoff value is a long position and a  $-$  sign a short position. The payoff formula (3.72) is written from a buyer's perspective.

Equation (3.72) shows that the payoff of the CP at maturity equals an investment in a zero bond and a long position in a European call option  $C(S, K, T)$  with strike  $K = S_0$ . The number of options is equal to the face value divided by the initial price. (3.72) is a replication of the payoff at maturity fixed in the contract. No arbitrage implies for the fair value of the contract  $V_0$

$$
V _ {0} = p (0, T) + \frac {b N}{S _ {0}} C (0, S, K) \tag {3.73}
$$

with  $p(0,T)$  the zero bond and  $C(S,K,0)$  the arbitrage free option price, i.e.  $S(0,S,K) = E^{Q}[D(0,T)\max (S_{T} - S_{0},0)]$ .

Consider an investor with different preferences:

- He beliefs that UBS stock is likely to raise over the next year.  
- He believes that the stock will not raise strongly. He also prefers a partial capital protection if UBS stocks falls. He is in turn willing to give up the upside potential of the stock.  
- He prefers a coupon which is larger than the UBS stock dividend.

A SP is able to match these investor preferences; A Barrier Reverse Convertible (BRC). The investor gets independent of UBS stock price movements a coupon, say 10 percent. The investment amount is fully paid back unless the underlying value dropped below a barrier level during the life time of the product: The repayed capital amount is contingent on an event of a barrier hit. If the underlying value UBS once hits the barrier, the capital protection is knocked out and the payback at maturity is the UBS stock value at this date plus the 10 percent coupon. A BRC delivers a higher coupon than the stock dividend plus a contingent capital protection. Contrary to CP, the investor faces market risk of UBS breaching the barrier. The investor gives up the stocks upside: The coupon is the maximum return possible which is higher than the UBS dividend yield. Consider the replication of the BRC. The BRC payoff at maturity is replicated with two products:

- a long zero coupon bond position and  
- a short down & in put (DIP). I.e. the investor sells a DIP - a barrier option on UBS. This money is used to generate the coupon value.

A barrier put option is characterized by a strike  $K$  and a barrier  $B$ . In our case  $B < K$  - this leads to the expression 'down'. The payoff is: If UBS is for the whole time to maturity not breaching  $B$ , the option is worthless. Contrary if at any date the barrier is at least hit once the put option becomes active - the option is 'in'. In the BRC the

investor is short the DIP - he sells it. If the barrier is hit a loss follows.

Contrary to the problem to classify innovations in general, for RSP successful classification schemes exist. One of them is the Swiss Derivative Map from the Swiss Derivative Association. With minor adaption this map is also used in the European Structured Product Association. The Swiss map defines main categories:

- Capital protection.  
- Yield Enhancement. BRC are a prominent product in this class.  
- Participation, i.e. product which globally have linear payoff profile. 'Globally' means that for some bounded region in the underlying value the payoff can be non-linear.  
- Leverage Products. This is the class of warrants and mini futures.  
- Reference Entity Products. In addition to the credit risk of the issuer, redemption is subject to the solvency (non-occurrence of a credit event) of the reference entity.

In each category there a sub categories.

We consider a discount certificate (DC) as a next example, see Figure 3.14 for the payoff profile at maturity of the DC.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d1ed9b8cec13b54f2d83ad1777f35280d023c237bdc1fdeb81a5e88d72061be4.jpg)  
Figure 3.14: Payoff of a discount certificate.

The investor is willing to give up the upside of the underlying in exchange for a buffer if the underlying drops. If the spot price of the underlying is CHF 236 and the issuing

price of the DC is CHF 210, i.e. 11 percentage lower than the price of the underlying, then the investors gets a discount of  $11\%$  and the maximum return is  $250 / 210 - 1 = 19\%$ . The final payoff of the DC is given by  $\min(S_T, K)$  with  $S_T$  the value of the underlying at maturity and  $K$  the strike value. To price a DC one replicates the payoff by using simpler products: the price of the DC is by no arbitrage equal to the replication payoff's price. Since the payoff is non-linear, options are needed for replication and a model such as Black and Scholes is used to price the options. The replication portfolio is long a LEPO (Low Exercise Price Option) and short a call with strike  $K = 250$ . LEPOs are European type call option with very low strike of  $K = 0.01$  CHF. The current value of a LEPO is equal to the current price of the underlying share compounded by the risk-free interest rate, less the accumulated value of dividends and the strike price. Since  $K$  is close to zero, the price sensitivity of th LEPO which implies that the price of the LEPO is well approximated by the price of the underlying minus the PV of the dividends. Hence, the DC payoff is graphically equivalent to a straight line(LEPO) plus a short call payoff.

# 3.4.11 Political Events: Swiss National Bank (SNB) and ECB and SP Investment

The SNB announced, on 15 January 2015, the removal of the euro cap and the introduction of negative CHF short-term interest rates. This decision caused the SMI to lose about 15 percent of its value within 1 - 2 days, and the FX rate EUR/CHF dropped from 1.2 to near parity. Similar changes occurred for USD/CHF. Swiss stocks from export-oriented companies or companies with a high cost base in Swiss francs were most affected. The drop in stock prices led to a sudden and large increase in Swiss stock market volatility. Swiss interest rates became negative for maturities of up to thirteen years.

It was also known at the time that the ECB would make public its stance on quantitative easing (QE) one week later. The market participants' consensus was that Mario Draghi - president of the ECB - would announce a QE program. The events in Switzerland, which came as a surprise, and the ECB QE measures subsequently announced paved the way for the following investment opportunities:

1. A Swiss investor could invest in high quality or high dividend paying EUR shares at a discount of 15 percent. EUR shares were expected to rise due to the forthcoming ECB announcement.  
2. All Swiss stocks, independent of their market capitalization, faced heavy losses independently of their exposure to the Swiss franc.  
3. The increase in volatility made BRCs with very low barriers feasible.  
4. The strengthening of the Swiss franc versus the US dollar, and the negative CHF interest rates, led to a USD/CHF FX swap opportunity that only qualified investors could benefit from.
5. The negative interest rates in CHF and rates of almost zero in the eurozone made investments in newly issued bonds very unattractive. Conversely, the low credit risk of corporates brought about by the ECB's decision offered opportunities to invest in the credit risk premia of large European corporates via structured products.

Before certain investment opportunities are discussed in more detail, it should be noted that by the time this paper had been written (about five months after the events described above took place), all investments were profitable and some even had two-digit returns. This certainly does not mean that the investments were risk free, as such investments are not risk free. But it shows that many investment opportunities are created by policy interventions. This contrasts with the often voiced complaints about negative interest rates and the absence of investment opportunities for firms, pension funds, and even private investors. Some investment ideas will now be considered in more detail.

# 3.4.11.1 Opportunities to Invest in High Dividend Paying EU Stocks

The idea was to buy such stocks at a discount due to the gain in value of the Swiss franc against the euro. The first issuer of a tracker offered such products on Monday, 19 January 2015 - that is to say, two business days after the SNB's decision was announced. With all products, investors participated in the performance of a basket of European shares with a high dividend forecast. The basket's constituents were selected following suggestions from the issuing banks' research units. Investors could choose between a structured product denominated in Swiss francs or in euros depending on their willingness to face - besides the market risk of the stock basket - also the EUR/CHF FX risk.

This investment had two main risk sources. If it was denominated in euros, the EUR/CHF risk held and one faced the market risk of the large European companies whose shares comprised the basket. Most investors classified the FX risk as acceptable since a significant further strengthening of the Swiss franc against the euro would meet with counter measures from the SNB. More specifically, a tracker on a basket of fourteen European stocks was issued. The issuance price was fixed at EUR 98.75. As of 1 April 2015 the product was trading at EUR 111.10 (mid-price) - equivalent to a performance of 12.51 percent pro rata. Similar products were launched by all the large issuers.

Other issuers launched a tracker on Swiss stocks, putting all large Swiss stocks in a basket that had only a little exposure to the Swiss franc, but which also faced a heavy price correction after the SNB announcement in January. Again, the input of each issuing bank's research unit in identifying these firms was key. The underlying investment idea for this product can be seen as a typical application of behavioral finance: an overreaction of market participants to events is expected to vanish over time.

The risk in this investment was twofold. First, one did not know whether the SNB would consider further measures, such as lowering interest rates further, which would

have led to a second drop in the value of Swiss equity shares. Second, international investors with euros or US dollars as their reference currency could realize profits since the drop in Swiss share values - around 15 percent - was more than offset by the gain from the currency, which lost around 20 percent in 'value'; roughly, an institutional investor could earn 5 percent by selling Swiss stocks. Since large investors exploit such opportunities rapidly, it became clear three days after the SNB's decision was announced that the avalanche of selling orders from international investors was over.

# 3.4.11.2 Low-Barrier BRCs

Investors and private bankers searched for cash alternatives with a 100 percent capital guarantee. The negative CHF interest rates made this impossible: if 1 Swiss franc today is worth less than 1 Swiss franc will be worth tomorrow, one has to invest more than 100 percent today to get a 100 percent capital guarantee in the future.

Low-barrier BRCs - say, with a barrier at 39 percent - could be issued with a coupon of 1 to 2 percent depending on the issuer's credit worthiness and risk appetite for a maturity of one to two years. S&P500, Eurostoxx 50, SMI, NIKKEI 225, and other broadly diversified stock indices were used in combination as underlying values for the BRCs. The low fixed coupon of  $1^{\sim}2$  percent takes into account that the product is considered as a cash alternative with a zero percent, or even a negative, return. See last section for more details about BRC.

# 3.4.11.3 Japan: Abenomics

As expected, the Liberal Democratic Party of Japan gained a substantial parliamentary majority in the 2012 elections. The economic program introduced by the newly elected PM Shinzo Abe was built on three pillars: 1) fiscal stimulus, 2) monetary easing, and 3) structural reforms ('Abenomics'). Subsequently, the Yen (JPY) plunged versus its main trading currencies, providing a hefty stimulus to the Japanese export industry. The issuer of one product offered an outperformance structured product on the Nikkei 225 in quanto Australian dollars, meaning that the structured product in question is denominated in AUD and not in JPY, which would be the natural currency given the underlying Nikkei 225. This means that investors did not face JPY/AUD currency risk but if they were Swiss investors, who think in Swiss francs, they still faced AUD/CHF risk. The term 'quanto' means 'quantity adjusting option'.

Outperformance certificates enable investors to participate disproportionately in price advances in the underlying instrument if it trades higher than a specified threshold value. Below the threshold value the performance of the structured product is the same as the underlying value. How can investors invest in an index in such a way as to gain more when markets outperform a single market index investment, but still not lose more if the index drops? The issuer uses the anticipated dividends of the stocks in the index to

buy call options. These options lead to the leveraged position on the upside (see Figure 3.15).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/35b07a1d2c41aa74c197cc917b7315dcd17ca9e056578d49187b1743751eb398.jpg)  
Figure 3.15: Payoff of an outperformance structured product.

The reason for using quanto AUD is the higher AUD interest rates compared to JPY interest rates. Higher interest rates lead to higher participation and the participation in the quanto product was 130 percent. The risk of the investment lay in whether Abenomics would work as expected; and possibly FX AUD/CHF. The economic program in Japan worked out well and the redemption rate lay at 198 percent after two years. This redemption contains a loss of 16.35 percent due to the weakness of the Australian dollar against the Swiss franc.

# 3.4.12 Market Events

The focus here will be on the credit risk of structured products. Although the examples are presented under the heading of market events, the status of the market in the most recent GFC and in 2014/2015 was the result of a complicated catenation of business activities, policy interventions, and market participants' reactions. The discussion below shows that structured products with underlying 'credit risk' offer, under specific circumstances, valuable investment opportunities to some investors. But the number of such products issued is much smaller than the number of equity products. One reason for this is that not all issuers are equally experienced or satisfy the requirements for issuing credit-risky structured products (necessary FI trading desk, balance sheet, and risk capital constraints). Another reason is the lack of acceptance of such products among investors, regulators, portfolio managers, and relationship managers, all of whom often

do not have the same level of experience and know-how as they have regarding equity products.

# 3.4.12.1 Negative Credit Basis after the GFC

Negative credit basis is a measurement of the difference in the same risk in different markets. The basis measures the difference in credit risk - measuring once in the derivatives markets and once fixed in the bond markets. Theoretically, one would expect that the credit risk of ABB has the same value independent of whether an ABB bond or a credit derivative defined on ABB's credit risk is being considered. This is indeed true if markets are not under stress - at which point the credit basis is close to zero. But if liquidity is an issue, the basis becomes either negative or positive. In the most recent GFC, liquidity was a scarce resource. The basis became negative since investing in bonds required funding the notional while for credit derivatives only the option premium needs to be financed. For large corporates, the basis became strongly negative by up to  $-7$  percent. Table 3.19 shows how the positive basis in May 2003 changed to a negative one in November 2008.

<table><tr><td>Corporate</td><td>Credit basis in May 2003 (bps)</td><td>Credit basis in November 2008 (bps)</td></tr><tr><td>Merrill Lynch</td><td>47</td><td>-217</td></tr><tr><td>General Motors</td><td>-32</td><td>-504</td></tr><tr><td>IBM</td><td>22</td><td>-64</td></tr><tr><td>J.P. Morgan Chase</td><td>22</td><td>-150</td></tr></table>

Table 3.19: Credit basis for a sample of corporates in 2003 and their negative basis in the most recent GFC.

To invest in a negative basis product, the issuer of a structured product locks in the negative basis for an investor by forming a portfolio of bonds and credit derivatives of those firms with a negative basis. For each day on which the negative basis exists a cash flow follows, which defines the participation of the investor. When the negative basis vanishes, the product is terminated.

# Example

Investing in the negative credit basis of General Motors (see Table 3.19) leads to a return, on an annual basis, of 5.04 percent if the basis remains constant for one year. If the product has a leverage of 3, the gross return is 15.12 percent. To obtain the net return, one has to deduct the financing costs of the leverage.

Structured products with this idea in mind were offered in spring 2009 to qualified investors. The products offered an annual fixed coupon of around 12 percent and participation in the negative basis. The high coupons were possible as some issuers leveraged

investors' capital. This could only be offered by those few issuers in the most recent GFC that were cash rich; typically AAA-rated banks. The products paid one coupon and were then terminated after 14 months since the negative basis approached its normal value. The product value led to a performance of around 70 percent for a 14-month investment period. Was this formidable performance realized ex ante a free lunch - that is to say, a risk-less investment? No. If the financial system had fallen apart, investors would have lost all the invested capital. But the investors basically only needed to answer the following question: Will the financial system and real economy return to normality? If yes, the investment was reduced to the AAA issuer risk of the structured product.

Many lessons can be drawn from these products. A very turbulent time for markets can offer extraordinary investment opportunities. The valuation of these opportunities by investors must follow different patterns than in times of normal markets: There is for example no history and no extensive back-testing, and hence an impossibility of calculating any risk and return figures. But there is a lot of uncertainty. Making an investment decision when uncertainty is the main market characteristic is an entirely different proposition to doing so when markets are normal and the usual risk machinery can be used to support decision-making with a range of forward-looking risk and return figures. If uncertainty matters, investors who are cold-blooded, courageous, or gamblers, and analytically strong, will invest, while others will prefer to keep their money in a safe haven.

# 3.4.12.2 Positive Credit Basis 2014

The monetary interventions of the ECB and other central banks led to excess liquidity, which was mirrored in a positive basis for several large firms. Monetary policy also implied low or even negative interest rates. This made investment in newly issued bonds unattractive. To summarize, investors were searching for an alternative to their bond investments, but an alternative that was similar to a bond.

A credit linked note (CLN) is a structured product. Its payoff profile corresponds to a bond's payoff in many respects. A CLN pays - similarly to a bond - a regular coupon. The size of the coupon and the amount of the nominal value repaid at maturity both depend on the credit worthiness of a third party, the so-called reference entity (the issuer of the comparable bond). This is also similar to the situation for bonds. But the size of the CLN coupon derives from credit derivative markets. Hence, if the credit basis is positive, a larger CLN coupon follows, as compared to the bond coupon of the same reference entity. CLNs are typically more liquid than their corresponding bonds since credit derivative markets are liquid while many bonds, even from large corporates, often suffer from illiquidity. CLNs are flexible in their design of interest payments, maturities, and currencies. CLNs also possess, compared to bonds, tax advantages; in fact, the return after tax for bonds that were bought at a price above 100 percent is in this negative interest rate environment often negative. The investor in a CLN faces two sources of credit risk: the reference entity risk as for bonds, and the issuer risk of the structured product.

As an example, Glencore issued a new 1.25 percent bond with a coupon in Swiss francs. Due to the positive basis, the coupon of the CLN was 1.70 percent. Another product with, as the reference entity, Arcelor Mittal in EUR implied a higher CLN effective yield compared to the bond of 1.02 percent in EUR.

Let us consider a more detailed example. Consider the reference entity Citigroup Inc. The bond in CHF matures in April 2021 and its price is 102.5 with a coupon of 2.75 percent. The bond spread is 57 bps, which leads to a yield to maturity of  $-0.18$  percent - an investor should sell the bond. The CLN has a spread of 75 bps, which proves the positive basis and an issuance price of 100. The coupon of the CLN is - then  $-0.71$  percent, which leads to a yield to maturity of 0.57 percent if funding is subtracted. Therefore, selling the bond and buying the CLN generates an additional return of 75 bps.

# 3.5 Collateral

# 3.5.1 Prime Finance

Prime Finance is an important trading activity which is frequently used by asset management firms. Prime Finance has different aspects:

- Lending and borrowing of securities, the Securities and Lending Business (SLB).  
- Repos, i.e. sale and repurchase agreements.  
- Synthetic finance such as synthetic SLB or synthetic Repo. These transactions combine a SLB with a derivative where the underlying is the security of the SLB transaction.

The general motivation for repos is the borrowing or lending of cash. In securities lending, the purpose is to temporarily obtain the security for other purposes, such as covering short positions or for use in complex financial structures. Securities are generally lent out for a fee. Securities lending trades are governed by different types of legal agreements than repos.

Prime finance business changed heavily after the GFC and is still transforming. Several rationales motivate prime finance activities and its transformation. A first rationale is collateralized banking. Repo business can be considered as secured banking were collateral serves as a creditor protector for non-retail investors. Creditors are bank, insurance companies, governments, firms, AM or pension funds. Markets which are widely collateralized are for example fixed income repo, equity finance, exchange traded securities, OTC derivatives, securities lending, banks loans, asset backed securities. An important property of collateral is its eligibility, i.e. the extend how collateral can be converted into an economic value if the counter party defaults. Liquidity, quality in terms of embedded credit risk and the possibility to settle the collateral define the collateral eligibility. Cash is the most used collateral followed by government bonds, large-cap shares.

For traders, repos are used to finance long positions, obtain access to cheaper funding costs of other speculative investments, and cover short positions in securities. A second rationale is cost reduction in the custody of securities where lending and borrowing securities generates earnings which lower these costs. Third, to cover short positions one has to borrow securities. Short positions can be the results of market making, the hedging of derivative positions or part of an investment strategy. Finally, regulatory requirements lead to lower risk weighted assets in the regulatory capital charge if one switches from unsecured to secured transactions.

# 3.5.2 Repo Transaction

A repo, a bilateral contract between a buyer and a seller, allows a borrower to use a financial security as collateral for a cash loan at a fixed rate of interest. The borrower agrees to sell immediately at 0 a security to a lender and also agrees to buy the same security from the lender at a fixed price at some later date 1. A repo is equivalent to a cash transaction combined with a forward contract. The difference between the forward price and the spot price is the interest on the loan while the settlement date of the forward contract is the maturity date of the loan. A repo can be cash or security driven. It is security driven if the investor wishes to lend a security. Repos can be described as follow:

- At 0: Assignment of the securities from the seller to the buyer.  
- At 1: Redemption of the loan and interest rate payments to the buyer and reassignment of the security from the buyer to the seller.

The purchase price in 0 equals the market value (dirty price) of the underlying security minus an add on (Haircut). The haircut provides a restricted protection against falling security prices. The payback price equals the purchase price plus an agreed interest payment (repo rate), which depends upon the quality of the security. If the security losses value, a margin call follows. Using a repo the Buyer obtains favourable rates compared to an unsecured loan and the Seller receives collateral.

Almost any security may be employed in a repo. But highly liquid securities are preferred because they can be easily secured in the open market where the buyer has created a short position in the repo security through a reverse repo and market sale. Treasury, Government bills, corporate and Treasury/Government bonds, and stocks may all be used as a collateral in a repo transaction. Coupons which are paid while the repo buyer owns the securities are passed to the repo seller although the ownership of the collateral rests with the buyer during the repo agreement. There are three types of repo maturities: overnight, term (i.e. with a specified date), and open repo.

The most important forms of a repo transactions are specified delivery and tri-party. The first form requires the delivery of a prespecified bond at the onset, and at maturity of the contractual period. Tri-party essentially is a basket form of transaction, and allows

for a wider range of instruments in the basket or pool. The tri-party agent, acts as an intermediary between the two parties to the repo. The tri-party agent is responsible for the administration of the transaction, marking to market, and substitution of collateral. The largest one being Clearstream and JP Morgan Chase.

A reverse repo is the same repurchase agreement from the buyer's viewpoint, not the seller's. The term reverse repo is used to describe a short position in a debt instrument where the buyer in the repo transaction immediately sells the security provided by the seller on the open market.

# Example:

While investors trade bonds on a stand alone basis, trading desks use repo jointly with bond trading. Buying a bond is completed immediately by selling the bond in a repo, i.e. one finances the bond. We consider an US Treasury Bond with the following dates:

- $T$  trading day to buy the bond.  
- $T_{1} = T + 1$  settlement day for the bond. Start/opening the repo.  
- $T_{2} = T + 2$ . Closing of the 1-day repo.

At  $T$  the trader buys the bond for the price  $B(T)$  from a counter party  $A$ . At  $T + 1$  the repo transaction starts to finance the bond. To achieve this

- the repo desk delivers the bond for 1 day, i.e. the period of the repo transaction is overnight from  $T_{1}$  to  $T_{2}$  for a price  $B(T_{1}^{\mathrm{Repo}})$ , to the repo counter party and  
- the repo desk agrees to buy the bond back at  $T_{2}$  for the price

$$
B (T _ {1} ^ {\mathrm {R e p o}}) (1 + r / 3 6 0)
$$

with  $r$  the repo rate.

The prices  $B(T)$  and  $B(T_1^{\mathrm{Repo}})$  can differ at  $T_1$ . The difference is a residual cash position with a cash rate  $r_{\mathrm{cash}}$ . This rate is in general different from the repo rate. At  $T_2$  the repo desk pays  $B(T_1^{\mathrm{Repo}})(1 + r / 360)$  to the counter party, receives the bond back and delivers the bond for the price  $B(T_1)$  to the buyer. The P& L of this transactions over 1 day reads:

$$
\begin{array}{l} \mathrm {P} \& \mathrm {L} = P \left(T _ {1}\right) - B (T) \quad \text {P r i c e C h a n g e B o n d} \tag {3.74} \\ - \quad B \left(T _ {1} ^ {\text {R e p o}}\right) r / 3 6 0 \quad \text {R e p o C o s t s} \\ + \left(B \left(T _ {1} ^ {\text {R e p o}}\right) - B (T)\right) r _ {\text {C a s h}} / 3 6 0 \quad \text {D i f f e r e n c e R e p o v s . C a s h M a r k e t}. \\ \end{array}
$$

Using the data notional 100 Mio. USD, coupon 4 percent,  $T$  is Oct 2 for trading the bond, settlement Oct 3 from the clean Price of the bond 100'078'125 USD (= 100 - 02+ in US Treasury notation) with accrued interest the settlement price 100'110'911 USD

follows where the accrued interest rate is  $\frac{3}{183} \times 0.04 / 2$ : The bond accrues interest since Sept 30 and a half a year has 183 days. The repo rate  $r$  equals 3.4 percent, the cash rate is 3.5 percent. Since the bond settles Oct 3, the repo desk finances the bond. The bond price changes from Oct 2 to Oct 3 by (100-05). Therefore, the value of the position in dirty prices increased to

$$
1 0 0 ^ {\prime} 1 8 9 ^ {\prime} 0 3 6 = (1 + 5 / 3 2 + \frac {3}{1 8 3} \times 0. 0 4 / 2) \times 1 0 0 \mathrm {M i o . U S D}.
$$

At Oct 3 the following payments/transactions are made:

- Bonds are received with value USD  $100'110'911$  and exchanged for a secured loan of USD  $100'189'036$  with the repo counter party.  
- They deliver cash payments of  $78^{\prime}125$  USD.

At Oct 4 the following payments/transactions are made:

- The repo counter party hands back the lent bond and obtains the repo rate interest:

$$
1 0 0 ^ {\prime} 1 9 8 ^ {\prime} 4 9 9 = 1 0 0 ^ {\prime} 1 8 9 ^ {\prime} 0 3 6 \times (1 + 0. 0 3 4 / 3 6 0).
$$

- The bond is sold from the repo desk to the buyer. The price equals the clean price of Oct 3 with Oct 4 settlement plus accrued interest. If the bond increased to 100-08, we have

$$
1 0 0 ^ {\prime} 2 9 3 ^ {\prime} 7 1 5 = (1 + 8 / 3 2 + \frac {4}{1 8 3} \times 0. 0 4 / 2) \times 1 0 0 \mathrm {M i o . U S D}.
$$

The P&L components are:

- Change in bond price:  $100'293'715 - 100'110'911 = +182'803$  USD.  
- Repo costs:  $-100'189'036 \times \frac{0.034}{360} = -9462$  USD.  
- Difference Repo vs. Cash Market:  $78'125 \times \frac{0.035}{360} = +7.7$  USD.

A 1-day P&L of 173'349 USD follows.

Contrary to the SLB business, repo is always of the type cash against security. Both transaction types face the same market risk but settlement risk can be different.

Eurex, one of the world wide largest exchange for futures and option trading, also offers platforms for bond trading and for repo (Eurex Repo). The platform is open to all financial institutions. The Eurex Repo platform is a TriParty platform with integrated trading and settlement functionalities. This means that a third party to the Buyer and Seller is responsible for administration and operations. The largest providers TriParty Repo programs are Clearstream and JP Morgan Chase. The Eurex platform integrates

trading, settlement and legal documentation. Participants at Eurex Repo can choose from a broad menu of repo transactions. An advantage of the Eurex Repo platform is that the securities which are received as collateral can be used immediately for a new repo transaction. This allows banks to raise cash if they need to do so. The Eurex market consists of four links for the participants in CHF repos:

- Trading is via the Eurex Repo platform.  
- Clearing, Settlement and Collateral Management takes place at SIX SIS.  
- Cash Clearing is done via SIX Interbank Clearing.  
- There is a link to SNB which publishes the SNB-eligible securities.

As an example, consider a bond trader (Seller) which wishes to borrow CHF 20 Mio. to finance for one week an investment of CHF 18 Mio. Swiss Government Bonds with 3 percent coupon. A repo buyer offers a repo rate of 2 percent. The seller accepts the rate. He delivers CHF 18 Mio. nominal against CHF 20 Mio. cash. At the same day he pays the buyer CHF 20 Mio. in exchange of the CHF 18 Mio. bonds. After one week the buyer gives back the bond to the seller. The seller pays back the loan plus accrued interest:

$$
2 0 ^ {\prime} 0 0 0 ^ {\prime} 0 0 0 \times \frac {0 . 0 2 \times 7}{3 6 0} = 7 ^ {\prime} 7 7 7. 8 \mathrm {C H F}.
$$

# 3.6 The Efficient Market Hypothesis (EMH)

The TAA raises the question of whether asset prices are predictable. Predictability is part of the broader Efficient Market Hypothesis (EMH) concept.

Malkiel (2003): *Revolutions often spawn counter-revolutions and the efficient market hypothesis [EMH] in finance is no exception.* The intellectual dominance of the efficient-market revolution has more been challenged by economists who stress psychological and behavioural elements of stock-price determination and by econometricians who argue that stock returns are, to a considerable extent, predictable.

Lo (2007): The efficient market[s] hypothesis (EMH) maintains that market prices fully reflect all available information. […] It is disarmingly simple to state, has far-reaching consequences …, and yet is surprisingly resilient to empirical proof or refutation. Even after several decades of research and literally thousands of published studies, economists have not yet reached a consensus about whether markets - particularly financial markets - are, in fact, efficient.

Asness and Liew (2015): The concept of market efficiency has been confused with everything from the reason that you should hold stocks for the long run to predictions that stock returns should be normally distributed to even simply a belief in free enterprise.

Shiller (2014): [If markets are efficient] there is never a good time or bad time to enter the market […]

We start with the EMH definition.19

Definition 48. A financial market is efficient when market prices reflect all available information about value.

All available information includes past prices, public information, and private information. These different information sets  $\mathcal{F}_t$  lead to different EMHs (see below). The statement 'reflecting all available information' is not defined. If a company announces to expect twice as much earnings, do stock prices double, triple, or fall? Reflect all available information means in the sense of Jensen that trading based on the information set does not lead to an economic profit. An asset pricing model is needed to make precise what reflecting all information means in the EMH. Efficiency testing means to test whether the properties of expected returns implied by the model of market equilibrium are observed in actual returns. This is referred to as the joint hypothesis problem (Fame [1970]):

- Pillar 1: Do prices reflect all available information - that is, are market efficient? Prices can only change if new information arrives. The information content.  
- Pillar 2: Developing and testing asset pricing models. The price formation mechanism (Asset Pricing Model).

See Section ?? for a discussion of information sets and their evolution over time.

Returning to the EMH, let  $R_{t + 1}$  be an asset's return,  $\mathcal{F}_M$  the assumed information used in the market to set the equilibrium price of the asset and  $\mathcal{F}$  the real information used to form asset prices. Market efficiency means that the expected returns at  $t + 1$  given the two information sets at time  $t$  are the same (we assume that rational expectations are formed)

$$
E \left(R _ {t + 1} \mid \mathcal {F} _ {M, t}\right) = E \left(R _ {t + 1} \mid \mathcal {F} _ {t}\right). \tag {3.75}
$$

The standard asset pricing equilibrium model of the 1960s assumed that the equilibrium expected returns are constant:  $E(R_{t + 1}|\mathcal{F}_{M,t}) =$  constant. If the EMH (3.75) holds, then

$$
E \left(R _ {t + 1} \mid \mathcal {F} _ {t}\right) = \mathrm {c o n s t a n t}
$$

follows. To test the EMH, the regression of the future  $R_{t + 1}$  returns on the known information  $\mathcal{F}_t$  should have a zero slope. If this is not the case, the market equilibrium model could be wrong or the definition of  $\mathcal{F}_{M,t}$  overlook information in price setting,  $\mathcal{F}_{M,t}$  and  $\mathcal{F}_t$  are not equal, or both channels could be flawed.

# Remarks

- The EMH does not hold if there are market frictions (trading costs, cost of obtaining information). In the US, reliable information about firms can be obtained relatively cheaply and trading securities is cheap too. For these reasons, US security markets are thought to be relatively efficient.  
- Grossman and Stiglitz (1980) show that perfect market efficiency is internally inconsistent.  
- The EMH does not assume rationality of investors. But to operationalize the EMH one often assumes rationality. Fama proposes the following form:

$$
E \left[ R _ {t + 1} - E \left[ R _ {t + 1} \mid \mathcal {F} _ {t} \right] \mid \mathcal {F} _ {t} \right] = 0. \tag {3.76}
$$

Given the information set there is on average no systematic deviation of future returns and its expectations. In this sense prices reflect all available information. Clearly, investors are assumed to be rational under this assumption. The EMH does not assume that all investors have to be informed, skilled, and able to constantly analyze the information flow. One can prove that market efficiency is possible even if a small number of market participants are informed and skilled.

- The EMH is applicable to all asset classes. If the EMH holds true, then prices react quickly to the disclosure of information.

Why is the EMH important for AM? Fama's work on market efficiency (1965, 1970) triggered passive investing with the first index launched 1971. In efficient markets buying and selling securities is a game of chance rather than one of skill. Active management is a zero-sum game. If the EMH holds, the variation of the performance of the active managers around the average is driven by luck alone. Many studies found little or no correlation between strong performers in one period and those in the next one, see Figure 3.16.

Suppose that one is able to pick in advance those managers who outperform others. As per the EMH, investors would give them all their money; no-one would select those managers doomed to underperform. But who will be on the other side of the outperformer's trades? This process would be self-defeating.

The same conclusion also holds for technical analysis, the study of past stock prices to predict future prices, and fundamental analysis, the analysis of financial company information to select undervalued stocks. If the EMH holds, both approaches are useless in predicting asset prices. The value of financial analysts is not in predicting asset values but to analyse incoming information fast such that the information is rapidly reflected in the asset prices. In this sense analysts support the EMH. Fama (1970) defines three different forms of market efficiency, this means different sets  $\mathcal{F}$ . In the weak-form EMH,  $\mathcal{F}$  is all available price information at a given date. Hence, future returns cannot be predicted from past returns or any other market-based indicator. This precludes technical analysis from being profitable. In the semi-strong EMH,  $\mathcal{F}$  is all available

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2659a451e656028e428fef1702e2280c970ee3fd51a2b816c43a5f3d963351a9.jpg)  
Figure 3.16: Performance ranking of the top 20 equity funds in the US in the 1970s and in the following decade. The average annual rate of return was 19 percent compared to 10.4 percent for all funds. In the following decade, the former 20 top funds had an average rate of return of 11.1 percent compared to 11.7 percent for all funds (Malkiel [2003]).

public information at a given date, i.e. financial reports, economic forecasts, company announcements, etc. matter. Technical and fundamental analyses are not profitable in this case. This the form of the EMH which is often subsumed in the literature. In the strong-form EMH,  $\mathcal{F}$  is all available public and private information at a given date. This extreme form serves mainly as a limiting case.

# Example

A well-known story tells of a finance professor and a student who come across a hundred dollar bill lying on the ground. As the student stops to pick it up, the professor says, 'Don't bother - if it were really a hundred dollar bill, it wouldn't be there.' This story illustrates well what financial economists usually mean when they say markets are efficient. But suppose that the student assumes that nobody so far tested whether the bill is indeed real but that all assumed that someone else checked the bill's validity. Then, there were no efforts made to generate the information needed to value the bill. But if

nobody faced the costs of generating that information then  $\mathcal{F}_t$  is the empty set. Then the EMH cannot hold. This shows that a reasonable assumption about human behavior can lead to a violation of the EMH.

# Example

A firm announces a new drug that could cure a virulent form of cancer. Figure 3.17 shows three possible reactions of the price paths. The solid path is the EMH path: prices jump to the new equilibrium value instantaneously and in an unbiased fashion. The dotted line represents a path where market participants overreact and the dashed one where they underreact. The dash-dotted line is a strong signal for insider trading, front running, or any other form of illegal trading.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/47f593cc15460efe3ed40642f2514dfee7e1f8de79e37f5036c202dc9b52299e.jpg)  
Figure 3.17: Possible price reactions as a function of the day relative to the announcement of a new drug.

# 3.6.1 Predictability

If the EMH holds, returns follow a random walk:

Definition 49. Let  $R_{t}$  be the return of an asset with the dynamics

$$
R _ {t} = R _ {t - 1} + m + \epsilon_ {t}, m \in \mathbb {R}, R _ {0} = r. \tag {3.77}
$$

If the sequence  $(\epsilon_t)$  is IID with mean zero, variance  $\sigma^2$  and zero covariance  $\operatorname{cov}(\epsilon_t, \epsilon_{t-1}) = 0$ , then  $R_t$  is a random walk with drift  $m$ .

Setting  $m = r = 0$ , then  $E[R_{t}] = 0$  and  $\mathrm{var}(R_t) = t\sigma^2$ . If we take the standard deviation as risk measure, then risk grows with the square-root of time. Assuming simple returns given by  $R_{t} = \frac{S_{t} - S_{t - 1}}{S_{t - 1}}$ , the random walk equation implies

$$
\frac {S _ {t + 1} - S _ {t}}{S _ {t}} = \frac {S _ {t} - S _ {t - 1}}{S _ {t - 1}} + \epsilon_ {t}
$$

and after some algebra

$$
S _ {t} = S _ {0} \prod_ {s = 1} ^ {t} \left(\frac {S _ {1}}{S _ {0}} + \sum_ {k = 1} ^ {s} \epsilon_ {k}\right).
$$

While in a random walk returns are a zero sum game, prices are by no means driftless.

A return  $R_{t+1}$  is predictable by the information set  $\mathcal{F}_t$  if the return is measurable w.r.t. to  $\mathcal{F}_t$ , i.e., 'the random variable is known and hence not random'.<sup>20</sup> In particular,

$$
E \left[ R _ {t + 1} \mid \mathcal {F} _ {t} \right] = R _ {t + 1}, \forall t, \tag {3.78}
$$

since conditioning on the information set  $\mathcal{F}_t$  has no value. When returns are not predictable, prices follow a martingale:

Definition 50. Assume

$$
E ^ {Q} \left[ S _ {t + 1} \mid \mathcal {F} _ {t} \right] = S _ {t}, \forall t, \tag {3.79}
$$

with the expectation is under a probability measure  $Q$ . Then  $S_{t}$  is a  $\mathcal{F}_t$ - $Q$ -martingale.

If  $S$  is a martingale, using the tower property of conditional expectation

$$
E ^ {Q} \left[ S _ {t + 1} \mid \mathcal {F} _ {t} \right] = E ^ {Q} \left[ S _ {t} \right], \forall t. \tag {3.80}
$$

Hence, the expected price of a non-predictable process is constant. The price process has no drift, else the average value would not be constant. But the price itself can vary. If returns are martingales, then the operational form of the EMH (3.76) holds true.

The return  $R_{t+}$  in period  $t$  to  $t + 1$  of a stock is equal to the capital gain plus a dividend yield  $D$ , i.e.

$$
R _ {t + 1} = \frac {S _ {t + 1} - S _ {t}}{S _ {t}} + \frac {D _ {t + 1}}{S _ {t}}. \tag {3.81}
$$

Rewriting this equation  $S_{t} = \frac{1}{1 + R_{t + 1}} (S_{t + 1} + D_{t + 1})$ . Solving this linear difference equation implies for  $k$  periods

$$
S _ {t} = \sum_ {j = 1} ^ {k} \left(\prod_ {m = 1} ^ {j} \frac {1}{1 + R _ {t + m}}\right) D _ {t + j} + \left(\prod_ {m = 1} ^ {k} \frac {1}{1 + R _ {t + m}}\right) S _ {t + k}. \tag {3.82}
$$

It is common to assume that asset price grows at a lower rate than the return - the second term has tend to zero for  $k \to \infty$ . We get:

Theorem 51. If the asset prices growth is lower than the asset returns, the price  $S_{t}$  is equal to the discounted future dividends, i.e.

$$
S _ {t} = \sum_ {j = 1} ^ {\infty} \left(\prod_ {m = 1} ^ {j} \frac {1}{1 + R _ {t + m}}\right) D _ {t + j}. (3. 8 3)
$$

Since there is no randomness, the future dividends are known. We extend this formula by adding risk and considering the EMH. Consider the operational form of the EMH (3.76) and take conditional expectations in (3.81):

$$
S _ {t} = \frac {E [ S _ {t + 1} | \mathcal {F} _ {t} ] + E [ D _ {t + 1} | \mathcal {F} _ {t} ]}{1 + E [ R _ {t + 1} | \mathcal {F} _ {t} ]}.
$$

This shows that an asset pricing model to evaluate  $E[S_{t + 1}|\mathcal{F}_t]$  is needed to calculate today's prices. If prices are a martingale, the last equation becomes

$$
S _ {t} = \frac {E [ D _ {t + 1} | \mathcal {F} _ {t} ]}{E [ R _ {t + 1} | \mathcal {F} _ {t} ]}.
$$

Hence, capital gains do not matter for asset pricing. If dividends are martingales and returns are random walks, then the famous pricing formula follows where asset prices are equal to the ratio of the constant expected dividend and expected return, see the next example.

Example constant dividends and returns

If expected dividends and returns are constant, the above valuation equation reads

$$
S _ {t} = \frac {D}{R} = \mathrm {c o n s t a n t}. (3. 8 4)
$$

But empirical evidence shows that expected returns and dividends are both not constant over time. Therefore, (3.84) is too naive. It implies that the volatilities of the growth rates are the same:

$$
\mathrm {v o l a t i l i t y} \left(\frac {d R _ {t}}{R _ {t}}\right) = \mathrm {v o l a t i l i t y} \left(\frac {d D _ {t}}{D _ {t}}\right).
$$

But the return volatility is around  $16\%$  while the dividend volatility is only about  $7\%$ . Therefore something else must be time varying. Furthermore, the return volatility is time varying. Monthly market return volatility fluctuated between values of  $20\%$  and more in market stress periods (Great Depression, Great Financial Crisis) and  $2\%$  in the 60s and mid-90s of last century, see next section.

Since the pricing formula has the same structure with and without risk, the formula of last theorem carries over to the case with risk providing the ex-ante version:

Theorem 52. If the expected asset prices growth is lower than the expected asset returns, the price  $S_{t}$  is equal to the discounted future dividends, i.e.

$$
S _ {t} = \sum_ {j = 1} ^ {\infty} \left(\prod_ {m = 1} ^ {j} \frac {1}{1 + E \left[ R _ {t + m} \mid \mathcal {F} _ {t} \right]}\right) E \left[ D _ {t + j} \mathcal {F} _ {t} \right]. \tag {3.85}
$$

Formula (3.85) is a fundamental asset pricing equation. The formula is highly non-linear which makes it challenging to test it empirically. Straightforward approximations, Taylor series, are used to linearize the formula. A second manipulation is to write the price of an asset today as the expected value of changes in dividends and returns. One shifts the pricing equation one step ahead and subtracts it from the non-shifted expression, see below.

Example Skill and luck, martingales

We show that a little amount of skill makes a huge difference for wealth growth in a gamble - the same observation is true if one considers skills in active asset management. Consider an investor with initial capital  $W_{0}$  playing a the following dice game: She invests in each period 1 unit of her capital. The outcome of the strategy in each period is of  $+1$  with probability  $p$  or  $-1$  with probability  $q = 1 - p$ . She does not change her strategy over time. The outcome in each period is an IID sequence  $(X_{k})$  of random variables. Her wealth after  $n$  periods reads

$$
W _ {n} = W _ {0} + \sum_ {k = 1} ^ {n} X _ {k}.
$$

What is the probability that she attains a final wealth level  $W_f > W_0$ ? To derive the wealth dynamics equation the first step is to define disjoint sets of events which allow to calculate probabilities. We set

$$
A _ {W _ {0}, n} = \left\{W _ {0} + \sum_ {k = 1} ^ {n} X _ {k} = W _ {f}, 0 <   W _ {0} + \sum_ {k = 1} ^ {m} X _ {k} <   W _ {f}, m <   n \right\}
$$

for the set where she reaches the desired wealth level for the first time after  $n$  plays without being bankrupt before. Since  $(X_{k})$  are IID, the sets  $(A_{W_0,n})_n$  are independent. Therefore the probability  $\tilde{p}(W_0,W_f)$  that the investor reaches the desired wealth level  $W_{f}$  sometime is given by

$$
\tilde {p} (W _ {0}, W _ {f}) = P \left(\bigcup_ {n = 1} ^ {\infty} A _ {W _ {0}, n}\right) = \sum_ {n = 1} ^ {\infty} P (A _ {W _ {0}, n}).
$$

The following dynamics

$$
\tilde {p} \left(W _ {0}, W _ {f}\right) = q \tilde {p} \left(W _ {0} + 1, W _ {f}\right) + p \tilde {p} \left(W _ {0} - 1, W _ {f}\right) \tag {3.86}
$$

captures game logic. This is a first order difference equation. A solution is found by inserting the guess

$$
\tilde {p} \left(W _ {0}, W _ {f}\right) = A + B r ^ {W _ {0}}, r = q / p \tag {3.87}
$$

if  $q \neq p$  with  $A, B$  two constants.  $A, B$  are determined by the two conditions  $\tilde{p}(0, W_f) = 0, \tilde{p}(W_f, W_f) = 1$ . We get for  $W_f > W_0$ :

$$
\tilde {p} \left(W _ {0}, W _ {f}\right) = \left\{ \begin{array}{l l} \frac {r ^ {W _ {0} - 1}}{r ^ {W _ {f} - 1}}, & \text {i f} p \neq q; \\ \frac {W _ {0}}{W _ {f}}, & \text {i f} p = q. \end{array} \right. \tag {3.88}
$$

If the game is fair (a martingale), then the probability to reach a 50 percent higher wealth level than the starting value of 100 units is  $66\%$ . If the investor's strategy has a small skill component such that  $q = 0.49$  and  $p = 0.51$ , then the probability to reach the desired level is  $98\%$ .

Predictability from a forecast point of view uses linear regressions of returns  $R$  on a variable  $x_{t}$  of the form

$$
R _ {t + 1} = a + b x _ {t} + \epsilon_ {t + 1} \tag {3.89}
$$

with  $a, b$  constants,  $\epsilon_{t+1}$  a sequence of IID normal random variables with mean 0 and variance  $\sigma^2$ . The variable  $x_t$  can be the return itself or a market price variable such as price-dividend ratios. The regression (3.89) becomes a random walk if  $b = 0$  or if  $a = 0$ ,  $b = 1$  and  $x_t = R_t$ . For the latter choice, the random walk regression

$$
R _ {t + 1} = R _ {t} + \epsilon_ {t + 1} \tag {3.90}
$$

implies

$$
R _ {t + 1} = R _ {0} + \sum_ {j = 1} ^ {t + 1} \epsilon_ {j}, E _ {t} (R _ {t + 1}) = R _ {0}, \sigma^ {2} (R _ {t}) = t \sigma^ {2}.
$$

This shows that  $R$  is martingale and that the variance increases over time.  $R_0 = 0$  is a reasonable assumption for short term returns and it implies that discounted price processes are martingales too. Therefore, discounted prices are martingales if the returns are martingales with expected zero return.

# 3.6.2 Testing Predictability

Cochrane (2013) tests for lag returns predictability by considering

$$
R _ {t + 1} = a + b R _ {t} + \epsilon_ {t + 1} \tag {3.91}
$$

<table><tr><td>Object</td><td>b</td><td>t(b)</td><td>R2</td><td>E(R)</td><td>σ(Et(Rt+1))</td></tr><tr><td>Stock</td><td>0.04</td><td>0.33</td><td>0.002</td><td>11.4</td><td>0.77</td></tr><tr><td>T bill</td><td>0.91</td><td>19.5</td><td>0.83</td><td>4.1</td><td>3.12</td></tr><tr><td>T bill excess</td><td>0.04</td><td>0.39</td><td>0.00</td><td>7.25</td><td>0.91</td></tr></table>

Table 3.20: Regression of returns on lagged returns annual data 1927-2008.  $t(b)$  is the t-statistic value and  $\sigma(E_t(R_{t+1}))$  represents the standard deviation of the fitted value  $bR_t$  (Cochrane [2013]).

for US stocks and T bills using annual data, see Table 3.20.

The result shows that stocks are almost not predictable while T bill returns are. A value of  $b = 0.04$  for stock means that a if returns increase by  $10\%$  this year the expectation is that they will increase by  $0.4\%$  next year. Also the  $R^2$  is tiny and the t-statistic is below its standard threshold value of 2. For the T bill returns the story is different - high interest rates last year imply that the rates this year will again be high with a high probability. Can this foreseeability of T bills be exploited by a trader? Suppose first that stocks would be highly predictable. Then one could borrow today and invest in the stock market. But this logic does not work for T bills since borrowing would mean to pay the same high rate than one receives. To exploit T bill predictability the investor has to change his behavior - save more and consume less today which is totally different from the stock case. This is a main reason why one considers excess returns  $R_e$  - return on stocks minus return on bonds - in forecasting with  $R_b$  the benchmark return:

$$
R _ {e, t} = R _ {s, t} - R _ {b, t}. \tag {3.92}
$$

By analysing the excess return one separates the different motivations 'to consume less and to save' from the willingness to bear risk. Table 3.20 shows that considering excess return we are back for T bills in the almost non-predictable stock case. Lo and MacKinlay (1999) find that short-run serial correlations are not zero and that the existence of 'too many' successive moves in the same direction enables them to reject the hypothesis that stock prices behave as random walks. There is some momentum in short-run stock prices. Even if the stock market is not a perfect random walk, its statistical and economic significance have to be distinguished. The statistical dependencies are very small and difficult to transform into excess returns. Considering transactions costs for example will annihilate the small advantage due to the momentum structure (see Lesmond et al. [2001]).

We consider longer time horizons and use market prices or yields to forecast returns following Cochrane (2005). Following the dividend/price  $(\mathrm{D} / \mathrm{P})$  issue of last section, we consider the return-forecasting regressions of Cochrane (2013) in Table 3.21. The regression equation reads

$$
R _ {t \rightarrow t + k} ^ {e} = a + b \frac {D _ {t}}{S _ {t}} + \epsilon_ {t + k} \tag {3.93}
$$

with  $R^{e}$  the excess return defined as  $\mathrm{CRSP}^{22}$  value-weighted return less the three-month Treasury bill return. The return-forecasting coefficient estimate  $b$  is large and it grows for

<table><tr><td>Horizon</td><td>b</td><td>t(b)</td><td>R2</td><td>σ(Et(Rte+1))</td><td>σ(Et(Rte+1)/E(Rte+1))</td></tr><tr><td>1 year</td><td>3.8</td><td>(2.6)</td><td>0.09</td><td>5.46</td><td>0.76</td></tr><tr><td>5 years</td><td>20.6</td><td>(3.4)</td><td>0.28</td><td>29.3</td><td>0.62</td></tr></table>

Table 3.21: Return-forecasting regressions, 1947-2009, annual data.  $t(b)$  is the  $t$ -statistic value and  $\sigma(E_t(R_{t+1}))$  represents the standard deviation of the fitted value  $b\frac{D_t}{S_t}$ ,  $\sigma(E_t(R_{t+1}^e)) = \sigma(b\frac{D_t}{S_t})$  (Cochrane [2013]).

longer time horizon. Hence, high dividend yields  $D / S$  (low prices) mean high subsequent returns and vice versa. The  $R^2$  of 0.28 is large when we compare it with an  $R^2$  of predicting stock returns on say a weakly basis which are seen to be not predictable. Therefore, excess returns are predictable by D/P ratios. Fama and French (1988) document that 25 to 40 percent of the variation in long-holding-period returns can be predicted in terms of a negative correlation with past returns. Behaviorists Behaviorists attribute this 'forecastability' to stock market price 'overreaction' which is due to investors facing periods of optimism and pessimism which cause the deviations from the fundamental asset values (DeBondt and Thaler (1995)).

The above tests are not stable. First, the point estimate of the return forecasting coefficients and its associated  $t$ -statistic vary significantly if different sample periods are considered. Second, the definition used for 'dividends' impacts the results.

If we take conditional expectations in equation (3.93),

$$
E _ {t} \left(R _ {t + 1} ^ {e}\right) = a + b \frac {D _ {t}}{S _ {t}}. \tag {3.94}
$$

Since dividend/price ratio varies over time between 1 and 7, return predictability is the same as to say that expected returns vary over time. Using  $b = 3.8$  and a variation of D/P by 6 percentage points, turns into a long-term variation of expected returns of  $3.8 \times 6 = 22.8$  percentage points which is too high given that the long-term average expected return is 7 percentage points

When we analyze the regression of dividend growth,  $\frac{D_{t + k}}{D_t}$  replaces the return in (3.93), Cochrane (2013) states: Returns, which should not be predictable, are predictable [see Table 3.21]. Dividend growth, which should be predictable, is not predictable.

This contradicts the traditional view that expected returns are constant and that if prices fall then future dividends should also decline: Dividends have to be predictable since they have to approach the low price levels. The above observation states that

on average we observe a different pattern. To deepen the discussion, we consider the multi-period Fundamental Asset Pricing equation (3.85),

$$
S _ {t} = \sum_ {j = 1} ^ {\infty} E _ {t} \left(\prod_ {k = 1} ^ {j} \frac {1}{R _ {t + k}} D _ {t + k}\right). \tag {3.95}
$$

Using log-variables (lower case symbols) change products into sums and we get for one-period from (3.95):

$$
s _ {t} - d _ {t} = E _ {t} \left(\Delta d _ {t + 1}\right) - E _ {t} \left(r _ {t + 1}\right). \tag {3.96}
$$

This generalises to many periods with  $\rho$  the discount factor:

$$
s _ {t} - d _ {t} \sim \sum_ {j = 1} ^ {\infty} E _ {t} \left(\rho^ {j - 1} \left(\Delta d _ {t + j} - r _ {t + j}\right)\right). \tag {3.97}
$$

Rearranging, it follows that long-run return uncertainty comes from cash-flow uncertainty (changes in dividends and D/P ratios). The more persistent  $r$  and  $\Delta d$  are, the stronger is their effect on the D/P ratio since more terms in the summation matter. If dividend growth and returns are not predictable, their conditional expectations are constant over time, then the D/P ratio is constant which is not observed. This extension to many periods for the D/P ratio also holds for the variance equation (3.99) where the discounted summation enters in the return and dividend growth variables. As in the one-period model, the long-run return and long-run dividend growth regression coefficients must add to one. By regressing the long-term return and dividend growth Cochrane (2013)states:

Return forecasts - time-varying discount rates - explain virtually all the variance of market dividend yields, and dividend growth forecasts or bubbles - prices that keep rising forever - explain essentially none of the variance of price.

This changes the traditional view on the EMH. Traditionally, expected returns were assumed to be constant (asset pricing model) and stocks were martingales with zero drift (random walks). In this reasoning, low D/P ratios happens when people expect declines in dividend growth and variations in D/P are due to cash flow news entirely (dividend predictability). The above result states that the opposite is true. The variance of D/P is due to return news and not to cash flow ones.

Predictability is also related to the volatility of prices. Shiller states that if prices are expected discounted dividends then prices should vary less than their expected variables.

But prices vary wildly more than they should even if we knew future dividends perfectly. This is the excess volatility of stock returns pointed out by Shiller.

We claim that return predictability and excess volatility have the same cause. To obtain an equation for the variance we first write regressions of returns and dividend

growth on  $d_t - p_t$  with  $b_r, b_d$  the respective coefficients. Plugging the regressions into (3.96) we get:

$$
1 = b _ {r} - b _ {d}, 0 = \epsilon_ {t + 1, r} - \epsilon_ {t + 1, d} \tag {3.98}
$$

where the residuals enter the two regression. Therefore, the expected return can be higher if the expected dividend is higher or the initial price is lower. The only way the unexpected return can be higher is if the unexpected dividend is higher, since the initial price cannot be unexpected. Since a regression coefficient is covariance over variance,  $1 = b_r - b_d$  reads:

$$
\sigma^ {2} \left(p _ {t} - d _ {t}\right) = \operatorname {c o v} \left(p _ {t} - d _ {t}, \Delta d _ {t + 1}\right) - \operatorname {c o v} \left(p _ {t} - d _ {t}, r _ {t + 1}\right). \tag {3.99}
$$

This shows that D/P ratios can only vary if they forecast dividend growth or forecast returns in regressions. Since the difference between the two coefficients must be one (3.98), if one coefficient is small in the regression then the other one has to be large.

To capture any positive autocorrelation in price movement econometricians use often the Autoregressive Moving Average (ARMA) model of Box and Jenkins (1970)

$$
R _ {t} = \sum_ {k = 1} ^ {p} a _ {k} R _ {t - k} + \sum_ {k = 1} ^ {q} b _ {k} \epsilon_ {t - k} + \epsilon_ {t} + c
$$

where the IID error term are  $\epsilon_t \sim \mathcal{N}(0, \sigma^2)$ . The variance of the error terms is then often modelled using a Generalised Autoregressive Conditional Heteroskedasticity (GARCH) model by Bollerslev (1986). The literature documents patterns of persistence which vary for the asset classes and the markets under consideration. While such patterns are found on daily, weekly, monthly or even on an annual basis for stocks and bonds, the time periods are much shorter for FX markets which we consider below.

# 3.6.3 Cross-Sectional vs Time Series Predictability

The prediction of financial returns can be based on a cross-sectional and a time-series approach. Which approach is better suited for return prediction? Consider a momentum strategy where past winning stocks in a cross section enter in a long position and post losers define a short position. Net investment is zero, i.e. the long and short exposure equalize at inception of the strategy. In a time-series momentum strategy, investors are long stocks with past returns above zero and short the other ones. The exposure do not add up to a zero investment but investors are net long in a bullish market. Using NYSE quoted stocks between 1946 and 2013 and considering the past annual performance for the long/short selection for the next month a cross-sectional annual return of 5 percent compared to the time-series strategies return of 9.3 percent. This observation was reported by Moskowitz et al. (2012). They conclude that time series strategies fully explain and subsume cross-sectional strategies. We note that the findings hold for individual assets as well as for indices of stocks, currencies or commodities.

Evidently, the two strategies are not directly comparable - one being a net zero investment and the other one either net long or short. Furthermore the threshold levels, i.e. which asset enters as a long or short position, is arbitrary and possibly, there is a natural or optimal threshold such that the observed differences qualitatively change.

Goyal and Jegadeesh (2018) make the two strategies comparable by correcting the net long/short position. Since more stocks earned positive returns than negative returns during the sample period, time series' long positions are bigger than the short positions. The average long and short positions are  \$1.24 and\$ 0.76, respectively. Therefore, the time-series-constructed portfolio earned returns for simply being net long during a bullish period. The authors therefore add to the cross-sectional strategy a time-varying investment in the market equal to the dollar value of the difference between the long and short sides of the time series strategy each month. Doing this exercise, for NYSE quoted stocks, the adjusted cross-sectional strategies show an annual return of 9.4 percent; similar to the 9.3 percent found when using time-series strategies. Therefore, the literature claims that time-series return predictability methods dominate cross-sectional ones is erroneous.

# 3.6.4 EMH Extensions and Critique

The debate about the EMH raises questions which are not related how to proceed with the joint hypothesis testing problem but whether the EMH per se is a meaningful concept. Considering the definition of the EMH in its operationalized form, three objects matter in the EMH [Lo (2004)]: Prices, probabilities and preferences. By the martingale property, see equation (3.100), prices, probabilities and preferences enter decision making of investors in a form such that no profits are possible by trading on the available information since any profit is already captured in present prices.

Given the three parts prices, probabilities and preferences of the EMH and the stringent martingale property which combines them, two critical points are immediate: Behaviour and technology. It is from a behavioural perspective not convincing that these highly behavioural sensitive parts of the EMH are related with a single mathematical property where behavioural facets do not matter. Whether the investors are greedy or whether they fearing market crashes does not matter how they perceive the odds in price formation (probability) nor how they value the outcome of their decision. The adaptive EMH of Lo adapts the original EMH and makes it context-dependent and dynamic. The adaptive EMH becomes a statement dependent on the environment of the economy and the markets and the behavior of market participants.

Definition 53 (Lo (2004)). Prices reflect as much information as dictated by the combination of environmental conditions and the number and nature of species [types of agents] in the economy.

The behavior of the agents is considered to follow evolutionary principles. The dynamics of how market participants interact and therefore how the price dynamics of the

assets follows is driven by evolutionary principles which are better suited to describe the market dynamics than the equilibrium concept in the EMH.

Lo (2004) states the following implications of the adaptive EMH. The risk and reward relation is not stable over time since the population of agents and how they interact are time varying. Similarly, the institutional and regulatory set-ups are also not constant over time. A second implication is that temporary arbitrage opportunities are possible and therefore, the EMH-critique of Grossman and Stiglitz (1980) does not apply for the adaptive EMH. The possibility of temporary arbitrage possibilities also shapes the performance of active investment strategies which in the EMH are useless. As an example one considers the rolling monthly first-order autocorrelation coefficient of the S&P Composite Index returns from January 1871 to 2003. By the EMH, the coefficient should be zero. The empirical plot shows that first the coefficient is typically positive where there are periods of clustering values of the coefficient. Finally, innovation is the key to survival. The EMH states that certain levels of expected returns can be achieved simply by bearing a sufficient degree of risk. Since in the adaptive form the risk/reward relation is not constant it turns out that adaption to the changing market conditions is the main source for stabilizing the risk/return reward.

Technology is one environmental factor which is under permanent change. Consider the information set  $\mathcal{F}_t$  which is used in decision-making by the agents or investors. The amount of data which is processed today and which will make available in the future due to big data analytics is not comparable with information available in the past. The Medaillon fund, see below, is an example where technology leads to a comparative advantage in specifying the information set. More precisely, the fund is able to separate valuable information from noise by processing permanently the extremely larger number of signals from the markets, the news and other communication types.

The discussion so far considered non-specific individuals. The examples Warren Buffet and Renaissance Medallion Fund show that particular skills and expertise allow individuals to generate excess returns as if the markets were inefficient while for many other investors the same markets are efficient. Buffet and the Renaissance Medallion Fund use their skills to predict future returns in very different forms. Buffet's goal is to understand specific firm in detail on an idiosyncratic level and then to embed view firm specific investment view in a sector and macro context. The Medallion Fund is a quant fund founded by the mathematician Jim Simons. The Fund which was set-up 1998 for the employees of Renaissance generated in the period 1998 to 2016 an annual return of  $80\%$  with 1999 the only year with a loss of around 4 percent. The fund generated in this period more than USD 55 billion in profit which is more profitable by several billions of USD than the next best funds. Even more notably the invested AuM have been smaller than those of their competitors.

The fund has always been very secret about the methodology used. One knows that

Simons hired top scientists from the computer industry, notably from IBM, and Ph.D in mathematics or physics from the top universities. The model which they constructed is based one signal detection. This means that their powerful IT system is processing all types of signals which are generated in the world. By a signal not only simple ones such as realized price changes are considered but also signals from speeches and from documents are detected. The success of their model is given by their power to separate noise from valuable information and then to translate them into trades. The model itself is not a single strategy encoded by a quantitative model but many different strategies are integrated into one system.

# 3.7 Asset Pricing

The fundamental asset pricing equation of the last sections are variants of the more basic equation which is a result in general equilibrium asset pricing :

$$
E _ {t} \left(M _ {t, t + 1} S _ {t + 1}\right) := E \left(M _ {t, t + 1} S _ {t + 1} \mid \mathcal {F} _ {t}\right) = S _ {t}, \forall t, \tag {3.100}
$$

with  $M$  the stochastic discount factor (SDF) and  $M_{t,t} = 1$ . Therefore,  $MS$  is a martingale. There are different expressions for  $M$ . The exact nature of the SDF depends on the nature of the asset pricing model. Specifying the asset pricing model specifies  $M$  and its name - SDF in general equilibrium when intertemporal marginal rate of substitution describe  $M$  or equivalent martingale measure in derivative pricing models.

# 3.7.1 Equivalent Formulation of the Fundamental Asset Pricing Equation

There are several extensions, equivalent formulations or straightforward conclusions of last section's fundamental pricing equations which we consider next. First, the future price  $S_{t + 1}$  of equity can be the sum of dividends and price changes of the asset  $S$ . Therefore, the notion of a payoff  $X_{t + 1}$  is used:

$$
S _ {t} = E _ {t} \left(M _ {t + 1} X _ {t + 1}\right) \tag {3.101}
$$

Second, since  $S_{t}$  is known at time  $t$ , equation (3.100) reads in terms of gross return - payoff divided by price -

$$
E _ {t} \left(M _ {t, t + 1} R _ {t + 1} ^ {g}\right) = 1. \tag {3.102}
$$

With  $R = R^g - 1$  the return we get

$$
0 = E _ {t} \left(M _ {t + 1} R _ {t + 1}\right) = \langle M _ {t + 1}, R _ {t + 1} \rangle_ {t} \tag {3.103}
$$

i.e. the return and SDF are orthogonal. Note that also the excess return  $R^{e} = R - R_{f}$  with  $R_{f}$  the risk free return, is orthogonal to the SDF. Using

$$
E (M R) = E (M) E (R) + \operatorname {c o v} (M, R)
$$

# 3.7. ASSET PRICING

we get for any asset  $i$  the traditional expression:

$$
E _ {t} \left(R _ {t + 1, j}\right) = \frac {\operatorname {c o v} _ {t} \left(- M _ {t + 1} , R _ {t + 1 , 1}\right)}{E _ {t} \left(M _ {t + 1 , j}\right)}, \tag {3.104}
$$

i.e. the expected asset return is expressed with its covariance with the SDF. Using the correlation notation,  $0 = E_{t}(M_{t + 1}R_{t + 1}^{e})$  implies for asset  $j$ :

$$
0 = E (M) E \left(R _ {j} ^ {e}\right) + \rho_ {M j} \sigma (M) \sigma \left(R _ {j} ^ {e}\right).
$$

Since the correlation is bounded between  $-1$  and  $1$ , the Hansen-Jagannathan volatility bound follows:

$$
\frac {\sigma (M)}{E (M)} \geq \frac {| E \left(R _ {j} ^ {e}\right) |}{\sigma \left(R _ {j} ^ {e}\right)}. \tag {3.105}
$$

This equation restricts the set of discount factors that can price a given set of returns, as well as a restriction on the set of returns given a specific discount factor. If (!)  $M$  is given in a pure finance economy without consumption, then we show that  $E(M) = \frac{1}{R_f}$ . By (3.105) we need very volatile SDF with a mean near one to understand stock returns. For US stocks from Oct 1926 to Dec 2016, the Sharpe ratio is 0.41 and the real  $R_f$  is 1. Hence, the volatility of the SDF should be higher than 0.41.

Rewriting equation (5.1),

$$
S _ {t} = E _ {t} \left(M _ {t + 1}\right) E _ {t} \left(X _ {t + 1}\right) + \operatorname {c o v} _ {t} \left(M _ {t + 1}, X _ {t + 1}\right). \tag {3.106}
$$

Hence, asset prices are equal to a expected discounted cash flow plus a risk premium. Idiosyncratic risk is by definition the part that is not correlated with the SDF and hence does not generate any premium. What can be said about the sign of the covariance in (3.106)? Since the SDF is an indicator of bad times but assets pay off well in good times, the covariance between them is typically negative:

$$
S _ {t} <   E _ {t} \left(M _ {t + 1}\right) E _ {t} \left(X _ {t + 1}\right). \tag {3.107}
$$

This generates a risk premium and allows risky assets to pay more than the interest rate. Setting  $X$  equal to the stock price  $S$  and writing  $\tilde{S}_t = S_t / M_t$ , (3.107) becomes

$$
\tilde {S} _ {t} <   E _ {t} \left(\tilde {S} _ {t + 1}\right). \tag {3.108}
$$

Investors expect positive gross asset returns. The asset price dynamics is not a martingale under the empirical probability. If asset price dynamics would be a fair coin toss then returns would not be predictable. Contrarily, to generate risk premia, asset prices have to be predictable in the statistical sense.

Insurance investments show the opposite behavior to financial assets in equation (3.106): A financial investment's return is positive in good times and negative in bad times. Contrary, an insurance investment's return is negative in good times but pays off well in bad times. The covariance in equation (3.106) is positive. Therefore the value of the insurance, the left-hand side of (3.107), is larger than the right-hand side.

Example

The price of a forward satisfies:

$$
0 = E _ {t} (M _ {T} X _ {T}) = E _ {t} (M _ {T} (S _ {T} - f _ {t, T})).
$$

This orthogonality equation states that the forward rate is given by the orthogonal projection:

$$
f _ {t, T} = E _ {t} (S _ {T}) + \operatorname {c o v} _ {t} (M _ {T}, S _ {T}) R _ {f}.
$$

The forward price is therefore equal to the expected future spot price at time  $T$  plus a risk premium.

As a first specification of the SDF we assume that it is given by a linear regression

$$
M _ {t} = b R _ {t} + \epsilon_ {t} \tag {3.109}
$$

with  $R$  any portfolio of  $N$  assets and  $b$  a vector of weights. Here geometry enters into play. We introduce to the geometry in the next section. We estimate the optimal value of  $b$ . Think about  $M$  and  $R$  to vectors. Then the optimal value of  $b$  is given by the shortest distance of  $M$  to  $R$ . But this is the perpendicular value of  $M$  on  $R$ , i.e. the orthogonal projection. The noise term is then perpendicular to  $bR$ . In other words, regressions are nothing but projections in a suitable space. This geometric notion is made precise in the next section.

# 3.7.2 Geometry of Asset Pricing

Starting point is the linear factor model for returns (3.109). See Back (2010) and LeRoy and Werner (2000) for a detailed discussion.

We assume that the random variables  $M, R$  and epsilon are square-integrable. The space of returns is an infinite dimensional complete normed vector space  $H$  (a Hilbert space). Although of infinite dimension, the geometric intuitions of the Hilbert space  $\mathbb{R}^3$  can be applied. In a Hilbert space, the notions of a basis of vectors, orthogonality, projection, least square distance common in  $\mathbb{R}^3$  are well-defined. The norm is induced by the scalar product for random variables  $y, x$ :

$$
\langle x, y \rangle := E (x y). \tag {3.110}
$$

The N-dimensional return  $R$  span a subspace  $\mathcal{R} \subset H$ . Then a regression  $M_{t} = bR_{t} + \epsilon_{t}$  is a projection of  $M$  on the space  $\mathcal{R}$ : The difference between the return and its projection is an orthogonal error  $\epsilon$ . The goal in empirical asset pricing is to find projections such that the error remains small, i.e. returns and their projection differ only slightly.

To gain intuition, we consider the regression

$$
R = b _ {1} F _ {1} + b _ {2} F _ {2} + \epsilon
$$

where for simplicity we omitted the time index and we consider the regression of a return  $R$  on two random variables  $F$  called factors. We switch to this example since it represents the prototype problem in AM. Let  $R \in \mathbb{R}^3$  and the factor space  $\mathbb{F}$  be 2-dimensional. We distinguish (i) the factor space is a vector space or (ii) the factor space plane does not intersect the origin (hyperplane), see Figure 3.18. The second case is generic in our context since the factor space is generated by random variables plus a constant; the risk free return.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/708e990b0d551cf021b7dfb925c23fb0f7b3c971c5cd64d27180e5fc05ba7605.jpg)  
Figure 3.18: Left panel - projection on the factor space which is a vector space. Right panel - projection where the factor space is an affine space, i.e. translated away from the zero vector.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f41685c6fde3fa48b0c134d562a275a73216c339197d1232e8dbc9c12d35ac64.jpg)

A map  $P$  is an orthogonal projection of a real vector space onto a subspace if it is linear,  $P^2 = P$  (projection of a projection does not alter the result), and  $P' = P$ . An orthogonal projection in Hilbert space of a vector  $X$  on a vector  $Y$  reads

$$
P _ {Y} (X) = \frac {\langle X , Y \rangle}{\langle Y , Y \rangle} Y =: E (X | Y), \tag {3.111}
$$

i.e. the conditional expectation operator is an orthogonal projection. Hence there is a possibility to think in geometric terms about the usual asset pricing equations and notions which are commonly expressed in probabilistic terms.

We project  $R$  on  $\mathbb{F} = \operatorname{span}\{F_1 + F_2\}$ , where the two factors are assumed to be orthonormal.[23]

Then

$$
P _ {\mathbb {F}} (R) = \sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} F _ {i}. \tag {3.113}
$$

It is straightforward to check the two properties that make  $P$  an orthogonal projection. If  $R$  is orthogonal to both factors the projection vector is zero, i.e. the orthogonal error is maximal. The factors used for regression are not able to explain the return at all. The opposite holds if one factor is collinear to the return vectors. If we project  $R$  on a affine space  $\mathbb{F} = \{a + \tilde{F}_1 + \tilde{F}_2\}$ , where the two factors are assumed to be orthogonal, then

$$
P _ {\mathbb {F}} (R) = a + \sum_ {I = 1} ^ {2} \frac {\langle R - a , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} F _ {i}. \tag {3.114}
$$

Therefore a simple shifts follows. As a consistency check, if  $a$  is equal to  $R$  then the projection is the identity. If the factors are orthonormal and not only orthogonal, then  $\langle F_i, F_i \rangle = 1$ . Using that the inner product in factor models is induced by the expectation, the last formula reads:

$$
P _ {\mathbb {F}} (R) = a + \sum_ {I = 1} ^ {2} \frac {\operatorname {c o v} \left(R - a , F _ {i}\right)}{\sigma^ {2} \left(F _ {i}\right)} F _ {i} \tag {3.115}
$$

and defining  $\frac{\operatorname{cov}(x,y)}{\sigma^2(y)} =: \beta_{x,y}$ , standard formulae such as the CAPM follow. Let  $F = R_M$

$$
P _ {F} (R) + P _ {F ^ {\perp}} (R) = R, P _ {F} + P _ {F ^ {\perp}} = \mathbb {I}. \tag {3.112}
$$

Then

$$
\tilde {F} _ {2} = \left(P _ {(\tilde {F} _ {1}) ^ {\perp}}\right) (F _ {2}) = F _ {2} - P _ {\tilde {F} _ {1}} (F _ {2}) = F _ {2} - \frac {\langle \tilde {F} _ {1} , F _ {2} \rangle}{\langle \tilde {F} _ {1} , \tilde {F} _ {1} \rangle} \tilde {F} _ {1}.
$$

This vector is orthonormal to the first one and the construction is continued for the next vector by projecting the third vector on the orthogonal complement of the first two orthogonal vectors.

24 For example

$$
\begin{array}{l} P _ {\mathbb {F}} \left(P _ {\mathbb {F}} (R)\right) = P _ {\mathbb {F}} \left(\sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} F _ {i}\right) \\ = \sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} P _ {\mathbb {F}} (F _ {i}) = \sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} \sum_ {j = 1} ^ {2} \frac {\langle F _ {j} , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} F _ {j} \\ = \sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} \sum_ {j = 1} ^ {2} \frac {\delta_ {i j}}{\langle F _ {i} , F _ {i} \rangle} F _ {j} = \sum_ {i = 1} ^ {2} \frac {\langle R , F _ {i} \rangle}{\langle F _ {i} , F _ {i} \rangle} F _ {i}. \\ \end{array}
$$

be the single market return factor, then for  $a = 0$  and omitting the time index:

$$
\begin{array}{l} P _ {R _ {M}} (R - R _ {f}) = E (R - R _ {f}) = E (R) - R _ {f} (3.116) \\ = \frac {\operatorname {c o v} \left(R - R _ {f} , R _ {M}\right)}{\sigma^ {2} \left(R _ {M}\right)} R _ {M} = \frac {\operatorname {c o v} \left(R , R _ {M}\right)}{\sigma^ {2} \left(R _ {M}\right)} R _ {M} (3.117) \\ \end{array}
$$

As a second example, consider the matrix linear regression

$$
y = X \beta + \epsilon
$$

with  $\epsilon, y \in \mathbb{R}^n$ ,  $\beta \in \mathbb{R}^{K+1}$  and  $X \in \mathbb{R}^{n \times K}$  the factor associated to  $\beta_1$  is 1, i.e. the first row in the matrix  $X$  has entries 1 in each cell. Using the above formalism we get:

Proposition 54. Given the above matrix linear regression, the least-square estimated plan  $\widehat{y} = P_X(y) = X\widehat{\beta}$  is given

$$
P _ {X} (y) = X \left(X ^ {\prime} X\right) ^ {- 1} X ^ {\prime} y, \widehat {\beta} = \left(X ^ {\prime} X\right) ^ {- 1} X ^ {\prime} y \tag {3.118}
$$

The residual matrix  $Q_{X} = 1 - P_{X}$  is given by

$$
\widehat {\epsilon} = y - \widehat {y} = y - P _ {X} y = Q _ {X} y. \tag {3.119}
$$

The residual sum of squares RSS is given by

$$
R S S := \langle \widehat {\epsilon}, \widehat {\epsilon} \rangle = \langle y, Q y \rangle .
$$

There are some basic results from projection theory on Hilbert spaces which are used over and over again in AM: The classic projection theorem states: the shortest distance between a point  $M \in H$  and a plane  $\mathbb{F}$  is achieved by a line perpendicular to the plane. Suppose that an asset  $x \in H$  is illiquid and let  $\mathbb{F}$  be span of liquid asset payoffs. The portfolio of liquid assets which is closest to  $x$  is the orthogonal projection. The projection of  $H$  onto  $\mathbb{F}$  can be difficult to calculate. Assume that  $\mathbb{F}$  can be decomposed into two orthogonal subspaces where it is simpler to calculate the projections onto these smaller spaces. Then, the original projection is equal to the sum of the two projections onto the smaller spaces. A different form of sequential projecting is the case where one has to project  $H$  onto a subset  $G \subset \mathbb{F}$ . Then o first projecting on  $\mathbb{F}$  and then projecting the result on  $G$  is the same as the direct projection on  $G$ . This is the tower property in the conditional expectation language.

Using this formalism we define:

Definition 55 (Factors). Factors  $F = (F_{1},\ldots ,F_{K})$  are independent square-integrable random variables with zero expectation.  $\mathbb{F}$  is the linear space of dimension  $K$  generated by the factors. A factor model is quantified by a SDF  $M = a + b'F$  where  $a$  is a number and  $b$  a vector of dimension  $K$ .

$M$  being element of a Hilbert space and  $(e_j)$  a basis of this space, then

$$
M = \sum_ {j = 0} ^ {\infty} a _ {j} e _ {j}
$$

where the sum over  $|a_j|^2$  is finite. This is the analogue to finite dimensional vectors except that we need a notion of convergence due to the infinite dimensionality of the Hilbert space. The similar decomposition applies to the factors and the factors span the SDF if  $M$  can be replicated exactly by the factors. If the factors span a subspace of the total space, then SDF possess an error in the factor representation.

Definition 56 (Beta Pricing Model). Let  $F = (F_{1},\ldots ,F_{K})$  be a vector of random variables,  $R_0$  a constant and  $\lambda$  a  $K$ -dimensional constant vector. There exists a multifactor beta pricing model with factors  $F$  if for each return  $R$ :

$$
E (R) = R _ {0} + \lambda^ {\prime} \beta \tag {3.120}
$$

with

$$
\beta := C _ {F} ^ {- 1} \operatorname {c o v} (F, R) \tag {3.121}
$$

the vector of multiple regression betas of the return  $R$  on the factors  $F$  and  $C_F$  the covariance matrix of the  $F$ 's.

The elements  $F_{j}$  are the risk factors and  $\lambda$  is the factor risk premium. If  $\lambda > 0$ , then an investor is compensated for holding extra risk by a higher expected return when risk is measured with the beta w.r.t.  $F$ . The coefficient  $\beta$  is the coefficient of an orthogonal projection of the return  $R$  on the space generated by the factors  $F$  plus a constant. The risky asset's risk premium is proportional to the covariance between its returns and the SDF (its systematic risk). In the CAPM for example, the market return replaces the SDF. Factors can be abstract random variables, portfolio returns, excess returns or dollar-neutral returns. The model is exact, because there is no error term in (3.120). One can always take factors to have zero means, unit variances and be mutually uncorrelated by using

$$
\widehat {F} := \mathrm {C D} ^ {- 1} (F - E (F)) \tag {3.122}
$$

with CD the Cholesky decomposition of  $C_F$ . If the factors  $F$  are returns then the factor risk premium  $\lambda$  becomes an ordinary risk premium  $\lambda = E(F) - R_0$ .<sup>25</sup>

When is a factor pricing model exact? By the Riesz theorem, see below, the price of an asset  $q(S_{t})$  is given by a scalar product  $\langle M_{t + 1}, S_{t + 1} \rangle$  of the future asset price and the SDF. If the SDF is element of the space spanned by the factors, then the pricing of the asset can be done by using the factors with arbitrary precision: Beta pricing and factor pricing models are then equivalent, see Proposition 65. In other words, the quality of the

# 3.7. ASSET PRICING

factors used to replicate the SDF determine the quality of the representation of expected return by their betas.

We consider the Riesz Representation Theorem. It states that any linear function on a Hilbert space can be represented by a scalar product.

Theorem 57. (Riesz) Let  $H$  be a Hilbert space and  $p: X \to \mathbb{R}$  a linear map. There exists a vector  $r^* \in H$ , the Riesz kernel, such that

$$
p (x) = \langle r ^ {*}, x \rangle
$$

for all  $x\in H$

To apply it in asset pricing, let  $X$  be the future payoff of an asset and  $p(X)$  the present pricing of the payoff. This pricing functional that maps future payoffs, elements of  $H$  into current prices, the reals. It is natural to assume that the pricing function  $p$  is linear, i.e. for no-arbitrage reasons we impose value-additivity. Furthermore  $p$  should be continuous, small payoff variations have small prices. That is  $p$  is a linear functional on the space of future payoffs. The Riesz theorem states that there exists a random variable  $M$  such that

$$
p (X) = \langle M, X \rangle = E (M X).
$$

Hence, by the Riesz Theorem to price any payoff it suffices to use  $M$  - the stochastic discount factor (SDF) and to apply the expectation. The theorem does not tell how to find  $M$ . In absolute (equilibrium) pricing it is given by the marginal consumption rate substitution; in derivative pricing a deterministic discount factor or any numeraire can be used.

# 3.7.3 Absolute Pricing (General Equilibrium

Investors solve a fully-fledged economic model: they choose optimal consumption and investment portfolios over time to maximize their expected utility function. The optimal policies clear the markets of all goods and financial assets which determines the equilibrium asset price dynamics. Only a few models can be explicitly solved, for more complicated ones numerical approximation methods are used. In equilibrium no rational investor has an incentive to deviate from the equilibrium allocation: If an investor is optimally short, there must be an investor who optimally buys the asset, else markets do not clear.[26]

This contrasts with relative or derivative pricing were no consumption, explicit utility function matters but only the no arbitrage principle. But it turns out that any general equilibrium allocation is free of arbitrage - it is a necessary condition for an equilibrium to exist.

We consider a simple general equilibrium model to highlight some ideas. Two investors  $i = 1,2$  can consume at the beginning and end of a single period a single good  $c$ .

Both derive utility from a logarithmic utility function over consumption.

They face the same endowment (salary) and only differ in their impatience: The time discount rates  $b^{1}$  and  $b^{2}$  are different and hence the time value of money is different. The only asset to invest in the financial market is a risk-free bond  $B$ , which they can exchange, i.e. there is no money.

An optimal policy fixes the optimal consumption levels at the two dates and the investment amount in the bond at the first date. These optimizations determine optimal consumption  $c^i(B)$  and investment  $\phi^i(B)$  for each investor. The policies depend on the yet exogenous given bond price  $B$ . Inserting these strategies in the market clearing condition fixes the endogenous price  $B = e^{-R_f}$  of the bond, i.e. the risk-free interest rate  $R_f$  follows from the interaction of the investors. Let  $\phi_k(S)$  be the number of bonds investor  $k$  buys and keeps at time 0. Market clearing means  $\phi_1 + \phi_2 = 0$ : what 1 sells (buys) must 2 buy (sell). Inserting the individual optimal investment strategy functions fixes the equilibrium risk-free interest rate

$$
R _ {f} = \frac {2 (1 - b ^ {1} b ^ {2})}{b ^ {1} + b ^ {2} + 2 b ^ {1} b ^ {2}}.
$$

All quantities which enter symmetrically in the optimization such as endowment have to cancel in the equilibrium expressions. The time value of money is driven by impatience. If impatience is zero, the risk-free rate is zero. Other limit or sensitivity cases follow at once.

We derive formally the solution by allowing for more heterogeneity. The log preferences are:

$$
u ^ {i} \left(c _ {0} ^ {i}, c _ {1} ^ {i}\right) = \log \left(c _ {0} ^ {1}\right) + b ^ {i} \log \left(c _ {1} ^ {i}\right), i = 1, 2, 0 \leq b ^ {i} \leq 1
$$

with  $b^{i}$  the time preference rate. The budget restrictions read for investor  $i$  (with  $e$  the endowment):

$$
c _ {0} ^ {i} - e _ {0} ^ {i} = - \frac {1}{1 + R _ {f}} \phi^ {i}
$$

$$
{c _ {1} ^ {i} - e _ {1} ^ {i}} = {\phi^ {i}}
$$

with  $R_f$  the yet unspecified risk free rate. We introduce the Lagrangian  $L$ :

$$
L ^ {i} (c ^ {i}, \phi^ {i}, \lambda^ {i}) = u ^ {i} - \lambda_ {0} ^ {i} (c _ {0} ^ {i} - e _ {0} ^ {i} + \frac {1}{1 + r} \phi^ {i}) - \lambda_ {1} ^ {i} (c _ {1} ^ {i} - e _ {1} ^ {i} - \phi^ {i}).
$$

The FOC read:

$$
0 = \frac {\partial L ^ {i}}{\partial c _ {j} ^ {i}} \Longrightarrow c _ {0} ^ {i} = \frac {1}{\lambda_ {0} ^ {i}}, c _ {1} ^ {i} = \frac {b ^ {i}}{\lambda_ {1} ^ {i}}
$$

$$
0 = \frac {\partial L ^ {i}}{\partial \phi^ {i}} \Longrightarrow \lambda_ {0} ^ {i} = \lambda_ {1} ^ {i} (1 + r)
$$

$$
0 = \frac {\partial L ^ {i}}{\partial \lambda_ {j} ^ {i}}.
$$

Solving these equations implies:

$$
{c _ {0} ^ {i}} = {\frac {e _ {0} ^ {i}}{(1 + b ^ {i})} + \frac {e _ {1} ^ {i}}{(1 + R _ {f}) (1 + b ^ {i})} = \frac {1}{1 + b ^ {i}} \mathrm {P V} (e ^ {i})}
$$

$$
{c _ {1} ^ {i}} = {\frac {b ^ {i} (e _ {0} ^ {i} (1 + R _ {f}) + e _ {1} ^ {i})}{1 + b ^ {i}}}
$$

$$
\phi^ {i} = \frac {- e _ {1} ^ {i} + e _ {0} ^ {i} b ^ {i} (1 + R _ {f}) - e _ {1} ^ {i}}{1 + b ^ {i}}
$$

$$
\lambda_ {0} ^ {i} = \frac {(1 + R _ {f}) (1 + b ^ {i})}{e _ {0} ^ {i} + R _ {f} e _ {0} ^ {i} + e _ {1} ^ {i}}
$$

$$
\lambda_ {1} ^ {i} = \frac {1 + b ^ {i}}{e _ {0} ^ {i} + R _ {f} e _ {0} ^ {i} + e _ {1} ^ {i}}.
$$

Using market clearing, we get the equilibrium interest rate:

$$
R _ {f} = \frac {e _ {1} ^ {1} + e _ {1} ^ {2} - e _ {0} ^ {1} b ^ {1} + e _ {1} ^ {2} b ^ {1} - e _ {0} ^ {2} b ^ {2} + e _ {1} ^ {1} b ^ {2} - e _ {0} ^ {1} b ^ {1} b ^ {2} - e _ {0} ^ {2} b ^ {1} b ^ {2}}{e _ {0} ^ {1} b ^ {1} + e _ {0} ^ {2} b ^ {2} + e _ {0} ^ {1} b ^ {1} b ^ {2} + e _ {0} ^ {2} b ^ {1} b ^ {2}}
$$

Assuming that endowment is the same for both agents, endowment cancels in the last expression and the above equilibrium rate follows. If risk enters in the model, the FOC conditions become equations with expected values but still the same logic applies.

We derive the fundamental asset pricing equation in the context with risk. Assuming separable preferences, rational investors derives expected utility from two-period consumption at the present date  $t$  and a future date  $t + 1$ ,

$$
E _ {t} \left[ u \left(c _ {t}, c _ {t + 1}\right) \right] = E _ {t} \left[ u \left(c _ {t} ^ {1}\right) \right] + b E _ {t} \left[ u \left(c _ {t + 1}\right) \right],, 0 \leq b \leq 1
$$

with  $b$  the time preference rate. He chooses investment to maximize expected utility where consumption is assumed to be al ready optimally chosen. There is only a single risky asset  $S$  and two budget constraints at time  $t$  and  $t + 1$  (with  $e$  the endowment):

$$
c _ {t} - e _ {t} = - \phi_ {t} S _ {t}
$$

$$
c _ {t + 1} - e _ {t + 1} = \phi_ {t} X _ {t + 1}.
$$

Introducing the Lagrangian, the FOC imply the Fundamental Asset Pricing Equation (5.1)- for asset  $S$  at time  $t$ :

$$
S _ {t} = E _ {t} \left(M _ {t + 1} X _ {t + 1}\right) \tag {3.123}
$$

with  $M$  the stochastic discount factor (SDF),

$$
M _ {t + 1} = b \frac {u ^ {\prime} \left(c _ {t + 1}\right)}{u ^ {\prime} \left(c _ {t}\right)} \tag {3.124}
$$

and  $u^{\prime}(c)$  marginal utility of consumption. Hence, price is expected discounted payoff. (5.1) assumes that there is the underlying general equilibrium model, which ensures that a single SDF exists which can be used to price all assets by discounting payoffs.

Since consumption at time  $t + 1$  is stochastic from vista time  $t$ ,  $M_{t + 1}$  is stochastic too. The SDF is high if time  $t + 1$  turns out to be a bad time - consumption is low in future states, see Figure 5.1. Then future payoffs are discounted weakly in the pricing equation (5.1) and they attribute to assets in bad times a high price.

The SDF relationship between asset prices and consumption states that investments proposed by asset managers should protect investors' optimal consumption in the short and long run. This sound theoretical model has drawbacks. First, investments derived from consumption data often underperform. Second, the assumption and knowledge of a single utility function is unrealistic. Data science is a feasible and powerful alternative.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/290301c01b978797eb88cedfa5ec74cfae0cfe1b9ace79c270a8ddbce78f19fc.jpg)  
Figure 3.19: Marginal utility  $u'$  is a decreasing function of consumption. Hence, in bad times where consumption is lower at the future  $t + 1$  than at present  $t$ , the ratio of marginal utilities in (5.2) is larger than one.

The ratio of marginal utilities in the SDF reflects that investors value money more when they need it in bad times than in good times. Marginal utility can therefore be seen as an index of bad times and the SDF as a substitution measure between present and future consumption is an index of growth in different times. The price changes of  $S$  in the fundamental pricing equation (5.1) can have three causes: The probability  $p$ , the discount factor  $M$  or the payoff  $X$ . There is strong evidence that expected return variation over time and across assets dominate and that asset valuation moves far more on news affecting the discount factor than on news of expected cash flows, that is, the payoff  $X$ .

We consider some examples. If we consider a risk-less asset  $S_0$ , that is  $X(s) = 1$  in all states  $s$ , then  $S_0 = E(M)$ . Therefore, the risk-less rate  $R_f$  satisfies

$$
1 + R _ {f} = \frac {S _ {T}}{S _ {0}} = \frac {1}{S _ {0}} = \frac {1}{E (M)}.
$$

Assuming a constant relative risk aversion utility function  $u(c) = c^{1 - \gamma}$ ,  $0 < \gamma < 1$ , the SDF reads

$$
M = b \left(\frac {c _ {t + 1}}{c _ {t}}\right) ^ {- \gamma} = b e ^ {- \gamma \ln \left(\frac {c _ {t + 1}}{c _ {t}}\right)} \sim b (1 - \gamma \Delta c _ {t + 1})
$$

up to the first order where  $\Delta c_{t + 1} = \ln \left(\frac{c_{t + 1}}{c_t}\right)$ . Expanding again up to first order:

$$
1 + R _ {f} = \frac {1}{E (M)} \sim \frac {1}{b} (1 + \gamma E _ {t} (\Delta c _ {t + 1})).
$$

Hence interest rates are higher if people are impatient (low  $b$ ) or if expected consumption growth is high. Since high consumption growth means people get richer in the future one has to offer high risk free rate such that they consume less now and save.

How much does  $R_{f}$  vary over time is the same to ask how much must one offer to individuals to postpone consumption. This variation is given by the risk aversion factor  $\gamma$ . Expanding the risk-free rate relation up to second order:

$$
1 + R _ {f} \sim \frac {1}{b} (1 + \gamma E _ {t} (\Delta c _ {t + 1}) - \frac {1}{2} \gamma^ {2} \sigma_ {t} ^ {2} (\Delta c _ {t + 1}).
$$

Therefore, higher consumption growth volatility lowers interest rates which motivates investors to save more in uncertain times.

Using

$$
E (M R) = E (M) E (R) + \operatorname {c o v} (M, R), \beta_ {i} = \operatorname {c o v} (M, R _ {i}) / \operatorname {v a r} (M)
$$

and  $\lambda = -\mathrm{var}(M) / E(M)$ , beta pricing follows (deleting time indices):

$$
E (R _ {i} ^ {e}) = \beta_ {i} \lambda \tag {3.125}
$$

Inserting the explicit utility function up to first order we get in  $(\ref{eq:1})$

$$
E _ {t} \left(R _ {t + 1} ^ {e}\right) = \beta \lambda \sim \gamma \operatorname {c o v} \left(R _ {t + 1} ^ {e}, \Delta c _ {t + 1}\right) = \underbrace {\gamma \sigma_ {t} ^ {2} (\Delta c _ {t + 1})} _ {= \lambda} \underbrace {\frac {\operatorname {c o v} \left(R _ {t + 1} ^ {e} , \Delta c _ {t + 1}\right)}{\sigma_ {t} ^ {2} (\Delta c _ {t + 1})}} _ {= \beta}. \tag {3.126}
$$

If assets covary positively with consumption growth or equivalently negatively with the SDF then they must pay a higher average return. High expected returns are equivalent to

low asset prices. From a risk perspective, the above equations state that average returns are high if beta on the SDF or on consumption growth  $\Delta c$  is large. This is the above 'bad times - low consumption growth - high SDF - high returns or high asset prices' story.

Using the fundamental equation (5.1) with a risk free rate and the approximation for the SDF we get:

$$
S _ {t} = E _ {t} (M _ {t + 1} X _ {t + 1}) \sim \frac {E _ {t} (X _ {t + 1})}{R _ {f}} - \gamma \mathrm {c o v} (X _ {t + 1}, \Delta c _ {t + 1}). \qquad (3. 1 2 7)
$$

Again, price is higher if the asset payoff is a good hedge against consumption growth (negative correlation).

# 3.7.4 Projection Pricing and SDF Formulation

We showed that pricing of assets can be represented by state prices or risk-neutral probabilities. We recall that projections are used to write any payoff in a Hilbert space as a sum of a payoff in the asset span and an orthogonal part. The Riesz representation states that any linear, continuous function on a Hilbert space can be represented by a scalar product which in our set-up is induced by an expected value. Finally, the inner product is induced by expectation, i.e.  $\langle x,y,\rangle \coloneqq E(xy)$ . The main source for this section is LeRoy and Werner (2000).

All random variables defined on the asset span  $\langle \mathbb{S} \rangle \subset \mathbb{R}^S$  also span a Hilbert space. Therefore, the Riesz Representation Theorem applies on the asset span functionals too. The expectations functional and the payoff pricing functional turn are of particular interest. Pricing functionals  $p$  are linear functionals  $\langle S \rangle \to R$ . The extension of  $p$  the whole asset space  $\mathbb{R}^S$  is the valuation functional. If markets are free of arbitrage,  $p$  is strictly positive. If  $x \in \langle \mathbb{S} \rangle$  is an Arrow-Debreu state,  $p = \psi$  is a state price. Hence,  $p$  is a linear combination of the basis state prices. If markets are complete, the unique representation  $\psi(x) = \langle \psi, x \rangle$  holds for the valuation and pricing functional. Formally:

Definition 58. The expectations functional  $E$  maps every payoff  $x \in \langle \mathbb{S} \rangle$  into its expectation  $E(x)$ . The payoff pricing functional  $p$  maps every payoff  $x \in \langle \mathbb{S} \rangle$  into its price  $p(x)$ .

By the Riesz Representation for both functionals exist a unique vector  $k^{*}, M^{*}$  such that

$$
E (x) = E \left(k ^ {*} x\right)
$$

and

$$
p (x) = E \left(M ^ {*} x\right).
$$

$M^{*}$  is called the pricing kernel - the SDF - and  $k^{*}$  the expectation kernel. The vector space generated by  $M^{*}$  and  $k^{*}$  is denoted  $\mathcal{E}$ .

The construction of the different kernels is straightforward. For the pricing kernel, consider the two-dimensional set  $\langle \mathbb{S} \rangle = \operatorname{span}(1, 1) \subset \mathbb{R}^2$ ,  $(1/4, 3/4)$  the probabilities of

# 3.7. ASSET PRICING

the expectation in the inner product and  $p(s) \coloneqq 2s_1$  for  $s = (s_1, s_2) \in \langle \mathbb{S} \rangle$ . Since (1,1) is a basis of the span, the Riesz kernel has to be a multiple  $a(1,1)$  of the basis vector with  $a \in \mathbb{R}$ :

$$
p (1, 1) = 2 \times 1 = 2 = E (r ^ {*} (1, 1) ^ {\prime}) = \frac {a}{4} \times 1 + \frac {3 a}{4} \times 1 = a,
$$

i.e.  $a = 2$  and the kernel reads  $r^* = (2,2)$ . To calculate the expectation kernel, let  $x_1, \ldots, x_m$  be  $m$  payoffs with  $\mathbb{S}$  components for the states with probabilities  $p_s$ ,  $s = 1, \ldots, S$ . Then,  $E(x) = \sum_{s} p_s x_s$  and  $E(k^* x) = \sum_{s} p_s k_s^* x_s$ . Since the expectation kernel is in the asset span,  $k^* = \sum_v a_s x_v$ : The kernel can be spanned by the payoffs with the coefficients unknown. But then

$$
p _ {s} x _ {s} = \sum_ {v} a _ {v} x _ {s} x _ {s v}
$$

defines a linear system for the  $a$ 's. Solving this system and using  $k^* = \sum_v a_s x_v$  provides the expectation kernel. If there are three states with equal probability, two payoffs  $x_1 = (1, 1, 0)$  and  $x_2 = (0, 1, 1)$ , then the expectation kernel reads  $k^* = (a_1, a_1 + a_2, a_2)$ , and from  $\frac{2}{3} = E(k^* x_j)$ ,  $j = 1, 2$  the linear system

$$
\left( \begin{array}{c} \frac {2}{3} \\ \frac {2}{3} \end{array} \right) = \frac {1}{3} \left( \begin{array}{c} a _ {1} \\ a _ {1} + a _ {2} \end{array} \right) + \frac {1}{3} \left( \begin{array}{c} a _ {1} + a _ {2} \\ a _ {2} \end{array} \right)  .
$$

Solving the system,  $k^{*} = \left(\frac{2}{3},\frac{4}{3},\frac{2}{3}\right)$  follows.

We summarize some basic facts.

Theorem 59. 1. If the risk-free payoff is in the asset span, then the expectations kernel is risk-free and equal to one in every state.

2. If the risk-free payoff is not in the asset span, then the expectations kernel is the orthogonal projection of the risk-free payoff on the asset span.  
3. The pricing kernel is unique regardless of whether markets are complete or incomplete.  
4. Let  $\psi_1, \ldots, \psi_S$  be the state prices of the  $\mathbb{S}$  states and  $p_s$  the corresponding probabilities of the states. Then  $-M^*$  is the orthogonal projection of the vector  $\psi / q$  on the asset span.  
5. For any SDF  $M$ ,  $E[(M - M^{*})x] = 0, x \in \langle \mathbb{S} \rangle$ .  $M^{*}$  is the projection  $M$  on  $\langle \mathbb{S} \rangle$ .  
6. $k^* = e$  if markets are complete.

We apply the representation to mean-variance theory.

Definition 60. The mean-variance frontier is the set  $\mathcal{M}$  which consists of all payoffs  $x\in \langle \mathbb{S}\rangle$  such that there exists no other payoff  $x^{\prime}$  in the asset span with the same expected value and the same valuation.

The next theorem is the main result.

Proposition 61. In a discrete, finite state market  $\mathcal{M} = \mathcal{E}$ .  $k^{*}$  and  $M^{*}$  are collinear iff all portfolios have the same expected return. If the risk-free asset is element of the asset span, then expectations kernel and the pricing kernel are collinear iff the expected payoff for each asset is equal to  $r$ . Then,  $k^{*} = e$  and  $M^{*} = \frac{1}{r} e$ .

Hence, a payoff is a mean-variance frontier payoff iff it lies in the span of the expectations kernel and the pricing kernel. Since return is defined as payoff divided by price and price is given by the valuation functional, we have for  $x = M^{*}$ :

$$
R ^ {M ^ {*}} := \frac {M ^ {*}}{p (M ^ {*})} = \frac {M ^ {*}}{E [ (M ^ {*}) ^ {2} ]}, R ^ {k ^ {*}} := \frac {k ^ {*}}{E [ k ^ {*} ]}.
$$

This two returns are frontier returns with unit price.

Proposition 62. Assume that the pricing and expectation kernel are not collinear.

a) The set of frontier returns is given by the line spanned by the two frontier returns  $R^{k^*}$  and  $R^{M^*}$ : For  $\lambda$  a number

$$
R _ {\lambda} = R ^ {k ^ {*}} + \lambda \left(R ^ {M ^ {*}} - R ^ {k ^ {*}}\right)
$$

is a frontier return.

b) If the expectation kernel is risk free,

$$
\operatorname {v a r} \left(R _ {\lambda}\right) = \lambda^ {2} \operatorname {v a r} \left(R ^ {M ^ {*}}\right). \tag {3.128}
$$

c) If the risk-free payoff is in the asset span, then the risk-free return is the minimum-variance frontier return. If the risk-free payoff is not in the asset span, then

$$
\lambda_ {0} := - \frac {\operatorname {c o v} \left(R ^ {k ^ {*}} , R ^ {M ^ {*}} - R ^ {k ^ {*}}\right)}{\operatorname {v a r} \left(R ^ {M ^ {*}} - R ^ {k ^ {*}}\right)}
$$

defines the minimum-variance frontier return  $R_{\lambda_0}$ .

d) Given any frontier return  $R_{\lambda}$ , which is different from the minimum-variance frontier return, there exists a zero-covariance frontier return  $R_{\lambda_C}$ , i.e.  $\operatorname{cov}(R_{\lambda}, R_{\lambda_C}) = 0$ .

Using this proposition, we can recover Beta pricing models. Let  $R_{j}$  be the return of an asset  $j$ . Then,

$$
R _ {j} = P _ {\mathcal {E}} R _ {j} + \epsilon_ {j}
$$

defines the projection on the space  $\mathcal{E}$  and the epsilon term is orthogonal to this space. Since this space is generated by the expectation and pricing kernel, epsilon is orthogonal to these two kernels and hence has zero expectation and price. This implies that the

projected return  $P_{\mathcal{E}}R_{j}$  is a frontier return. We span this return in a new basis  $R_{\lambda}$  and the zero-covariance return, i.e. for some parameter  $\beta_{j}$

$$
R _ {j} = R _ {\lambda_ {C}} + \beta_ {j} (R _ {\lambda} - R _ {\lambda_ {C}}) + \epsilon_ {j}.
$$

Taking expectations and the covariance w.r.t.  $R_{\lambda}$ , which is uncorrelated with the zero-covariance return and the epsilon, implies that the beta coefficient is the ordinary regression coefficient of  $R_{j}$  on  $R_{\lambda}$ . If the risk-free payoff is in the asset span, the beta pricing equation

$$
E (R _ {j}) = R _ {f} + \beta_ {j} (E (R _ {\lambda}) - R _ {f})
$$

follows. Since the market return in the CAPM turns out to be also a frontier return,  $R_{\lambda}$  can be replaced by the market return. Hence, the SML of the CAPM is a special case of beta pricing. The analysis not only holds for a single asset but for a portfolio.

The beta pricing with one factor  $R_{\lambda}$  is generalized in the above geometric set-up in a straightforward way. The span  $\mathcal{E}$  is replaced by a span  $\mathcal{F}$  of  $K$  normalized factors  $f_{j}$ , i.e., their expected value is zero, and the risk-free asset  $x_{f}$ . Projecting an arbitrary payoff  $x_{j}$  on the new span space, switching from prices to return the usual representation

$$
R _ {j} = E \left(R _ {j}\right) + \sum_ {k = 1} ^ {K} \beta_ {j k} f _ {k} + \epsilon_ {j} \tag {3.129}
$$

follows with the beta's the factor loadings. As in the proof of the beta pricing representation, if the pricing kernel and the risk free asset are elements of  $\mathcal{F}$ , then the exact factor pricing equation

$$
E (R _ {j}) = F _ {f} + \sum_ {k} \beta_ {j k} \lambda_ {k}
$$

holds with  $\lambda_{k} = -E(R^{M^{*}}f_{k})R_{f}$

So far we did not consider any equilibrium economy analysis in this representation set-up. To do so, consider a two period economy where agents derive utility from consumption of a single good, the utility function is a smooth function, individuals are strictly risk averse, there are  $K$  factors  $f_{j}$  and where the expected error epsilon in (3.129) conditional on the factors is zero.

Theorem 63. Under the above assumption, if the risk-free asset, the factors, and agents' endowments at date 0 lie in the asset span and if the aggregate date 0 endowment lies in the factor set, then exact factor pricing holds in any equilibrium in which the consumption allocation is interior.

We finally relate this representation to the case where the SDF  $M$  is linearly related to factor returns, such as for the CAPM

$$
M _ {t + 1} ^ {*} = a + b R _ {M, t + 1}, \tag {3.130}
$$

with  $a, b$  constants. Using this SDF, the CAPM formulation follows

$$
E \left(R _ {j}\right) = R _ {f} + \beta_ {j, M} \left(E \left(R _ {M}\right) - R _ {f}\right) \tag {3.131}
$$

if the parameters  $a$  and  $b$  are appropriately chosen. For the mean-variance model,

$$
M _ {t + 1} ^ {*} = a + b R _ {m v, t + 1},
$$

where  $R_{mv,t+1}$  is any mean-variance efficient return. Again given any  $R_{mv,t+1}$  and a risk-free rate, we find a SDF that prices all assets and vice versa. This shows that the CAPM and Markowitz model are approximations to the general equilibrium pricing kernel or SDF - the ratio of marginal utilities of consumptions at different dates is approximated by affine functions in the market and mean-variance return respectively.

It is worth to express the relationship between factor models and beta representations in general since the expression of a risk premium given in (5.3) is of limited practical use because it involves the unobservable SDF. The idea is to start with investable factors and then derive the beta representation which is equivalent to the SDF approach.

Definition 64. A  $K$ -factor model is quantified by  $M = a + b'F$  where  $F$  is the  $K$ -dimensional vector of factors,  $a$  is a number and  $b$  is a vector of numbers. A factor  $F_k$  that has a non-zero loading  $b_k$  is said a pricing factor.

The equivalence between factor models and beta pricing models is given in the next proposition.

Proposition 65. A scalar  $a$  and a vector  $b$  exist such that  $M = a + b'F$  prices all assets if and only if a scalar  $\kappa$  and a vector  $\lambda$  exist such that the expected return of each asset  $j$  is given by

$$
E \left(R _ {j}\right) = \kappa + \lambda^ {\prime} \beta_ {j} \tag {3.132}
$$

where

$$
\lambda = - \frac {1}{E (M)} c o v (M, F), \kappa = \frac {1}{E (M) - 1}.
$$

The  $K \times 1$  vector  $\beta_{j}$  is the vector of multivariate regression coefficients of the return of asset  $j$  on the risk factor vector  $F$ .

The vector  $\lambda$  is called the factor risk premia. The constant  $\kappa$  is the same for all assets and it is equal to the risk-free rate if such a rate exists. We mentioned above that factor models often are not given as pay-offs nor as returns, but the fundamental pricing equation is expressed using pay-offs. It possible to replace a given set of pricing factors by a set of pay-offs that carries the same information. The following proposition summarizes:

Proposition 66. Starting with a SDF in the factor model format  $M = a + b'F$ , we can always construct a new SDF  $M^{*} = a^{*} + b'F^{*}$  where  $a^{*}$  and  $F^{*}$  are the constant a mimicking and the factor  $F$  mimicking payoffs. These mimicking expressions depend on the original factors and the payoff  $x$  as follow:

$$
a ^ {*} = E (x) ^ {\prime} E (x x ^ {\prime}) ^ {- 1} x, f _ {k} ^ {*} = E (F _ {k} x) ^ {\prime} E (x x ^ {\prime}) ^ {- 1} x, k = 1, \dots , K.
$$

'Mimicking' means that the new SDF is as close as possible chosen to match the payoff. Summarizing, there is no loss of generality from searching for pricing factors among pay-offs.

Cochrane (2013) distinguishes between pricing factors and priced factors. Consider  $M = a + b'F$  and the factor risk premia  $\lambda$  of Proposition 65. The coefficient  $b$  in the SDF is the multivariate regression factor of the SDF on the factors. Each component of the factor risk premia is proportional to the univariate beta of the SDF with respect to the corresponding factor. If  $b$  is non-zero for a given factor means that the factor adds value in pricing the assets given all other factors - a pricing factor. If the component of the factor risk premia is non-zero, then the factor is rewarded - a priced factor. The two concepts are not equivalent except in the case where all factors are independent.

Summarizing, the three representations - discount factors, mean-variance frontiers, and beta representation - are all equivalent. They all carry the same information. Given one representation, the others can be found. Economist prefer to use discount factors, finance academics prefer the mean-variance language, and practitioners the beta or factor model expressions.

But there is bad news. Factors are related to consumption data entering the SDF. While multi-factor models try to identify variables that are good indicators of bad vs good times - such as market return, price/earnings ratios, the level of interest rates, or the value of housing - the performance of these models often varies over time. The overall difficulty is that the construction of the SDF by empirical risk factors is more an art than a science. There is no constructive method that explains which risk factors approximate the SDF in all possible future events reasonably well.

So far we did not consider how to choose risk factors for investment. We discuss some theoretical recommendations for the choice of risk factors. First, factors should explain common time variation in returns. Second, assuming that there exist a risk-free rate  $r_f$  and  $M = a + b'F$ , then the definition of the SDF implies for any asset  $k$  return  $r_k$ :

$$
b ^ {\prime} \mathrm {c o v} (r _ {k}, F) = 1 - \frac {E (r _ {k})}{1 + r _ {f}}.
$$

For all assets earning a different expected return than the risk-free rate, the vector of covariances between the risk factor and the asset's return must be non-zero. Regressing

the returns on the candidate pricing factors, all assets should have a statistically significant loading on at least one factor. This choice recommendation is model independent.

The next recommendation is based on the APT model. APT not only requires that factors explain common variation in returns but the theory suggests that these factors should also explain the time variation in individual returns. This ensures that the payoff and hence the price of an asset can be approximated as the pay-off of a portfolio of factors. Therefore, the idiosyncratic terms should be as small as possible. Performing a PCA, the largest eigenvalues follows and hence the main factors.

# 3.7.5 Arbitrage Pricing Theory (APT)

Ross's (1976b) arbitrage pricing theory (APT) starts from the SML and no arbitrage. Like the CAPM, APT assumes that asset prices are based on systematic risk and not total risk. But different to the CAPM (i) it not assumes that all investors behave alike, i.e. not all investors need to keep the same portfolio, (ii) nor that the tangency portfolio or capital-weighted market portfolio is the only risky asset that investors hold and (iii) that more factors than the single market factor act as risk sources: APT is based on the idea that portfolios of stocks can be good approximated as linear combinations of returns of a few basic major macroeconomic factors. Specifically, the assumptions underlying the APT are:

- security returns can be described by a linear factor model;  
- there are sufficiently many securities available to diversify away any idiosyncratic risk: In a large and diversified portfolio the idiosyncratic risk contributions should be negligible due to the law of large numbers - investors holding such a portfolio require compensation only for the systematic part.  
- arbitrage opportunities do not exist.

APT does not assume an economic equilibrium nor the existence of risk factors driving the opportunity set for investments. While CAPM and ICAPM represent the SDF in terms of an affine combination of factors, APT decomposes returns into factors. CAPM explains the risk premia; APT leaves the risk premia unspecified.

Assume that there are  $k$  factors  $F_{k}$  with a non-singular covariance matrix  $C_F$  and  $N >> F$  returns  $R_N$ . Projecting the returns orthogonally on the set generated by the factors plus a constant:

$$
R _ {i} = E (R) _ {i} + \operatorname {c o v} (F, R _ {i}) C _ {F} ^ {- 1} \mathbf {F} + \epsilon_ {i} \tag {3.133}
$$

with  $\mathbf{F}_k = F_k - E(F_k)$  the centred factors and idiosyncratic risks  $\epsilon_i$  satisfying  $E(\epsilon_j) = \operatorname{cov}(F_k, \epsilon_j) = 0$  and  $E(\epsilon_j \epsilon_k) = 0$  for all  $j \neq k$ . The restriction that the residuals should be uncorrelated across assets implies:

$$
C = \beta^ {\prime} C _ {F} \beta + C _ {\epsilon} \tag {3.134}
$$

where  $C_{\epsilon}$  is a diagonal matrix with non-zero elements the variances of the idiosyncratic risks,  $C_F$  is the factor covariance matrix and  $\beta$  is a  $m \times N$  matrix of betas.

Definition 67. The returns in equation (3.133) have a factor structure with the factors  $F_{1}, \ldots, F_{k}$  if all residuals are uncorrelated.

To understand APT, assume first that idiosyncratic risks are zero in (3.133). We can derive an exact beta pricing model starting from the fundamental asset pricing equation  $E(MR_{i}) = 1$ . Writing the expectation product as single expectations plus the covariance term, inserting (3.133) for the return and rearranging implies the beta pricing equation (3.132) in Proposition 65:

$$
E (R _ {j}) = \kappa + \lambda^ {\prime} \beta_ {j} \tag {3.135}
$$

If the residuals are not zero, we get

$$
E \left(R _ {j}\right) = \kappa + \lambda^ {\prime} \beta_ {j} - \frac {E \left(M \epsilon_ {j}\right)}{E (M)} \tag {3.136}
$$

with the additional the pricing error. The idea is  $E(M\epsilon_{j}) \to 0$  if we increase the number of uncorrelated assets, see Proposition 4. The analysis requires a precise mathematical modelling under the assumption that no arbitrage holds. The APT theorem states that if there are enough assets then the beta pricing equation is approximately true for most assets.

# Example

Consider two assets with two different factor loadings but the same factor  $\mathbf{F}$ . What relationship holds between their expected returns if there is no arbitrage? Let  $\phi$  be the weight of the first asset in a portfolio and  $1 - \phi$  the weight of the second one. The portfolio return reads (we set for simplicity idiosyncratic risk to zero)

$$
R _ {P} = \left(\mu_ {R, 1} + \beta_ {1} \mathbf {F}\right) \phi + \left(\mu_ {R, 2} + \beta_ {2} \mathbf {F}\right) (1 - \phi).
$$

We choose  $\phi$  such that the portfolio return becomes

$$
R _ {P} = \frac {(\mu_ {R , 1} - \mu_ {R , 2}) \beta_ {1}}{\beta_ {2} - \beta_ {1}} + \mu_ {R, 2}
$$

This is a risk-free portfolio. Therefore, the return must be equal to the risk-free rate  $\mu_0$ . Rearranging,

$$
\frac {\mu_ {R , 1} - \mu_ {0}}{\beta_ {1}} = \frac {\mu_ {R , 2} - \mu_ {0}}{\beta_ {2}} = \lambda .
$$

Since the two expressions are the same for any asset, the ratios must be equal to a constant value  $\lambda$ ; the factor risk premium since it represents the expected excess return above the risk-free rate per unit of risk (as quantified by  $F$ ). The two assets have the same factor risk premium. Otherwise, arbitrage is possible. This equality can be rewritten as

$$
\mu_ {R} = \mu_ {0} + \beta \lambda , \tag {3.137}
$$

the exact beta factor relation holds.

# 3.7.6 Pricing Real-Estate Risk

We apply the asset pricing theory to real estate risk. This is an important risk source. In the US, the value of real estate owned by households and non-profit organizations in 2017 was USD 23.8 tr. We state some characteristics of real estate risk.

First, the market for real estate is often larger in valuation than the entire stock markets. In Switzerland, the value of real estate in (2014) was about 4 to 5 times larger than the value of all companies listed on the SIX exchange. Second, pure real estate risk is illiquid. The annual turnover of private owned real estate is in the low one-digit domain. Table 3.22 illustrates the illiquidity using data from the state of Zurich in 2011.

<table><tr><td>Number of houses in the state</td><td>690’000</td></tr><tr><td>Of which property</td><td>210’000 (30%)</td></tr><tr><td>New constructions in 2011</td><td>11’000 (1.6%)</td></tr><tr><td>Of which property</td><td>4’300 (40%)</td></tr><tr><td>Arm’s-length transactions</td><td>7’110</td></tr><tr><td>Resales</td><td>3’700 (1.7%)</td></tr></table>

Table 3.22: Liquidity for the state of Zurich.

The holding period median value of the private persons' homes is 25 years. Hence, the construction of a repeated sales index, which would be a transaction based price index, is not meaningful. Third, one cannot short property. Fourth, historically real estate risk is the most prominent a frequent driver for a financial crisis. Fifth, friction costs for direct real estate transaction are high. Sixth, since each property is unique, the construction of a standardized asset which can be aggregated to form an index is not a trivial task. Summarizing, real estate markets are incomplete and inefficient. Hence pricing real estate risk is more an art than a science.

What do we mean by real estate risk? Figure 3.20 provides an overview of investments and consumption in the real estate asset class.

# 3.7.6.1 US market: Repeated Sales Index versus Constant Quality Index

Case and Shiller (1994) tested the efficiency of the US market for single-family homes. Since resales of houses occur over time periods of decades, the usual tests that work for equity could not be applied. The quarterly published 'Constant Quality Index' produced

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/39cd1055d8196679e0d153bacbe54d9aa86ed73ab29f1b0a45535388fb53f4bc.jpg)  
Figure 3.20: Different use of the real estate asset class (Extension of Zürcher Kantonalbank (2015)).

by the US Census Bureau is compared with the Case and Shiller 'Repeat Sales' index in Figure 3.21. price index (Case and Shiller [1987, 1989, 1990]). A constant quality index corrects for different quality characteristics  $z_{k}, k = 1, \ldots, K$  such as size of the property, view, shopping facilities, number of bedrooms, location, etc. 'Hedoni' refers to the concept that the value of a home is given by the value of the constituent components of a home. Therefore, hedonic house prices are not inherently skewed by for example people shifting to larger properties: Without accounting for change in the parameter size, property prices increase due to this change in demand or if say the characteristic 'nearness to the city center' changes due to say new traffic possibilities, than only this characteristic's price changes. With enough data points a regression model can be used to determine the relationship between each of these parameters and the value of a home. In the time dummy linear model, a single hedonic regression equation is estimated from data across characteristics starting for quarterly periods  $0, 1, \ldots, T$ . The dummy variable takes the value  $\delta^t$  if the house is sold in period  $t \neq 0$ , and zero otherwise. For property  $j$  with prices  $S$  in two adjacent periods  $t, t + 1$  the regression reads<sup>27</sup>

$$
S _ {j} ^ {t, t + 1} = \beta_ {0} + \delta^ {t + 1} D _ {j} ^ {t + 1} + \sum_ {k = 1} ^ {K} \beta_ {k} z _ {k, j} ^ {t, t + 1} + \epsilon_ {j} ^ {t, t + 1} \tag {3.138}
$$

with  $\beta$  the estimated weights of the characteristic. More general models account for time varying beta over longer time periods. Hedonic models contain between 20 and 30

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c871e5067b52390dd355e15f4b1a0e6b97aa6b277a562da89682e0be5b98f6de.jpg)  
Figure 3.21: Two indices of US home prices divided by the Consumer Price Index (CPI-U), both scaled to  $1987 = 100$ . Monthly observations in the period 1987-2013 are considered (Shiller [2014]).

different characteristics for private property.

Figure 3.21 shows that both indices are smooth over time. For real estate price momentum dominates price volatility. The boom in house prices after 2000 is visible in the Case Shiller index but not in the Census Constant Quality Index. The reason is that new homes are built where it is possible and profitable to build them. This is often not the case in the expensive area of a city. Therefore, the constant quality index level through time is more accurately determined by simple construction costs if as in the US there is a huge reservoir of cheap land.

# 3.7.6.2 Constant Quality Index: Greater London and Zurich Area

Figure 3.22 shows the house price indices in the Greater London and Zurich areas. Both indices, the Halifax and the ZWEX, are transaction based hedonic models which include condominiums and single-family houses.

Figure 3.22, left panel, shows that in the mid-1990s house prices in Zurich and London started to grow at different rates. This is in line with London becoming the world's major financial center. In the GFC, the greater vulnerability of the Halifax index is visible while during the whole GFC house prices in Zurich never fell.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d08ffa8d33a1daa50f232cb19876e738167d7b9ab42ebe34fbd46778a3df5ff3.jpg)  
Figure 3.22: Left Panel: The Halifax Greater London price index and the Zurich price index (ZWEX) (ZKB and Lloyds Banking Group). Right Panel: Halifax Greater London price index and forwards on the index (Syz and Vanini (2008)).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/6f38e1030f258f583dc84b55f7a6bcd86aea26072b8f02d5c46cc499a41b281e.jpg)

The right panel shows forwards on the Halifax index at different time periods in the GFC period. In May 2007 the forecast was still on an increasing value of the house prices: Market participants failed to identify the GFC. During the GFC, forward levels of the index sharply corrected in each month. The culmination point was October 2008 where the forward levels were predicted too low but the turning point of the index was identified almost perfectly.

The EMH requires that markets are free of frictions. But in housing markets there are many sources of friction. Figure 3.23 shows friction sources for different types of real-estate investments in Switzerland. 'Direct' means that investors buy houses, 'indirect' means to invest in stocks that are related to housing or investment funds and and 'derivative' refers to property derivatives defined on property indices.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4ea4ee91bc60e737278b944263a78fa830f101a476a00c8f546eba82a438e764.jpg)  
Figure 3.23: Frictions for investment in real-estate markets in Switzerland. Lex Koller is a federal law which restricts the purchase of property by foreigners (Syz and Vanini [2008]).

# 3.7.6.3 Investment, Derivatives

Property derivatives on property indices are niches products compared to REITs in the US or property investment funds. Property derivative markets never really established. The first reliable indices which overcame the standardization problem was launched 1994 in London. The markets started in 2005 in the US where again OTC products dominated. The CME started to launch 2006 futures with very limited success for residential investment based on the S&P/ Case-Shiller Index. The most common transactions are swaps. Derivative instruments allow investors to gain exposure to the real estate asset class, without having to buy or sell properties by replacing the real property with the performance of a real estate return index. Most popular instruments are swaps, total return swaps while options are much less established.

Consider the case of derivatives on the residential, hedonic real transactions property index ZwEX of Zurich Area. In 2006 warrants, calls and puts on the ZwEX, were issued to allow investors to protect home owner's capital against falling future house prices (index mortgages, i.e. ordinary mortgage plus a put on the real estate index) and to offer leveraged investments at the same time. Fix a home owner which seeks protection from falling house prices at the end of his 5y fixed mortgage contract. He buys a put option on the ZwEX, see Salvi et al. (2008). The put option should finance possible forced amortizations at maturity of the mortgage if ZwEX falls. To show the impact on capital

protection, consider a present house price of CHF 1 mn and a maximum loan-to-value (LTV) of  $80\%$ , i.e. the mortgage notional is CHF  $800'000$ . Suppose that house prices are down  $20\%$  after five years. Then,  $80\%$  LTV of CHF  $800'000$  means CHF  $640'000$ . Without a protective put, he is forced to amortize CHF  $160'000$ . The costs of the put option are 50 bps p.a. Figure 3.24 shows the effectiveness of the hedge for three different real estate house price evolutions. How can the bank as the issuer of put hedge its risk? To

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/831932482e03938ffb637b51ab518ca786084266b8ac7ae8ef3b510bdcade068.jpg)  
Figure 3.24: Effectiveness of the put option hedge for a 5 year mortgage under three different real estate price scenarios (Syz and Vanini (2008)).

achieve this, a cross hedge between homeowners seeking protection and investor betting on house prices by buying options from the trading department applies. To be effective, such a cross hedge assume that the demand on the mortgage and trading side are similar. But while there was a strong belief that Zurich house price will drop in the GFC period from investors buying puts, homeowners did not shared this belief. This disequilibrium led to a failure of the product innovation. One reason was nearness. The buyer of a put during or after the GFC has a short time horizon while the homeowner has long time horizon in mind, i.e. when the mortgage contracts are due.

A second example of property derivatives are property swaps, i.e. OTC contracts, see Geltner and Miller. Assume that a small firm BUY wants to invest in real estate without facing high costs and illiquity of a direct investment. The firm SELL is over-invested in real estate and wants to sell real estate market risk exposure. No party intends to buy or sell objects they are actually invested to circumvent large transaction costs and to keep regular income stream from the physical objects. A NCREF Appreciation Swap

('Swap') allows BUY to swap a fixed return for NPI appreciation return, i.e. the return of the property index, and SELL takes the short position of BUY, pays the floating, quarterly NPI appreciation return and receives from BUY quarterly the fixed return. Netting of the payments occurs quarterly and notional amounts are not exchanged.

We price the Swap using a replication portfolio and no arbitrage. We assume that it is possible to replicate a NPI return with a portfolio of assets, that there are no frictions and short-selling is possible. Although these assumptions are violated in practice, the pricing defines a benchmark which can be compared to the second equilibrium pricing. The assumptions allow us to construct a risk-less hedge using the replicating portfolio and the swap. We consider two periods,  $t, t + 1, t + 2$ ,  $I_{t}$  the value level of NPI,  $E[y]$  expected income of NPI with  $y$  the same random income in each period and  $S$  the unknown fixed leg / spread of swap.

<table><tr><td></td><td>t</td><td>t+1</td><td>t+2</td></tr><tr><td>Short Index</td><td>It</td><td>-gt+1It-Et[y]It</td><td>-gt+2It-E[y]It-I</td></tr><tr><td>Risk-less ZCB</td><td>-RfIt</td><td>0</td><td>It</td></tr><tr><td>Long Swap</td><td>0</td><td>gt+1It-SIt</td><td>gt+2It-SIt</td></tr><tr><td>Hedge</td><td>(1-Rf)It</td><td>-(S+E[y])It</td><td>-(S+E[y])It</td></tr></table>

Table 3.23: Risk-less hedge Swap, long position of BUY. ZCB means Zero Coupon Bond,  $D$  discounting with the risk free rate and  $g$  is the growth rate of NPI.

The  $t + 1$  and  $t + 2$  part of the hedge are risk-less. Setting the NPV of the hedge equal to zero, this means excluding arbitrage, implies for the fixed leg

$$
S = R _ {f} - E _ {t} [ y ]. \tag {3.139}
$$

The fixed spread  $S$  is independent of the NPI level value and only the borrowing costs of the investor BUY as well the expected income stream matter. If we consider a total return swap, i.e. all proceeds from the index are also exchanged, then expected income  $E_{t}[y]$  is also part of the index value and  $S = R_{f}$  follows using the same replication approach.

For the equilibrium valuation, we introduce the risk premium

$$
F _ {I} = E [ R _ {I} ] - R _ {f}
$$

and decompose  $E[y] = E[R_I] - E[g]$  with  $E[g]$  the real estate appreciation rate. Then the fixed no-arbitrage spread

$$
S = E [ g ] - F _ {I},
$$

is equal to the expected index appreciation rate minus the risk premium. A no arbitrage argument is not allowed since it is not possible to short  $I_{t}$ . We assuming linear pricing rules in equilibrium. BUY expects the net return which consists of the NPI appreciation

return  $E^{BUY}(g)$ , minus  $S$  plus receives  $R_{f}$  from the covering bond position to be not smaller than the swap risk premia:

$$
E ^ {B U y} [ g ] - S + R _ {f} \geq R _ {f} + F _ {I}.
$$

SELL also considers his overall net return. It consists of  $S$  plus the expected return on his real estate portfolio  $E^{SELL}(R_S)$  which should be as close as possible to the return of the NPI minus NPI appreciation return  $E^{SELL}(g)$ . Since by assumption  $E[y]$  is constant and the NPI swap obligation is covered by the bond portfolio, net risk exposure is zero. Summarizing, SELL's requirement is:

$$
S - E ^ {S E L L} (g) + E ^ {S E L L} (R _ {S}) \geq R _ {f}.
$$

Connecting the two requirements implies the price range:

$$
R _ {f} - E ^ {S E L L} (R _ {S}) + E ^ {S E L L} (g) \leq S \leq E ^ {B U Y} (R) - F _ {I}.
$$

This is not an equilibrium condition since beliefs can differ. If beliefs are the same for BUY and SELL, then  $R_{S} = F$  and the two inequalities become the equality  $F = E[g] - F$ , i.e. the single price in the complete market using no-arbitrage follows. Assuming that the expectation of BUY of  $g$  is  $b$  bps higher than the market expectation and SELL expects  $g$  to be lower by  $-s, s \geq 0$ , bps below the market expectation, then  $S$  can vary between  $S \pm b + s$  bps. Clearly, infeasible beliefs are also possible. If say SELL assumes that market expectations will be lower than his expectations for example, then no  $S$  will exist.

# 3.7.7 Multi-Period Asset Pricing and Multi-Risk-Factors Models

If we consider equity with  $D = X$  the dividends, we get in many periods the fundamental value equation of the dividend discount model of corporate finance generalizing (5.1):

$$
S _ {t} = \sum_ {j = 1} ^ {\infty} E _ {t} \left(\frac {1}{(1 + R) ^ {j}} D _ {t + j}\right), \tag {3.140}
$$

with  $R$  the internal rate of return on expected dividends: For two stocks with the same expected dividends but different prices, the stock with the lower price has to have a higher expected return. Merton's (1973) multi-factor inter-temporal CAPM (ICAPM) generalizes to the case of several factors assuming:

- Investors choose an optimal consumption path and an optimal investment portfolio to maximize their lifetime expected utility.  
- Investors care about the risk factors market return  $R_{M}$  and so-called innovations  $Y$ .
- Innovation factors describe changes in investment opportunity which by definition is equal to the set of all attainable portfolios. Examples are changing volatilities, changing interest rates, or labour income. Innovations are orthogonal to the asset space generated by the market return.

In the Markowitz model, the investment opportunity set consists of all efficient and inefficient portfolios. If the investment opportunity set changes over time, then variables  $Y$  other than the market returns drive returns. Working without these factors trivializes human behavior and needs. Using market return only for example, all investors are jobless since no labor income exists. The possible change of the investment opportunity set for investors is more important for longer-term investment horizons than for shorter ones since the deviations from a static opportunity set can become larger for longer time horizons. The solution of the ICAPM model generalizes (5.3) to

$$
S _ {t} \left(R ^ {e}\right) = b _ {M} \lambda_ {M} + b _ {I} \lambda_ {I} = \Theta \operatorname {c o v} \left(R ^ {e}, R _ {M}\right) - \Omega \operatorname {c o v} \left(R ^ {e}, R _ {I}\right) \tag {3.141}
$$

where  $\Theta$  is the average relative risk aversion of all investors and  $\Omega$  is the average aversion to innovation risk. The mean excess returns are driven by covariances with the market portfolio and with each innovation risk factors. The geometric intuition of this beta pricing model is the same as in the case with fixed opportunity sets. The first term in (3.141) is mean-variance efficient but the total portfolio is no longer mean-variance efficient. Economically, the average investor is willing to give up some mean-variance efficiency for a portfolio that better hedges innovation risk. The mutual fund theorem of the Markowitz model generalizes to a  $K + 2$  fund theorem if there are  $K$  innovations risk sources. Investors will split their wealth between the tangency portfolio and  $K$  portfolios for innovation risk.

# 3.8 Applications

# 3.8.1 Low Volatility Strategies

Low-beta stocks outperform in many empirical studies high beta stocks and volatility negatively predicts equity returns (negative leverage effect), see Haugen and Heins (1975), Ang et al. (2006), Baker et al. (2011), Frazzini and Pedersen (2014), Schneider et al. (2016). This means, high beta (risk) is not rewarded as it should be according to the asset pricing equations. These define the beta and volatility low risk anomalies.

There are different ways how to rationalize these anomalies by enlarging models which lead to the anomalies. Schneider et al. (2016) show that taking equity return skewness into consideration rationalize these anomalies. Thy generalize the CAPM which serves as an approximation and allows for higher moments of the return distribution. This leads to skew-adjusted betas. They use credit worthiness of the firms as the source for skewness in returns: The higher a firm's credit risk, the more the CAPM overestimates the firm's market risk, because it ignores the impact of skewness on asset prices (Schneider et al.

# 3.8. APPLICATIONS

(2016)). Benchmarked returns against the CAPM then appear to be too low since the CAPM fails to capture the skewness effect. Formally, starting with (5.3), defining the regression coefficient  $\beta_{i} = \mathrm{cov}(M,R_{i}) / \mathrm{var}(M)$  and the variable  $\lambda = -\mathrm{var}(M) / E(M)$ , we get the equivalent equation to (5.1)

$$
E _ {t} (R _ {i} ^ {e}) = \frac {\operatorname {c o v} (M , R _ {i})}{\sigma (M)} \frac {\sigma (M)}{E (M)}. \tag {3.142}
$$

Schneider (2015), Kraus and Litzenberger (1976) and Harvey and Siddique (2000) define the risk premium as the difference between the expected value of a derivative  $X$  based on the historical probability  $P$  and on the risk neutral probability  $Q$ :

$$
\text {R i s k} = E _ {t} ^ {P} \left(X _ {T}\right) - E _ {t} ^ {Q} \left(X _ {T}\right). \tag {3.143}
$$

The two probabilities  $P, Q$  can be related to each other by the state price density  $L$ :<sup>28</sup> f

$$
L = \frac {d Q}{d P}, E ^ {P} (L) = 1. \tag {3.144}
$$

To illustrate the technique, consider two states with probabilities  $P = \left(\frac{1}{2},\frac{1}{2}\right)$  and  $Q = (1/3,2/3)$ . Then in state 1,  $L_{1} = \frac{1/3}{1/2}$ . Therefore,

$$
E ^ {P} (X) = p _ {1} X _ {1} + p _ {2} X _ {2} = \frac {1}{2} (X _ {1} + X _ {2}) = E ^ {Q} [ L X ] = q _ {1} L _ {1} X _ {1} + q _ {2} L _ {2} X _ {2}.
$$

Using  $M = L$  in (3.142) and the risk premia for the market risk return we get:

$$
E _ {t} \left(R _ {i} ^ {e}\right) = \frac {\operatorname {c o v} \left(L , R _ {i}\right)}{\operatorname {c o v} \left(L , R _ {M}\right)} E _ {t} \left(R _ {M} ^ {e}\right). \tag {3.145}
$$

The expected return on asset  $i$  is proportional to the expected excess return on the market, scaled by the assets covariation ratio with the pricing kernel - the true beta. Since  $L$  is not observable, the authors approximate  $L(R) \coloneqq E^{P}(L|R)$  in a power series in  $R$ . Using a linear and a quadratic approximation of  $L$  in (3.145) changes the true beta into a CAPM beta (linear case) or a skew-adjusted beta in the quadratic case.

… a firm's market risk also explicitly depends on how its stock reacts to extreme market situations … and whether its reaction is disproportionately strong or weak compared to the market itself. A firm that performs comparably well … in such extreme market situations, has a skew-adjusted beta that is lower relative to its CAPM beta…. investors require comparably lower expected equity returns for firms that are less co-skewed with the market. Schneider et al. (2016)

To incorporate time-varying skewness in the stock returns the authors consider corporate credit risk by using the Merton (1974) model. In this models, equity value at maturity date is an European call option on the firm value with strike equal to debt (which is a zero-coupon bond). For firms with high credit risk, the increased probability to default is reflected in strong negative skew of the return distribution. The forward value of equity is then given by the expected value of the call option discounted with the SDF  $M = L$  under  $P$ . This forward value defines with the call option value the firm's  $i$  excess equity return  $R_{i}^{e}$ . The expected gross return is given by (3.145) with the linear and quadratic approximation replacing the SDF. For the linear CAPM the betas increase with credit risk, i.e. the asset volatility or the leverage, and the firm correlation to the market. Comparing this beta with the skew-adjusted one, the latter one is in general larger. The difference increases the higher credit risk: The firm becomes more and more an 'idiosyncratic risk factor' and hence less connected to the market the stronger the skew is. In this sense the CAPM approximation overestimates expected equity returns, i.e. the return anomaly.

Schneider et al. (2106) apply their model implications to low risk anomalies, the so-called *Betting-Against-Beta* (BAB) strategy, see Frazzini and Pedersen (2014). BAB is based on the empirical observation that stocks with low CAPM betas outperform high beta stocks. Hence, investors believing in BAB goes long a portfolio of low-beta stocks and short a portfolio of high-beta stocks. To reach an overall zero beta, the strategy takes a larger long than short position. The strategy is financed with riskless borrowing. Frazzini and Pedersen (2014) document that the BAB strategy produces significant profits across a variety of asset markets. Using empirical evidence from 20 international stock markets, Treasury bond markets, credit markets, and futures markets Frazzini and Pederson (2014) ask:

- How can an unconstrained arbitrageur exploit this effect, i.e., how do you bet against beta?  
- What is the magnitude of this characteristic relative to the size, value, and momentum effects?  
- How is BAB rewarded in different countries and asset classes?

They find that for all asset classes alphas and Sharpe ratios almost monotonically decline in beta. Alphas are decreasing from low beta to high beta portfolios for US equities, international equities, treasuries, credit indices by maturity, commodities and foreign exchange rates. Constructing the BAB factors within 20 stock markets they find for the US a Sharpe ratio of 0.78 between 1926 and March 2012 which is twice as much as the value effect and still  $40\%$  larger than momentum. The results for international assets are similar. They also report that BAB returns are consistent across countries, time, within deciles sorted by size, and within deciles sorted by idiosyncratic risk and are robust to a number of specifications. Hence, coincidence or data mining are unlikely

explanations.

The BAP strategy is rationalized in the model of Schneider et al. (2016) as follows. The CAPM betas increase for fixed credit risk (fixed volatilities and leverage) with the firm's correlation to the market: buy stocks with low and sell stocks with high correlation to the market. The alpha of this strategy, the excess expected return relative to market covariance risk, is given by the firm's expected return for the skewness. These typically positive alphas increase with increasing credit risk. Summarizing, the BAB returns can be directly related to the return skewness induced by credit risk.

# 3.8.2 What Happens if an Investment Strategy is Known to Everyone?

We follow Asness (2015) who considers the value risk factor - that is to say, bets that cheap stock investments will beat expensive investments. What happens to a strategy if it becomes more and more widely known? Intuitively, at the beginning of a strategy one faces true alpha which is expected to move towards a beta strategy the wider the strategy is used. But even a public known strategy can continue working for different reasons. First, the investor is receiving a rational risk premium, i.e the strategy exists in equilibrium. If the long (cheaper) stocks are more risky than the short and more expensive one on a portfolio level which cannot be diversified away, then it is rational that there is a persistent risk premium. A second reason is behavioural: Investors make from a rational point of view errors. The long stocks have a higher expected return not because they are riskier, but because of these errors - the stocks are too cheap and one earns a return if they return to their rational value.

The relative impact of both explanations can vary over time. During the tech bubble of 1999-2000 for example, cheap value stocks - which typically are cheaper because they are riskier - were cheaper because investors were making errors.

The two explanations behave differently when a strategy becomes known. In the rational model the value strategy still works but at a level consists with the equilibrium demand and supply side. The equilibrium property conserves both the expected return and the risk of the strategy.

In the behavioural explanation, the risk source is not systematically linked to the return in equilibrium. There is no systematic demand and supply as in the equilibrium model to guarantee that the risk premium will not go away. It is therefore difficult to be convinced that risk remains stable over time.

Asness (2015) compares these two different views using historical data and the Sharpe ratio. If a strategy has an impact on the risk premia if it becomes more common, the Sharpe ratio is expected to fall. Either because excess return diminishes or because risk increases. With regard to the returns, one could argue that if the value strategy becomes more popular, then the 'value spread' between the long and short sides of the strategy

gets smaller. This spread measures how cheap the long portfolio is versus the short portfolio. If more and more investors are investing in this strategy, then both sides face a price movement - long is bid up and short is bid down. This reduces the value spread.

The author uses the FF approach for value factor construction. He calculates the ratio of the book-to-price ratio of the cheapest one-third over the BE/ME of the most expensive one-third of large stocks. Clearly, cheaper stocks always have a higher BE/ME than the expensive stocks. But the point is to compare how the ratio of large-cheap over large-expensive changes over time as an approximation of the attractiveness of the value strategy. Considering 60 years of data, the ratio is very stable, with a 60-years median value of 4. There is no downward or upward trend. The only two periods during which the ratio grew significantly - reaching a value of 10 - correspond to the dot-com bubble and the oil crisis of 1973. This measurement shows little evidence that the simple value strategy was arbitraged away in the last 60 years.

To analyze the risk dimension, the annualized, rolling, 60-month realized volatility of the value strategy for the last 56 years is considered. Again, the dot-com bubble is the strongest outlier followed by the GFC and the '73 oil crisis. There is again little evidence that the volatility of the strategy is steadily rising or falling. The attractiveness of a strategy is best measured by the inand outflows of investment in the strategy. Increasing inflows should, on a longer time scale, increase the return of a strategy and the opposite holds if large outflows occur. This was not observed in the above return analysis.

# 3.8.3 Short-Term versus Long-Term Investment Horizons

This section is based on Campbell and Viceira (2002). The theoretical set-up allows us to discuss the relevant practical questions or observations:

- Financial planners often recommend investors with a longer investment horizon to take more risks than in the case of a short time horizon.  
- Conservative investors are advised to hold more bonds relative to stocks than aggressive investors. This contrasts the constant bond - stock ratio in the tangency portfolio of the CAPM. This is the asset allocation puzzle.  
- Judgement of risk may be different for long-term and short-term investors. Cash which is considered risk free for the short term becomes risky in the longer-term since it must be reinvested at an uncertain level of real interest rates.

# 3.8.4 Time-Varying Investment Opportunities

When investment opportunities vary, optimal long-term portfolio choice is different from myopic portfolio choice. Investment opportunities can vary because market factors do so

(interest rates, volatility, risk premia) or because non-market factors vary (labor income).

We consider the case of time-varying short-term interest rates. An investor with constant relative risk aversion maximizes his consumption paths by investing in a single risky equity asset and a risky short-term rate asset. The optimal investment in the risky asset in (3.14) reads

$$
\phi (t) = \frac {\mu_ {t} - r _ {t}}{\sigma_ {t} ^ {2}} \mathrm {R R A} ^ {- 1} + (1 - \mathrm {R R A} ^ {- 1}) \frac {\operatorname {c o v} \left(I _ {t + 1} , - E _ {t} \left(I _ {t + 1}\right)\right)}{\sigma_ {t} ^ {2}} \tag {3.146}
$$

with  $I_{t + 1}$  the short-term interest rate at time  $t + 1$ .

If the interest rate return is IID, then the optimal strategy is the myopic one, i.e. the second is zero. Assume returns are not IID. If the investor becomes more risk averse,  $\mathrm{RRA}^{-1}$  tends to zero. A conservative investor will not invest in the risky asset to capture its short-term risk premium but rather fully hedge the future risk of the risky asset. Hence, short-term market funds are not a risk-less asset for a long-term investor. Campbell and Viceira (2002) show that the risk-less asset is in this case an inflation-indexed perpetuity or console. Note that for all results an individual investor's viewpoint is considered buy not an equilibrium. Hence, possible equilibrium feedback effects on the asset prices and returns are missing.

Predictable asset returns lead to a hedging demand. If equity is predictable, there will be an inter-temporal hedging demand for stocks. Campbell and Viceira (2002) consider a model where long-term investors face a time varying opportunity due to changing interest rates or changing equity risk premia. A striking result is that a conservative investor will hold stocks even if the expected excess return of the stock is negative. How is he compensated for doing so? We first assume that the covariance between risky asset returns at two consecutive future dates is negative. This captures that equity returns are mean-reverting: an unexpectedly high return today reduces expected returns in the future. This describes how the investment opportunities related to equity vary over time. If the average expected return is positive, the investor will be typically long on stocks. Given a negative correlation, for stocks with a high return today future return will be low and hence the investment opportunity set deteriorates. The conservative investor wants to hedge this deterioration. Stocks are just one asset that delivers increasing wealth when investment opportunities are poor. Figure 3.25 illustrates, for a conservative investor, three alternative portfolio rules.

The horizontal line represents the optimal investment rule if the expected excess stock return is constant and equal to the unconditional average expected excess stock return. The TAA is the optimal strategy for an investor who observes, in each period, the conditional expected stock return. The myopic strategy and TAA cross at the point at which the conditional and unconditional returns are the same. The TAA-investor is a myopic investor with a one-period horizon. The SAA line represents the optimal investment of a long-term investor. There is a positive demand for stocks even if the

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0af5d0f7f4e00db32852b31da48589c456c5719108b303202b4400fd4393df33.jpg)  
Figure 3.25: Portfolio allocation to stocks for a long-term investor, a myopic investor, and for a CIO choosing the TAA (Campbell and Viceira [2002]).

expected return is negative. This reveals that the whole discussion in this section can be seen as describing the structure of strategic asset allocation (SAA). In fact, Formula (3.14) can be transformed as follows:

$\phi (t) =$  Short-Term Weight  $^+$  Opportunistic Weight  
= Short-Term Weight - Long Run Myopic Weight  

+ Long Run Myopic Weight + Opportunistic Weight (3.147)

The long-term investor should hold long-term, inflation-indexed bonds and increase the average allocation to equities in response to the mean-reverting stock returns (time-varying investment opportunities). Empirical tests suggest that the response to changing investment opportunities occurs with a higher frequency for stocks than for the interest rate risk factor. Therefore, this long-term weight or SAA should be periodically reviewed and the weights should be reset.

# 3.8.5 Model Portfolios

Whether or not investors use long-term investments as described in the last sections depends on constraints taken from WEF (2011):

1. Liability profile - the degree to which the investor must service short-term obligations, such as upcoming payments to beneficiaries.
2. Investment beliefs - whether the institution believes long-term investing can produce superior returns.  
3. Risk appetite - the ability and willingness of the institution to accept potentially sizable losses.  
4. Decision-making structure - the ability of the investment team and trustees to execute a long-term investment strategy.

Comparing this with optimal investment formula (3.15), point 3. is captured by risk aversion, 2. defines the asset universe selection of the model and 1. is part of the utility function.

The WEF (2011) report considers the question who is the long-term investors. They build the following five categories. Family offices with USD 1.2 trillion AuM, endowments or foundations with USD 1.3 trillion AuM, SWFs with USD 3.1 trillion AuM, DB pension funds with USD 11 trillion AuM and five insurers with USD 11 trillion AuM. Matching these different types of investors to the above listed four constraints leads to the following long-term investment table (Source for the table is WEF (2011) and the many sources cited therein):

<table><tr><td>Investor</td><td>Liability constraint</td><td>Risk appetite</td><td>Decision</td><td>Estimated</td></tr><tr><td>Family offices</td><td>In perpetuity</td><td>High</td><td>Low</td><td>35%</td></tr><tr><td>Endowments</td><td>In perpetuity</td><td>High</td><td>Low</td><td>20%</td></tr><tr><td>SWFs</td><td>In perpetuity</td><td>Moderate</td><td>Moderate</td><td>10%</td></tr><tr><td>DB pension funds</td><td>D 2-15 yrs</td><td>Low</td><td>High</td><td>9%</td></tr><tr><td>Insurers</td><td>D 5-15 yrs</td><td>Low</td><td>High</td><td>4%</td></tr></table>

Table 3.24: Decision represents the decision making structure,  $\overline{D}$  the average duration and Estimated the estimated allocation to illiquid investments (WEF [2011]).

The following model portfolio construction of Ang et al. (2018) provides an a practitioner's approach to long and short term investment in asset classes.

Their model portfolios are parametrized by investor's preferences such as risk tolerance and the selection of the asset universe. Their construction combines three portfolios: A performance benchmark reflecting investor's risk appetite, a construction of the strategic model relative to the benchmark which reflects long-term view on market and finally a tactical model portfolio is considered mimicking short-term views.

The benchmark portfolio  $\phi_B$  is a fixed equity-bond portfolio, say 80/20. The chosen fraction mimics risk tolerance of the investor. Such benchmarks can be implemented at low costs and the performance of more complicated portfolio can be measured without difficulty. The strategic portfolio  $\phi_S$  is the solution of a mean-variance optimization problem relative to  $\phi_B$  where both the risk aversion and covariance matrix are long-term

parameters. Several constraints are used such as equalizing the equity components of the strategic to the benchmark portfolio, long-only, full-investment and many more. The short-term or tactical portfolio  $\phi_S$  also solves a mean-variance problem where the short-term expected returns and covariance matrix parameters enter. The two main constraints are  $\langle \phi_S, e \rangle = 0$ , i.e. it is a zero-dollar long-short portfolio which shapes the strategic allocation, and  $\langle \phi_S, C_S \phi_S \rangle = 1$ , i.e. the short-term risk aversion follows from this constraint. This short term portfolio is weighted by market signals implying the so-called long-short combined portfolio  $\phi_C = \langle w, \phi_S \rangle$  where the weights  $w_i$  add up to one. Adding  $\phi_C + \phi_S$  defines the target portfolio  $\phi^*$ . Finally, the model portfolio  $\phi_M$  is the portfolio which minimizes the variance  $\langle (\phi - \phi^*, C_S (\phi - \phi^*)) \rangle$  subject to the full-investment constraint and linear constraints for the asset classes.

The authors use liquid ETFs to implement the approach. Besides the broad equity and bonds which enter the benchmark portfolio they use ETFs for the styles momentum, minimum volatility, value, quality and size. These more complicated indices are added in the strategic portfolio and the tactical portfolio. Figure 3.26 illustrates their model portfolio construction.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c68a2e9284d727a6f1486e3521167dab15bad31052735c57843699c070e215eb.jpg)  
Figure 3.26: Tactical U.S. equity model portfolio construction process. White MSCI USA Index, Red MSCI USA Minimum Volatility Index, Blue MSCI USA Momentum Index, Green MSCI Risk Weighted Index, Light Blue MSCI Value Index. (Ang et al. (2018)).

The figure shows that the start is to choose performance benchmark reflecting the preferences, i.e. blending with MSCI USA Minimum Volatility Index the MSCI USA

Index. Active risk of 250 bps relative to the performance benchmark is added in the strategic model portfolio. For the model portfolio capturing short-term tactical views on the chosen style, the factors are re-weighted relative to the strategic portfolio. This means to add additional an average of 110 bps risk. The model is tested full amount of active risk relative to the performance benchmark is approximately 300 bps. The model is tested using data from Jan 2000 to Jun 2017. Note that not all styles existed for the whole period, i.e. the index values are then theoretically calculated. The final model portfolio generated an annual return of  $8.9\%$ , outperforming the performance benchmark by  $3.4\%$  per year. The outperformance is attributed to two sources. The strategic portfolio tilts the factors which possess inherent and persistent risk premia. Second, the short-term indicators have some ability to predict factor returns. These time-varying active positions versus the strategic benchmark generate excess return.

Comparing this approach with the general optimal decision making formula, the two components of long term and short term are present. The way how they enter in the final model portfolio is a multi-stage process which consists of several plausible particular optimizations. Why the whole approach should be optimal at all is not considered at all. Furthermore, since one period decisions are made in each model type, risks are not distributed over time in an optimal way but in a kind of a static long term part and a varying short-term allocation.

# 3.8.6 Fallacies in Long Term Investment

When asset returns are IID, the variance of a cumulative risky return is proportional to the time horizon implying that the standard deviation is proportional to the square root of the time horizon (the square-root rule). Since the Sharpe ratio uses standard deviation, the ratio grows with the square-root of the time horizon. It is therefore tempting to increase the investment time horizon to increase the Sharpe ratio. This is a pseudo risk-return improvement since Sharpe ratios must always be measured over the same time interval.

Are equities less risky than bonds in the long run? Siegel states (Siegel [1994]):

It is widely known that stock returns, on average, exceed bonds in the long run. But it is little known that in the long run, the risks in stocks are less than those found in bonds or even bills! […] But as the horizon increases, the range of stock returns narrows far more quickly than for fixed-income assets […] Stocks, in contrast to bonds or bills, have never offered investors a negative real holding period return yield over 20 years or more. Although it might appear riskier to hold stocks than bonds, precisely the opposite is true: the safest long-term investment has clearly been stocks, not bonds.

Using the standard deviation, Siegel advices that long-term investors should buy and hold equities due to the reduced risks of stock returns at long maturities. But such a risk reduction only holds if stock returns are mean reverting: returns are not IID. But we

showed that a long-term buy-and-hold strategy is not optimal. The optimal strategy is a strategic market timing strategy with a mixture of myopic and hedging demand parts. If one follows Siegel's advice, the buy-and-hold investment strategy is not optimal. The other logical direction is also true: an optimal long-term investment strategy does not produce the suggested portfolio weights of Siegel.

The herding of pension funds. Pension funds consider, by their very definition, an infinite time horizon in their investments since each year there are new entrants to the pension scheme. As long-term investors, one would expect pension funds to focus on their long-term investment strategies. They should therefore behave differently than typical short-term asset-only managers. But there is a different investment motivation, which may counteract long-term investment behavior: the fear of underperforming relative to their peer group, which defines such funds incentive to herd.

Such herding may be stronger for institutional investors than for private investors. First, there is more trade transparency between institutional investors than between private investors. Second, the trading signals that reach institutional investors are more correlated and hence increase the likelihood of eliciting similar reactions. Finally, because of the size of the investments, institutional herding is more likely to result in stronger price impacts than is the herding of private investors. Therefore, to adopt a position, as an institutional investor, outside the herd will have a stronger return impact than would such a position if adopted by private clients.

Blake et al. (2015) study the investment behavior of pension funds in the UK, analyzing - on an asset-class level - to what extent herding occurs. Their data set covers UK private sector and public sector defined-benefit (DB) pension funds' monthly asset allocations over the past 25 years. They present information on the funds' total portfolios and asset class holdings, and are also able to decompose changes in portfolio weights into valuation effects and flow effects.

These authors find robust evidence of reputational herding in subgroups of pension funds. Similar pension funds follow each other. Public-sector funds for example follow other public-sector funds of a similar size. This follows from a positive relationship between the cross-sectional variation in pension funds' net asset demands in a given month and their net demands in the preceding month. A second result is that pension funds seem to use strong short-term portfolio rebalancing. Funds rebalance their long-term portfolios such that they match their liabilities. Since the maturity of pension fund liabilities increased, pension funds have systematically switched from UK equities to conventional and index-linked bonds.

The authors also find that pension funds mechanically rebalance their short-term portfolios if restrictions in their mandates are breached. They therefore, on average, buy in falling markets on a monthly basis and sell in rising markets. This is suboptimal given the optimal investment rule (3.141). Therefore, pension funds' investments fail to move

# 3.8. APPLICATIONS

asset prices toward their fundamental values, and hence do not stabilize financial markets. The market exposure of the average pension fund and the peer-group benchmark returns match very closely the returns on the relevant external asset-class market index. This is evidence that pension fund managers herd around the average fund manager: they could simply invest in the index without paying any investment fees.

As a final result, the pension funds studied captured a positive liquidity premium contrary to the expectation that these long-term investors should be able to provide liquidity to the markets and earn a risk premium in return.

# Chapter 4

# Portfolio Construction

# 4.1 Steps in Portfolio Construction

So far, we did not consider the logic of portfolio construction but used different portfolios in examples on an ad hoc basis. Several steps define portfolio constructions:

- Grouping of assets: How do we select the assets to form a portfolio?  
- Allocation of assets: How much wealth (weight) do we invest at each date in the specific assets?  
- Implementation of the allocation: How do we transform the asset allocation into trades?

The grouping of the assets or asset selection can be done on different levels:

- Asset classes (AC)  
- Single assets  
- Risk factors

The allocation of the assets can follow different rules:

- Optimal investment (Markowitz, CAPM, Black-Litterman, dynamic Merton-type models, mean-surplus maximization)  
Heuristic rules (EW, ERC, risk budgeting, factor investing)  
- Big data based methods

The implementation of the asset allocation can be done using different liquid assets:

- Cash products such as stocks and bonds  
- Derivatives such as futures, forwards and swaps
- Options  
- Mutual funds, certificates, ETFs, money market funds

Further implementation issues are liquidity, tax and compliance (eligibility, suitability and appropriateness).

# 4.2 Allocation - Foundations of Investment Decisions

The risk, return and diversification properties of assets of last sections were the result of ad hoc or experience based decision rules. We focus on optimal investment, i.e. rational decision-making in a probabilistic set-up (statistical models). We distinguish between optimal investment where people consume and invest (ALM) or where they only invest (asset-only).

We assume that investors use the expected utility criterion as a rule of choice: The higher the expected value is for an investment, the more is such an investment preferred. Like any mathematical model, expected utility theory is an abstraction and simplification of reality. There exists a large academic literature which reports about systematic violations of empirical behavior of investors compared to the expected utility theory predictions. A prominent theory is prospect theory by Kahneman and Tversky (1979) which is also an optimization problem but typical behaviors of models such as in Markowitz is enriched. But most investment theories used in practice are still based on expected utility theory.

The theory assumes that investors form correctly beliefs and that they choose optimal actions or decisions. The beliefs define the probabilistic set-up about the dynamics of future returns. One optimal action is the choice of the portfolio weights over time. The optimal decision is based on the investor's preferences which are represented by her utility function. Optimization requires to maximize expected utility subject to constraints such as the budget constraint. Decision problems in term of mathematical optimization are since decades an active field of research.

If investors face situations where risks (probabilities) are not known, uncertainty dominates. Then it makes no sense to rely on optimal investment theory but to use heuristic reasoning, see Section 4.2.4.

# 4.2.1 Statistical Models, Quadratic Optimization

Most classic investment models such as Markowitz, the CAPM, arbitrage pricing theory (APT) and Black-Litterman are asset-only models. With new technologies it is possible today to consider also the liabilities or goals for private investor or pension funds.

Preferences are described by a utility function  $u$  wealth  $W$ . Utility increases  $u'(W) > 0$  with increasing consumption (positive marginal utility) but marginal utility decreases,

$u''(W) < 0$ . These mathematical conditions imply that investors:

- Prefer more money to less;  
- Are risk averse.

We further assume that investors are impatient: They prefer 1 CHF today than 1 CHF tomorrow.

The mean-variance model was the first model in portfolio optimization based on the return-risk trade-off. Markowitz stated in 1952: The investor should consider expected return a desirable thing and variance of return as an undesirable thing. Three methods are common to operationalize this principle:

1. Either the investor chooses a portfolio  $\phi$  to maximize the expected return where volatility cannot exceed a predefined level  $\sigma$ , or  
2. Volatility is minimized such that the expected return cannot be lower than a predefined level  $r$  or  
3. A mean-variance utility function is optimized. The solution  $\phi$  is parametrized by the risk aversion,  $\theta$ .

All solutions are equivalent. We formalize the ideas. Consider  $N$  risky assets with a return vector  $R$  in a single period. The expected returns are  $\mu = E(R)$  and the covariance matrix  $C$  of the returns is given by

$$
C = E \left(\left(R - \mu\right) ^ {\prime} (R - \mu)\right).
$$

The objective is to maximize the quadratic utility function which reflects the trade-off between reward and risk:

$$
u (R) = \phi^ {\prime} R - \frac {\theta}{2} \phi^ {\prime} (R - \mu) ^ {\prime} (R - \mu) \phi .
$$

$\theta$  is the risk aversion of the investor.2 Taking the expectations

$$
E _ {P} (u (R)) = \phi^ {\prime} \mu - \frac {\theta}{2} \phi^ {\prime} C \phi .
$$

Optimization means to find a portfolio  $\phi$  which maximizes the above expected utility, i.e.

$$
\max  _ {\phi} E _ {P} (u (R)) = \max  _ {\phi} \left(\phi^ {\prime} \mu - \frac {\theta}{2} \phi^ {\prime} C \phi\right) \tag {4.1}
$$

with the solution

$$
\phi^ {*} = \frac {1}{\theta} C ^ {- 1} \mu . \tag {4.2}
$$

The matrix  $C^{-1}$  is the information matrix. The elegance of this formula, which is the simplest one in the Markowitz model, cannot be overestimated. Just plug in the information matrix and the expected return and you will get an optimal portfolio. But both inputs are not observable and hence must be estimated. What is the best way to do this? This led to a half century of academic research and to frustration by practitioners using this model. We consider the reasons in detail below. Suppose that there is only one risky asset and risk free asset with return  $\mu_f$ . Then the above optimal rule reads:

$$
\phi^ {*} = \frac {1}{\theta} \frac {\mu - \mu_ {f}}{\sigma^ {2}}. \tag {4.3}
$$

The fraction  $\frac{\mu - \mu_f}{\sigma^2}$  is the market price of risk. It is proportional to the Sharpe ratio.

An investor with zero risk aversion puts all the money in the asset with the largest expected return. If risk aversion is not zero and since risk is always positive, the higher risk, the lower the optimal level of expected utility. Formula (4.3) states that the optimal amount invested in each asset is given by a mix of the expected returns of all assets with the information matrix doing the mix. What is the intuition of how the information matrix acts? Does it favours diversification? Again, we consider this below.

The success of mean-variance optimization is mathematically due to the success of quadratic programming (QP) - easy to solve and available, powerful mathematical software, solving Since mean-variance optimization does not imply diversification, the meaningfulness of an allocation depends on the chosen constraints. Fortunately, many practical problems with constraints can be rewritten as QP problems. A quadratic programming (QP) is an optimization w.r.t. to a quadratic objective function and linear inequality constraints:

$$
\phi^ {*} = \arg \max _ {\phi} \phi^ {\prime} \mu - \frac {\theta}{2} \phi^ {\prime} C \phi , V \phi \leq Z \tag {4.4}
$$

where  $C$  is a  $N \times N$  matrix and  $V, Z$  are two matrices. The constraints  $V\phi \leq Z$  allows for equality constraints (budget - or full investment constraint), inequality constraints or band constraints  $a \leq \phi \leq b$  (asset class bounds in a TAA). QP problems are solved using active set, gradient projection and interior point methods.

Several practical variation of the Markowitz problem are in fact QP, see Perring and Roncalli et al. (2019) for details. The first one is to consider a general benchmark  $\mathbf{b}$ . The expected excess return or expected tracking error reads  $\mu()$  between an active managed portfolio  $\phi$  and the benchmark  $\mathbf{b}$

$$
\mu (\phi , \mathbf {b}) = (\phi - \mathbf {b}) ^ {\prime} \mu , \tag {4.5}
$$

where the difference

$$
\psi := \phi - \mathbf {b} \tag {4.6}
$$

defines the active bets of the investor. The tracking error volatility TE is by definition the volatility of the tracking error difference:

$$
\mathrm {T E} = \sigma (\phi , \mathbf {b}) = \sigma (\mathbf {e}) = \sqrt {(\phi - \mathbf {b}) ^ {\prime} C (\phi - \mathbf {b})}. \tag {4.7}
$$

Minimizing the tracking error volatility and maximizing the expected excess return (or the alpha) can be written as QP

$$
\phi^ {*} = \arg \max _ {\phi} \tilde {\phi} ^ {\prime} \mu - \frac {\theta}{2} \phi^ {\prime} C \phi , (4. 8)
$$

where  $\tilde{\phi}^{\prime} = \phi +\theta Cb$  is the regularized vector of expected returns, see below for regularization. Second, consider index sampling, i.e. to replicate an index portfolio  $\mathbf{b}$  with a smaller number of assets than the index. The goal is to minimize tracking volatility under some constraints such as full investment and long-only constraints which are linear. The extra constraint which assures that the number of assets is smaller than the index asset size can be written in the linear form

$$
\sum \chi_ {\{\}} \leq \mathrm {S i z e o f d e s i r e d a s s e t s}
$$

where  $\chi$  is the indicator function. Despite this non-linear function, the constraint is linear and hence the whole problem is of the QP type. Other relevant models consider a turnover constraint, i.e. the amount of sold and bought asset in an optimization is limited, or transaction constraints, that is the net expected portfolio by subtracting the bid and ask trading costs, is also a QP problem.

An insightful investor doubts that the probability law is known. He could therefore consider the investment situation where different probabilities matter in the portfolio choice problem. Then, uncertainty besides risk matter. Formally, let  $\mathcal{P}$  be a set of admissible probabilities. The optimization becomes

$$
\min  _ {P \in \mathcal {P}} \max  _ {\phi} E _ {P} (u (R)) = \min  _ {P \in \mathcal {P}} \max  _ {\phi} \left(\phi^ {\prime} \mu - \frac {\theta}{2} \phi^ {\prime} C \phi\right). \tag {4.9}
$$

The investor assumes that out of all possible probabilities (who defines this set?) the worst one is chosen by a second player called 'nature'. This defines a robust optimization problem. The solution will be more conservative than the original one. If one asset is risk-free, this asset will attract a large part of the invested money. Although theoretically sound, robust investments in this sense are hardly considered since the wealth allocation is often to conservative and it is difficult to single out the set of admissible probabilities. We do not consider this approach any further.

Summarizing, maximizing expected utility has the following general structure.

- There is an utility function  $u$ , decision variables  $\chi$ , such as consumption and portfolio weights, and state variables  $\xi$ , such as wealth.
- The constraints define the admissible set  $A(\xi)$ . Examples are the full investment constraint, the budget constraint, the max and min amounts for each asset class, a turnover constraint or a downside risk bound.

# 4.2.1.1 Examples

Consider a single period investment problem where the investor derives utility  $u(W_{1})$  from final wealth  $W_{1}$ . The investor chooses a portfolio  $\phi \in \mathbb{R}^{n}$  for  $n$  assets to maximize  $E(u(W_{1}))$  under the two budget constraints at time 0 and 1:  $\sum_{j}\phi_{j}S_{j,0} = W_{0}$  with  $S_{j}(0)$  the price of asset  $j$  and  $W_{1} = \sum_{j}\phi_{j}S_{j1}$ . The first order condition (FOC) for optimality reads:

$$
E \left(u ^ {\prime} \left(W _ {1}\right) \left(R _ {i} - R _ {j}\right)\right) = 0, \tag {4.10}
$$

for all asset pairs  $i, j$ . This equation has several implications. First,  $R_{i} - R_{j}$  means a long-short combination is optimal. Second, the FOC holds also if one asset is risk free asset. Third, geometrically the condition states that the excess return vector and marginal utility are orthogonal to each other, that is<sup>3</sup>

$$
\langle u ^ {\prime} \left(W _ {1}\right), R _ {i} - R _ {j} \rangle = 0. \tag {4.11}
$$

Fourth, assume that the investor is risk averse  $u'' < 0$ . Then it is never optimal to fully invest in the risk free asset. By contradiction, assume that the investor puts all his initial wealth in the risk free asset. But then final wealth  $W_{1}$  will be non-random and also  $u'(W_{1})$  is deterministic and it which can be taken outside the expected value in (4.10). But then, unless all risky returns are the same, the FOC cannot be satisfied.

The utility function defines risk preferences. Consider an investor who is given the choice a lottery that pays-off either 50 or 100 with the same probability or a lottery with a guaranteed payoff of 75: The bet has the same expected value as the guaranteed payoff. A risk-neutral investor is indifferent between the two lotteries, a risk-averse investor prefers the guaranteed payoff.<sup>4</sup>

Figure 4.1 shows the payoff and utilities for the risk-averse and the risk-neutral investor. For the risk-averse investor, the expected value of the bet lies also on a straight line but its utility value (yellow dot) is strictly lower than the utility of the guaranteed payoff (red dot). A risk-averse investor needs an extra compensation 'red minus yellow dot' such that he becomes indifferent.

Investment restrictions are widely used. Practitioners often impose constraints if the output of an investment optimization is not in line with what they consider a

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9f63d7e13768d0de54fa22b77340aaefbd7aacc20d8c6726157011ffb305289b.jpg)  
Figure 4.1: Risk-neutral and risk-averse investors.

reasonable strategy. But very constraint has an economic price; the shadow price. The larger this price the lower is the constrained optimum compared to an unconstrained one. Furthermore, adding many ad hoc constraints makes it difficult to explain whether a portfolio is optimal due to the investor's preferences or due to the many constraints. Often in wealth management several dozen constraints are imposed - constraints expressing client's preferences ('not investing in hedge funds'), compliance constraints ('Chinese bonds are excluded') or CIO-related constraints ('weight of Swiss equity is between  $20 - 40\%$  for a specific investor').

We show the loss of utility in restricted optimization. The optimal value of an unrestricted optimization problem is never lower than the value of a restricted problem. Consider the minimization of the parabola  $u(x,y) = x^{2} + y^{2}$ . The minimum is achieved for the vector  $(0,0)$  and the optimal value is  $u(0,0) = 0$ . We insert the restriction that  $x + y = r > 0$ . This means that  $x$  and  $y$  are positioned on a line. The optimal values are  $x = y = \frac{r}{2}$  and  $f\left(\frac{r}{2},\frac{r}{2}\right) = \frac{r^2}{2}$  which is larger than the optimal unrestricted value. The Lagrange multiplier  $\lambda$  associated to the constraint  $x + y = r$  has the value  $\lambda = r$  (shadow price). Since the unrestricted optimum is a the origin, the larger we choose  $r$ , that is

the more distant the line is from the origin, the more value is lost. This is exactly the statement of the shadow price.

# 4.2.2 Rational Dynamic Decision Making

Investors often face a long-term investment horizon. Pension funds have to satisfy a liability stream over time, private clients would like to finance different goals in the future. This defines a dynamic expected utility problem, see Sections 4.3.2 and 4.3.3. The investor searches a portfolio  $\phi_t$  at different dates such that the expected present value of the investment is maximized. To solve such an investment problem optimally one has to proceed backwards: Solve, in discrete time, the last period investment decision. This is an optimal single period decision. Then solve the second to last decision given the last one will be optimal and so on. This backward induction is based on the optimality principle of Bellman (1954): An optimal policy has the property, that whatever the initial state is and initial decisions are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.

Why should one consider dynamic investment at all?

Fact 68. Optimal dynamic investment allows to distribute investment risk not only in the cross-section (single-period models) but also over time.

Despite the meaningfulness of multi-period models, most investment models used are static ones. There are three main reasons. First, technology was not able in the past to solve dynamic problems in time, i.e. machines were not fast enough. Second, most asset managers are well-educated in static models but knowledge about dynamic models is sparse. Third, yet static models are flawed by parameter uncertainty (estimation risk). The intertemporal set-up adds additional uncertainty.

Optimal dynamic investment is able to take into account changing future investment opportunities in an optimal way. Static models do not have any foresight power to react today what could happen in future periods. Changing investment opportunities are key for long-term investors such as for pension funds.

Example Backward versus forward induction

Consider the case where you have to drive from New York to Boston. Using a repeated static model (forward induction) you decide at each crossroad given the traffic situation which direction to follow next. Using this strategy you will never arrive in Boston.

Dynamic optimally means that you start with the end in mind: You work backwards starting in Boston. At each crossroad in the backward approach, you calculate whether it is best to turn left or right knowing that all decisions which follow are optimal. Given

the circumstances it may be globally optimal to take a non-optimal small road in a single step if for example this road leads to the next highway. This singles out between the myriad of paths between New York and Boston the truly optimal one.

Repeating say 10 times an optimal one-period model decision (forward solution) is not the same than making optimal investment decisions backwards, except for some particular situations.

# 4.2.3 Growth Optimal Portfolios

Growth optimal portfolio (GOP) by definition have a maximal expected growth rate over any time horizon. Therefore, a GOP dominates any other portfolio strategy when the time horizon increases. If such a strategy exists, why do then people care about any othcr investment strategies?

The origins of GOP is attributed to Kelly (1956) which also leads to the Kelly criterion in investment. Kelly was not interested in investment but wrote his work with gambling and information theory in mind. The Kelly strategy, i.e. a GOP, is an optimal strategy such that with probability one the strategy accumulates more wealth than any other strategy. The expression 'with probability one' is key. Deleting this expression leads to wrong statements and decisions concerning GOP.

To motivate GOP, consider a binary gamble, see Rotando and Thorp (1993). Let  $W_0$  be initial wealth,  $B_k$  the bet  $k$ ,  $p$  the probability of winning and  $q$  the probability of loosing the bet. Then,

$$
E \left(W _ {n}\right) = W _ {0} + \sum_ {k = 1} ^ {n} (p - q) E \left(B _ {k}\right).
$$

If the game's expectation is positive,  $p > q$ , then to maximize  $E(W_{n})$  is the same to maximize  $E(B_{k})$  at each trial. Therefore, it is optimal to bet on all resources in each trial -  $W_{0} = B_{1}$  is the starting bet. The ruin probability of such a strategy is  $1 - p^{n}$ , i.e. you get bankrupt fast almost certain. Contrary, if one minimizes the ruin probability then one also minimizes expected return. The GOP is an intermediate strategy between these two over-aggressive or over-timid strategies.

Consider the strategy to invest a fixed fraction  $c$  of present wealth in the next bet, i.e.  $B_{k} = cW_{k - 1}$ . If  $s$  is the number of successful bets and  $f$  the number of failures in  $n$  bets, then

$$
W _ {n} = W _ {0} (1 + c) ^ {s} (1 - c) ^ {f}.
$$

If  $0 < c < 1$ , ruin is not possible. Using the compounding identity

$$
e ^ {n \log \left(\frac {W _ {n}}{W _ {0}}\right) ^ {1 / n}} = \frac {W _ {n}}{W _ {0}}
$$

the exponential growth rate per trial is given by

$$
\log \left(\frac {W _ {n}}{W _ {0}}\right) ^ {1 / n} = \frac {s}{n} \log (1 + c) + \frac {f}{n} \log (1 - c).
$$

Setting  $G(c)$  equal to the expected value of this growth rate, we get

$$
G (c) = p \log (1 + c) + q \log (1 - c).
$$

Since  $G(c) = \frac{1}{n} E(\log W_n) - \frac{1}{n} \log W_0$ , maximizing  $G(c)$  is equivalent to the maximization of log utility  $E(\log (W_n))$ . Taking the derivative,  $G' = 0$  if the optimal fixed fraction  $c^* = p - q$  is chosen. Furthermore  $G'' < 0$  and  $c = c^*$  is the unique maximum.

Proposition 69. 1. If  $c \in (0, c^*)$  is chosen, then wealth will grow unlimited if  $n \to \infty$  except for a finite number of wealth terms. Contrary, if  $c \in (c^*, 1)$  is chosen, ruin follows if  $n \to \infty$ .

2. Consider the optimal fixed fraction strategy  $c^*$  and any other strategy  $\phi$ . Then the ratio of wealth  $W(c^*) / W(\phi)$  tends to infinity if the number of trials goes to infinity except for a finite number of wealth terms.  
3. The fastest time to reach a target wealth level starting from any level  $W$  is given asymptotically by a strategy which maximizes expected log-wealth utility.

Rotando and Thorp apply the GOP to S&P investing using the data 1926-1984. First, they calculate the probability of a return below a T-bill return. This probability decreases from  $38\%$  for  $n = 2$  years to  $21\%$  after ten years to  $8\%$  after 30 years. The optimal fixed fraction to invest is  $117\%$ , i.e. it is optimal to borrow  $17\%$  of existing wealth in each year. This suggests that GOP needs long-term investment horizons and the optimal strategy is leveraged. Summarizing, a GOP has the theoretical advantage of maximum rate of growth of wealth but it turns out to be too risky in practice.

These results triggered many discussions about the usefulness of GOP. A main critique was formulated from Samuelson in the 60's of last century. He states that if one is not willing to accept a single bet then one rationally will never accept a sequence of such bets: If the ruin probability is not acceptable for the first year investment given  $c^*$  I will never accept 30 bets of this type. This non-transitivity of preferences is refused by Samuelson. Thorp answered that the limit GOP respects transitivity.

This discussion about transitivity is central to GOP: Does a property is valued in the limit  $n \to \infty$  or for a finite but large  $n$ , and how large is such an  $n$  in practice? Christensen considers geometric Brownian motions. The GOP strategy is to replace volatility of the price process by the market price of risk  $\theta = \frac{a - r}{\sigma}$  and the drift  $a$  by the

risk free rate  $r$ . Then even with a Sharpe ratio of 0.5 it would take almost 30 years to beat the risk-free bond with a  $90\%$  probability.

Summarizing, GOP are too risky: No money manager can survive with a limit-offering if he is hit say twice in the first 5 years of his mandate. Impatience of investors rules out any long term investment strategies which are focussing on maximum return growth without controlling the possible finite shortfall risks. But controlling for short fall risks in a mathematical way brings us back to a return-risk framework. A different approach is to mix the mathematics of GOP with business experience by selecting those stocks for GOP which are not expected to have shortfall risks. W. Buffet seems to apply an investment approach of this form.

# 4.2.4 Heuristic Models

The heuristic approach is radically different from the statistical one. Heuristics are methods used to solve problems using rules of thumb or experience. Heuristics need not be optimal in a statistical modelling sense. Heuristics could be seen as a poor man's concept compared to statistical models. But there are situations where heuristic approaches are meaningful.

One reason for the use of heuristics arises if one distinguishes between risk and uncertainty. According to Knight (1921), risk refers to situations of perfect knowledge about the probabilities of all outcomes for all alternatives. This makes it possible to calculate optimal choices. Uncertainty refers to situations in which the probability distributions are unknown or unknowable - that is to say, risk cannot be calculated at all. Situations of known risk are relatively rare. Savage (1954) argues that applying standard statistical theory to decisions in large, uncertain worlds would be utterly ridiculous because there is no way of knowing all the alternatives, consequences, and probabilities. Using optimal solutions in a world with uncertainty just adds non-controllable model risk. To understand when people use statistical models in decision-making and when they prefer heuristics requires the study of how the human brain functions, see Camerer et al. [2005] and Plicher and Fehr [2013].

# Example - Uncertainty examples

Ellsberg (1961) invented the following experiment to reveal the distinction between risk and uncertainty. An individual considers the draw of a ball from one of two urns:

- Urn A has 50 red and 50 black balls.  
- Urn B has 100 balls, with an unknown mix of red and black.

First, subjects are offered a choice between two bets:

- USD 1 if the ball drawn from urn A is red and nothing if it is black.
- USD 1 if the ball drawn from urn B is red and nothing if it is black.

Second, the same subjects are offered a choice between the following two bets:

- USD 1 if the ball drawn from urn A is black and nothing if it is red.  
- USD 1 if the ball drawn from urn B is black and nothing if it is red.

In both cases, the first bet is generally preferred in experiments. That is, individuals belief in the first case that the number of red balls in urn B is less than  $50\%$  and in the second case the same individuals assume that the number of black balls in urn B is also smaller than  $50\%$ . This probability assessments are inconsistent. Ellsberg's interpretation was that individuals are averse to the ambiguity regarding the odds for the ambiguous urn B. They therefore prefer to bet on events with known odds. Consequently they rank bets on the unambiguous urn, A, higher than the risk-equivalent bets on B.

# Example - Uncertainty in macroeconomics

Caballero (2010) and Caballero and Krishnamurth (2008) consider the behavior of investors in the following flight-to-quality episodes:

- 1970 - Default by Penn Central Railroad's prime-rated commercial paper caught the market by surprise.  
- 1987 - Speed of the stock market's decline led investors to question their models.  
- 1998 - Co-movement of Russian, Brazilian, and US bond spreads surprised almost all market participants.  
- 2008 - Default on commercial paper by Lehman Brothers created tremendous uncertainty. The Lehman bankruptcy also caused profound disruption in the markets for credit default swaps and interbank loans.

They find that investors were re-evaluating their models, used conservative behavior or even disengaged from risky activities. These reactions cannot be addressed by increasing risk aversion about macroeconomic phenomena. The reaction of investors in an uncertain environment is fundamentally different from a risky situation with a known situation and environment.

# Example - Greece and the EU

In spring 2015 uncertainty about the future of Greece in the EU increased. Four different scenarios were considered:

- Status quo. Greece and the EU institutions agree on a new reform agenda such that Greece receives the remaining financial support of EUR 7.2 billion from the second bailout package.  
- Temporary introduction of a currency parallel to the euro. If the negotiations under A are taking longer than Greek liquidity can last, Greece will introduce a parallel currency to fulfill domestic payment liabilities.  
- Default with subsequent agreement between the EU and Greece. There is no agreement under A. Greece fails to repay loans and there will be a bank run in Greece. The ECB takes measures to protect the European banking sector.  
- Brexit - that is, Greece leaves the eurozone. Greece stops all payments and the ECB abandons its emergency liquidity assistance. Similar conclusions hold for the Greek banking sector as under C. Greece needs to create a new currency since the country cannot print euros.

The evaluation of the four alternatives is related to uncertainty and not to risk: the probability of each scenario is not known, there are no historical data with which to estimate the probabilities, and the scenarios have dependencies but they are of a fundamental cause-effect type, which cannot be captured by the statistical correlation measure. This shows that valuable management is related to situations which are based on uncertainty.

The use of 'uncertainty' and 'risk' does not follow clear standards and conventions in practice. A volatility index such as VIX is sometimes called a measure of uncertainty: If volatility increases one often states that uncertainty increases. Strictly speaking this makes no sense since the VIX is a calculated index of risk. Hence, risk increases or decreases but this has a priori no relation to uncertainty. A similar logic is that investor state if uncertainty increases often markets become more volatile and equity markets fall (negative leverage effect) or if uncertainty increases, then credit spreads of corporates or governments should widen. Again risk and uncertainty are used interchangeably. 2016 provides an example that one should not mix risk and uncertainty. In 2016 many events happened where it was impossible to calculate risk - Brexit, election of Trump, increasing geopolitical tensions in the Middle East, political instability in major countries such as Brazil and Turkey for example. There were for example no data to assess the risk of the Trump election. But if large uncertainty means large risks, then heavy market reactions should follow. But most assets classes ended the year with positive returns. There was almost no market reaction to the events. Furthermore, plotting an uncertainty index such as policyuncertainty.com versus credit spreads measured in USD show that uncertainty increased in 2016 while the spreads fell.

# 4.3 Portfolio Construction Examples

# 4.3.1 Heuristic Allocation: Static 60/40 Portfolio

A classic portfolio construction is the so called '60/40 portfolio'. After each time period, the portfolio values are rebalanced such the value of equity is 60 percent of the actual wealth level and the fixed income government bond investment has weight 40 percent. The two components equity and government bonds are equally weighted portfolios of stocks and bonds ('dollar weighted'). The 60/40 portfolio in the US has generated a 4 percent average annual return back to 1900.

The 60/40 portfolio turns out to be not diversified enough when markets are distressed or booming. The dot-com bubble and the financial crisis of 2008 revealed that different asset classes moved in the same direction and behaved as if they were all of the same type, although capital diversification was maintained: Risk weights are not the same as dollar weights.

Deutsche Bank (2012) reports the following risk contributions using volatility risk measurement for 60/40 portfolios with S&P 500 and US 10y government bonds. The long-term risk contribution, 1956 to 2012, by asset class was 79/21 percentage different from a 60/40 capital diversification. The risk contribution in extreme market periods of US government bonds varied between  $53\%$  in 19981 and  $7\%$  in 1973.

The left panel in Figure 4.2 illustrates the strong positive correlation between equity and bonds: In the left panel, world wide equity portfolios are compared to a balanced equity and bond portfolio. The linear relationship between the two returns with low variability indicate that a single global equity portfolio is as good as a balanced equity bond portfolio. The performance and risk of traditional balanced portfolios is mostly driven by the equities quota. The  $R^2$  is  $95\%$ , i.e.  $95\%$  of the risk is explained by equity risk. Hence, asset classes consist of a bundle of 'risk factors' where the same risk factors can belong to several asset classes. This extends to all asset in the case of systemic liquidity events: The monthly dollar returns between the classic asset classes and alternative classes show rather low correlation between 2000 and 2007 but increase sharply during the GFC and remain elevated as the sovereign debt crisis follows in 2011. This failure of alternatives to diversify during the GFC led to critique about the diversification concept based on asset classes per se, see Figure 4.2. In the middle panel commodities and hedge funds are added to the balanced portfolio. While the variability increases one still sees that equity risk factors are driving the returns, the allocation of risk is only slightly improved. Still  $90\%$  of risk is explained by the equity risk factor. Finally, if one replaces equity by bonds in the right panel, a cloud-type scatter plot follows. This indicates that equity and not bond risk factors are the return drivers.

The time varying correlation in Figure 2.18 shows that the correlation between stocks and bonds varies over time. Historically, periods of rising inflation and heightened sovereign risk have driven stock and bond correlations sharply positive. In contrast,

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7d28c1b0e3fa211561691a2deb40afa1860334dc518cfa4eadf28bcf1c0cde37.jpg)  
Figure 4.2: Left Panel: Monthly return equities world vs monthly return balanced portfolio (Equities world:  $50\%$ , bonds world:  $50\%$ ), Bloomberg: 12/1998-3/2013. Middle Panel: Monthly return equities world vs monthly return balanced portfolio (Equities world:  $40\%$ , bonds world:  $40\%$ , commodities:  $10\%$ , hedge funds global:  $10\%$ ) Commodities database: DJUBSTR, Hedge Funds database: HFRXG. Right Panel: Monthly return bonds world vs monthly return balanced portfolio (Equities world:  $50\%$ , bonds world:  $50\%$ ) Bloomberg: 12/1998-3/2013, local data.

correlations often turned negative when inflation and sovereign risk were at low levels.

If stocks and bonds can be described by their exposure to macroeconomic factors, their correlations could be determined entirely through their relative exposures to the same set of factors. Therefore, why not measure the exposures of stocks and bonds to common factors and act according to the volatility and correlation forecast instead using the static 60/40 rule? This is not effective since the true factor structure is unobservable, economic factors are not investable or investor's sentiment impact the correlation structure, which makes the prediction of changing correlation difficult. Kaya et al. (2011) find that the economic factors growth and inflation have accounted for only 2 percent of the total volatility of the 60/40 portfolio in the US since 1957, while 98 percent of the volatility of the portfolio has been the result of missing factors, mis-specified factors, or risks that are specific to each asset class.

Summarizing, the 60/40 asset allocation based on asset classes correlations between asset classes is time-varying, not risk-stable and difficult to forecast. Risk weights are

not the same as dollar weights. Asset classes seem not to be the right level for risk aggregation.

# 4.3.2 Optimal Allocation: Dynamic Merton Model

We consider the Merton model (1973) of dynamic optimal consumption and investment. This seminal contribution is the benchmark model for dynamic optimal decision making.

The choice variable is a vector  $(c, \phi)$  with consumption rate  $c$ ,  $\phi$  the fraction of wealth invested in the risky asset and  $1 - \phi$  in the risk-less asset. The state variable  $W_{t}$  represents wealth and utility reads

$$
u (t, c) = e ^ {- r t} \frac {c ^ {a}}{a}, 0 <   a <   1.
$$

The individual optimizes expected utility:

$$
V (W _ {0}) = \max _ {c, \phi} E \left[ \int_ {0} ^ {\infty} e ^ {- r t} \frac {c _ {t} ^ {a}}{a} d t \right], 0 <   a <   1.
$$

The maximization is done subject to the dynamic budget constraint for the wealth dynamics  $W_{t}$ . Wealth growth is driven by the price evolution of a single risky asset  $S$ , a risk free asset  $B$  and the consumption rate at each date. The risky asset  $S$  dynamics follows a geometric Brownian motion with constant drift  $\mu$  and volatility  $\sigma$  and the growth rate of the risk free  $r$ . Inserting this information provides us with the dynamic budget constraint

$$
d W = (\phi \mu W + (1 - \phi) r W - c) d t + \sigma \phi W d B
$$

with  $B$  the standard Brownian motion. The optimality principle of Bellman starting in  $t_0$  for a period  $t_0 + dt$  reads:

$$
V (t _ {0}, W _ {0}) = \max  _ {c, \phi} E \left[ \int_ {t _ {0}} ^ {t _ {0} + d t} u (t, c, W) d t + V (t _ {0} + d t, W _ {0} + d W) \right]. \tag {4.12}
$$

Hence, the value at  $t_0$  is equal to the sum of optimal utility over short time  $dt$  plus the value reached at  $t_0 + dt$ , i.e. all decisions are optimal after  $t_0 + dt$ . Expanding the future value in a Taylor series, using the dynamics of the assets transforms the above equation into a non-linear partial differential equation for the value function  $J$ . The solution of this equation implies the following optimal strategies:

$$
V (W) = \alpha^ {*} W ^ {a}, c ^ {*} = W \left(a \alpha^ {*}\right) ^ {\frac {1}{a - 1}}, \phi^ {*} = \frac {\mu - r}{\sigma^ {2}} \frac {1}{1 - a} \tag {4.13}
$$

where  $\alpha^{*}$  is the explicit solution of an algebraic equation involving the preference and growth rate parameters. The optimal investment in the risky asset  $\phi^{*}$  is equal to the market price of risk (MPR)  $\frac{\mu - r}{\sigma^2}$  times the relative risk aversion  $\frac{1}{1 - a}$ . The MPR is itself proportional to the Sharpe ratio (which is also the solution of the Markowitz problem).

This validates the claim that the Markowitz problem also holds in a dynamic context unless the investment opportunity sets are changing over time, see Section ??. Optimal consumption is proportional to the wealth level which is reasonable. There are many extensions of the basic Merton model - such as many assets, adding income, allowing for a bequest motif, adding linear investment constraints. As a fact, analytical tractability is lost in most extensions.

# 4.3.3 Optimal Allocation: Goal Based Investment

The ideas of Merton can be applied to maximizing the probability of financing several goals (liabilities) at different future dates. since private clients often think in terms of goals  $G$ . They are interested to choose an optimal strategy such that the probability of financing their future goals is maximized. The trivial case is where initial  $W_{0}$  is larger the risk-free PV of all goals.

Assume that risk is needed to finance the goals. Goal based investment (GBI) means to find a strategy  $\phi(t)$  which maximizes the probability

$$
\max  _ {\phi} P \left(W _ {T} \geq G _ {T}\right). \tag {4.14}
$$

To this objective function one adds the asset dynamics, the initial wealth level and additional constraints. Assume that there are  $N$  risky assets which all are coupled by a time-varying but deterministic covariance matrix  $C$  and where each asset has a time-varying expected return  $\mu (t)$ . There is a risk less asset with a time-varying deterministic short-term rate  $r(t)$ . The asset dynamics defines the wealth dynamics  $dW_{t}$  starting at  $W_{0}$ . The optimal policy, using the Bellman Principle, is derived by Browne (1999):

$$
\phi^ {S} (t) = \frac {C ^ {- 1} (t) \Theta (t)}{\sqrt {\int_ {t} ^ {T} \Theta (s) ^ {\prime} \Theta (s)}} \frac {\phi (\mathcal {N} ^ {- 1} (z (t)))}{z (t)} W _ {t} \tag {4.15}
$$

with the discount factor  $D(t,T) = e^{-\int_t^T r(s)ds}$ ,  $\phi$  the density function of a standard normal distribution,  $\mathcal{N}$  the associated cumulative distribution function,  $\Theta = C^{-1}(\mu - re)$  the market price of risk (MPR),  $e$  a  $N$ -dimensional unit vector,  $z(t) = \frac{W_0}{G_T} D^{-1}(t,T)$  the percentage of the discounted goal reached at time  $t$

The optimal investment formula 4.15 states:

- At each time  $t \leq T$  optimal investment is a linear function of wealth.  
- The linear function is weighted by a time-dependent part proportional to the MPR and a part  $\frac{\phi\left(\mathcal{N}^{-1}(z(t))\right)}{z(t)}$  which measures how much of the goal has been achieved at time  $t$ .  
- The investor or asset manager at each date  $t$  observes the optimal wealth  $W_{t}$  and then chooses the investment for the next (infinitesimal) period according to the

optimal formula. The problem can be discretized in order to obtain real investment periods.

- At each date the deterministic expected means and covariances enter. These functions can be determined by the CIO office or the advisory function using a SAA and TAA approach. Besides the actual values also the values for the remaining life-time matter. Therefore, by changing these forecast values at time  $t$  implies a reshaping of the optimal investment policy at this date. Given the simplicity of the optimal formula the investment universe can be set-up by a large number of different assets ensuring diversification of wealth growth.  
- Suppose that all assets lose in value from the beginning for some time. Then if wealth has dropped enough in value there is not enough time left such that the wealth level can beat the goal. Then, the investor has to borrow or to inject additional money or to reduce the size of the goal. Browne shows in an example that for  $T = 10y$  the wealth has to drop more than  $62\%$  in the first year in order to need to borrow. If there is only one month left, then the investor must borrow unless wealth is already of  $88\%$  distance to the investment goal.

The approach can be generalized to include income and consumption streams, beating a benchmark portfolio and controlling for downside risk, see Browne (1999).

# 4.3.4 Optimal Allocation: Markowitz

# 4.3.4.1 The Two-Asset Case

Consider two assets and two portfolios  $A, B$  shown in the portfolio expected return and standard deviation space in Figure 4.3.

Solving the mean-variance optimization problem in this two risky asset case shows that the portfolio opportunity set is a hyperbola in the  $(\sigma, \mu)$ -portfolio coordinates (line 3). It is maximally bowed for perfect negative correlation. The lower correlation is, the higher are the gains from diversification. For perfect positive or negative correlation the hyperbola degenerates to straight lines. Line 1 represents all possible portfolio choices if there is perfect positive correlation,  $+1$ . Similarly, for perfect negative correlation the straight line  $2a$  or  $2b$  follows. In the presence of perfect negative correlation we can fully eliminate portfolio risk (point  $C$ ).

The following definitions are common.

Definition 70. 1. If a portfolio offers a larger expected return than another portfolio for the same risk, then the latter portfolio is strictly dominated by the first one.

2. Portfolios that are not strictly dominated are called mean-variance efficient. The set of these portfolios form the efficient frontier.  
3. The portfolio  $\phi_{m}$  at the point  $D$  is the global minimum variance (GMV) portfolio.

The lines 1, 2b and the line between  $D$  and  $B$  are efficient frontiers.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b72d919b21ae6a9c317cc7f28e6fb67c1fb083e26aefcdfc7bea76808e3d581d.jpg)  
Figure 4.3: Portfolio frontiers in the two-asset case. The portfolio opportunity set is a hyperbola in the portfolio coordinates expected return and standard deviation.

# 4.3.4.2 Many Risky Assets

Considering many assets does not add new economic insights. We therefore keep this section short. The assumptions of the Markowitz model are:

1. There are  $N$  risky assets and no risk free asset. Prices of all assets are exogenous given.  
2. There is a single time period. Hence risks cannot be distributed over time but only in the cross-section.  
3. There are no transaction costs. This assumption can be relaxed nowadays by solving the model numerically.  
4. Markets are liquid for all assets.  
5. Assets are infinitely divisible. Without this assumption, we have to rely on integer programming which makes sense and which today is feasible.  
6. If borrowing and lending is excluded, full investment holds,  $\langle e,\phi \rangle = 1$  with  $e = (1,\ldots ,1)\in \mathbf{R}^n$ .  
7. Portfolios are selected according to the mean-variance criterion.  
8. The vectors  $e, \mu$  are linearly independent. If they are dependent then the optimization problem does not have a unique solution.
9. All first and second moments of the random variables exist, i.e. the mean and covariance are not defined.

We define the auxiliary variables:  $a = \langle \mu, C^{-1}\mu \rangle, b = \langle e, C^{-1}e \rangle, c = \langle e, C^{-1}\mu \rangle, \Delta = ac - b^2$  and

$$
A = \left( \begin{array}{c c} a & c \\ c & b \end{array} \right)  .
$$

Proposition 71. Consider  $N$  risky assets and the above assumptions. Then the Markowitz problem

$$
\min  _ {\phi \in \mathbf {R} ^ {n}} \quad \frac {1}{2} \langle \phi , C \phi \rangle \quad (\mathbf {M}) \tag {4.16}
$$

$$
s. t. \quad \langle e, \phi \rangle = 1, \langle \mu , \phi \rangle = r.
$$

has a unique solution

$$
\phi_ {M V} = r \phi_ {1} ^ {*} + \phi_ {2} ^ {*} \tag {4.17}
$$

with

$$
\left( \begin{array}{c} \phi_ {1} ^ {*} \\ \phi_ {2} ^ {*} \end{array} \right) = A ^ {- 1} \left( \begin{array}{c} C ^ {- 1} \mu \\ C ^ {- 1} e \end{array} \right). \tag {4.18}
$$

The portfolio weights are linear in the expected portfolio return  $r$ . Inserting  $\phi_{MV}$  into the variance implies the optimal minimum portfolio variance  $\sigma_p^2$ -hyperbola:

$$
\sigma_ {p} ^ {2} (r) = \langle \phi_ {M V}, C \phi_ {M V} \rangle = \frac {1}{\Delta} (r ^ {2} b - 2 r c + a). \tag {4.19}
$$

Diversification in the mean-variance model means that adding more assets causes the efficient frontier to widen: for the same risk, a higher expected return follows (see Figure 4.4).

The Markowitz model fails to be stable in the following sense. Consider a GMV portfolio with two assets, hence the optimal portfolio only depends on covariance but not on returns. Suppose that both assets have a volatility of 20 percent and full positive correlation of 1. Then, the optimal weights are 50 percent in each asset. Suppose next that asset 1 has only  $19.9\%$  volatility, all other numbers unchanged. Then, 100 percent is invested in this asset and zero in the second one.

Example

Consider three assets with expected returns  $(20\%, 30\%, 40\%)$  and covariance

$$
C = \left( \begin{array}{c c c} 0. 1 & & \\ 0. 0 8 & 0. 1 5 & \\ 0. 0 9 & 0. 0 7 & 0. 2 5 \end{array} \right)
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/36175bcc452a390e44ca76a75da3eba560c2ab965b536a346cad6572ff2b858f.jpg)  
Figure 4.4: Different efficient frontiers for different numbers of assets. It follows that adding new assets allows for higher expected return for a given risk level (measured by the portfolio standard deviation). The portfolio with the lowest standard deviation is the global minimum variance (GMV) portfolio (Ang [2012]).

We assume that the investor expects a minimum return of  $r = 30\%$ . He could then fully invest in asset 2 to achieve this return goal. But the optimization  $\phi_{MV}$  shows that he can reach this target with lower risk, where

$$
\phi_ {M V} = (0. 2 8, 0. 4 3, 0. 2 8) ^ {\prime}
$$

The investor is fully invested and long in all assets. The risk of the optimal portfolio is  $\sigma_{p} = 10.7$  percent which is less than the 15 percent if the investor only invests in the second asset. We compare the Markowitz portfolio with the equally weighted (EW) portfolio and the risk-parity portfolio of inverse volatility (IV) - that is to say, investment in each asset is inversely proportional to its volatility. We get

$\phi_{MV} = (0.28,0.43,0.28)^{\prime}$  

- $\phi_{EW} = (0.33, 0.33, 0.33)'$  
$\phi_{IV} = (0.48, 0.32, 0.19))'$ .

The MV strategy considers variances and covariances, EW does not consider them at all, and the risk-parity strategy only considers variances. The statistics for the three strategies are:

<table><tr><td>Strategy</td><td>Expected return</td><td>Portfolio σP</td></tr><tr><td>MV</td><td>35.7%</td><td>10.7%</td></tr><tr><td>EW</td><td>29.7%</td><td>10.6%</td></tr><tr><td>IV</td><td>26.8%</td><td>9.6%</td></tr></table>

# Example

Consider two assets with expected returns of  $\mu_{1} = 1$  and  $\mu_{2} = 0.9$  and

$$
C = \left( \begin{array}{c c} 0. 1 & \\ - 0. 1 & 0. 1 5 \end{array} \right)  .
$$

Asset 1 seems more attractive than asset 2. It has a higher expected return and lower risk. Naively one would invest fully in the first asset. But negative correlation makes an investment in asset 2 necessary to obtain an optimal allocation. The expected return constraint is set equal to  $r = 0.96$ . We consider four strategies:

- $\phi_1 = (1,0)$ , full investment in asset 1.  
$\phi_2 = \left(\frac{1}{2},\frac{1}{2}\right)$  , an equal distribution.  
- $\phi_3 = (5/9, 4/9)$ , optimal Markowitz strategy without the expected return constraint.  
- $\phi_{MV}^{*} = (0.6, 0.4)$ , optimal Markowitz solution with the expected return constraint.

The following expected portfolio returns and risk for the different strategies hold:

<table><tr><td>Strategy</td><td>μ</td><td>σP</td></tr><tr><td>φ1</td><td>1</td><td>0.1</td></tr><tr><td>φ2</td><td>0.95</td><td>0.0125</td></tr><tr><td>φ3</td><td>0.955</td><td>0.011</td></tr><tr><td>φ*MV</td><td>0.96</td><td>0.012</td></tr></table>

$\phi_{1}$  satisfies the expected return condition but risk is much larger than in all other strategies - lack of diversification. The risk of  $\phi_{3}$  is minimal but the return is smaller than required. To generate the return and keep risk minimal, 40 percent has to be optimally invested in the not very attractive asset. This is the Markowitz phenomenon: to reduce the variance as much as possible, a combination of negatively correlated assets should be chosen.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0e6d85dcc02e14494f6bcf0c5ff743674c993ac1da3267275ef00c73c1d36311.jpg)  
Figure 4.5 shows that an under-diversified portfolio follows for portfolios on the efficient frontier which becomes more pronounced for higher risks. Furthermore, the steep  
Figure 4.5: Efficient allocations for 21 different portfolios. The first portfolio is the GMV portfolio and moving to the right optimal portfolios on the efficient frontier follow. Data 1991-2016, monthly data, long-only portfolio constraint.

vertical changes in the asset allocation indicate that the allocations are not robust: Small changes in covariance data lead to large changes in the asset allocations. Does a Markowitz portfolio provide a reasonable diversification for portfolios over time? The answer, see Figure 4.10, is again no: One observes an under-diversification and non-stability of the asset allocation.

# 4.3.4.3 Mutual Fund Theorem

The Mutual Fund Theorem (MFT) $^{10}$  is one of the most important results for investment theory and investment practice. Under suitable assumptions, which are satisfied in the Markowitz model, the optimal investment strategy is to invest in the risk-free asset and a second risky asset (ETF, mutual fund) which is a linear combination of the risky assets available on the financial market. The Proposition for the case with risky assets only reads:

Proposition 72. Any minimum variance portfolio can be written as a convex combination of two distinct minimum variance portfolios.

Formally, if  $\phi_{MV}^{*}(r)$  is any optimal minimum variance portfolio, then there exists a function  $\nu (r)$  for any two other optimal minimum variance portfolios,  $\phi_1^* (r),\phi_2^* (r)$ , such that

$$
\phi_ {M V} ^ {*} (r) = \nu \phi_ {1} ^ {*} (r) + (1 - \nu) \phi_ {2} ^ {*} (r). \tag {4.20}
$$

The entire mean-variance frontier curve can be generated from just two distinct portfolios. This holds since the efficient frontier is a one-dimensional affine subspace in  $\mathbf{R}^n$ . The Mutual Fund Theorem allows investors to generate an optimal portfolio by searching for cheaper or more liquid portfolios and invest in these portfolios in the prescribed way. This theorem led to the growth of mutual fund and ETF industry. The Mutual Fund Theorem also holds for some dynamic models such as the Merton model of last sections. But if there are risk sources for assets which cannot be hedged then more than two funds are needed to construct an optimal investment strategy. In general, structure of the investor's preferences and the structures of the asset markets both determine whether a mutual fund theorem is valid.

# 4.3.4.4 Markowitz Model with a Risk-Free Asset

If we assume that one asset is risk-less and the other ones are risky, the whole optimization program of Markowitz can be repeated. Most properties of the risky-only asset case carry over to the case with a risk-free asset.

The efficient frontier is a straight line which has at least one point in common with the efficient frontier - the case, where it is be fully invested in risky assets. The portfolio where the two frontiers intersect is the tangency portfolio  $T$  (see Figure 4.6; left panel).

Natural candidates for the mutual fund theorem are the tangency portfolio and the risk-less-asset investment. In the right panel of Figure 4.6, different portfolios on the efficient frontier are shown. The investors can add cash to become more conservative or borrow cash for an aggressive investment. The portfolios on the Capital-Market-Line (CML) depend on the investor's preferences  $\theta$  in (4.1). The higher risk aversion, the closer is the point in the CML to the risk-free investment. Ang (2012) estimates an aggregate risk aversion parameter value as follow. He calculates the optimal minimum variance portfolio using USA, JPN, GBR, DEU, and FRA risky assets only. Then he adds a risk-free asset and searches for the point on the CML that delivers the highest utility. This point implies a risk aversion of  $\theta = 3$ . The optimal portfolio with a risk-free asset can be seen in Figure 4.6 in the region where the aggressive investor is shown. The investor is long on all risky assets and short on the risk-free asset. But in reality, only half of investors invest their money on the stock market and the remainders keep their money risk free. In some European countries stock market participation is lower than 10 percent. This is the non-participation puzzle of mean-variance investing.

Geometry implies for the CML

$$
\mu_ {p} = R _ {f} + \frac {\mu_ {T} - R _ {f}}{\sigma_ {T}} \sigma_ {p}
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3e854afdc3e4641ba29095817021b0259788a793171fb5d86fac1ac65adfd842.jpg)  
Figure 4.6: Mean-variance model with a risk-free asset. Left panel - straight line efficient frontier (CML), which is tangential to the efficient frontier when there are risky assets only. The tangency point  $T$  is the tangency portfolio where investment in the risk-free asset is zero. Right panel - investors' preferences on the efficient frontier. Moving from the tangency portfolio to the right, the investor starts borrowing money to invest in the risky assets. The investor is short cash in this region to finance the borrowing amount.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/fdf5cdada817f21a384015672c3b61afc28b0d07df2c1c3c7852dd37e347ad47.jpg)

with  $\mu_T, \sigma_T$  the expected mean and standard deviation of the tangency portfolio, respectively. The slope of the CML is the Sharpe ratio  $\mathbf{SR} = \frac{\mu_T - R_f}{\sigma_T}$ . This is the price of one unit risk of for an efficient portfolio.

# 4.3.4.5 Mean-Value-at-Risk Portfolios

One critique of the mean-variance criterion for optimal portfolio selection often concerns the variance as a symmetric risk measurement: Why penalize the upside in portfolio selection? Also, the variance is not seen as a true measurement of risk since it fails to detect the states that reflect stress situations. Risk-sensitive asset managers prefer to use a mean-downside risk approach such as mean-Value-at-risk (VaR) instead.

To gain some ideas about stress periods, table 4.1 reports data about periods when Swiss stock market faced a stress. Besides the maximum drawdown, the time period where prices were falling and when they rebound are shown. The last two periods represent the global financial crisis and the dot-com bubble, respectively. On average it takes longer for the markets to recover than to drop and a second observation are the heavy maximum drawdowns. This illustrates that also in an optimal portfolio choice the

evaporation of diversification - that is correlations become close to 1 - in time of market stress happens.

<table><tr><td>Period</td><td>1928-1941</td><td>1961-1968</td><td>1972-1979</td><td>1989-1992</td><td>00-05</td><td>08-13</td><td>Av.</td></tr><tr><td>Low</td><td>1935</td><td>1966</td><td>1974</td><td>1990</td><td>2002</td><td>2008</td><td></td></tr><tr><td>MDD %</td><td>41.3</td><td>37.5</td><td>47.2</td><td>20.2</td><td>42.3</td><td>34.1</td><td>36</td></tr><tr><td>yfp</td><td>7</td><td>5</td><td>2</td><td>1</td><td>2</td><td>2</td><td>2.86</td></tr><tr><td>yrp</td><td>6</td><td>2</td><td>5</td><td>2</td><td>3</td><td>5</td><td>3.57</td></tr></table>

Table 4.1: Periods involving large drawdowns in Swiss equity markets. The drawdown is the measurement of the decline from a historical peak. The maximum drawdown (MDD) up to time  $T$  is the maximum of the drawdown over the overall time period considered, yfp means years with falling prices, yrp years with rising prices and Av. average (Kunz [2014]).

We consider mean-VaR portfolio optimization.  $\mathrm{VaR}(a)$  is the minimum dollar amount an investor can lose with a confidence of  $1 - a$  for a given holding period where the portfolio is not changed.[11] If the portfolio returns are normal  $\mathcal{N}(\mu, \sigma)$ , the dollar amount  $VaR(a)$  is for a unit time period

$$
\operatorname {V a R} (a) = \sigma k (a) + \mu , \tag {4.21}
$$

where  $\mu$  is the portfolio return,  $\sigma$  the volatility of the portfolio return, and  $k(a)$  is a tabulated function of the confidence level  $1 - a$ . Hence, under normality, VaR is proportional to volatility. This translates into the optimization problem: Mean-variance is equivalent to mean-VaR by rescaling the volatility.

Figure 4.7 shows an efficient frontier and several VaR constraints, i.e. the problem is to maximize expected return under the constraint

$$
P (R \leq x) \leq a. \tag {4.22}
$$

This  $\operatorname{VaR}(a)$  constraints define straight lines assuming normality. The impact on the optimal portfolio choice is as follow. Starting with the benchmark of say  $-3\% = x$  loss

What is the probability that the loss exceeds USD 10 - that is to say,  $P(100 - S_1 < 10) = ?$ . Hence, the loss amount is given; the probability of the loss is unknown. VaR answers a related question: the investors search a USD amount - the VaR - such that the probability of a loss is not larger than the predefined quantile level on average. That is to say,

$$
P (100 - S _ {1} <   ?) \leq a \%,
$$

where  $? =$  is the Dollar VaR amount. Hence, the probability of the loss is given; the loss amount is unknown.

capacity, the straight blue lines. The intersection between this line and the mean variance frontier select the optimal mean-VaR portfolio. If loss capacity increases, the line moves parallel to the right implying higher possible optimal risks and returns. The same effect follows if for a fixed loss capacity the confidence level is lowered - more risk and return becomes optimal.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/35c1c1b2dfe3f1835d4544ddf2b1d5f4399274818797c521d4da74c15dfcc596.jpg)  
Figure 4.7: Mean-drawdown optimal portfolio. The straight lines represent the VaR constraints. If loss capacity increases, the VaR lines move to the right indicating higher risk and returns in the optimal portfolio. The same result follows if the confidence level is lowered.

We conclude with two VaR calculations. Consider a position with value USD 1 million. Assuming normality of returns, the goal is to calculate the one-day VaR on the 95 percent level. The estimated daily mean is 0.3 percent and the volatility is 3 percent. With  $k(5\%) = 1.6449$  follows

$$
\mathrm {V a R} (a) = (1. 6 4 4 9 \times 0. 0 3 + 0. 0 0 3) \times \mathrm {U S D} 1 m n = \mathrm {U S D} 5 2, 3 4 7.
$$

Therefore, on average in 1 out of 20 days the loss is larger than the calculated VaR of USD 52,347.

To be more realistic for AM, we calculate VaR for an Euro investor with the portfolio: There are three equity risk sources (DAX, DJ, Novartis), two FX risks USDEUR (spot 1.05) and CHFEUR (spot 0.8) and US interest rate risk for the bond, i.e. 6 risk factors. The goal is to calculate the weekly Euro VaR on a  $95\%$  level.

<table><tr><td>Position</td><td>Type</td><td>Market Price</td><td>Currency</td></tr><tr><td>1</td><td>10 Equity Funds Shares DAX</td><td>1’000</td><td>Euro</td></tr><tr><td>2</td><td>5 Equity Funds Shares DJ</td><td>5’000</td><td>USD</td></tr><tr><td>3</td><td>200 Novartis Stocks</td><td>50</td><td>CHF</td></tr><tr><td>4</td><td>10 US Treasury, 10y, Zero Coupon Bonds</td><td>800</td><td>USD</td></tr></table>

We first need the variance and covariance information, then the calculation of the exposure in Euro and the allocation of the EUR exposure to the risk factors using market data in the following table. We first calculate the EUR exposure and the allocation of the

Table 4.2: Initial value of the investor's portfolio.  

<table><tr><td></td><td>σ</td><td>DAX</td><td>DJ</td><td>Novartis</td><td>USDEUR</td><td>CHFEUR</td><td>US 10y</td></tr><tr><td>DAX</td><td>30%</td><td>1</td><td>0.5</td><td>0.6</td><td>0.4</td><td>0.55</td><td>-0.2</td></tr><tr><td>DJ</td><td>20%</td><td>0.50</td><td>1</td><td>0.55</td><td>0.77</td><td>0.66</td><td>-0.4</td></tr><tr><td>Novartis</td><td>25%</td><td>0.60</td><td>0.55</td><td>1</td><td>0.23</td><td>0.72</td><td>-0.22</td></tr><tr><td>USDEUR</td><td>15%</td><td>0.40</td><td>0.77</td><td>0.23</td><td>1</td><td>0.73</td><td>-0.49</td></tr><tr><td>CHFEUR</td><td>5%</td><td>0.55</td><td>0.66</td><td>0.72</td><td>0.73</td><td>1</td><td>-0.21</td></tr><tr><td>US 10y Treasury</td><td>10%</td><td>-0.20</td><td>-0.4</td><td>-0.22</td><td>-0.49</td><td>-0.21</td><td>1</td></tr></table>

EUR exposure to the risk factors: The portfolio variance  $\sigma_p^2$  is given by  $\sigma_p^2 = \langle X, CX \rangle$

Table 4.3: Market Data.  

<table><tr><td>Posit.</td><td>Price</td><td>EUR Exp</td><td>DAX</td><td>DJ</td><td>Nov.</td><td>USDEUR</td><td>CHFEUR</td><td>USD10y</td></tr><tr><td>10 DAX</td><td>1&#x27;000</td><td>10&#x27;000</td><td>10&#x27;000</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>5 DJ</td><td>5&#x27;000</td><td>26&#x27;250</td><td></td><td>26&#x27;250</td><td></td><td>26&#x27;250</td><td></td><td></td></tr><tr><td>200 Novartis</td><td>50</td><td>8&#x27;000</td><td></td><td></td><td>8&#x27;000</td><td></td><td>8&#x27;000</td><td></td></tr><tr><td>10 US Treas.</td><td>800</td><td>8&#x27;400</td><td></td><td></td><td></td><td>8&#x27;400</td><td></td><td>8&#x27;400</td></tr><tr><td></td><td></td><td>Sum (X)</td><td>10&#x27;000</td><td>26&#x27;250</td><td>8&#x27;000</td><td>34&#x27;650</td><td>8&#x27;000</td><td>8&#x27;400</td></tr></table>

Table 4.4: EUR exposure and allocation of the exposure to the risk factors.

where  $X$  is the EUR exposure vector allocated to the risk factors and  $C_{ij} = \sigma_i\sigma_j\rho_{ij}$ . Calculating these matrix products gives  $\sigma_p^2 = 160'804'032$ . This is the value on an annual basis. To obtain the result on a weekly basis, we obtain for the variance

$$
\sigma_ {w} = \sqrt {1 6 0 ^ {\prime} 8 0 4 ^ {\prime} 0 3 2 / 5 2} = 1 ^ {\prime} 7 5 8.
$$

The critical value on the  $95\%$  level is  $k_{95\%} = 1.644853$ . This implies the 1w EUR VaR of using

$$
- \mathrm {V a R} _ {\alpha} = \sigma k _ {\alpha} \sqrt {T} = \sqrt {X ^ {\prime} C X} k _ {\alpha} \sqrt {T}
$$

where the drift is zero:

$$
\mathrm {V a R} = 1 ^ {\prime} 7 5 8 \times 1. 6 4 4 8 5 3 = 2 ^ {\prime} 8 9 2 \mathrm {E U R}.
$$

We then get for the VaR contribution:

$$
\frac {\partial \mathrm {V a R}}{\partial X} = k _ {\alpha} \sqrt {T} \frac {C X}{\sqrt {X ^ {\prime} C X}} = k _ {\alpha} ^ {2} T ^ {2} \frac {C X}{\mathrm {V a R}}.
$$

This implies the contribution rule:

$$
\mathrm {V a R} = \sum_ {j} X _ {j} \frac {\partial \mathrm {V a R}}{\partial X _ {j}} = k _ {\alpha} \sqrt {T} \sum_ {j} X _ {j} \frac {(C X) _ {j}}{\sqrt {X ^ {\prime} C X}} = \sum_ {j} \mathrm {V a R} _ {j}. \tag {4.23}
$$

Applying this to the portfolio, the US Treasury bond is negative: Due to its negative correlations to the other factors the VaR is reduced by 6 percent. The largest VaR contribution is from the DAX risk factor with 31 percent, although the exposure is only 10.5 percent. The contribution of USDEUR is 19 percent to VaR whereas the factor exposure is the largest one of 36 percent.

# 4.3.4.6 SAA and TAA

The Markowitz optimization approach can be used to define the SAA and TAA rigorously. We follow Leippold (2011), Lee (2000) and Roncalli (2014). Consider the optimization problem (4.1):

$$
\max _ {\phi} \left(\langle \phi , \mu \rangle - \frac {\theta}{2} \langle \phi , C \phi \rangle\right)
$$

where we assume the full investment condition. Then, the solution can be written as a sum of the GMV portfolio and a second portfolio  $\phi_X$ :<sup>12</sup>

$$
\phi = \phi_ {G M V} + \phi_ {X}.
$$

To introduce the SAA, we use the unconditional long-term (equilibrium) mean of the returns. Adding and subtracting the long-term mean  $\tilde{\mu}$  in the second component, the solution can be written after some algebra in the form:13

$$
\phi = \phi_ {G M V} + \phi_ {S} + \phi_ {T}. \tag {4.24}
$$

The second and the third component are the SAA and the TAA component, respectively. The sum of the three components is an efficient portfolio.

Each SAA component  $\phi_{j,S}$  is proportional to  $\tilde{\mu}_j - \tilde{\mu}_k$  for  $k\neq j$ . If the long-term forecasts of all assets are the same, the SAA component is zero. If the long-term forecasts differ, the holdings are shifted to the asset with the higher equilibrium return. The size of pairwise bets depend on the relative risk aversion  $\theta$  and the covariance  $C$  which enter

$\phi_S$ . The sum of the GMV and the strategic portfolio is called the benchmark portfolio in the asset management industry and the strategic mix portfolio in investment theory.

For each TAA component,  $\phi_{j,T}$  is proportional to

$$
\mu_ {j} - \tilde {\mu} _ {j} - \left(\mu_ {k} - \tilde {\mu} _ {k}\right)
$$

for  $k \neq j$ . Hence, there are again bets between the assets case where there are no bets against the same asset and the bets are of an excess return type with the SAA as benchmark. For  $N$  assets, there are  $N(N - 1)/2$  bets. As in the SAA case, the bets are weighted by the covariance matrix and the relative risk aversion.

# 4.3.4.7 Active Investment and Benchmarking

We consider the case of mean-variance optimization considering a general benchmark  $\mathbf{b}$ , see (4.5) for the notation. The investor chooses the bets such that the quadratic utility is maximized:

$$
\max  _ {\psi} \left(\langle \psi , \mu \rangle - \frac {\theta}{2} \langle \psi , C \psi \rangle\right) \tag {4.25}
$$

Assuming full investment, the solution of this active risk and return program can be written as a sum of two parts. One part is given by the benchmark and the second one by the bets. Note that in general this bet vector is different from the tactical asset allocation vector in last section.

Proposition 73. Consider the active risk and return optimization in (4.25) with the full investment constraint. The efficient frontier are straight lines in the  $(\sigma(\psi, \mathbf{b}), \mu(\psi, \mathbf{b}))$ -space. Inserting further linear constraints, the efficient frontier are non-degenerate hyperbolas.

# 4.3.4.8 Comparing Mean-Variance Portfolios with Other Approaches

We follow Ang (2012). Consider four asset classes - Barcap US Treasury (US govt bonds), Barcap US Credit (US corporate bonds), S&P 500 (US stocks), and MSCI EAFE (international stocks) for the period 1978 to 2011. Different strategies are chosen monthly and for the estimated parameters the past five years of data are used:

- Mean-variance (MV), equal weights (EW), Global Minimum Variance (GMV) and equal risk contribution (ERC) are four strategieess  
- Diversity weights, which are transformations of market weights using entropy as a measure of diversity, define another strategy.  
- Risk parity (RP). The optimal portfolio weights are chosen proportional to inverse volatility. This approach mimics negative leverage in the markets - if asset prices fall, volatility rises. This strategy ignores the correlation structure.  
- The Kelly rule.

<table><tr><td>Strategy</td><td>Return</td><td>Volatility</td><td>Sharpe ratio</td><td>USD 100 after 33 years</td></tr><tr><td>Mean-variance</td><td>6.06</td><td>11.59</td><td>0.07</td><td>697</td></tr><tr><td>Market weights</td><td>10.25</td><td>12.08</td><td>0.41</td><td>2,503</td></tr><tr><td>Diversity weights</td><td>10.14</td><td>10.48</td><td>0.46</td><td>2,422</td></tr><tr><td>EW</td><td>10</td><td>8.66</td><td>0.54</td><td>2,323</td></tr><tr><td>RP</td><td>8.76</td><td>5.86</td><td>0.59</td><td>1,598</td></tr><tr><td>GMV</td><td>7.96</td><td>5.12</td><td>0.52</td><td>1,252</td></tr><tr><td>ERC</td><td>7.68</td><td>7.45</td><td>0.32</td><td>1,149</td></tr><tr><td>Kelly rule</td><td>7.97</td><td>4.98</td><td>0.54</td><td>1,256</td></tr></table>

Table 4.5: Risk and return figures for the different investment strategies. (Ang [2012] and own calculations).

The mean-variance portfolio is the strategy with the worst performance: choosing market weights, diversity weights, or EW leads to higher returns and lower risk. A reason for the outperformance of the global GMV is that there is a tendency for low-volatility assets to have higher returns than high-volatility assets.

# 4.3.5 Review Markowitz Model

We considered so far properties of the Markowitz model without asking basic questions about the pros and cons of the model. This is the objective in this section.

First the Markowitz model is the most used model in portfolio allocation. There are two main reasons for this fact. First its simple and convincing economic assumption about the risk and return trade-off. Second, it defines a quadratic optimization problem (QP). This means  $\langle \mu, \phi \langle -\frac{\theta}{2} \langle \phi, C\phi \rangle$  is minimized under a set of linear constraints  $A\phi \leq b$  with  $A$  a matrix and  $b$  a vector. In its simplest form QP problem are even analytically solvable. Adding more constraints, the problem is numerically approached where decades of research in this direction provide efficient algorithms. Summarizing, portfolio optimization with a benchmark, a tracking-error problem, also the problem of Black-Litterman with views, index sampling, turnover constraints and the case with linear and quadratic transaction costs are all QP! Its specific mathematical form is therefore a success factor for mean-variance portfolio allocation.

Explained why the mean-variance analysis is successful, we consider its general properties:

- Portfolio theory in general and the mean-variance approach in particular are assumed to be related to diversification. But what does this really mean?  
- Is optimal investment in the Markowitz model to risk factor, arbitrage factors, hedging factors?  
- How smooth and robust is mean-variance optimization?

We start with the diversification issue and recall that optimal investment is proportional in the basic Markowitz model to  $C^{-1}\mu$ : the information matrix mixes expected returns for the optimal allocation and not the covariance matrix. But what can be said about the information matrix? Stevens (1998) derives an expression for the information matrix in the Markowitz model. Using general matrix inversion, the OLS regression of  $R_{t,i}$  on the return of all other assets  $R_{t,-i}$  plus a noise term which is normally distributed with mean zero and variance  $\sigma_i^2$  reads:

$$
R _ {t, i} = \beta_ {0} + \beta_ {i} ^ {\prime} R _ {t, - i} + \epsilon_ {i, t}.
$$

He proves that

$$
C _ {i i} ^ {- 1} = \frac {1}{\sigma_ {i i} (1 - R _ {i} ^ {2})}, C _ {i j} ^ {- 1} = - \frac {\beta_ {i j}}{\sigma_ {i i} (1 - R _ {i} ^ {2})}.
$$

Using this model, the information matrix elements follow as ratio between the estimated betas and the unhedgeable risk of the regression.

Proposition 74 (Stevens (1998)). Consider the standard Markowitz model 4.1.

$$
\phi_ {i} ^ {*} = \frac {1}{\lambda} \frac {\hat {\mu} _ {i} - \sum_ {k \neq i} \beta_ {i k} i \mu_ {k}}{\sigma_ {i} ^ {2} (1 - R _ {i} ^ {2})}.
$$

where  $R_{i}^{2} = 1 - \frac{\hat{\sigma}_{i}^{2}}{\sigma_{i}^{2}}$

In other words, the optimal MV allocation rewards large hedging errors in the above sense weighted by the tracking error of the hedging portfolio. The difference  $\hat{\mu}_i - \sum_{k\neq i}\beta_{ik}i\mu_k$  is a long-short combination of the asset's expected return and the hedge portfolio. MV optimality therefore does not mean that it is optimal to diversify across the risk sources but to concentrate the exposure on the long-short combination of risk minus the hedge. This is a complete different story than 'do not put all eggs in the same basket'. The better the hedge, i.e. the larger the  $R^2$  of the regression, the smaller is the denominator in the optimal policy and therefore the more weight the asset receives. But a high  $R^2$  means that the asset  $i$  is strongly correlated to the other assets. Hence, yet small variations of the dependence create strong variation in the optimal policy. This shows why strongly correlated assets are a source of instability of mean-variance optimal portfolios. An investor is long in asset  $i$  if the expected return of this asset is larger than the return of all other assets and similarly for a short position (and similar for a short position).

Bourgeron et al. (2018) provide a characterization of the above difference between the expected return and the optimal hedge:

Proposition 75 (Bourgeron et al. (2018)). Consider the standard Markowitz model 4.1.

$$
\phi_ {i} ^ {*} = \phi_ {i, 0} ^ {*} + \omega \left(\phi_ {i, 0} ^ {*} - \phi_ {i, h} ^ {*}\right)
$$

where  $\phi_{i,0}^{*}$  is the optimal portfolio by assuming zero correlation,  $\phi_{i,h}^{*}$  is the optimal portfolio of the hedging strategies and  $\omega$  is the leverage defined as the ratio between the idiosyncratic variance and the tracking error variance.

If tracking error is small, a larger leverage follows. This characterization shows that MV diversification means to leverage a hedge portfolio: The MV optimal portfolio is an aggressive portfolio by selecting a few bets!

To control for this incentives one uses constraints. The simplest one is full investment  $\sum_{i}\phi_{i} = 1$ . Solving (4.1) with such a constraint amounts to consider a Lagrangian function and then calculating the First-Order-Condition (FOC). Further constraints can be added. Real optimizer in asset and wealth management can consider up to hundreds of constraints. This destroys analytical tractability and in some sense leads optimization ad absurdum: If you know what you want by imposing many constraints why don't you simply state the investment policy? Furthermore, each constraint has an economic price, the shadow price, which reduces unconstrained utility. This should be made transparent to the investor what the economic price of his own constraints are, such as loving a particular stock, and what the price of constraints are induced by the AM firms such as the band with of the SAA and TAA. From an efficient frontier perspective, adding constraints transforms the hyperbola into piecewise straight lines and piecewise hyperbolas, Globally the constraint frontier lies below the efficient frontier and shifted towards more risk.

We now consider the second challenge, how to complement the Markowitz optimizations such that for example solutions are smooth, i.e. varying inputs slightly should lead to smooth changes of the allocation, controlling for a smooth rebalancing and controlling for turnover costs. Reconsidering the optimal portfolio  $\phi = \frac{1}{\theta} C^{-1}\mu$  the two inputs  $C$  and  $\mu$  need to be estimated. If there is estimation error in the covariance matrix this will be amplified for the information matrix. Since covariance matrices are large, say  $1000\times 1000$  matrices, and  $\mu$  is also an estimate the solution of the optimality condition is only an approximation to the unique solution if the inputs were known. We discuss this issue below. But also the returns need to be estimated. This is not easier than for the covariance matrix - the myriads of factors and factor all try to provide to explain or predict returns.

The main strategy is to add an additional term  $T$  to the quadratic utility function (Thikonov Regularization)

$$
\langle \mu , \phi \rangle - \frac {\theta}{2} \langle \phi , C \phi \rangle - c | | \Gamma \phi - \phi_ {0} | | _ {2} ^ {2}
$$

with  $c > 0, \Gamma$  a matrix,  $\phi_0$  an initial portfolio and  $||\ldots||_2$  the Euclidean norm.  $c$  controls the importance of the regularization term. These terms are commonly added to promote sparsity or to reduce sensitivity to outliers. There are many different ways how regularizations can be implemented.

The de-noising techniques of the covariance matrix are not sufficient for obtaining the stability of the solution. Figure 4.9 provides the intuition. Each covariance matrix can be diagonalized where the eigenvalues are all positive, real numbers in the diagonal matrix. Ordering the eigenvalues according to their size, we show below that the largest

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b7e186d22199d4aa2096aceb0e918932da8b176bc672d8162c8a98300517c491.jpg)  
Figure: Ridge solution with a target portfolio

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/efc6722aab772d238f08c7b5eebb3808b6f65e30c7389f8489c4a84cb4a1a46f.jpg)  
Figure: Ridge solution without a target portfolio  
Figure 4.8: Ridge solution for a portfolio with and without a target. The figures show how the ridge solution provides smooth portfolio components (denoted by  $x_{j}$ ) as a function of the control parameter  $c$ , (Source: Roncalli (2018))

eigenvalues of  $C$  account for portfolio risk. The smallest eigenvalues however matter for the information matrix  $C^{-1}$  which is the proportion constant for the optimal investment rule: The noisy eigenvalues drive optimal investment. Regularization techniques handle this small eigenvector problems. But this is not sufficient to obtain a meaningful optimal asset allocation since as stated above, the Markowitz model makes bets on the long-short portfolio of expected return minus the beta hedge. But these factors are distributed on the whole range of eigenvalues. Therefore, considering the largest ones and treating the smallest one using regularization leaves out all intermediate eigenvalues which impact also the stability and smoothness of the optimal allocation. Hence, more than de-noising of the covariance matrix is needed.

Some practitioners prefer to introduce restrictions into the optimization problem to stabilize the optimization problem. This approach has drawbacks:

Each restriction has an economic price.  

- Compare two constraint models. Is one allocation better than the other because of a better model or because of the chosen constraints? Constraints are ad hoc, discretionary decisions that impact a model's performance in a complicated way.

To introduce regularization, we consider the problem of optimizing or fitting for  $\phi_1, \phi_2$  in the objective  $||1(\phi_1 + \phi_2)||_2^2$ . There are infinitely many solutions  $\phi_1 = 1 - \phi_2$ .

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b7bfad52199ee031f32ade697749f09551d0fbb426a5133e9f41f7338fc822cf.jpg)  
Figure 4.9: Distribution of eigenvalues of a covariance matrix.

$\phi_1 = 10^{100}$  and  $\phi_2 = 1 - 10^{100}$  are two solutions which we do not like. Adding a penalty  $||\phi ||_1\coloneqq |\phi_1| + |\phi_2|$  an optimal solution is the sparse solution  $\phi_{1} = 1,\phi_{2} = 0$  . For different choices of  $c,\Gamma$  , different well-known regularization approaches follow. If  $\Gamma$  is set equal to the identity matrix, the ridge regularization follows. We next denote  $\hat{C}$  the unbiased empirical covariance matrix,  $F$  an estimator which is biased but converges more quickly than the empirical covariance,  $\hat{C} (\nu)\coloneqq \nu \hat{C} +(1 - \nu)F$  and if  $\nu^{*}$  is the minimizer of  $E(||\hat{C} (\nu) - C||^2)$  . If we set  $c = \frac{1 - \nu^{*}}{\nu^{*}}$  and  $\Gamma$  equal to the Cholesky decomposition of  $F$  then the Ledoit-Wolf covariance shrinkage method follows, see Section 4.4.2 for a discussion. We discuss regularization in different sections below.

# 4.3.6 Views and Portfolio Construction - The Black-Litterman Model

In all model considered so far, the views of the investors did not enter in a systematic form. But most investors have some views about specific assets and they wish to apply these views to their asset management. For example high past returns may not be the same in the future and the asset manager would like to correct this by implementing a prior view in the model. By doing this, the acceptance of the model increases. The views should be integrated consistently in the model such that stable estimations for the expected return and covariances follow.

There are many different approaches how views can be used in portfolio construction. We consider the Black-Litterman (BL) model (BL [1990]) to be the first, and still the most popular, model used by practitioners.

For further reading, in addition to BL, we cite Walters (2014), Satchell and Scowcroft (2000), Brand (2010), Meucci (2010), Idzorek (2006), Herold (2003), and He and Litterman (1999).

# 4.3.6.1 Black-Litterman Model

The two contributions of BL model to the asset allocation problem are:

- The equilibrium market portfolio serves as a starting prior for the estimation of asset returns.  
- It provides a clear way of specifying an investor's linear views on returns and of blending these views with prior information. The investor is not forced to have a view for all assets and the views can span arbitrary combinations of assets.

For non-linear view, consider entropy pooling. In the construction of BL, the first step is to define the reference model. Assume that for the returns  $R\mathcal{N}(\mu, C)$ , where both mean and covariance are unknown. Since the goal of BL is to model expected returns we start with a model for the mean:  $\mu \sim \mathcal{N}(\pi, C_{\pi})$ . Hence,  $\mu = \pi + \epsilon$  with  $\epsilon \sim \mathcal{N}(0, C_{\pi})$ . The covariance of the returns  $C_R$  about the estimate  $\pi$  is - given  $\mu$  and  $\epsilon$  are not correlated - is given by

$$
C _ {R} = C + C _ {\pi}. \tag {4.26}
$$

Therefore, the reference BL model is given by  $R \sim \mathcal{N}(\pi, C_R)$ . The mean  $\pi$  represents the best guess for  $\mu$ , and the covariance  $C_{\pi}$  measures the uncertainty of the guess. How do we fix  $\pi$ , the prior estimate of returns, that is to say the returns before we consider views?

BL uses a general equilibrium approach since if a portfolio is at equilibrium of supply and demand in the markets, then each sub-portfolio must be at equilibrium too. Therefore, an equilibrium approach for the return estimate is independent of the size of the portfolio under consideration. BL and many other use the CAPM in the following reverse engineering way. But there is no model restriction.

Using the CAPM means that all investors have a mean-variance utility function. Without any investment constraints, the optimal strategy  $\phi$  maximizes the expected utility given in (4.1)

$$
E (u) = \phi^ {\prime} \pi - \frac {\theta}{2} \phi^ {\prime} C \phi ,
$$

where we have replaced the expected returns by the unknown expected return estimate  $\pi$ . The solution gives us the optimal strategy  $\phi$  as a function of the return and covariance:  $\phi = \frac{1}{\theta} C^{-1}\pi$ .

Given the equilibrium strategy  $\phi$  in the CAPM we immediately get the excess return estimate

$$
\pi = \theta C \phi . \tag {4.27}
$$

How do we fix the risk aversion parameter? Multiplying (4.27) with the market portfolio  $\phi'$  implies that

$$
R _ {M} - R _ {f} = \theta \sigma_ {M} ^ {2} \tag {4.28}
$$

with  $R_{M}$  the total return of the market portfolio. In other words, the risk aversion parameter is equal to the market price of risk. Using (4.28) in (4.27), the CAPM specifies in equilibrium the prior estimate of returns  $\pi$ .

We consider next the insertion of views, where we follow Walters (2014). A view is a statement on the market. Views can exist in an absolute or relative form. A portfolio manager can, for example, believe that the fifth asset class will outperform the fourth one. BL assumes that views

- apply linearly to the market mean  $\mu$ ,  
- face uncertainty,  
- are fully invested (the sum of weights is zero for relative views or one for absolute views), and  
- do not need to exist for some assets.

More precisely, an investor with  $k$  views on  $N$  assets uses the following matrices:

- The  $k \times n$  matrix  $P$  of the asset weights within each view.  
- The  $k \times 1$  vector  $Q$  of the returns for each view. That is,  $P\pi = Q$  expresses the views.  
- The  $k \times k$  diagonal matrix  $\Omega$  of the covariance of the views, with  $\omega_{nn}$  the matrix entries. The matrix is diagonal as the views are required to be independent and uncorrelated. The inverse matrix with the entries  $1 / \omega_{nn}$  are known as the confidence in the investor's views.

The conditional distribution of the mean and variance can be represented in the view space as

$$
P (\text {V i e w} | \text {P r i o r}) \sim \mathcal {N} (Q, \Omega).
$$

Since the matrix  $P$  is in general not invertible, this expression cannot be written in a useful way in the asset space. But using Bayes' theorem, a posterior distribution of the returns that blends the above prior and conditional distribution follows. Since the asset returns and views are normally distributed, the posterior is also normally distributed. It is given by the Black-Litterman master formula for the mean returns  $\pi_{BL}$  and the covariance  $C_{BL}$

$$
\pi_ {B L} = C _ {\pi} ^ {- 1} \binom {\mathbb {I}} {P} \Omega^ {- 1} \binom {\mu} {Q} \tag {4.29}
$$

$$
C _ {B L} = C + C _ {\pi}
$$

$$
C _ {\pi} = \left( \begin{array}{c} \mathbb {I} \\ P \end{array} \right) \Omega^ {- 1} \left( \begin{array}{c} \mathbb {I} \\ P \end{array} \right)  .
$$

The parameters  $\Omega$  and  $C$  are not observable and must be fixed additionally.  $C$  is typically replaced by the estimated covariance matrix  $\widehat{C}$ . There are several ways of specifying  $\Omega$ . One can assume that the variance of the views will be proportional to the variance of the asset returns, one uses a confidence interval or one uses the variance of residuals if a factor model is used. We refer to Walters (2014) for details. How do we estimate the variance of the mean  $\pi$ -that is, how do we fix  $C_{\pi}$ ? BL assume the proportionality

$$
C _ {R} = \tau C \tag {4.30}
$$

with  $\tau$  the constant of proportionality factor. The uncertainty level  $\tau$  can be chosen proportional to the inverse investment period  $1 / T$ . The longer the investment horizon is, the less uncertainty exists about the market mean; the higher the value of  $\tau$ , the less weight is attached to the CAPM. Summarizing, the prior return distribution is a normally distributed random variable with the mean given in (4.27) and variance  $(1 + \tau)C$ . With this choices, the Black-Litterman master formula for the mean returns  $\pi$  and the covariance  $\mathbf{C}$  read

$$
\pi_ {B L} = \pi + \tau C P ^ {\prime} \left(P \tau C P ^ {\prime} + \Omega\right) ^ {- 1} (Q - P \pi) \tag {4.31}
$$

$$
C _ {B L} = \left(\left(\tau C\right) ^ {- 1} + P ^ {\prime} \Omega^ {- 1} P\right) ^ {- 1}.
$$

Several consistency checks can be applied to (4.31): First, if  $\Omega$  vanishes, which means absolute certainty about the views, then the posterior mean becomes independent or insensitive to the parameter  $\tau$ . Next, if the investor has a view on every asset, the matrix  $P$  becomes invertible. Since the covariances are by definition invertible the posterior mean equation simplifies to  $\pi = P^{-1}Q$ . Finally, if the investor is fully uncertain about the validity of his or her views - that is to say, the matrix entries of  $\Omega$  tend to infinity, there is no value added by adding any views to the model since the prior and posterior return distribution agree:  $\pi = \pi$ .

# Example

Consider four assets and two views. The investor believes that asset 1 will outperform asset 3 by 2 percent with confidence  $\omega_{11}$  and that asset 2 will return 3 percent with confidence  $\omega_{22}$ . The investor has no other views. Mapping these views into the above-defined matrices implies

$$
P = \left( \begin{array}{c c c c} 1 & 0 & - 1 & 0 \\ 0 & 1 & 0 & 0 \end{array} \right), Q = \left( \begin{array}{c} 2 \\ 3 \end{array} \right), \Omega = \left( \begin{array}{c c} \omega_ {1 1} & 0 \\ 0 & \omega_ {2 2} \end{array} \right). \tag {4.32}
$$

The technique developed by BL provides a framework in which more satisfactory results are obtained from a larger set of inputs than are obtained using the mean-variance framework. The model is usually applied to asset classes rather than single assets. Besides generating higher returns, the BL model leads to more stable portfolio allocations over time.

# 4.3.6.2 CIO Investment Process and Black-Litterman

A Black-Litterman-oriented investment process would have at least the following steps (Walters [2014]):

- Determine which assets constitute the market.  
- Compute the historical covariance matrix for the assets.  
- Determine the market capitalization for each asset class.  
- Use reverse optimization to compute the CAPM equilibrium returns for the assets.  
- Specify views on the market.  
- Blend the CAPM equilibrium returns with the views using the Black-Litterman model.  
- Feed the estimates (estimated returns, covariances) generated by the Black-Litterman model into a portfolio optimizer.  
- Select the efficient portfolio that matches investors' risk preferences.

These steps only define one part of the investment process of a CIO. In general, the CIO receives information from different sources the investment process: A macroeconomic view from research analysts, market information, chartist information and valuation information. Assume that one output of this information is to 'overweight Swiss stocks - underweight European stocks'.

This defines a pair-wise bet. All bets of this type form the tactical asset allocation (TAA). Several questions follow:

A How strong is the bet - that is to say, how much should the two stock positions deviate from the actual level 'overweight Swiss stocks - underweight European stocks'?  
B Should any possible currency risk in the bet be hedged?  
C How long should this bet last?  
D How confident is the CIO and his or her team about the bet?  
E Is the bet implementable and what is the precision of such an implementation measured by the tracking-error?  
F Will there be a stop-loss or profit-taking mechanism once the bet has been implemented?  
G How does the CIO measure the performance of the bet?

The approach to question A is often based on the output of a formal model. That is to say, a risk budgeting model, a BL model, or a mean-variance optimization model proposes to increase Swiss stocks by 5 percent and to reduce the European stock exposure by 5 percent. It is then common practice that this proposal is corrected by the CIO, either because it creates too much turnover for the portfolio managers or because he considers such a change to be too strong.

Question B is - among other things - a consistency question since, on the one hand, the  $+ / - 5$  percent increase in equities also changes the FX exposure of the whole TAA and, on the other hand, there could be a CHF-EUR bet following from the many information sources. Typically - question C - bets are made for one month. This is the standard time after which the CIO and his or her team review the TAA.

Question D is the information risk issue. Information risk is different from statistical risk. The most well-known statistical risk measurement in the industry is the tracking error, which measures the volatility of alpha over a period of time. The risk sources are market, counterparty, and liquidity risk of the assets. Bernstein (1999) defines information risk as the quality of the information advantage of a decision-maker under uncertainty.

Reconsider the above Swiss stock-European stock bet. This view must be driven by our information set, as well as by the proprietary process of analyzing the information and data. To evaluate information risks, we ask (Lee and Lam [2001]):

- What is the completeness and timeliness of our information set?  
- Have we missed something?  
- Have we misinterpreted something?  
- How confident are we about our models and strategies?

These questions suggest that some information risk may be quantified with a good deal of precision while in most cases precise measurement of information risks seems impossible, and well-informed judgement may be necessary. This may result in a final statement on the decision-maker's confidence of adding alpha. If, say, the confidence is 50 percent, we are not confident at all about the bet. A standard approach to measuring the performance of bets is the hit rate (HR).

A hit rate of 60 percent means that we add alpha in 60 percent of the months in which we make an active bet. The confidence in adding alpha can be interpreted as the expected value of the hit rate. Information risk is then quantified by the expected hit rates of our investment views.

# Example

We follow Lee and Lam (2001). They assume that alpha is normally distributed around its mean value. Then, there is a unique one-to-one mapping between the hit rate HR and the information ratio IR. To derive this relation, we have for the  $\alpha$  of an asset which follows a normal distribution:

$$
\mathrm {H R} = P (\alpha > 0), \alpha \sim \mathcal {N} (\overline {{\alpha}}, \mathrm {T E})
$$

with  $\overline{\alpha}$  the arithmetic average alpha and  $TE$  the tracking error. Changing variables:

$$
\mathrm {H R} = \frac {1}{\sqrt {2 \pi}} \int_ {- \frac {\overline {{\alpha}}}{\mathrm {T E}}} ^ {\infty} e ^ {- \frac {1}{2} y ^ {2}} d y
$$

with  $x = \frac{\alpha_i - \overline{\alpha}}{\mathrm{TE}}$  and defining the information ratio

$$
\mathrm {I R} = \frac {\overline {{\alpha}}}{\mathrm {T}}
$$

, we get:

$$
\mathrm {H R} = \frac {1}{\sqrt {2 \pi}} \int_ {- \mathrm {I R}} ^ {\infty} f (y) d y = 1 - \Phi (- \mathrm {I R}), \tag {4.33}
$$

with  $f$  the standard normal density function,  $\Phi$  the standard normal distribution function and IR the information ratio. Once the expected alpha and expected tracking error, and therefore the expected information ratio, are stated, the complete ex ante distribution of alpha is specified. The hit rate is the area to the right of  $0\%$  alpha. Using the square-root law the following information risks, confidence levels, and information ratios follow:

<table><tr><td>Information risks</td><td>Confidence (monthly HR)</td><td>Monthly IR</td><td>Annualized IR</td></tr><tr><td>Low</td><td>60%</td><td>0.25</td><td>0.88</td></tr><tr><td>Medium</td><td>56%</td><td>0.15</td><td>0.52</td></tr><tr><td>High</td><td>52%</td><td>0.05</td><td>0.17</td></tr><tr><td>Infinity</td><td>50%</td><td>0</td><td>0</td></tr></table>

Table 4.6: Information risks, confidence levels, and information ratios (Lee and Lam [2001]).

# 4.3.7 Heuristic Allocation: Risk Budgeting Portfolio Construction

Risk-based portfolio construction - called risk budgeting - has two basic properties:

1. It is not based on the optimization of an investor's utility function, unlike the Markowitz model.
2. It uses only explicitly the risk dimension of investment.

The first property derives from the mentioned problems using quadratic optimization. The second one reflects the difficulty of forecasting expected returns. Although only risk is explicit, returns are implicit and the approach therefore a priori does not lead to very conservative portfolios.

Constructing risk-based portfolios has three steps:

- Define how risk is measured.  
- Consider the risk allocation.  
- Define and solve the risk-budgeting problem. This implies the investment strategy.

# 4.3.7.1 Risk Measurements

The foundations of coherent risk measurement are given in the work of Artzner et al. (1999). They define a set of properties that each risk measure should satisfy, prove the existence of such measures, construct such measures and show that some widely used measures violate some of these properties. The properties that a coherent risk measure should satisfy (Artzner et al. [1999]) are:

1. The risk of two portfolios is smaller than the sum of the risks.  
2. The risk of a leveraged portfolio is equal to the leveraged risk of the original portfolio.  
3. Adding a cash amount to a portfolio reduces the risk of the portfolio by the cash amount.

There are several variations of this axiomatic approach to risk theory.

Value at risk (VaR) is only a coherent risk measure for elliptical return distribution. General VaR fails to satisfy axiom 1. Expected shortfall, i.e. what is the expected loss given the loss exceeds a VaR-value, is a coherent and convex risk measurement. Volatility risk measurements do not satisfy an additional property which is often assumed: If a portfolio's return dominates another portfolio's return in all scenarios, the risk of the former portfolio dominates the risk of the latter. Under the normal distribution distributed, VaR, expected shortfall and volatility risk measurement are equivalent by scaling the risk figures.

# 4.3.7.2 Risk Allocation

The main tool for risk allocation is the Euler allocation principle, see equations (2.13) and (2.14).

# 4.3.7.3 Risk Budgeting

We restrict ourselves to the case of two risk budgets; the generalization is obvious. The main idea is that the portfolio is chosen such that the individual risk contributions, using a specific risk metrics, equal a predefined risk budget.

Let  $B_{1}$  and  $B_{2}$  be two risk budgets in USD. For a strategy  $\phi = (\phi_{1},\phi_{2})$ , the risk budgeting problem is defined by the two constraints, which equate the two risk contributions  $RC_{1}$  and  $RC_{2}$  to the risk budgets - that is to say, the strategy is chosen such that the following equations hold:

$$
R C _ {1} (\phi) = B _ {1}, R C _ {2} (\phi) = B _ {2}. \tag {4.34}
$$

Summing the left-hand sides of (4.34) is, by the Euler principle, equal to total portfolio risk. The sum on the right-hand side is the total risk budget. Problem (4.34) is often recast in a relative form. If  $b_{k} = cB_{k}$  is the percentage of the sum of total risk budgets, (4.34) reads

$$
R C _ {1} (\phi) = b _ {1} R (\phi), R C _ {2} (\phi) = b _ {2} R (\phi). \tag {4.35}
$$

The goal is to find the strategies  $\phi$  which solve (4.34) or (4.35). This is in general a complex numerical mathematical problem. But introducing the beta  $\beta_{k}$  of asset  $k$ ,

$$
\beta_ {k} = \frac {\mathrm {c o v} (R _ {k} , R (\phi))}{\sigma^ {2} (\phi)} = \frac {(C \phi) _ {k}}{\sigma^ {2} (\phi)},
$$

the weights are given by

$$
\phi_ {k} = \frac {b _ {k} \beta_ {k} ^ {- 1} (\phi)}{\sum_ {j} b _ {j} \beta_ {j} ^ {- 1} (\phi)}. \tag {4.36}
$$

The weight allocated to component  $k$  is thus inversely proportional to the beta. This equation is only implicit since the beta depends on the portfolio  $\phi$ . The next proposition summarizes some explicit solvable cases.

Theorem 76. Consider the risk budgeting program (4.35) for  $N$  assets with volatility risk measure.

1. If correlation  $\rho = 0$  among all assets,

$$
\phi_ {k} = \frac {\sqrt {b _ {k}} \sigma_ {k} ^ {- 1}}{\sum_ {j} \sqrt {b _ {j}} \sigma_ {j} ^ {- 1}}. \tag {4.37}
$$

2. If correlation  $\rho = 1$  among all assets,

$$
\phi_ {k} = \frac {b _ {k} \sigma_ {k} ^ {- 1}}{\sum_ {j} b _ {j} \sigma_ {j} ^ {- 1}}. \tag {4.38}
$$

3. If correlation is minimal, i.e.  $\rho = -\frac{1}{N - 1}$  among all assets, the ERC portfolio follows:

$$
\phi_ {k} = \frac {\sigma_ {k} ^ {- 1}}{\sum_ {j} \sigma_ {j} ^ {- 1}}. \tag {4.39}
$$

4. In all other correlation cases, the implicit formula (4.36) holds.
5. If all volatilities are the same:

$$
\phi_ {k} \sim \left(\sum_ {j} \phi_ {j} \rho_ {i k}\right) ^ {- 1} \tag {4.40}
$$

1. implies for example that the higher volatility of a component, the lower is its weight in the RB portfolio. For equal risk contributions (ERC) model where all weights for the risk budget  $b_{k}$  are set equal to  $1 / N$ , Maillard et al. (2008) show that the volatility of the ERC model is furthermore located between the volatility of the minimum variance (MVP) portfolio and the volatility of an equally capital weighted (EW) portfolio:

$$
\sigma_ {M V P} \leq \sigma_ {E R C} \leq \sigma_ {E W}. \tag {4.42}
$$

The ERC portfolio is equal to the MV portfolio if (i) the correlation is constant and (ii) the correlation value attains its lowest possible value. The ERC is equal to the EW portfolio if all volatilities are identical.

Definition 77. The (ERC) approach is called the risk parity (RP) approach.

Although closed-form analytical solution for risk budgeting problems are possible only in some particular cases, there is a simplified heuristic allocation mechanism - inspired by the allocation (4.36):

$$
\phi_ {k} = L \times \frac {\operatorname {R i s k} _ {k} ^ {- m}}{\sum_ {k} \operatorname {R i s k} _ {k} ^ {- m}} \tag {4.43}
$$

with Risk any risk measure,  $L$  the portfolio leverage which is needed if one defines exante a risk level for the portfolio (risk-targeting approach) and  $m$  a positive number. If  $m = 0$ , the portfolio is equally weighted. For increasing  $m$ , the portfolio allocation becomes more and more concentrated on the assets with the lowest individual risk. For example, the GMV portfolio follows if all correlations are set equal to zero and  $m = 2$  and ERC by assuming that all correlations are constant and  $m = 1$ .

Teiletche (2014) illustrates some properties for the above four portfolios using Kenneth French's US industry indices, 1973-2014; see Figure 4.10.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/96fecd76987c94f705de2445422b7c7afcbbf0a95b98d857224c408b0f639a47.jpg)  
Equal Weight (EW)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/284f70fcbff09256ca497aa68291d879042b29d5db40fcdd1ca39bfc25549b2a.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/743fb36f5ebc5a1d9ce030978f542101ebf31370bf983a4ddbf9ebd75208997c.jpg)  
Minimum Variance (MV)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7a764159fb54d1cc7d054c9f20103c4a7f709650efb986ad142dc17b8805f495.jpg)  
Maximum Diversification (MD)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/fd1609071cf842a5e9554bb409c71fb4a147deef6c0f4567c27ec6f5f0cd4160.jpg)  
Risk Parity (RP)  
Figure 4.10: Risk-weighting solutions for EW, GMV, MD, and RP (ERC) portfolios using sector indices from Kenneth French. The variance-covariance matrix is based on five years of rolling data (Teiletche [2014]).

Figure 4.10 indicates that GMV has a preference for lower volatility sectors (e.g., utilities or consumer non-durables), MD prefers low correlation (e.g., utilities or energy), EW is not sensitive at all to risk measures, and RP (ERC) is mixed. The RP and EW show similar regular asset allocation patterns and GMV and MD asset allocation patterns are much less regular. The latter react much more to changing economic circumstances and are therefore more defensive.

Maillard et al. (2009) compare the ERC portfolio with  $1 / N$  and MVP portfolio for a representative set of the major asset classes from Jan 1995 to Dec 2008. $^{15}$  The ERC portfolio has the best Sharpe ratio and average returns. The Sharpe ratio of the  $1 / N$  portfolio (0.27) is largely dominated by MVP (0.49) and ERC (0.67). MVP and ERC differ in their balance between risk and concentration. The ERC portfolios are much less concentrated than their MVP counterparts and also their turnover is much lower. Lack of diversification in the MVP portfolios can be seen by comparing the maximum drawdown values: The value for MVP is  $-45\%$  compared to  $-22\%$  of the ERC portfolio.

When we restrict the risk measurement to volatilities, the heuristic approach (4.43)

takes the following generic component-wise form (Jurczenko and Teiletche [2015]):

$$
\phi = k \sigma^ {- 1}, \tag {4.44}
$$

where  $k$  is a positive constant,  $\sigma$  is a vector of volatilities of  $N$  assets, and  $\phi$  is the vector of risk-based portfolio weights. Equation (4.44) corresponds to the risk parity and maximum diversification portfolio solutions when the correlation among assets is constant, the minimum variance portfolio when correlation is zero, and the  $1 / N$  portfolio when all volatilities are equal. Many practitioners use (4.44) to scale their individual exposures and the MSCI Risk Weighted Indices attribute the weights proportionally to the inverse of the stock variances.

The constant  $k$  can be calibrated in different ways. Using a capital-budgeting constraint, that is to say, the sum of the components  $\phi_{i}$  is equal to 1, implies

$$
k = \frac {1}{\sum_ {k} \sigma_ {k} ^ {- 1}}.
$$

So, (4.44) becomes the heuristic model (4.43) with  $m = 1$  and zero leverage. If we use a volatility-target constraint  $\sigma_T$  for the risk-based portfolio, we get

$$
k = \frac {\sigma_ {T}}{N \text {C o n c e n t r a t i o n}} = \frac {\sigma_ {T}}{N C (\bar {\rho})} \tag {4.45}
$$

with  $\overline{\rho}$  the average pair-wise correlation coefficient of the assets and  $C(\overline{\rho})$  the concentration measure<sup>16</sup>

$$
C (\bar {\rho}) = \sqrt {N ^ {- 1} (1 + (N - 1) \bar {\rho})}. \tag {4.46}
$$

The concentration measure varies from 0, when the average pair-wise correlation reaches its lowest value, to  $+1$ , when the average correlation is  $+1$ . Hence,  $k$  increases when the diversification benefits are important - that is, when the correlation measure decreases. In this case, each constituent's weight needs to be increased to reach the desired volatility target: the risk-based portfolio even becomes leveraged. Risk-based investing often faces the criticism that it cannot allow for views. This is not true, see Jurczenko and Teiletche (2015) and Roncalli (2014).

To prove this formula, we write  $\Lambda_{\sigma}$  for the diagonal matrix with the vector of volatilities  $\sigma$  on its diagonal,  $\rho$  the correlation matrix of returns and  $\mathbf{I}$  the identity matrix. The covariance matrix can be written in the form  $C = \Lambda_{\sigma}\rho \Lambda_{\sigma}$  which implies

$$
\langle \sigma^ {- 1}, \Lambda_ {\sigma} \rho \Lambda_ {\sigma} \sigma^ {- 1} \rangle = \langle e, \rho e \rangle .
$$

The volatility of the risk-based portfolio is then given by (using (4.44)):

$$
\sigma_ {R B} = \sqrt {\phi C \phi} = k \sqrt {\langle e , \rho e \rangle} = k \sqrt {1 + \sum_ {i} \sum_ {j \neq i} \rho_ {i j}}.
$$

Introducing the average pairwise correlation coefficient

$$
\overline {{\rho}} = \frac {1}{N (N - 1)} \sum_ {i} \sum_ {j \neq i} \rho_ {i j}
$$

implies (4.45).

# 4.4 Estimation: The Covariance Matrix

The quality of the estimation of the input variables expected returns and covariance matrix is key. We follow in several parts de Nard et al. (2018) and Ledoit and Wolf (2019). Estimating the expected return has been for a long time in the focus of researchers starting with the CAPM, the Fama-French model and the explosion of factor models in the last years. One reason for the focus on returns is the existence of the The fundamental asset pricing equation. It states that changes in asset price returns are driven by changing expectations of the cash flows, changing correlations between the assets or changes in the discount factors. We refer the reader to Ilmanen (2012) for a discussion of estimating the expected return.

There is no comparable economic equation as the fundamental pricing equation for the covariance matrix which identifies the drivers. The main theoretical property of a covariance matrix is the possibility to diagonalize the matrix. This representation, the Principal Component Analysis (PCA), reduces the complexity of a  $N \times N$  covariance matrix to the study of  $N$  eigenvalues (entries of the diagonal matrix). Many approaches in estimating the covariance matrix start with an analysis of the eigenvalues.

The estimation problem of the covariance matrix faces estimation risk: The true parameters in the models are not known and one has to estimate these parameters given only a finite data set. Whichever statistical approach we choose, there is risk that the estimated parameters are different from the unknown, true parameter values.

There are different methods to estimate the covariance. We can classify the methods in three dimensions:

1. Static versus dynamics estimate of the covariance matrix.  
2. Number of degrees to estimate.  
3. Structure-Free Models versus Exact Factor Models versus Approximate Factor Models.

The number of degrees varies from order  $N^2$  with  $N$  the number of assets to the order  $N$  to low orders of 1, 2, 3 and the order zero. The order  $N^2$ , which means to use a sample estimate follows by the dimension of the covariance matrix  $N(N - 1)/2$ . Using a factor model, the order grows linearly since  $K + N(K + 2)$ , if there are  $K$  factors, is the size growth of the covariance matrix. We first rule out the possibility to estimate the covariance matrix using an unbiased sample estimates  $C^S$ . Given  $N$  assets and a time series of length  $T \sim N$ , then one cannot estimate an number of parameters which is of order  $N^2$  by the same order of magnitude of available data. This leads to a large estimation error. Considering  $N = 1000$  assets, a five years time series means  $T \sim 10000$  which we

claim is by far not long enough to control estimation error.

To quantify this, let  $R(j)$  be the rate of return in the past month  $j$ . The average return of  $n$  observations assuming IID returns has itself a mean  $\overline{R}$  and a standard deviation  $\sigma / \sqrt{n}$ . These are the true values. For an assumed annual return of  $12\%$ , the true monthly return is  $\overline{R}_{1m} = 1\%$ . For an annual standard deviation of  $\sigma = 5\%$  the monthly estimate  $\sigma_{1m} = 5 / \sqrt{12} = 1.44\%$  follows. This estimate is larger than the mean itself, i.e. not meaningful. Using  $n = 60$  (five years of data), the standard deviation estimate becomes 0.00645, which is not significantly smaller than the mean. If we would like to have a standard deviation estimate of, say, 1/10 of the mean, the equation  $0.05 / \sqrt{n} = 0.001$  implies  $n = 2,500$ . This corresponds to a time series of more than 208 years (2,500/12).

To illustrate estimation risk, we estimate the sample mean  $\widehat{\mu}^S$  and sample covariance  $\widehat{C}'S$  from the data and plug the values into the optimal portfolio rule (4.3):

$$
\phi_ {M V} = \frac {1}{\theta} \widehat {C} ^ {- 1, S} \widehat {\mu} ^ {S}. \tag {4.47}
$$

Assuming that the plugged-in parameters are the true ones leads to zero estimation risk. But this is not an optimal approach. $^{18}$  One has to define a procedure outside of the investment optimization program which fixes the values of the parameters.

Bouchaud and Potters (2009) illustrate this. They consider the Markowitz model without the full investment constraint. The optimal policy, if we assume the true  $\rho$  known:

$$
\phi_ {M V} = r \frac {\rho^ {- 1} \mu}{\langle \mu , \rho^ {- 1} \mu \rangle} \tag {4.48}
$$

with  $r$  the expected mean return. The true minimal risk is then

$$
\sigma_ {M V} ^ {2} = \left\langle \phi_ {M V}, \rho \phi_ {M V} \right\rangle = r ^ {2} \frac {1}{\left\langle \mu , \rho^ {- 1} \mu \right\rangle}. \tag {4.49}
$$

We compare this optimal case with the in-sample and out-of-sample risks. The in-sample estimate uses the known empirical correlation matrix  $\widehat{\rho}^S$  of the corresponding period. The out-of-sample matrix uses the empirical correlation  $\tilde{\rho}^S$  which is observed in the next period. The portfolio risks read:

$$
\sigma_ {M V, i n} ^ {2} = r ^ {2} \frac {1}{\langle \mu , \widehat {\rho} ^ {- 1 , S} \mu \rangle}, \sigma_ {M V, o u t} ^ {2} = r ^ {2} \frac {\langle \mu , \tilde {\rho} ^ {- 1} \rho \tilde {\rho} ^ {- 1} \mu \rangle}{(\langle \mu , \tilde {\rho} ^ {- 1} \mu \rangle) ^ {2}}. \tag {4.50}
$$

If the posterior estimate is equal to the true one, then the risk of the out-of-sample estimate is equal to the optimal one. Assuming that the in-sample estimate is not biased,

convexity properties for positive definite matrices imply:

$$
\sigma_ {M V, i n} ^ {2} \leq \sigma_ {M V} ^ {2} \leq \sigma_ {M V, o u t} ^ {2}. \tag {4.51}
$$

How far away are the inand out-sample risk from true risk? Pafka and Kondor (2004) show that for IID returns and large portfolios:

$$
\sigma_ {M V, i n} ^ {2} = \sigma_ {M V} ^ {2} \sqrt {1 - q} = \sigma_ {M V, o u t} ^ {2} (1 - q), q = \frac {N}{T}. \tag {4.52}
$$

The in-sample risk is  $\sqrt{1 - q}$  smaller than the true risk and while the out-of-sample risk is larger than true risk by the value  $1 / \sqrt{1 - q}$ . This defines data snooping.

But also estimation risk of the mean matters. Ang (2014) estimates the original mean-variance frontier using data from January 1970 to December 2011. The mean of US equity returns is 10.3 percent. Ang changes the mean to 13.0 percent. Such a change is within two standard error bounds. The minimum variance portfolios for a desired portfolio return of 12 percent are given in Table 4.17. This change caused the US position to change from -9 percent to 41 percent, and the UK position to move from 48 percent to approximately 5 percent.

<table><tr><td>Asset</td><td>US mean = 10.3%</td><td>US mean = 13.0%</td></tr><tr><td>USA</td><td>-0.0946</td><td>0.4101</td></tr><tr><td>JPN</td><td>0.2122</td><td>0.3941</td></tr><tr><td>GBR</td><td>0.4768</td><td>0.0505</td></tr><tr><td>DEU</td><td>0.1800</td><td>0.1956</td></tr><tr><td>FRA</td><td>0.2257</td><td>-0.0502</td></tr></table>

Table 4.7: MV portfolios for two different expected equity returns (Ang [2014]).

Returning to the estimation of the covariance matrix, the main question is how to reduce the number of degrees of freedom for the estimation purpose? The fully agnostic view of assuming equal weights to be optimal,  $\phi = 1 / N$ , is the other extreme to using sample estimates. Assuming EW means to avoid the need to estimate any input parameter - neither variances, correlations nor returns. DeMiguel et al. (2009) compare 14 optimized portfolio approaches across 7 datasets with the  $1 / N$  EW investment. Surprisingly,  $1 / N$  is difficult to beat by the 14 optimal portfolios. They empirically compare the Sharpe ratios, analytically derive the critical estimation window length for mean-variance strategy to outperform  $1 / N$  and use simulations to extend the models to classes of models which are designed to control estimation risk. The findings are:

- Empirically none of the 14 portfolio models consistently dominates  $1/N$  across all data sets in terms of Sharpe ratio and turnover.  
- Using US stock data, for 25 assets in the portfolio the critical estimation window is around  $3^{\prime}000$  months of data. This figure doubles for twice as much assets in the portfolio.
- Models which control for estimation risk also need very long data series to outperform  $1 / N$ .<sup>19</sup>

These results contradict the common view that heuristics is less successful than statistical optimization models. Ignoring part of ambiguous information - insufficient historical data for estimation of model input parameters - is what makes heuristics  $1 / N$  robust for the unknown future. But as we discuss below, there are now convincing alternatives to beat this agnostic case.

The  $1 / N$  model can also be used to get insights about which estimation risk is more severe - return or covariance risk? We follow Rohner (2014). Assume that  $\mu$  and  $C$  are known for 10 assets such that  $1 / 10$  is invested optimally in each asset. To see the impact if either of the two parameters is not known, simulate multivariate normal returns, use rolling window estimation with an integration period of 100 and calculate 300 sample means and estimated covariances. Use these estimates to calculate for each date the optimal portfolio weights, see Figure 4.11.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/fcc3dfadd99f3b4f7175acc9057defc465a0847abbe4ed5212c6c4d0548c0225.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/76cba6ce27ceef77fe49860a7d4b345544761ba8d2918297603cef7d3fe68955.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f99613b40f98de8a5aa6fddb278b4b973ab44856b7abd72ca821aa54b27cf3a9.jpg)  
Figure 4.11: Significance of return and covariance estimation risk. Source: Rohner [2014].

Even if the distribution of returns is known, estimated portfolio weights can deviate largely from their theoretical optimal values. It follows, that estimation error in expected returns has a larger impact than dependency estimation errors on the optimal portfolio weights. Therefore, GMV portfolio which do not depend on estimated returns are more

robust than other efficient portfolios.

Having argued against the agnostic and the  $N^2$  methods to estimate the covariance matrix, the next step is to consider low dimensional methods or methods which grow linearly with  $N$ . The linear shrinkage approach or the factor model approach are examples of low dimensional models and we compare these approaches with the order  $N$  approach of Ledoit and Wolf (2018), a non-linear shrinkage approach.

We proceed as follows: We first consider the topic of diagonalization of the covariance matrix (PCA, random matrices) and then we consider the linear and non-linear shrinkage approach.

# 4.4.1 Dimension Reduction: Eigenvalues and Eigenvectors

The estimation of the covariance is high dimensional. It is natural to reduce its dimension by projecting to a lower dimension space or by finding a better data representation. Principal Component Analysis (PCA) is a simple and successful method which dates back to a 1901 paper by Pearson. Let  $(R_k) \in \mathbb{R}^N$  be a return time series of length  $T$ . The goal is to project the data to a lower dimensional subset  $K$ : First, find the  $K$  dimensional affine space such that the projection of  $P_K(R_k)$  are the best approximation to  $R_k$ . Second, find  $K$  dimensional projection  $P_K$  of  $R_k$  such that as much variance of the data as possible is preserved.

Let

$$
R _ {k} \sim \mu + \sum_ {j = 1} ^ {K} \beta_ {k j} v _ {j}
$$

an approximation with  $W = (v_{1},\dots,v_{K})$  where  $(v_{j})$  is an orthonormal basis for subspace  $K$ . Then,  $W^{\prime}W = \mathbb{I}$  do to be orthonormality of the vectors  $(v_{j})$ . Finding the best linear fit means to solve the least square optimization:

$$
\min _ {\mu , W, \beta_ {k}, W ^ {\prime} W = \mathbb {I}} \sum_ {k = 1} ^ {N} | | R _ {k} - (\mu + W \beta_ {k}) | | ^ {2}.
$$

Optimizing for  $\mu$  implies

$$
\mu^ {*} = \mu_ {N},
$$

i.e. the sample mean follows. Optimizing  $\beta_{k}$  implies (orthonormality of the  $v$ 's):

$$
\beta_ {k} = W ^ {\prime} (R _ {k} - \mu_ {N}).
$$

Inserting this in the objective function implies

$$
\min _ {W, W ^ {\prime} W = \mathbb {I}} \sum_ {k = 1} ^ {N} | | W (R _ {k} - \mu_ {N}) ^ {\prime} W W ^ {\prime} (R _ {k} - \mu_ {N}) | | ^ {2} = (N - 1) \mathrm {t r} (W ^ {\prime} C ^ {S} W)
$$

with  $C^S$  the sample covariance and tr the trace of a matrix. But the matrix under the trace can be diagonalized according to the spectral theorem of linear algebra applies:

Proposition 78. Let  $C$  be a symmetric, positive definite and real matrix of dimension  $N \times N$ . There exists a diagonal matrix  $\Lambda$  and matrix  $W$  such that

$$
W ^ {\prime} C W = \Lambda . \tag {4.53}
$$

The diagonal elements of  $\Lambda$  are real-valued and positive (the eigenvalues  $\lambda_1, \ldots, \lambda_N$ ). The eigenvalues solve the polynomial equation  $\operatorname{det}(C - \lambda \mathbb{I}) = 0$  with  $\mathbb{I}$  the identity matrix. Given any eigenvalue  $\lambda_k$ , the solution of the linear equation  $Cv_k = \lambda_k v_k$  is called an eigenvector  $v_k$ . They form an orthonormal basis and  $W = (v_1, \ldots, v_N)$ .

Hence, the PAC is given by finding the largest eigenvalues and the corresponding eigenvectors. The restriction to the largest eigenvalues means 'de-noising' the covariance matrix. A covariance matrix  $C$  of dimension  $N \times N$  does not tell us how much the unobservable risk rivers of the  $N$  assets add to the total portfolio variance. Transforming the matrix using PCA allows us to derive how important the risk factors are in explaining portfolio risk? Consider Figure 4.12 where in the left panel the closing values of the Dow and S&P 500 index are shown. The two series are heavily dependent: A data point of the Dow corresponds to a S&P closing price such that the pair is close to the diagonal (think about the bifurcation for low closing prices). The dependence can be off-set, if we rotate the coordinate system. In the new coordinate system, data points have almost no variance in the  $y_{2}$  direction but only one in the  $y_{1}$  direction. Therefore, the  $y_{1}$ -direction factor explains most of the portfolio variance. De-noising then means to neglect the  $y_{2}$ -risk contribution. PCA does this.

The eigenvectors explain the variance of the factors in (2.2):

$$
\begin{array}{l} \sigma_ {p} ^ {2} = \langle \phi , C \phi \rangle = \langle \phi , W ^ {\prime} \Lambda W \phi \rangle \\ = \langle W \phi , \Lambda W \phi \rangle = \langle \psi , \Lambda \psi \rangle = \sum_ {i} \lambda_ {i} \psi_ {i} ^ {2}. \tag {4.54} \\ \end{array}
$$

Factors with low eigenvalues add only little to the portfolio risk and are therefore avoided - the de-noising of the covariance matrix. But the eigenvalues that are important from a risk perspective are the least important ones from a portfolio optimization perspective where  $C^{-1}$  matters, see (4.3)  $\phi = \frac{1}{\theta} C^{-1}\mu$ . But the eigenvalues of the information matrix are the reciprocal values  $1 / \lambda_{k}$  of the eigenvalues  $\lambda_{k}$ . This trade-off between risk and investment is one reason why portfolio managers often do not use portfolio optimization methods. Furthermore the small values of the inverse eigenvectors needed for optimal portfolios are not robust - a small change of the values heavily changes the portfolio. Therefore, regularization techniques are used.

Consider the matrix

$$
M = \left( \begin{array}{c c} 2. 2 5 & 0. 4 3 3 0 \\ 0. 4 3 3 0 & 2. 7 5 \end{array} \right)  .
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c509fdc6ba5ab8d041e113fb2c191109a0ca56f473d20e86425d5129c5941802.jpg)  
Figure 4.12: Closing values for the S&P 500 and Dow Jones Index in 2006. The red coordinate systems denote the rotation applied in PCA.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/cdd033c20ee7a1a479aa16a5da212422950d0560d5a5dd62ad2eb015e2034428.jpg)

This matrix is symmetric. Solving the eigenvalue equation

$$
\det (M - \lambda \mathbb {I}) = (2. 2 5 - \lambda) (2. 7 5 - \lambda) - 0. 4 3 3 0 ^ {2} = 0
$$

we get the two eigenvalues,  $\lambda = 3$  and  $\lambda = 2$ . Therefore, matrix  $M$  is also positive definite and satisfies all the mathematical properties of a covariance matrix. The information matrix  $M^{-1}$  has the inverse eigenvalues  $1/3$  and  $\frac{1}{2}$  on its diagonal, which shows that the ranking order reversion. Solving the two linear systems for the eigenvectors implies

$$
v _ {1} = (- 1. 7 3 2 0 5, 1) ^ {\prime}, v _ {2} = (1, 1. 7 3 2 0 5) ^ {\prime}.
$$

The two vectors are orthogonal.

As an application, consider the linear factor model (2.2) with  $N$  assets and  $K$  risk factors  $F$ . How does one estimates the model? Let  $R = (R_{1}, \ldots, R_{t})$  be the  $N \times T$  matrix and assume that  $K < N$ . Then (Kempthorne, Factor Models, MIT Lecture Notes, Fall 2013)

- Step 1: PCA analysis  
- $\bar{x} = \frac{1}{T} X\mathbf{I}$ , means of the rows with  $\mathbf{I}$  the identity matrix.  
- De-meaning of returns  $X^{*} = X - \bar{x}\mathbf{I}$

<table><tr><td>[% ]</td><td colspan="3">PCA of C</td></tr><tr><td></td><td>Factor 1</td><td>Factor 2</td><td>Factor 3</td></tr><tr><td>Asset 1</td><td>65</td><td>-72</td><td>-22</td></tr><tr><td>Asset 2</td><td>70</td><td>69</td><td>-20</td></tr><tr><td>Asset 3</td><td>30</td><td>-2</td><td>95</td></tr><tr><td>EV</td><td>8</td><td>0.8</td><td>0.3</td></tr><tr><td>Cumulated σp-contribution</td><td>88</td><td>97</td><td>100</td></tr></table>

Table 4.8: PCA analysis of covariance matrix. Note that the eigenvalues of  $C^{-1}$  are 12, 119, 380 for the factors 1, 2, 3, i.e. the inverse ordering relation compared to the covariance matrix. The first factor in the covariance matrix is a market factor since all components in the eigenvector are positive. It has the largest eigenvalue and contributes 88 percent to the portfolio's volatility.

Sample covariance  $\widehat{C} = \frac{1}{T} X^{*}X^{*^{\prime}}$  

- PCA:  $\widehat{C} = \widehat{W\Lambda}\widehat{W}'$  
- Step 2: Fixing initial estimates  
- $\widehat{\alpha}_{0} = \bar{x}$  
- $\widehat{\beta}_0 = \widehat{W}_m(\widehat{\Lambda}_m)^{\frac{1}{2}}$  where the subindex indicates the submatrix of the first  $m$  columns  
$\widehat{D}_0 = \mathrm{diag}(\widehat{C}) - \mathrm{diag}(\widehat{\beta}_0\widehat{\beta}_0^{\prime})$  
$\widehat{C}_0 = \widehat{\beta}_0\widehat{\beta}_0^{\prime} + D_0$  
- Step 3 Adjustment  
- Adjust sample covariance to  $\widehat{C}^* = \widehat{C} -\widehat{D}_0$  
- Adjust PCA, i.e. compute eigenvalues and eigenvectors for  $\widehat{C}^{*} = \widehat{W}\widehat{\Lambda}\widehat{W}^{\prime}$ ; update the eigenvalue and eigenvector matrices  
- Repeat the initial fixing steps leading to  $\widehat{\beta}_1, \widehat{D}_1$  and  $\widehat{C}_1 = \widehat{\beta}_1 \widehat{\beta}_1' + D_1$ .  
- Step 4: Generate sequence of estimates  
- Repeat the adjustments of the last step  
- Leads to sequence of triple  $\widehat{\beta}_k, \widehat{D}_k, \widehat{C}_k$  for  $k = 1,2,\ldots$  until  $D_s$  becomes sufficiently small  
- Finally, use the estimates from the last step

Another approach to find the parameters is to use a maximum likelihood estimation. Geometrically, the matrix  $\beta$  is found by an orthogonal projection of the returns on the set generated by the factors. This projection are the betas in beta pricing models or the factor risk premia in the APT model. Analytically,  $\beta$  is given by the eigenvectors of the PCA.

# Example Roncalli (2104)

Consider the S&P 500, SMI, Eurostoxx 50, and Nikkei 225 indices from Apr 1995 to Apr 2015. Calculating the correlation matrix on a weekly basis using the closing prices:

$$
\rho = \left( \begin{array}{c c c c} {1} & & & \\ {0. 8} & {1} & & \\ {0. 8 2} & {0. 8 8} & {1} & \\ {0. 6 7} & {0. 5 6} & {0. 5 8} & {1} \end{array} \right) s
$$

The data indicate that the correlation between the European and American markets is stronger than between the Japanese market and the European or American one. We therefore set up a two-linear-factor model.

The matrix  $\beta$  follows from the likelihood estimation

$$
\beta = \left( \begin{array}{c c c c} - 0. 0 1 5 & 0. 2 1 & 0. 2 9 & 0. 3 5 \\ . 9 1 & 0. 9 3 & 0. 9 6 & 0. 7 6 \end{array} \right)
$$

The portfolio is long only in one factor, the market factor by definition, and long/short in the second factor. Here it is short in the S&P 500 and long in the other three indices.

Given a PCA analysis of a covariance matrix - how noisy are the estimated eigenvalues? Random Matrix Theory (RMT) considers the study of the eigenvalues, eigenvectors of large-dimensional matrices whose entries are sampled according to known probability densities.[21] Basically, if the eigenvalue distribution of a covariance matrix is close to those of a matrix of completely random entries, then randomness dominates in the covariance matrix. A main feature of RMT is universality: The asymptotic behavior of random matrices is often independent of the distribution of the entries. A second one is that the limiting distribution takes non-zero values only on a bounded interval, displaying sharp edges. Sharp edges indicate that eigenvalues outside of the asymptotic range are non-random.

We write the empirical covariance  $(\ref{eq:1})$  in the form

$$
C ^ {S} = \frac {1}{T} R R ^ {\prime} \tag {4.55}
$$

where  $R$  is a  $N \times T$  matrix whose rows are the time series of the returns, one row for each stock. We assume that returns are normalized by their standard deviation such that their variance is 1. Suppose that the entries of  $R$  are random IID variables with mean zero and variance  $\sigma^2$ , i.e.  $R \sim \mathcal{N}(0, C)$ .  $R$  is a random matrix. Using PCA, the hope is to find a low dimensional structure in the distribution which corresponds to large eigenvalues of  $C$ . How close are the spectral properties of  $C^S$  and  $C$ ? If  $N$  is fixed and  $T \to \infty$ , the law of large numbers guarantees  $E[C^S] = C$ . But  $N$  is often of the order of  $T$  or even larger. In this case it is not clear whether  $C^S$  converges towards  $C$ .

We start with  $C = \mathbb{I}$ , i.e. there is no low dimensional structure. For  $T = 500$ ,  $N = 1000$  the histogram in Figure 4.13 shows that for finite  $N$  there is a positive probability of finding eigenvalues that may be above or below the theoretical bounds. The red line is the eigenvalue distribution predicted by the Marchenko-Pastur distribution.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7b6301d3723f1c5aa79ea7e87fbe3225ba051f5bcf49a145c4bb8539d5786d34.jpg)  
Eigenvalues Distribution C= Identity Matrix Marchenco-Pastur Law  
Figure 4.13: Simulation for  $N = 1000$  stocks and  $T = 500$ , i.e. daily data for two years. The red line is the theoretical eigenvalue distribution of Marcenko and Pastur. Source: Gatheral [2008].

The random matrix corresponds to the null hypothesis that the set of stocks considered are strictly independent, and that the correlation matrix is the identity matrix. Any deviation from this structure in the empirical correlation matrix suggest the presence of true information. All eigenvalues which belong to the theoretical spectrum of eigenvalues are noisy and should not be considered in portfolio optimization.

How are the PCA eigenvalues related to the eigenvalues of the random matrix covari

ance? The Theorem of Marcenko and Pastur provide the answer:

Proposition 79 (Marcenko-Pastur). Let  $R$  be the random matrix defined above. In the limit  $N, T \to \infty$  where the ratio  $Q \coloneqq T / N \geq 1$  is kept constant, the density of eigenvalues of  $\lambda$  is given by

$$
\rho (\lambda) = \frac {Q}{2 \pi \sigma^ {2}} \frac {\sqrt {(\lambda_ {+} - \lambda) (\lambda_ {-} - \lambda)}}{\lambda} \tag {4.56}
$$

where

$$
\lambda_ {\pm} = \sigma^ {2} \left(1 \pm \sqrt {\frac {1}{Q}}\right) ^ {2}.
$$

The random matrix  $C^S$  is a random Wishart matrix,  $\lambda_{pm}$  are the theoretical minimum and maximum eigenvalues of the random correlation matrix and  $\rho$  is the Marcenko-Pastur density.[22] The proof of the theorem is based on the following moment expansion and combinatorics:

$$
\frac {1}{N} E [ R ^ {\prime} R) ^ {k} ] = \int_ {\lambda_ {-}} ^ {\lambda_ {+}} \lambda^ {k} d \rho (\lambda).
$$

What can be said about the distribution of the largest eigenvalue? Can we find the cut-off the eigenvalues separating noisy from eigenvalues with have true information? What can be said about the eigenvalue distribution if  $N > T$  and can the IID assumption in RMT be relaxed? The answer to the first question is given by the Tracy-Widom law: The probability distribution of the largest eigenvalue can analytically expressed in case of normally distributed random variables. We refer to the literature for details.

Figure 4.14 compares the case of a random identity matrix with the eigenvalue distribution of a risk model (blue histogram). The higher frequency for large eigenvalues indicates that the largest eigenvalues in the risk model which determine the risk is not driven by noise compared to the identity matrix assumption. In other words, the risk model is able to capture true risk information. A similar conclusion follows for the small eigenvalues which dominate in optimal portfolio construction. For the intermediate eigenvalues there is virtually no difference to the pure noise case. These the factors which matter in the Markowitz model in the long-short portfolio of the expected return minus the beta hedge which lead to unstable optimal allocations.

# 4.4.2 Linear Shrinkage of the Covariance Matrix

The sample covariance matrix in (4.55) is unbiased and the maximum likelihood estimator under normality. Stein (1956) and James and Stein (1961) showed that in dimensions  $N$  larger than 3, a better estimator than the sample mean exists by shrinking, i.e. by using a linear combination of the sample mean and the target vector: The mean squared error (MSE) of the shrugged estimator is smaller than for the sample mean. Ledoit and

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b52bc5ed44f38e529725fabe887dbdc1feb19b4294253d6cb455fc551c2d5931.jpg)  
Figure 4.14: Simulation for  $N = 1000$  stocks and  $T = 500$ , i.e. daily data for two years. The blue histogram corresponds to a the eigenvalue frequencies of a risk model.

Wolf (2004) extended Stein's approach to the covariance matrix. To this end, we use the Frobenius norm for a  $N \times N$  matrix  $A$ :

$$
\left\| A \right\| _ {F}; = \sqrt {\operatorname {t r} \left(A ^ {\prime} A\right) / N}.
$$

Linear shrinkage is the approach where a highly structured estimator  $\mathbb{I}$ , say the identity matrix representing the  $1 / N$  approach, is combined with the unstructured sample covariance matrix  $C^S$  with  $N^2$ -growth in the form

$$
\hat {C} = a _ {1} F + a _ {2} C ^ {S}, \nu \in [ 0, 1 ].
$$

The shrinkage value  $a_{j}$  is constant. To find the optimal weights, one solves

$$
\min  _ {a _ {j}} E | | \hat {C} - C | | _ {F} ^ {2} ]
$$

where  $\hat{C}$  is given by the above linear form. A straightforward calculation proves:

Proposition 80. The above optimization problem has the unique solution:

$$
\hat {C} ^ {*} = a ^ {*} \mu \mathbb {I} + (1 - a ^ {*}) C ^ {S} \tag {4.57}
$$

where

$$
a ^ {*} = \frac {E [ | | C ^ {S} - C | | _ {F} ^ {2}}{E [ | | C ^ {S} - \mu | | _ {F} ^ {2}}, \mu = \sqrt {t r (C ^ {\prime} \mathbb {I}) / N}.
$$

The matrix  $\hat{C}^*$  is invertible.

The optimal solution can be interpreted as shrinking the sample covariance matrix towards the shrinkage target  $\mu \mathbb{I}$  with (shrinkage) intensity  $a^*$ . Ledoit and Wolf (2003) state: The beauty of the principle is that by properly combining two 'extreme' estimators one can obtain a 'compromise' estimator that performs better than either extreme.

The above optimal convex combination depends on unknown population parameters of the true covariance matrix, i.e. the estimator is not feasible. But is not difficult to derive a feasible estimator that is asymptotically as good. Asymptotically here means that both  $N, T$  tend to infinity but the ratio  $N / T$  converges to a positive, fixed ratio, see Ledoit and Wolf (2019) for the analysis.

To illustrate the shrinkage idea, consider a  $N \times N$  covariance matrix where  $\sigma_{ij}$  is the non-observable true covariance for  $i \neq j$  and  $\operatorname{cov}_{ij}$  is the sample covariance. The squared deviation of the weighted average from the true value reads  $(1 - a)\operatorname{cov}_{ij} - \sigma_{ij})^2$  which is a loss measure. Since the sample covariances are random, we take the expected loss function and minimization is a routine quadratic optimization with the following optimal shrinkage intensity

$$
a = \frac {\sum_ {j > i} \mathrm {v a r} (\mathrm {c o v} _ {i j})}{\sum_ {j > i} | \mathrm {v a r} (\mathrm {c o v} _ {i j} + \sigma_ {i j} |}.
$$

Hence, to fix the optimal shrinkage intensity  $a^*$ , the variances have to be estimated. Since the nominator and dominator are both positive and the latter one dominates the former one the shrinkage intensity takes values in the unit interval.

# 4.4.3 Non-Linear Shrinkage of the Covariance Matrix

The class of non-linear shrinkage estimators was introduced by Stein (1975, 1986). Intuitively, small eigenvalues of the sample covariance matrix are pushed up and the large ones pulled down by an amount that is determined individually for each eigenvalue. Given  $N$  eigenvalues, there are  $N$  degrees of freedom. This therefore defines an intermediate approach to covariance estimation between the low dimensional optimized approaches and the unstructured sample estimate. Based on the work of Stein and Theorem of Marcenko and Pastur, see also the Random Matrix Section. Contrary to the linear shrinkage, were all shrinkage of the target  $\mu \mathbb{I}$  is uniform or global, in the non-linear case entries with relatively more (less) sampling error should be moved more (less) to the corresponding entries of the target. Ledoit and Wolf (2019) show how to control for two problems with a local or non-linear approach. First, the number of distinct entries of  $\hat{C}$  is of the order  $N^2$ . Second, using different shrinkage intensities one has to assure that the resulting shrinkage estimator will be positive semi-definite. To control these two issues one starts from the spectral decomposition of the sample covariance matrix, i.e. one works with the eigenvalues and eigenvectors. The authors show that the spectral representation of the optimal sample covariance matrix can be written with the same eigenvectors as for the

sample covariance matrix but with the eigenvalues replaced by the convex combination

$$
\hat {\lambda} _ {i} = a ^ {*} \mu + (1 - a ^ {*}) \lambda_ {i}
$$

where  $\lambda_{i}$  is an eigenvalue of the sample covariance matrix. Then one uses different shrinkage intensities for different sample eigenvalues. Since there are  $N$  eigenvalues, the method is of order  $N$ . As in the case of linear shrinkage, one defines a similar optimization problem which leads to an infeasible estimator. One therefore also relies on asymptotic analysis. But since there are  $N$  parameters in the limit  $N,T$  to infinity, the number of parameters explodes. To perform the analytics one has to use the machinery of random matrix theory. We refer to the literature.

We review two extensions of the set-up: The extension to dynamic models and the extension to factor models. The dynamic models allow us to get rid of the IID assumption for the  $T$  observations. In order of not running in the curse of dimensionality problem, instead of multivariate GARCH models, Ledoit and Wolf suggest to use a version of the dynamic conditional correlation (DCC) model of Engle (2002) based on correlation targeting. They define a GARCH(1,1)-type of model for the conditional covariance of devolatized returns, see the literature for details.

The second extension is to use factor models to estimate the covariance matrix of a large universe of asset returns. Setting up a factor model, the approach is to use shrinkage estimation for the residual covariance matrix of a general factor model. The factor model can be static, i.e. the intercepts and the factor loadings are time-invariant, the conditional covariance matrix of the vector of factors is time-invariant and the conditional covariance matrix of the vector of errors is time-invariant. Dynamic factor models are then given by assuming all static components to be dynamic except the intercept since the authors found that in this context of portfolio selection the conditional factor models do not work better.

# 4.4.4 Comparing Different Approaches - Asymptotics

Ledoit and Wolf (2018) provide an asymptotic analysis on a monthly basis using Center of Security Prices, Jan 1 1972 until Dec 31 2011. The out-of-sample period ranges from Jan 19 1973 to Dec 31 2011, i.e.  $T = 480$  months. Each month the covariance matrix is estimated using the most recent  $T = 250$  daily returns. Portfolio sizes  $N$  are 30, 50, 100, 250, 500 covering the majority of important stock indices. They first fix the 500 largest stocks with a complete return history over 1 year and expected over the next month and then select at random the  $N$  stocks.

The test goal is the estimate of the GMV portfolio without any short-sales restrictions. They consider 11 portfolio but we restrict to the following cases:

- $1 / N$  portfolio.
- Sam: Sample covariance matrix estimate portfolio.  
- Lin: Linear Shrinkage portfolio.  
- Non-Lin: Non-linear Shrinkage portfolio.  
- Inv-Non-Lin: Non-linear Shrinkage portfolio where the information matrix is estimated.  
- Sharpe: The portfolio where the estimate is given by a single factos.  
- FF: Estimated covariance is given by the Fama-French three-factor model.

Table 4.9 presents the results. Since the standard deviation of the true GMV portfolio  

<table><tr><td>Portfolio</td><td>1/N</td><td>Sam</td><td>Lin</td><td>Non-Lin</td><td>Non-Lin-Inv</td><td>Sharpe</td><td>FF</td></tr><tr><td>N=30</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>AV</td><td>11.14</td><td>8.64</td><td>8.52</td><td>8.71</td><td>8.72</td><td>8.22</td><td>9.39</td></tr><tr><td>SD</td><td>20.05</td><td>14.21</td><td>14.16</td><td>14.08*</td><td>14.08</td><td>14.08</td><td>14.59</td></tr><tr><td>SR</td><td>0.56</td><td>0.61</td><td>0.6</td><td>0.62</td><td>0.62</td><td>0.56</td><td>0.66</td></tr><tr><td>N=50</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>AV</td><td>9.54</td><td>4.65</td><td>5.1</td><td>5.21</td><td>5.22</td><td>5.22</td><td>5.44</td></tr><tr><td>SD</td><td>19.78</td><td>13.15</td><td>12.75</td><td>12.68***</td><td>12.68</td><td>13.04</td><td>12.51</td></tr><tr><td>SR</td><td>0.48</td><td>0.35</td><td>0.4</td><td>0.41</td><td>0.41</td><td>0.4</td><td>0.43</td></tr><tr><td>N=100</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>AV</td><td>10.53</td><td>4.74</td><td>4.99</td><td>5.1</td><td>5.12</td><td>4.81</td><td>5.8</td></tr><tr><td>SD</td><td>19.34</td><td>13.11</td><td>11.79</td><td>11.52***</td><td>11.55</td><td>11.96</td><td>11.3</td></tr><tr><td>SR</td><td>0.54</td><td>0.36</td><td>0.42</td><td>0.44</td><td>0.44</td><td>0.4</td><td>0.51</td></tr><tr><td>N=250</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>AV</td><td>9.57</td><td>275.02</td><td>5.81</td><td>6.26</td><td>6.43</td><td>5.95</td><td>6.6</td></tr><tr><td>SD</td><td>18.95</td><td>3,542.90</td><td>10.91</td><td>10.34***</td><td>10.49</td><td>11.3</td><td>10.47</td></tr><tr><td>SR</td><td>0.5</td><td>0.08</td><td>0.53</td><td>0.61</td><td>0.61</td><td>0.52</td><td>0.63</td></tr></table>

Table 4.9: Performance measures for various estimators of the GMV portfolio. AV, average; SD, standard deviation; SR, Sharpe ratio; FF, Fama-French three-factor model. All measures are based on 10,080 daily out-of-sample returns in excess of the risk-free rate. In the rows SD, the lowest number appears in bold. In the columns Lin and NonLin, significant out-performance of one of the two portfolios over the other in terms of SD is denoted by asterisks: *, **, and ** indicate significance at the 10%, 5%, and 1% level, respectively (Ledoit and Wolf [2018]).

decreases in  $N$ , this should be reflected by the different constructions. Increasing from  $N = 30$  to  $N = 500$ , the standard deviation of  $1 / \mathrm{N}$  decreases by only 1.1 percentage points compared to Lin and Non-Lin with 3.9 and 4.4 percentage points. In general,  $1 / \mathrm{N}$  is consistently outperformed in terms of the standard deviation by all other portfolios with exception the sample portfolio. Non-Lin has the uniformly best performance among

the rotation-equivariant portfolios. For  $N = 250$  and 500, Sharpe ratio gains are 0.08 and 0.06 or in relative terms  $15\%$  and  $12\%$ , respectively. If one forms the factor portfolio Non-Lin-Sharpe, then it outperforms FF which outperforms SF (numbers not displayed.) Summing up, Non-Lin dominates all other rotation-equivariant portfolios portfolios in terms of the standard deviation and additionally Lin in terms of the Sharpe ratio. Considering the summary statistics of portfolio weights over time, the most dispersed weights among the rotation-equivariant portfolios are found for Sam. The three shrinkage methods have generally the least dispersed weights. The authors provide robustness tests, tests with transaction costs and tests where individual stocks are replaced by the Ken French portfolios.

Table 4.10 presents the results for the case where dynamic and factor models are used.  

<table><tr><td></td><td colspan="3">N=100</td><td colspan="3">N=1000</td></tr><tr><td></td><td>AV</td><td>SD</td><td>IR</td><td>AV</td><td>SD</td><td>IR</td></tr><tr><td>EW</td><td>16.55</td><td>21.33</td><td>0.78</td><td>17.55</td><td>20.3</td><td>0.87</td></tr><tr><td>NL</td><td>14.76</td><td>14.16</td><td>1.04</td><td>15</td><td>8.75</td><td>1.71</td></tr><tr><td>DCC-NL</td><td>14.95</td><td>14.13</td><td>1.06</td><td>14.82</td><td>7.95</td><td>1.86</td></tr><tr><td>EFM1</td><td>15.37</td><td>16.5</td><td>0.93</td><td>16.33</td><td>12.78</td><td>1.28</td></tr><tr><td>EFM5</td><td>15.22</td><td>15.49</td><td>0.98</td><td>15.94</td><td>11.39</td><td>1.4</td></tr><tr><td>AFM1-NL</td><td>14.79</td><td>14.16</td><td>1.04</td><td>15</td><td>8.75</td><td>1.72</td></tr><tr><td>AFM5-NL</td><td>14.78</td><td>14.17</td><td>1.04</td><td>14.9</td><td>8.75</td><td>1.7</td></tr><tr><td>AFM1-DCC-NL</td><td>14.69</td><td>14.02</td><td>1.05</td><td>15.76</td><td>7.84</td><td>2.01</td></tr><tr><td>AFM5-DCC-NL</td><td>14.58</td><td>14.09</td><td>1.04</td><td>15.28</td><td>7.91</td><td>1.93</td></tr></table>

Table 4.10: Annualized performance measures (in percent) for various estimators of the Markowitz portfolio with momentum signal. AV = average; SD = standard deviation; and IR = information ratio. AV is the average of the 10,080 out-of-sample returns and then scaled to one year. SD is the standard deviation of the 10,080 out-of-sample returns and then scaled to one year. IR is the ratio AV/SD. EFM means Exact Factor Models, AFM Approximate Factor Models. The number after EFM and AFM stands for the number of considered Fama-French factors. DCC means the dynamic model and NL non-linear shrinkage. *** denotes significance at the 0.01 level.(Ledoit and Wolf [2018]).

The return signal is given by momentum, i.e. the geometric average of the previous 252 returns on the stock but excluding the most recent 21 returns. The vector of these averages define the expected return  $\mu$  signal. The first result is that all models consistently outperform the  $1 / \mathrm{N}$  model. Second, approximate factor models consistently outperform the exact factor models. Third, DCC-NL outperforms the other structure-free models and the exact factor models and AFM-DCC-NL consistently outperforms DCC-NL for large portfolio sizes. For the one-factor AFM-DCC-NL with  $\mathrm{N} = 1000$  the outperformance is statistically significant. In a nutshell, dynamic models dominate static ones,  $1 / \mathrm{N}$  becomes a dominated strategy in this fine-tuned non linear shrinkage approach

and dynamics plus one factor does better than using more factors. This is an indication that instead of searching a large number of factors a sound dynamics of the estimation of the covariance matrix leads to more performing results.

# 4.5 Factor Models

One searches for liquid objects - risk factors - which are (i) random variables that should explain return of assets, (ii) not divisible into smaller parts and (iii) different risk factors should do not contain the same risk sources (risk unbundling). Do risk factors exist? How are they selected? Several different approaches are used to select factors.

The first one uses theory. The classic is the CAPM where the market portfolio return is only factor which determines expected returns. Merton (1973) extended the theory to the inter-temporal context. In this model any state variable that predicts future investment opportunities such as term premium, volatility premium, default premium, inflation define additional factors.

Statistical factor selection is a second approach with the arbitrage pricing theory (APT) of Ross as the classic model. Finally, identifying factors based on firm characteristics with the famous the three-factor model of Fama and French (1993) defines the empirical approach to facto selection.

# 4.5.0.1 Style Investment: Quality and Momentum

Empirical observations of some liquid trading strategies, all different from investing in the broad market, can show empirical time-averaged persistent return patterns in the data. The patterns are based on grouping the assets in so-called styles or factors. The Fama-French factors value and size are examples. The factors capture firm characteristics such as valuation ratios derived from the balance sheets and income statements or market parameters such as volatility. A characteristic is then mapped into a tradeable liquid strategy in a long-only or a long-short (market neutral) combination. Figure 4.15 illustrates the decomposition of risk premia into traditional and alternative ones. We stress that the different premia have common risk sources, i.e. they are not orthogonal to each other.

# 4.5.0.2 Quality Premium

We consider the quality risk factor (EQ Quality), see Figure 4.16, for all stocks in the MSCI Europe. One calculates on a monthly basis firm specific figures such as profitability, net profit or degree of indebtedness. This allows to calculate the quality figure (Q-figure) for all firms. To consider the sector structure, the Q-figure is normalized by using the average sector Q-figure and the sector volatility. This defines the Q-score - the characteristic. Ranking these scores one observes that on average those firms with a high

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9844cb7776da2551a80334772d29e581a602f7cc1be5d326c280f8379846428f.jpg)  
Figure 4.15: Overview.

score led to a larger return than those with a lower score. This empirical feature called EQ Quality. If one believes that this historical return pattern will continue to hold on average in the future, one can invest in such a strategy. A long-short EQ implementation removes directional risks. There are institutional investors which do not want or do not can invest in long-short vehicles. But investing long only in a risk premia is not market neutral. Market neutrality is lost and correlation between risk premia and between traditional asset classes moves significantly away from a weak correlation structure. But a long-short strategy is not free of risk, see the momentum crash below. Factor investing has emerged as the new paradigm among sophisticated institutional investors. A large body of literature suggests that shorting is difficult to implement. Therefore, institutional investors often prefer long-only approaches since they are also less exposed to liquidity risk, have greater capacity, and do not require the use of leverage or derivatives. The producer offer the risk premia products as fully transparent indices. Different wrappers are used for risk premia investment - UCITS funds, ETFs or structured notes.

# 4.5.0.3 Momentum Factor

The idea is to extrapolate past performance into the future by 'buying the past winners (long) and selling the past losers (short)', see Figure 4.17. Daniel and Moskowitz (2012) consider a time series from 1932 to 2011 using international equities; there are 27 commodities, 9 currencies, and 10 government bonds in their data set. They find that in the period past WWII through 2008, the long/short equity momentum strategy had an average return of 16.5 percent per year, a negative correlation (beta) with the

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/e16d89334f6eeafc5e7d5aba57417deeb84133bc1c58f8ee19260551277de35c.jpg)  
Figure 4.16: Construction of the risk factor quality.

market of  $-0.125$ , and an annualized Sharpe ratio of 0.82. They document that momentum is pervasive for equities, currencies, commodities, and futures. The maximum monthly momentum return was  $26.1\%$  and that the worst five monthly returns were  $-79\%, -60\%, -46\%, -44\%$ , and  $-42\%$ . Intuitively, the premium is positive if the winner's return is larger than the loser's one. In a momentum crash, past winners will be future losers and vice versa - you are wrong both the long and short leg of the investment. This happened in fast market rebounds:

- In June 1932 the market bottomed. In the period July-August 1932, the market rose by 82 percent. Over these two months, losers outperformed winners by 206 percent.  
- In March 2009 the US equity market bottomed. In the following two months, the market was up by 29 percent, while losers outperformed winners by 149 percent. Firms in the loser portfolio had fallen by 90 percent or more (such as Citigroup, Bank of America, Ford, GM). In contrast, the winner portfolio was composed of defensive or countercyclical firms like AutoZone.

The rationale is simple. Suppose markets are crashing. Then losers already lost in value before the crash and during the crash they are becoming extremely cheap if one beliefs that they will not default. Since investors are convinced that markets will recover, the demand for the losers exceeds the gainers one which leads to the winner-loser reversal.

Byun und Jeon (2018) suggested to adapt the momentum strategy in order to reduce the impact of momentum crashes. They considered to observe past returns for 12

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3387efcb2555f3e03779f3fae69ce98b52427477eff81261e3d5b2db28b506ae.jpg)  
Figure 4.17: We assume that stocks are screened based on their past return over the last  $J = 3$  months, where also  $J = 6,12$  months are used. This screening identifies the past winners and losers and defines the formation period. After this identification, no action is taken for one month. The reason is to filter out any possible erratic price fluctuations in the past winners and losers selection portfolio. Finally, in the holding period the selected stocks are hold for  $K = 3$  months where again longer holding periods are possible. Afterwards the positions are closed. This procedure is repeated monthly leading to an overlapping roll-over portfolio allocation.

months but only invest 1 month and the decision criterion for going long and short is past cumulated 52 weeks return. Therefore, the authors expect that 52-week high subsumes the predictive power of past 12-month return and investing only for one month adapts to often seen fast momentum reversals. This mimics that as the market rebound, investors demand increases on stocks that are far from their 52-week highs. This bias induces that the 52-week high negatively related with future returns. The authors show that during the crash periods, stocks far from their 52-week highs outperform stocks near their 52-week highs.

Figure 4.19 shows the return of investing \(1 in 1956 until 2015 in a market factor, and the styles size, value or momentum.[23]

In this long-term view three observations are immediate: Simple grouping of assets can lead to significant outperformance of the market return for long periods but there

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8fbf19274018a9f008fe1bb8c452c682d8f5540b0db78bf58fb728e548c94267.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/bbb8d659324b3b896ee8744eabcd2bf6c31a5a092b922c035d9ef4299950ffd3.jpg)  
Figure 4.18: Long-only momentum strategies. Left panel - momentum strategies 1947-2007 Right panel - momentum strategies during the GFC (Daniel and Moskowitz [2012]).  
Figure 4.19: Investment return of \(1 in 1956-2014 in the market, market plus value, market plus size and market plus momentum factor (Ken French's website).

are also short time periods where factor investment can crash. This is most dramatic seen for the momentum crash during the GFC. Finally, the factors do not seem to be independent - momentum and markets crash and boom in parallel during the GFC and the following decade.

Is there a theoretical foundation of styles/risk factors? Can theory differentiate between style which are supported in in equilibrium and styles which are fantasies? How are risk factors identified and turned into tradeable strategies? How can it be that in the long run simple grouping of assets produce much higher returns persistently, i.e. why aren't they arbitraged away? Who is on the other side of the trades? We consider these question in the sequel.

# 4.5.1 Industry Perspective

A key step for the industry about factor investing were the requirements published in the Professor's report (2009) written for the Norwegian Government Fund. The authors required that factors, different from the market risk premia, which can explain the cross section of asset excess returns should:

have an intellectual foundation (rational or behavioural) [Explainable].  

- exhibit significant premiums which are expected to persist in the future [Persistence].  
- be not correlated among themselves and to asset classes in good times and negatively correlated in bad times [Independence].  
- be implementable in liquid, tradeable instruments [Liquidity].

The notion of 'good' and 'bad' times is made precise in economic theory by the stochastic discount factor (SDF).

The financial industry defines factor investing similar to the Professor's report. Deutsche Bank [2015] states additional to the above requirements:

- Accessible - risk factors must be accessible at a level of cost that is sufficiently low to avoid the dilution of the return.  
- Fully transparent - strategies are fully systematic and work within well-defined rules.  
- Low cost - a well-defined systematic approach makes possible efficient transactions costs.  
- Flexible access - strategies can be accessed in a variety of formats - either funded or unfunded as a portfolio overlay and in a variety of wrappers (OTC, structured notes, UCITS funds, etc.).

Factor investing means alternative strategies defined on liquid assets and not the creation of new, illiquid asset classes. Transparency radically changed in the last decade. In the past, an investment bank's offering of a momentum strategy basically was a black box for the investor. Today, each factor is constructed as an index with a comprehensive documentation about the index mechanics, risks and governance. Hedge funds often use factor investing strategies too but often they are not transparent.

# 4.5.1.1 Industry Offering

We consider the practice of factor offering by large asset managers.[24] The process of building a risk factor portfolio is as follows (Deutsche Bank [2015]):

- Identify first the key objectives of the portfolio and the preferences of the investor.  
- Start with a long list of potential risk factors and select a core portfolio made up of the most attractive risk factors. Figure 4.20, shows the cross asset risk factor list of DB.  
- Add any uncorrelated factors if they offer a benefit to the portfolio.  
- Finalize the list of selected risk factors and construct a portfolio using a risk-parity methodology.  
- Review and test the portfolio against general measures of diversification.

Figure 4.20, upper panel, shows the cross asset risk factor list of DB and some key figures.

Risk and return properties of the different risk factors differ. Therefore, if one invests into a portfolio with a target volatility to control downside risk, leverage is needed because else combining a low vol  $2\%$  interest rate risk premia with a  $12\%$  vol equity premia makes no sense. Figure 4.12 shows monthly correlations. The lower triangular matrix correlations are calculated for turbulent markets; those for normal markets are shown in the upper triangular matrix.[25]

The correlation for the equally weighted portfolio of risk factors (ARP) implies an annualized correlation of  $4\%$  in normal markets and  $5\%$  in stressed ones. The correlation with traditional asset classes is also low. Correlations between the different asset classes are however much larger. In this sense the risk factors are closely mutually uncorrelated

- May 97 to Feb 98 Asian financial crisis  
- Jul 98 to Sep 98 Russian default and collapse of LTCM  
- Mar 00 to Mar 01 Dot-com bubble bursts
- Sep 01 to Feb '03 9/11 and market downturn of 2002  
- Sep 08 to Mar. 09 US subprime crisis and collapse of Lehman Bros.  
- May 10 to Sep 10 European sovereign debt crisis

<table><tr><td>Category</td><td>EQ 
Equities</td><td>IR 
Interest Rates</td><td>CR 
Credit</td><td>FX 
Currencies</td><td>CO 
Commodities</td></tr><tr><td rowspan="2">Carry</td><td>EQ Dividends</td><td>IR Carry Diversified</td><td>CR Carry HY vs. IG</td><td>FX Global Carry</td><td>CO Carry (Curve)</td></tr><tr><td>EQ Merger Arb</td><td>IR Muni/Libor</td><td></td><td></td><td></td></tr><tr><td>Value</td><td>EQ Value</td><td></td><td></td><td>FX Value</td><td>CO Value</td></tr><tr><td rowspan="2">Volatility</td><td>EQ Glob Vol Carry</td><td>IR Vol</td><td></td><td>FX Vol Basket</td><td>CO Vol Divers.</td></tr><tr><td>EQ Mean Reversion</td><td></td><td></td><td>FX Vol Single</td><td>CO Vol Single</td></tr><tr><td>Momentum</td><td>EQ Moment.</td><td>IR Moment.</td><td>CR Moment.</td><td>FX Moment.</td><td>CO Trend 
CO Momentum</td></tr><tr><td rowspan="2">Idiosyncratic</td><td>EQ Low Beta</td><td></td><td></td><td></td><td></td></tr><tr><td>EQ Quality</td><td></td><td></td><td></td><td></td></tr></table>

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/979b295f44cd85439788b73cdf1c5bb6ab9c51b293bd0c010994bea846ab6f5a.jpg)  
Annual Returns (dark), Volatilities (light) and Sharpe Ratios (diamonds) For DB-Factors since Start Date  
Figure 4.20: Upper Panel: Risk factor list of DB London. Risk factors are grouped according to their asset class base and the five styles used by practitioners. Lower Panel: Average annualized volatilities, returns and Sharpe ratios for the risk factors (DB [2015]).

compared to asset classes. This lower correlation is due to the use of long and short positions. Short positions give factors the appearance of lower correlations. We discuss in the next section that it is impossible to produce more efficient portfolios, in sample, by expressing exposures as factors instead of assets, as long as the investable units are the same.

Low beta portfolios, that is to say, a portfolio of risk factors should have low correlation to equities and bonds in normal market periods and negative correlation to equity in turbulent markets, are of particular importance since they promise to resist a joint market downturn. Suitable risk factors are value and momentum risk factors for all asset classes, low beta risk factors, quality, and US muni curves vs Libor. The correlation of this portfolio to equity is  $-1.6\%$  and to bonds  $7.6\%$ . In turbulent markets, correlation to equity is  $-37.5\%$  and to bonds  $8.8\%$ . The Sharpe ratio is very high and the maximum drawdown is low, at  $-5.6\%$ , see Table 4.12.

A deeper analysis of the correlation structure reveals that the risk factors can be clustered into three broad groups.

<table><tr><td>-</td><td>ARP</td><td>EQ</td><td>Bonds</td><td>Commodities</td><td>HF</td><td>Real Estate</td><td>PE</td></tr><tr><td>ARP</td><td>5%/4%</td><td>10%</td><td>4%</td><td>7%</td><td>16%</td><td>8%</td><td>9%</td></tr><tr><td>EQ</td><td>4%</td><td>-</td><td>6%</td><td>39%</td><td>47%</td><td>64%</td><td>27%</td></tr><tr><td>Bonds</td><td>6%</td><td>4%</td><td>-</td><td>18%</td><td>5%</td><td>7%</td><td>-20%</td></tr><tr><td>Commodities</td><td>6%</td><td>43%</td><td>19%</td><td>-</td><td>30%</td><td>24%</td><td>28%</td></tr><tr><td>HF</td><td>13%</td><td>41%</td><td>11%</td><td>32%</td><td>-</td><td>29%</td><td>40%</td></tr><tr><td>Real Estate</td><td>4%</td><td>66%</td><td>9%</td><td>34%</td><td>28%</td><td>-</td><td>52%</td></tr><tr><td>PE</td><td>4%</td><td>78%</td><td>-21%</td><td>36%</td><td>35%</td><td>52%</td><td>-</td></tr></table>

Table 4.11: The correlations in the top-left cell is the average equally-weighted portfolio of factos (AP) correlation of a portfolio of all DB risk premia. PE means Private Equity. In the lower triangular matrix the correlations are calculated for turbulent markets; those for normal markets appear in the upper triangular matrix (DB [2015]).  

<table><tr><td>Statistics</td><td>Low beta portfolio</td></tr><tr><td>% positive 12m returns</td><td>99.5%</td></tr><tr><td>IRR</td><td>10.7%</td></tr><tr><td>Volatility</td><td>5.0%</td></tr><tr><td>Sharpe ratio=IRR/volatility</td><td>2.16</td></tr><tr><td>Maximum drawdown</td><td>-5.6%</td></tr><tr><td>IRR/MDD</td><td>1.93</td></tr><tr><td>Days to recover from MDD</td><td>120</td></tr><tr><td>Correlation to equity</td><td>-1.6%</td></tr><tr><td>Correlation to bonds</td><td>7.6%</td></tr><tr><td>Stress correlation to equitie</td><td>-37.5%</td></tr><tr><td>Stress correlation to bonds</td><td>8.8%</td></tr></table>

Table 4.12: Summary statistics for the low beta portfolio (DB [2015]).

# DB (2015):

- High beta, higher information ratio factors. These factors exhibit high information ratios but also contain some equity market risk.  
- Low beta, stable correlation factors. Factors with moderate correlation levels which are typically stable.  
- Negative beta, lower information ratio factors. Factors that exhibit negative correlations to equity markets.

This observation leads to timed factor portfolio investments, see the literature for details.

We conclude this section by comparing a low volatility portfolio of risk premia of JP Morgan - the  $7.5\%$  target volatility index - with the MSCI world, see Figure 4.21.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c2cc1408476ee7262c6948d030b0a55ed4c455dce63acdaa59b1542ab7d7c13e.jpg)

<table><tr><td colspan="2">Great Financial Crisis</td></tr><tr><td>JPM</td><td>15.86%</td></tr><tr><td>MSCI</td><td>-42.86%</td></tr></table>

<table><tr><td colspan="2">European Debt Crisis</td></tr><tr><td>JPM</td><td>13.70%</td></tr><tr><td>MSCI</td><td>-11.90%</td></tr></table>

<table><tr><td colspan="2">Stress Q1 2016</td></tr><tr><td>JPM</td><td>3.16%</td></tr><tr><td>MSCI</td><td>0.02%</td></tr></table>

XRJPBE5E - 7.5% Volatility Target  

<table><tr><td></td><td>Jan</td><td>Feb</td><td>Mar</td><td>Apr</td><td>May</td><td>Jun</td><td>Jul</td><td>Aug</td><td>Sep</td><td>Oct</td><td>Nov</td><td>Dec</td><td>Year</td></tr><tr><td>2006</td><td></td><td></td><td></td><td>-0.48%</td><td>-2.41%</td><td>-0.27%</td><td>1.30%</td><td>1.63%</td><td>0.57%</td><td>2.67%</td><td>-0.06%</td><td>2.79%</td><td>5.78%</td></tr><tr><td>2007</td><td>2.04%</td><td>-1.62%</td><td>2.13%</td><td>3.14%</td><td>2.63%</td><td>-0.34%</td><td>-0.27%</td><td>1.15%</td><td>1.59%</td><td>2.09%</td><td>0.87%</td><td>3.40%</td><td>18.01%</td></tr><tr><td>2008</td><td>-1.46%</td><td>8.20%</td><td>1.35%</td><td>-2.49%</td><td>1.79%</td><td>2.19%</td><td>1.22%</td><td>0.21%</td><td>-1.10%</td><td>3.85%</td><td>3.93%</td><td>6.26%</td><td>25.15%</td></tr><tr><td>2008 MSCI</td><td></td><td></td><td></td><td>5.31%</td><td>1.16%</td><td>-8.34%</td><td>-2.72%</td><td>-2.35%</td><td>-12.68%</td><td>-19.91%</td><td>-6.80%</td><td>3.47%</td><td></td></tr><tr><td>2009</td><td>0.15%</td><td>2.61%</td><td>-0.67%</td><td>-0.34%</td><td>2.27%</td><td>1.18%</td><td>1.59%</td><td>0.00%</td><td>2.65%</td><td>3.10%</td><td>1.61%</td><td>1.77%</td><td>16.20%</td></tr><tr><td>2009 MSCI</td><td>-8.63%</td><td>-10.02%</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2010</td><td>1.54%</td><td>2.28%</td><td>1.41%</td><td>1.27%</td><td>-2.93%</td><td>2.45%</td><td>0.99%</td><td>2.10%</td><td>1.47%</td><td>3.16%</td><td>-1.19%</td><td>1.87%</td><td>15.23%</td></tr><tr><td>2011</td><td>-0.14%</td><td>0.74%</td><td>-0.90%</td><td>4.60%</td><td>1.92%</td><td>-0.53%</td><td>1.83%</td><td>1.05%</td><td>3.91%</td><td>-0.90%</td><td>1.82%</td><td>2.51%</td><td>16.93%</td></tr><tr><td>2011 MSCI</td><td></td><td></td><td></td><td>3.86%</td><td>-2.52%</td><td>-1.75%</td><td>-1.73%</td><td>-7.53%</td><td>-9.65%</td><td>10.62%</td><td>-3.21%</td><td></td><td></td></tr><tr><td>2012</td><td>2.93%</td><td>1.65%</td><td>0.09%</td><td>1.79%</td><td>3.49%</td><td>2.38%</td><td>3.98%</td><td>-0.72%</td><td>2.23%</td><td>-0.07%</td><td>1.99%</td><td>-0.84%</td><td>20.45%</td></tr><tr><td>2013</td><td>2.44%</td><td>4.78%</td><td>2.86%</td><td>1.44%</td><td>-2.33%</td><td>-2.78%</td><td>1.17%</td><td>-2.00%</td><td>1.38%</td><td>1.43%</td><td>2.99%</td><td>0.03%</td><td>11.70%</td></tr><tr><td>2014</td><td>-1.85%</td><td>1.55%</td><td>0.87%</td><td>0.37%</td><td>0.99%</td><td>1.82%</td><td>0.05%</td><td>1.36%</td><td>0.90%</td><td>-1.79%</td><td>3.32%</td><td>-0.55%</td><td>7.12%</td></tr><tr><td>2015</td><td>0.61%</td><td>0.72%</td><td>1.24%</td><td>-0.53%</td><td>2.04%</td><td>-2.01%</td><td>3.04%</td><td>-4.43%</td><td>5.19%</td><td>-0.69%</td><td>1.82%</td><td>-1.57%</td><td>5.20%</td></tr><tr><td>2016</td><td>3.17%</td><td>1.36%</td><td>-1.37%</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>3.14%</td></tr><tr><td>2016 MSCI</td><td>-6.09%</td><td>-0.90%</td><td>7.16%</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

Figure 4.21: Top panel. The return of JP Morgan risk premia index and MSCI world 2006-2016. The middle statistics shows the cumulative returns of the two indices for three stress events. The bottom panel shows the monthly returns of the JPM index and for the three stress events - GFC, EU debt crisis, Q1 2016 - the returns of the MSCI are also shown. (JPM [2016]).

The top panel shows that investing world wide diversified did not provide any positive return in the ten year investment period if the concept of asset diversification is used. The JPM index, contrary showed an impressive performance. More detailed, the risk premia performance slope is not the same in the ten years period: After the GFC 2008 until the end of 2012, the returns were largest with very low risk. Then for about one and a half years there was a stand still period which was followed by a positive return

period with larger risks - the return chart is more zigzagged than in previous years. If we compare the performance of the JP Morgan Index with MSCI in three stress periods - GFC, EU debt crisis and Q1 2016 - we observe that the risk premia index did well compared to the MSCI in the GFC and the EU debt crisis: The construction mechanics to be uncorrelated to traditional asset classes in general and negatively correlated in market stress situations worked. In the Q1 2016 event, things are more complicated. While the same can be said for Jan and Feb 2016, the March data show that the risk premia index largely underperformed MSCI. To understand the reason, from an asset class perspective, there was a sharp and fast rebound of stock markets after the ECB's president Draghi's speech. This rebound was to fast for the risk premia index' rebalancing quarterly basis rebalancing frequency. Furthermore, the speech of Draghi also affected credit risk premia in a way which is the exception rather than the rule: The credit spread tightening was more pronounced for the Itraxx Europe Main index than for the Crossover index of the same family. This means that risk factors collecting the credit risk premia generated negative returns since they were wrong both the long and the short risk premia portfolios. A similar remark applies to interest rate risk premia.

How many risk factors are they? Harvey et al. (2015) use 313 published works and selected working papers and catalogue 316 risk factors and Hou, Xue, and Zhang (2017) report in their study 447 factors. It is clear that not hundred of factors will be rewarded, i.e. they are anomalies. We show in the section backtesting that an appropriate use of statistical methods rules out most of them. Hou et al.(2017) for example find that two-third of the 447 factors are insignificant at the 5 percent level using the usual critical t-value of two and 85 percent becomes insignificant if a critical value of three is used.

# 4.5.2 Non-Performance of Alternative Risk Premia

Are alternative risk premia performing? The HFR Bank Systematic Risk Premia Indices reflect the performance of the universe of investible risk premia strategies. The indices which represent many styles across six asset classes comprise over one thousand individual component strategies.

Table 4.13 shows for premia indices and for individual premia show that most premia fail to deliver a promised performance. Essentially, the indices show over the last three year zero performance. What are the reasons for this underperformance compared to the promising values of the premia providers in the section before? First, backtesting is not used correctly, see Section Backtesting. Second, global stock markets closed out their worst year since the financial crisis. The equity market has been stoked by concerns of a slowing global economy, tightening monetary policy and mounting geopolitical tensions (trade war between the US and China, Brexit). The year on the stock market was marked by zigzag movements that followed one another quickly. This was an expression of uncertainty, which was exacerbated by the constant tweets of the US President: One day he threatened in the trade war and the next he spoke again of great achievements. The long-short factor portfolios could not follow this rapid change; investors were often

<table><tr><td>Name Premia(index)</td><td>YTD</td><td>LAST 36M</td></tr><tr><td>Risk Premia Commodity Index</td><td>-11.72%</td><td>-2.95%</td></tr><tr><td>Risk Premia Credit Index</td><td>-13.00%</td><td>5.70%</td></tr><tr><td>Risk Premia Currency Index</td><td>-3.98%</td><td>-1.34%</td></tr><tr><td>Risk Premia Equity Index</td><td>-16.29%</td><td>-2.18%</td></tr><tr><td>Risk Premia Multi-Asset Index</td><td>-20.81%</td><td>0.02%</td></tr><tr><td>Risk Premia Rates Index</td><td>-2.93%</td><td>-3.46%</td></tr><tr><td>Risk Premia Commodity Carry Index</td><td>-6.99%</td><td>1.19%</td></tr><tr><td>Risk Premia Commodity Volatility Index</td><td>-16.52%</td><td>-9.89%</td></tr><tr><td>Risk Premia Credit Momentum Index</td><td>-26.87%</td><td>-3.12%</td></tr><tr><td>Risk Premia Credit Multi-Style Index</td><td>-4.30%</td><td>20.29%</td></tr><tr><td>Risk Premia Currency Momentum Index</td><td>-6.08%</td><td>-6.65%</td></tr><tr><td>Risk Premia Currency Value Index</td><td>-5.43%</td><td>6.50%</td></tr><tr><td>Risk Premia Equity Size Index</td><td>-25.10%</td><td>-11.85%</td></tr><tr><td>Risk Premia Equity Smart Beta Index</td><td>-13.66%</td><td>5.73%</td></tr><tr><td>Risk Premia Equity Value Index</td><td>-11.81%</td><td>0.03%</td></tr><tr><td>Risk Premia Equity Volatility Index</td><td>-28.59%</td><td>-5.38%</td></tr><tr><td>Risk Premia Multi-Asset Momentum Index</td><td>-17.83%</td><td>3.19%</td></tr><tr><td>Risk Premia Multi-Asset Volatility Index</td><td>-35.20%</td><td>-31.94%</td></tr><tr><td>Risk Premia Rates Carry Index</td><td>-5.80%</td><td>-8.52%</td></tr><tr><td>Risk Premia Rates Volatility Index</td><td>-5.72%</td><td>4.28%</td></tr><tr><td>Risk Premia Alternative Income Index</td><td>-0.47%</td><td>4.99%</td></tr><tr><td>Risk Premia Risk Mitigation Index</td><td>-6.91%</td><td>-4.55%</td></tr></table>

Table 4.13: Performance of risk premia YTD (12. 12. 2018) and for the last three years. In the upper part risk premia indices' performances are shown. Below, I selected the best and worst performing individual risk premia for the six asset classes on the three year basis. (Source: HFR Database,(2018)).

wrongly positioned on both sides.

# 4.5.3 A Critical Review of the Industry Perspective

The allocation of portfolios to factors rather than to assets was fashionable in the last years. A main motivation, as we showed in last section, is that factors are less correlated with each other than assets: Factors allow for better diversification. Since ultimately any portfolio must be invested in assets it is impossible to produce a better in-sample portfolio by describing the portfolio as a set of factors than assets. But factor over asset stratification can be meaningful if several hypothesis hold true. If factor predictability is larger than an asset one a factor approach makes sense. But such an EMH-type hypothesis do not exist. Other statistical facts could make factors more favourable. Investors rely on long samples of historical data to forecast returns, standard deviations, and correlations over shorter future periods for investment. These forecasts are subject to three sources of estimation error. We follow Cocoma et al. (2017). Third, independent-sample error arises when known parameters from one sample are projected onto a separate, independent sample.

- Interval error, i.e. say monthly estimates on the large past sample deviate from annual forecast in the future period.  
- Small-sample error, i.e. estimates on the large past sample can differ from estimates on the smaller future sample.  
- Stationarity between large past and smaller future samples can be different.  
- Reducing the dimensionality of the set of assets to a smaller set of factors reduces noise more effectively than reducing dimensionality to a smaller set of assets.

In all four cases the prediction errors for the future investment could be more reliable for factors than for assets. If this is the case, then factor allocation dominates asset allocation.

Before we consider these issues, we comment on the widely documented fact that the pairwise correlations among risk factors are often lower than those among asset classes. Does this imply that risk factors are superior to asset classes? Sources are Idzorek and Kowara (2013) and Martellini and Milhau (2015). Idzorek and Kowara (2013) first provide an answer in an idealized world where the number of risk factors is equal to the number of asset classes where unconstrained mean variance optimization is considered. The same dimensionality of asset classes and risk factors implies a one-to-one relationship and then with no surprise, returns are the same.

The authors then consider a real world example. They focus on liquid US asset classes and risk factors. The number of risk factors (eight) is not equal to the number of asset classes (seven). The data set are monthly data starting Jan 79 until Dec 11. They first confirm that the average pairwise correlation for risk factors 0.06 is smaller than for asset classes 0.38. Besides long-short for factors another main reason is that the market

portfolio is part of the asset classes but not of the risk factors. The authors then consider two different time horizons to derive the optimal allocations: The full time series and in the second case Jan 02 to Dec 11.

The risk factor weights define a lower dimensional space that the asset classes weights since there are more constraints for the long-short risk factors. This lower dimensionality seems favouring the asset classes. But it is in fact not possible to state which opportunity set is larger since the exposure of risk factors can be  $-100\%$  compared to asset classes which are long only. Summarizing, the opportunity sets are complex large dimensional spaces and it is not possible to find out in general which set is larger. Since an efficient frontier dominates another one if and only if assets define the opportunity set, both sets of frontiers are subject to the same constraints, and the results are shown in the same return units as the inputs, it is not clear which optimal asset allocation - assets or factors - dominates.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8678ffaa406df426757ee101df594b2f65865f0f110d803b6835ad1df50ceb33.jpg)  
Figure 1. Long-Only Constraints: Asset Classes vs. Classic Risk Factors, January 1979-December 2011

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/02bb166957595589ed661725ae05c5c7e496e8d30d9f304daf9e2144b8ccb8e0.jpg)  
Figure 2. Long-Only Constraints: Asset Classes vs. Classic Risk Factors, January 2002-December 2011  
Figure 4.22: Optimal asset classes versus optimal risk factors. Left panel: Long time series. Right panel: Short time series. The US asset classes are large value stocks, large growth stocks, small value stocks, small growth stocks, Treasuries, mortgage backed assets, credit and cash. The risk factors are market, size, value, mortgage spread, term spread, credit spread and cash (Idzorek and Kowara [2013]).

The results indicate that by cherry picking a particular historical time period, almost any desired result can be found. This illustrates that there is nothing obvious about the superiority of asset allocation based on risk factors. This result does not depend on the fact that historical data are used. Idzorek and Kowara (2013).

The interval error arises if the assumption of analysts that the square-root rule apples between one month past estimates and longer periodicities is not true. That is lagged auto-correlations are zero which evidence reveals to be wrong. The standard deviation of the cumulative continuous returns of  $x$  over  $N$  periods,  $R_{t,N} = \sum_{N=0}^{N-1} R_{t+N}$ , reads

$$
\sigma \left(R _ {t, N}\right) = \sigma \left(R _ {t, 1}\right) \sqrt {N + 2 \sum_ {m = 1} ^ {N - 1} (N - m) \rho_ {t , t + m}}. \tag {4.58}
$$

If auto-correlations is zero, the square-root rule follows. A similar formula holds for the correlation between the cumulative returns over  $N$  periods and the one-period case. Again, the longer-interval correlations will differ from shorter-interval correlations due to the auto-correlations. Errors due to non-zero lagged correlations, the interval error  $IE$ , are defined as the absolute difference between the parameter estimate  $R_{1}$  using the full-sample, one-month returns, to the full-sample, three-year rolling returns  $R_{R}$  scaled by the full-sample standard deviation of three-year returns:

$$
I E = \frac {| R _ {1} - R _ {R} |}{\sigma_ {R}}.
$$

. An IE of 0.3 means that the parameter value estimated from monthly returns is 0.3 standardized units away from the parameter value estimated from three-year returns, expressed in monthly units. We refer to Cocoma et al. (2017) for the definitions of the small-sample error (SSE) and the independent-sample error (ISE).

The authors distinguish between two types of assets: asset classes and industry groupings and three types of factors: fundamental factors, security attributes, and statistical factors derived from principal components analysis. We refer to their paper for the construction of factors, the asset selection and the various tests.

They summarize that no evidence was found that factors produce more stable results for IE, SSE and IS than assets across varying frequencies. On the contrary, they found evidence of the opposite, on average. The same conclusion follows when comparing the complexity reduction of the asset set to factor versus the reduction to a smaller asset set. No evidence was found that factors are meaningfully more effective than assets at noise reduction.

# 4.5.4 The CAPM as a Beta Pricing Model

The capital asset pricing model (CAPM) is an exact one-factor beta pricing model. We start with linear times series regression for the asset returns. Consider for a stock  $i$  with return  $R_{t,i}$ ,  $R_{t,f}$  the risk-free rate, and  $R_{t,M}$  the return of a broad market index the linear regression

$$
R _ {t, i} - R _ {t, f} = \alpha_ {i} + \beta_ {i, M} \left(R _ {t, M} - R _ {t, f}\right) + \epsilon_ {t} \tag {4.59}
$$

where  $\alpha$  is the intercept,  $\beta_{i,M}$  the slope or regression coefficient, and  $\epsilon_t$  the standard normal error term satisfying (2.2). Beta measures the unit changes in stock excess return for every unit change in market excess return. The intercept indicates the performance of the stock that is not related to the market and that a portfolio manager attributes to her skills.

# Example

For both regression coefficients  $\alpha$  and  $\beta$  confidence intervals can be determined using the estimated parameter value, the standard error of the estimate (SEE), the significance level for the  $t$ -distribution and the degrees of freedom. For the  $\beta$  confidence interval,  $\overline{\beta} \pm t_c \times \mathrm{SEE}$ , where  $\overline{\beta}$  is the estimated value and  $t_c$  the critical  $t$ -value at the chosen significance level.

Consider the linear regression between an European equity fund's returns (dependent variable) and the EUROSTOXX 50 index (independent variable). Statistical analysis implies for 20 observation dates the estimates  $\overline{\beta} = 1.18$ ,  $\mathrm{SEE} = 0.147$  and  $18 = 20 - 2$  degrees of freedom. The Student's t-distribution at the 0.05 significance level with 18 degrees of freedom is 2.101. This implies the confidence interval  $1.18 \pm (0.147)*(2.101) = 0.87, 1.49$ . There is only a 5 percent chance that  $\beta$  is either less 0.87 or greater than 1.49. There is a  $95\%$  confidence that this fund is at least  $87\%$  as volatile as the S&P 500, but no more than  $149\%$  as volatile, based on our five-year sample.

We relate this empirical approach to the unconditional equilibrium asset pricing model CAPM. The CAPM states that within the model the following exact cross-section relation has to hold (deleting time indices):

$$
E \left(R _ {i}\right) - R _ {f} = \beta_ {i, M} \left(E \left(R _ {M}\right) - R _ {f}\right) =: \beta_ {i, M} F. \tag {4.60}
$$

The risk premium of the asset  $i$  is  $E(R_{i}) - R_{f}$  and the market portfolio risk factor is  $F = E(R_{M}) - R_{f}$ . The CAPM states that some assets have higher average returns than other ones but it is not about predicting returns. An asset has a higher expected return because of a large beta and not the other way around. Furthermore, projection theory implies that the beta is the projection coefficient:

$$
\beta_ {i, M} = \frac {\operatorname {c o v} \left(R _ {i} , R _ {M}\right)}{\sigma^ {2} \left(R _ {M}\right)}. \tag {4.61}
$$

Summarizing, the time series regression (4.59) fixed the  $\beta$  which enters the CAPM model (4.60) which predicts that alpha should be zero.

The linear relation (4.60) in the CAPM between the excess return of an asset and the market excess return follows from the following assumptions:

- Investors act competitively, optimal, have a one-period investment horizon and there are many investors with small individual endowments. Hence, they cannot influence prices and are so-called price takers.  
- All investors have mean-variance preferences.  
- All investors have the same beliefs about the future security values.  
- Investors can borrow and lend at the risk-free rate, short any asset, and hold any fraction of an asset.  
- There is a risk-free asset in zero net supply. Since markets clear in equilibrium, total supply has to equal total demand. Given the net supply of the risk-free asset, we combine the investor's portfolios to get a market portfolio. This will imply that the optimal risky portfolio for each investor is the same.  
- All information is accessible to all investors at the same time to all investors - there is no insider information.  
- Markets are perfect: There are no frictions such as transaction costs or lending or borrowing costs, no taxes, etc.

The proposition summarizes:

Proposition 81. (CAPM) Under the above assumptions:

- Each investor is investing in the risk-less asset and the tangency portfolio.  
- The tangency portfolio is the market portfolio.  
- All investors hold the same portfolio of risky securities.  
- For each title  $i$ , the linear relationship between risk and return (the security market line [SML]) (4.60) holds:

$$
E \left(R _ {i}\right) - R _ {f} = \beta_ {i, M} \left(E \left(R _ {M}\right) - R _ {f}\right) \tag {4.62}
$$

with the beta given in (4.61) measuring the risk between asset  $i$  and the market portfolio  $M$ .

The SML implies that beta measures how systematic risk is rewarded in the CAPM, there is no idiosyncratic risk entering the SML.[26] There is no reward, via a high expected rate of return, for taking on risk that can be diversified away. A higher beta value does not imply a higher variance, but a higher expected return.[27]

The behavioural assumptions that all investors consider the same mean-standard deviation chart implies that all possess a mean-variance efficient portfolio. By the mutual fund theorem, each minimum variance portfolio is a combination of a risk less asset and a fixed risky asset portfolio. Therefore, all investors invest in all risky assets in the same proportions. Since demand equals supply in the asset market equilibrium, all investors must hold the market portfolio which in turn is mean-variance efficient. Therefore, no investor needs to perform a mean-variance analysis but just invest in the market portfolio.

The linearity of (4.62) implies that the portfolio beta is the sum of asset betas multiplied by the portfolio weights. In the CAPM, all optimal portfolios are a combination of the risk-free portfolio and the market portfolio. Tobin's separation states how individually tailored portfolios can be constructed. First, the portfolio manager constructs the risk free and market portfolio. Then, investment advisor determines his risk profile which fixes the optimal allocation between risk-free and risk investments.

Inserting  $\operatorname{cov}(R_i, R_M) = \rho(i, M)\sigma_k\sigma_M$  in (4.62) implies for the Sharpe ratio

$$
\mathbf {S R} _ {k} := \frac {\mu_ {k} - R _ {f}}{\sigma_ {k}} = \rho (k, M) \frac {\mu_ {M} - R _ {f}}{\sigma_ {M}}. \tag {4.63}
$$

The Sharpe ratio of asset  $k$  is equal to the slope of the CML times the correlation coefficient. Comparing SML and CML, see Figure 4.23, all portfolios lie on the SML but only efficient portfolios lie on the CML.[28] Finally, SML plots rewards vs systematic risk while CML plots rewards vs total risk.

Consider three risky assets  $A, B$ , and  $C$  and 3 investors with capital of 250, 300, and 500, respectively, who have the following portfolios:

<table><tr><td>Investor</td><td>Risk-less asset</td><td>A</td><td>B</td><td>C</td></tr><tr><td>1</td><td>50</td><td>50</td><td>50</td><td>100</td></tr><tr><td>2</td><td>-150</td><td>150</td><td>200</td><td>100</td></tr><tr><td>3</td><td>100</td><td>75</td><td>75</td><td>250</td></tr><tr><td>Market Cap. 1,050</td><td>0</td><td>275</td><td>325</td><td>450</td></tr></table>

Table 4.14: CAPM.

Market capitalization is then  $1'050$ , the tangency portfolio follows from the Markowitz model  $\phi_T = (0.2619, 0.3095, 0.4286)$  and the market portfolio is  $\phi_M = (275/1050, 325/1050, 450/1050)$ , i.e. the two portfolios are equal.

Consider three risky assets, the market portfolio, and a risk-free asset given by the data in Table 4.17 (taken from Kwok (2010)):

The CML implies, at the standard deviation levels 10 percent and 20 percent, respectively, expected returns of 13 percent and 16 percent. Therefore portfolio 1 is efficient,

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/a052e2bb90eb06b2aac6eddea195b54669dd8c436937a72f8a5c1aae4141df30.jpg)  
Figure 4.23: Left panel - capital market line in the Markowitz model. Right panel - security market line in the CAPM model. Assume that the borrowing and lending rate are different. Draw the CML for these two rates.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4ddb9cab7873793c2bdb57f1e015183893c6fa19a0737def5cc09e5817d541ee.jpg)

but the other two portfolios are not. Portfolio 1 is perfectly correlated with the market portfolio but the other two portfolios have non-zero idiosyncratic risk. Since portfolio 2 has a correlation closer to one it lies closer to the CML. The expected rates of return of the portfolios for the given values of beta, calculated with the SML, agree with the expected returns in the table:

$$
\mu = \mu_ {f} + (\mu_ {M} - \mu_ {f}) \beta = 13 \%,
$$

i.e. there is no mis-pricing.

<table><tr><td>Portfolio</td><td>σ</td><td>ρ with RM</td><td>β</td><td>μ</td></tr><tr><td>1</td><td>10%</td><td>1</td><td>0.5</td><td>13%</td></tr><tr><td>2</td><td>20%</td><td>0.9</td><td>0.9</td><td>15.4%</td></tr><tr><td>3</td><td>20%</td><td>0.5</td><td>0.5</td><td>13%</td></tr><tr><td>Market portfolio</td><td>20%</td><td>1</td><td>1</td><td>16%</td></tr><tr><td>Risk-free asset</td><td>0%</td><td>0</td><td>0</td><td>10%</td></tr></table>

Table 4.15: Asset pricing in the CAPM.

# 4.5.4.1 Performance Measurement

We considered several Risk-Reward-Ratios (RR) in Section ??. The ratios mostly differed in the risk measurement. The popular Sharpe and Treynor ratios are not monotonic RR in the sense that they guarantee that more return is better than less. Despite this weakness, the Sharpe ratio encourages diversification: It can rank portfolios, portfolio managers, fund, identify poorly diversified portfolios and too high charged funds. Which measure should one choose if the portfolio is less diversified? Jensen's alpha, the appraisal ratio, and the Treynor ratio are used. They are all based on the SML while the Sharpe ratio is based on the CML.

Jensen's alpha

$$
\alpha_ {k} := \mu_ {k} - R _ {f} - \beta_ {k} \left(\mu_ {M} - R _ {f}\right) \tag {4.64}
$$

is a performance measurement between the realized and theoretical returns of the CAPM. Since alpha is a return it should be used for the compensation of portfolio managers. While the Sharpe ratio can be illustrated in the return-volatility space, Jensen's alpha is shown in the return-beta space. Jensen's alpha measures how far above the SML the asset's performance is. It does not consider the systematic risk that an investment took on earning alpha. The Treynor Ratio measurement (TR) adjusts for this systematic risk taken:

$$
\mathbf {T R} _ {k} := \frac {\mu_ {k} - R _ {f}}{\beta_ {k}}.
$$

The TR equals the slope of the SML for the actively managed portfolio. If the CAPM holds, then the Treynor ratio is the same for all securities. Both, the Jensen and Treynor measurements do not adjust for idiosyncratic risk in the portfolio.

The appraisal ratio (AR) or information ratio (IR) divides the excess return over the benchmark by the tracking error (TE).

Values of the IR around 0.5 are considered to be good values while a value greater than 1 is extraordinary. The IR generalizes the Sharpe ratio since it substitutes the passive benchmarks for the risk-free rate.

Example - Performance Measurement We calculate the different ratios for the data in 4.17.

The beta of  $A$  is equal to its market portfolio correlation times its volatility divided by the market volatility - that is,  $0.9 \times 15\% / 20\% = 0.675$ . The Sharpe ratio for  $A$  is  $\mathbf{SR} = (12\% - 4\%) / 15\% = 0.53$ . Jensen's alpha for portfolio  $A$  reads  $12\% - 4\% - 0.675(15\% - 4\%) = 0.575\%$  and the Treynor ratio for  $A$  is given by  $(12\% - 4\%) / 0.675 = 0.119$ . The IR and the TE follow in the same way. We finally get:

<table><tr><td>Portfolios</td><td>Return</td><td>Volatility</td><td>Correlation with market</td></tr><tr><td>A</td><td>12%</td><td>15%</td><td>0.9</td></tr><tr><td>B</td><td>16%</td><td>24%</td><td>0.94</td></tr><tr><td>C</td><td>18%</td><td>17%</td><td>0.98</td></tr><tr><td>Market</td><td>15%</td><td>20%</td><td>-</td></tr><tr><td>Risk-free rate</td><td>4%</td><td>-</td><td>-</td></tr></table>

Table 4.16: Data set for the performance ratios.  

<table><tr><td>Portfolio</td><td>Beta</td><td>TE</td><td>SR</td><td>Jensen</td><td>TR</td><td>IR</td></tr><tr><td>A</td><td>0.675</td><td>9.22%</td><td>0.53</td><td>0.58%</td><td>0.119</td><td>0.062</td></tr><tr><td>B</td><td>1.128</td><td>8.58%</td><td>0.5</td><td>-0.41%</td><td>0.106</td><td>-0.048</td></tr><tr><td>C</td><td>0.833</td><td>4.75%</td><td>0.84</td><td>4.84%</td><td>0.168</td><td>1.017</td></tr><tr><td>Market</td><td>1</td><td>0%</td><td>0.55</td><td>0%</td><td>0.11</td><td>-</td></tr></table>

Table 4.17: CAPM.

It follows that portfolio  $C$  is the best portfolio. We summarize the relevance of the different performance measurements:

- Beta is relevant if the individual risk contribution of a security to the portfolio risk is considered.  
- TE is relevant for risk budgeting issues and risk control of the portfolio manager relative to a benchmark.  
- The Sharpe ratio is relevant if return compensation relative to total portfolio risk is considered.  
- Jensen's alpha is the maximum amount one should pay an active manager.  
- Treynor measurement should be used when one adds an actively managed portfolio, besides the many yet existing actively managed one, to a passive portfolio.  
- The information ratio measures the risk-adjusted return in active management. It is frequently used by investors to set portfolio constraints or objectives for their managers, such as tracking risk limits or attaining a minimum information ratio. Grinold and Kahn (2000).

Warnings: If return distributions are not normal since they show fatter tails, higher peaks, or skewness, then the use of these ratios can be problematic, since higher moments than the second one contribute to risk. Furthermore, the IR depends on the chosen time period and benchmark index. Finally, the chosen benchmark index affects all benchmark-based ratios: Managers benchmarked against the S&P 500 Index have lower IR than

managers benchmarked against the Russell 1000 Index [Goodwin (2009)].

# 4.5.4.2 Testing the CAPM

The CAPM triggered an enormous econometric literature that addresses the verification of (4.60). Although Black, already in 1972, verified that the risk premia are not proportional to their beta, it took many more years and much more academic writing for a majority of researchers to accept the non-empirical evidence of (4.60). The many assumptions of the CAPM are the cause of the empirical failure of the CAPM. The CAPM can, for example, not explain the size or value effect. The CAPM on average explains only 80 percent of portfolio returns. One needs more factors than just the covariance between the asset return and the return on the market portfolio. The classic papers are Black et al. (1972), Fama and MacBeth (1973) and for a review about cross-section regression Goyal (2012).

Standard assumptions for testing CAPM are rational expectations, i.e. in particular realized returns are a proxy for expected theoretical returns and that the holding period of assets is known, typically one month. The CAPM equation which should be tested

$$
E \left(R _ {i}\right) - R _ {f} = \beta_ {i, M} \left(E \left(R _ {M}\right) - R _ {f}\right) \tag {4.65}
$$

raises several questions: Are beta's stable measures of systematic risk? Are the expected returns linearly related to the betas (Q1)? Is beta the only systematic risk measure (Q2)? Does the expected return of the market portfolio exceed the expected return of assets uncorrelated to the markets (Q3)? Finally, do assets uncorrelated to the market portfolio have the risk-free rate return (Q4)? There two linear tests of the CAPM equation. Once the returns of different assets are regressed over the betas (cross-section, Q2, Q3) and once the CAPM equation for each individual asset over time is regressed (time-series, Q4).

The cross-sectional regression is used to test the CAPM equation. over a period  $T$  years. Since expected returns are not measurable, the CAPM equation is tested for average annual realized returns. The temporal individual asset test using time-series regression tests the CAPM on a number of fixed sub-periods up to time  $T$ : Excess asset return is regressed over the excess market return in each sub-period.

Using the time series regression equation,

$$
R _ {t, k} - R _ {t, f} = \alpha_ {k} + \beta_ {k, M} \left(R _ {M, t} - R _ {t, f}\right) + \epsilon_ {t}.
$$

to estimate alpha, beta and epsilon, it follows that. The estimates of beta  $\widehat{\beta}$  are volatile both for stocks and for sectors; see Figure 4.24.

Since the CAPM is only interesting for portfolios with beta the significant risk measure, an application to single securities does not make sense.

We consider tests of the CAPM where we restrict to three key papers. The beta instability led to CAPM test for portfolios only. The first one is the paper of Black,

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2c7df7e4f913f56b9b4fed13a9bee74e362105b64ba9fc3d4000d68bc5f1f93c.jpg)  
Figure 4.24: Beta estimates for AT&T (left panel) and the oil industry (right panel) (Papanikolaou [2005]).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c82c40baea97cebe110a9b65b40c7143777a0bbb895603094a683b519678343c.jpg)

Jensen and Scholes (1972).<sup>29</sup> It starts with the observation that zero-beta assets earned more than the risk-free rate and that the beta premium was lower than the market excess return. This violates Q3. The authors support these findings and postulated a modified version of the CAPM, the zero-beta CAPM: That is it accommodates zero-beta returns above the risk-free rate or in other words, all investors can lend and borrow any amount of money at the risk-free rate. They formed ten portfolios ordered from highest to lowest beta securities. Their time series regression finds that high-beta (low-beta) portfolios consistently show negative (positive) alphas which violates Q4. In the cross-section, the regression line has a flatter slope than the SML and an intercept which is significantly greater than zero. But linearity of between return and beta is confirmed.

Consider the cross-section where the factors  $F$  are non-traded portfolios with an existing risk-free rate. Using the time series regression, estimates of factor risk premia and pricing errors can be obtained. But in the cross-section the estimation is simplified using the two-pass regressions. First, betas are estimated from the time-series regressions,

and then a cross-sectional regression of average returns on betas follows. That is the estimated betas are in the second step the explanatory variables. $^{30}$  The pricing errors are given by the cross sectional residuals  $\tilde{\alpha}$ . The estimates of the cross-section can be obtained by OLS or by using GLS more efficient estimates follow since the cross-section residuals are correlated. The betas in the second-pass CSR are time series estimates which leads to the problem of errors-in-variables. Shanken (1992) showed how to correct the standard errors of the risk premium and pricing error estimates. The predictions of CAPM are that alpha is zero, lambda is equal to the market premia, that any other variables are zero. Typically, alpha is estimated to be positive, lambda is positive but smaller than the market premium and other factors are not rejected.

So far all results are under the assumption of a small number of assets and the estimators are time horizon  $T$  consistent. If the number of assets increases for a fixed  $T$ , the error-in-variables problem also leads to biased and inconsistent coefficient estimates. Shanken (1992b) derives an estimator that is  $N$ -consistent. Finally, Gagliardini et al. (2011) explore the properties of these estimators under both  $T, N \to \infty$ .

Suppose that the  $R^2$  is large in the cross-sectional CAPM equation (4.60). The CAPM then explains the cross-section of average returns successfully and the alpha in cross-section is small. This can be the case even if the  $R^2$  of the time series regression (4.59) is low. The main goal of the CAPM is to see whether high average returns in the cross-section are associated with high values of the factors.

Summarizing, findings are that excess returns on high-beta stocks are low, that excess returns are high for small stocks and that value stocks have high returns despite low betas while momentum stocks have high returns and low betas. The CAPM does not explain why in the past firms with high B/M ratios outperformed firms with low B/M ratios (value premium), or why stocks with high returns during the previous year continue to outperform those with low past returns (momentum premium). Despite these findings, the CAPM is used for figuring out the appropriate compensation for risk, is used as a benchmark model for other models, and is elegantly simple and intuitive.

# 4.5.4.3 Conditional CAPM

Some researchers assumed that the poor empirical performance of the CAPM could be due to its assumption of constant conditional moments but that a conditional CAPM will possess a better empirical performance. They therefore model explicitly the time varying conditional distribution of returns as a function of lagged state variables.

The conditional CAPM works as follows. Consider two stocks. Suppose that the

times of recessions and expansions are not of equal length in an economy, that the market risk premia are different and that the two stocks have different betas in the different periods. The CAPM then observes only the average beta for each stock for both periods. Assume that this beta is 1 for both stocks. Therefore, the CAPM will predict the same excess return for the two stocks. But in reality the two stocks will show due to their heterogeneity different returns for the two different economic periods. One stock can for example earn higher return than explained by the CAPM since its risk exposure increases in recessions, when bearing risk is painful, and decreases in expansions. Therefore such a stock is riskier than the CAPM suggests and the CAPM would detect an abnormal high return suggesting this is a good investment. The conditional CAPM corrects this since return comes from bearing the extra risk of undesirable beta changes.

Lewellen and Nagel (2006) did not questioned the fact that betas vary considerably over time. But they provide evidence that betas do not vary enough over time to explain large unconditional pricing errors. As a result, the performance of the conditional CAPM is similarly poor as the unconditional model: It is unlikely that the conditional CAPM can explain asset-pricing characteristics like book-to-market and momentum. These statistical criticisms are not unique to the CAPM. Most asset pricing models are rejected in tests with power.

# 4.5.5 Factor Investing: 3-Factor Model of Fama and French

The non-zero alpha in the CAPM and the non-vanishing of factors different than the market premia led Fama and French to add additional factors value (HML) and size (SMB) in the 90s. They sorted stocks in into five market cap and five book-to-market equity (B/M) groups at a specific date, which leads to 25 portfolios. The sorted portfolios scatter around the CAPM line. The interpolated line between the sorted portfolios is too flat compared to the CAPM line: stocks with low B/M should provide high average returns and high betas but the betas are not small for high expected return. They even have the wrong sign - betas are lower for higher return securities. This observation led FF to introduce the two new factors and state the exact beta pricing relation:

$$
E (R _ {i}) - R _ {f} = \beta_ {i, M} \left(E \left(R _ {M}\right) - R _ {f}\right) + \beta_ {i, S M B} E \left(R _ {S M B}\right) + \beta_ {i, H M L} E \left(R _ {H M L}\right). \tag {4.67}
$$

While the CAPM has a theoretical foundation, the FF model is an ad hoc model introduced to better fit empirical data. The three factor model is routinely included in empirical research.

We follow Kenneth French's web site for the FF factor construction. The factors are constructed using the six value-weighted portfolios formed on size and book-to-market.

- SMB (small minus big) is the average return on the three small portfolios minus

the average return on the three big portfolios

$$
\begin{array}{l} \mathrm {S M B} = \frac {1}{3} (\text {S m a l l V a l u e + S m a l l N e u t r a l + S m a l l G r o w t h}) \tag {4.68} \\ - \frac {1}{3} (\text {B i g V a l u e} + \text {B i g N e u t r a l} + \text {B i g G r o w t h}). \\ \end{array}
$$

- HML (high minus low) is the average return on the two value portfolios minus the average return on the two growth portfolios

$$
\mathrm {H M L} = \frac {1}{2} (\text {S m a l l V a l u e} + \text {B i g V a l u e}) - \frac {1}{2} (\text {S m a l l G r o w t h} + \text {B i g G r o w t h}).
$$

- Whether a stock belongs to, say, Small Value depends on its ranking. Small Value contains all stocks where the market value of the stock is smaller than the median market value, say, of the NYSE and where the book-to-market ratio is smaller than the 30 percent percentile book-to-market ratio of NYSE stocks.  
- SMB for July of year  $t$  to June of  $t + 1$  includes all NYSE, AMEX, and NASDAQ stocks for which there exist market equity data for December of  $t - 1$  and June of  $t$ , and (positive) book equity data for  $t - 1$ .

Why should one include factors which cannot explain average returns? The CAPM worked until stocks were grouped by their book-to-market ratio (value) but it still works when stocks are grouped according to their size. If FF were only to consider factors which explain the average returns then they could left them out. But size is important for return variance reduction.

To see this work, assume that the CAPM is perfect. Then,

$$
E \left(R _ {k}\right) = \beta_ {k} E \left(R _ {M}\right)
$$

where we set the risk free rate to zero. Include an additional industry portfolio in the regression, i.e.

$$
R _ {t, k} = \alpha_ {k} + \beta_ {k, M} R _ {t, M} + \beta_ {k, I} R _ {t, I} + \epsilon_ {t, k}.
$$

The regression generically leads to a coefficient  $\beta_{k,I} > 0$  and taking expectations:

$$
E \left(R _ {t, k}\right) = \alpha_ {k} + \beta_ {k, M} E \left(R _ {t, M}\right) + \beta_ {k, I} E \left(R _ {t, I}\right).
$$

This additional industry portfolio return contradicts that the CAPM is perfect. To resolve the puzzle, one uses a nested projection approach: First project the industry portfolio on the market return:

$$
R _ {t, I} = \alpha_ {I} + \beta_ {I, M} R _ {t, M} + \epsilon_ {t, I}.
$$

If the CAPM is right, the industry alpha is zero and

$$
E (R _ {t, I}) = \beta_ {I, M} E (R _ {t, M}).
$$

Then orthogonalize the industry return, i.e.:

$$
R _ {t, I} ^ {*} := R _ {t, I} - E (R _ {t, I}) = R _ {t, I} - \beta_ {I, M} R _ {t, M}.
$$

This is equivalent to beta-hedge the portfolio. The expected value of the new return is zero if the CAPM is right. Run a regression on this orthogonality-adjusted CAPM. This improves the  $R^2$ , the  $t$ -statistics and the volatility of the residual while the mean of the CAPM is unchanged.

Considering different portfolios, the CAPM- $R^2$  statistics for the increased for different portfolios from 78 percent to 93 percent in the FF portfolios. Roncalli (2013) states that the improvement in the  $R^2$  is not uniform:

- The difference in  $R^2$  between the FF and the CAPM is between 18 percent and 23 percent in the period 1995-1999.  
- This difference is around 30 percent during 2000 and 2004.  
- The difference then decreases and is around 11 percent during the GFC.  
- In the period starting after the GFC and running until 2013 the difference is 7 percent.  
- SMB and HML explain the variation of returns across stocks; the market factor explains why stock returns are on average higher than the risk-free rate.

Are the FF factors global or country specific? Griffin (2002) concludes that the FF model exhibits its best performance on a country-specific basis. This view is largely accepted. While FF performed originally regressions on portfolios of stocks, Huij and Verbeek (2009) and Cazalet and Roncalli (2014) provide evidence that mutual fund returns are more reliable than stock returns transaction costs, trade impact, and trading restrictions are of less impact.

Figure 4.25 illustrates the different FF factors' performance since 1991 and momentum factor. The size factor only generates low returns. This is the reason why most risk premia providers do not offer size risk premia.[31] Cyclicality is common to most risk factors. Some factors show persistent excess risk-adjusted returns over long time periods but over shorter horizons they show cyclical behavior with underperformance. Ang (2013) argues that the premia exist to reward long-horizon investors for bearing that risk. FF (1993) tested their model in the period 1963-1991. They rejected the assertion that all intercepts from the regression of excess stock returns on excess market return, SMB

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4e9b6e6220894674002bf973a8c8bac7875bcf24a909866b15f79953dd880c10.jpg)  
Figure 4.25: Left panel - FF annual factor performance in the period 1991-2014 starting each year in January and ending in December. Mkt is the market return, RF the risk-free return, and WML the momentum factor. Right panel - monthly returns of the momentum risk factor (Kenneth French's web site).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8e7973b2a111131ce7409e4fee20102f33029c4254e441c7eb7b135ec0774f9b.jpg)

and HML are zero. The FF performed better than any single factor model and it failed only slightly due to the low-B/M portfolios. Their return was too low and the return on the big-size portfolio was too high; i.e. the size effect was missing in the lowest-B/M quintile.

# 4.5.6 Factor Investing: 5-Factor Model of Fama and French

Fama and French (2015) proposed a five-factor model extension of their three-factor model. The motivation of the model follows from firm valuation equation:

$$
\frac {M _ {t}}{B _ {t}} = \frac {\sum_ {j = 1} ^ {\infty} E _ {t} \left(\frac {1}{(1 + R) ^ {j}} \left(Y _ {t + j} - \Delta B _ {t + j}\right)\right)}{B _ {t}} \tag {4.69}
$$

with  $M$  the current market cap,  $Y$  total equity earning,  $\Delta B$  the change in total book value in the period, and  $R$  the internal rate of return of the expected dividends. Equation (4.69) follows from the fundamental pricing equation; see Equation (3.140). Equation (4.69) implies that  $\mathrm{B} / \mathrm{M}$  value is an imperfect proxy for expected returns: The market cap  $M$  also responds to forecasts of earnings and investment (expected growth in book value) which define the two new factors. The regression (4.67) reads (neglecting time

indices)

$$
R _ {i} - R _ {f} = \beta_ {i, M} \left(R _ {M} - R _ {f}\right) + \sum_ {k \in \{\mathrm {S M B}, \mathrm {H M L}, \mathrm {R M W}, \mathrm {C M A} \}} \beta_ {i, k} R _ {k} + \alpha_ {i} + \epsilon_ {i}, \tag {4.70}
$$

with  $R_{RMW}$  the earnings risk factor (difference between robust and weak profitability) and  $R_{CMA}$  the innovation risk factor (difference between lowand high-investment firms). This is again an exact factor model by definition. The explicit construction of the risk factors is a long/short combination similar to (37); see Fama and French (2015).

Fama and French (2015) first analyze the factor pattern in average returns following the construction of the three-factor model:

- One-month excess return on the one-month US treasury bill rate follow.  
- The returns follow for 25 value-weighted portfolios of US stocks from independent sorts of stock (five size and five B/M groups ranking into quintiles). The authors label the quintiles from Small to Big (Size) and Low to High (B/M).  
Data are from 1963 to 2013.

<table><tr><td></td><td>Low</td><td>2</td><td>3</td><td>4</td><td>High</td></tr><tr><td colspan="6">Panel A: Size-B/M portfolios</td></tr><tr><td>Small</td><td>0.26</td><td>0.81</td><td>0.85</td><td>1.01</td><td>1.15</td></tr><tr><td>2</td><td>0.48</td><td>0.72</td><td>0.94</td><td>0.94</td><td>1.02</td></tr><tr><td>3</td><td>0.50</td><td>0.78</td><td>0.79</td><td>0.88</td><td>1.07</td></tr><tr><td>4</td><td>0.60</td><td>0.57</td><td>0.71</td><td>0.85</td><td>0.86</td></tr><tr><td>Big</td><td>0.46</td><td>0.51</td><td>0.48</td><td>0.56</td><td>0.62</td></tr><tr><td colspan="6">Panel B: Size-OP portfolios</td></tr><tr><td>Small</td><td>0.56</td><td>0.94</td><td>0.90</td><td>0.95</td><td>0.88</td></tr><tr><td>2</td><td>0.59</td><td>0.78</td><td>0.84</td><td>0.81</td><td>0.98</td></tr><tr><td>3</td><td>0.53</td><td>0.77</td><td>0.72</td><td>0.78</td><td>0.94</td></tr><tr><td>4</td><td>0.57</td><td>0.65</td><td>0.63</td><td>0.70</td><td>0.82</td></tr><tr><td>Big</td><td>0.39</td><td>0.33</td><td>0.43</td><td>0.47</td><td>0.57</td></tr><tr><td colspan="6">Panel C: Size-Inv portfolios</td></tr><tr><td>Small</td><td>1.01</td><td>0.98</td><td>0.99</td><td>0.89</td><td>0.35</td></tr><tr><td>2</td><td>0.92</td><td>0.91</td><td>0.92</td><td>0.90</td><td>0.48</td></tr><tr><td>3</td><td>0.90</td><td>0.93</td><td>0.81</td><td>0.82</td><td>0.50</td></tr><tr><td>4</td><td>0.79</td><td>0.72</td><td>0.71</td><td>0.75</td><td>0.54</td></tr><tr><td>Big</td><td>0.71</td><td>0.52</td><td>0.49</td><td>0.48</td><td>0.42</td></tr></table>

Figure 4.26: Return estimates for the  $5 \times 5$  size and B/M sorts. Size is shown on the vertical and B/M on the horizontal. OP are the earnings factor portfolios and Inv the investment factor portfolios. Returns are calculated on a monthly basis in excess to the one-month US treasury bill rate returns. Data start in July 1963 and end in December 2013, thus covering 606 months (Fama and French, 2015).

Panel A in Figure 4.26 shows that average returns typically fall from small to big stocks - the size effect. There is only one outlier - the low portfolio. In every row, the average return increases with B/M - the value effect. It also follows that the value effect is stronger among small stocks. In Panel B, the sort B/M is replaced by operating profitability due to the definition found in Fama and French's 2015 paper. Patterns are similar to the size-B/M sort in panel A. For every size quintile, extremely high rather than extremely low operating profitability (OP) is associated with a higher average return. In panel C the average return on the portfolio in the lowest investment quintile is dominates the return in the highest quintile. Furthermore, the size effect exists in the lowest four quintiles of the investment factor.

The authors perform an analysis to isolate the effect of the factors on average return. The main results are:

- Persistent average return patterns exist for the factors HML, CMA, RMW, SMB.  
- As expected, statistical tests reject a five-factor model constructed to capture these patterns.  
- The model explains between 71 percent and 94 percent of the cross-section variance of expected returns for HML, CMA, RMW, SMB.  
- HML (value) becomes a redundant factor. Its high average return can be completely generated by the other four factors, in particular to RMW and CMA.  
- Small stock portfolios with negative exposure to RMW and CMA are problematic: Negative CMA exposures are in line with evidence that small firms invest a lot. Negative exposures to RMW, contrary, is not in line with a low profitability.

Why Fama and French did not introduce momentum? Asness et al. (2015) state that momentum and value are best viewed together, as a system, and not stand-alone. Therefore, it is not a surprise that value becomes redundant in the five-factor model where momentum is not considered. The authors redo then the estimation of 5 factor model where they also find that HML can be reconstructed and is better explained by a combination of RMW and CMA. But the other direction is not true. CMA cannot be explained for example by HML and RMW. The authors then add momentum which is negatively correlated to value: Then, value becomes statistical significant in explaining returns.

# 4.5.7 Risk Factor Allocation

Several aspects determine how risk factors should be allocated. First, by construction risk factors should show weak correlations in normal and stressed markets. This strongly suggests that any short-term discretionary interventions should be excluded. Furthermore, any rebalancing of the portfolio weights should be considered within a time period where short-term fluctuations are no longer influential. Typically, rebalancing take place

quarterly or even semi-annually. Second, some factors are pro-cyclical with the business cycle while others are historical defensive or not related to the business cycle. Pro-cyclical is value, growth, momentum, size and liquidity. Defensive or of low volatility are factors exploiting the volatility, yield and quality. This suggests that there should be a discretionary control about which factors should be included in the investment portfolio. Given the periodicity of the cyclical behavior such a control should take place on an annual or even bi-annual basis.

Following Leippold et al. (2019), we restrict us to a long-only strategy and we ask whether we can improve the performance by timing the factors; this is often called Smart Beta in the industry but there is no need to use this expression. The author focus on few factors using equity-level data in a long-only context: the 3 and 5 FF and classical momentum. The portfolio weights are improved by including the information of the covariance matrix of equity returns in the construction, i.e. by relying on the GMV portfolio. Furthermore, realistic transaction costs are considered and particular attention is paid of reducing the common pitfalls of out-of-sample backtesting. They jointly test US, developed, and emerging equity markets. For the US market for example a significant out-of-sample alphas relative to the multi-factor benchmark that are robust to multiple-hypothesis testing, ranging between  $0.36 - 0.42\%$  per month follows. The results are solely due to the timing ability. They exploit momentum not in the factor returns but in the optimal factor weights.

The portfolios are based on factor scores. They rank each individual factor  $f$  at each date  $t$  and normalize it from zero (worst) to one (best) to obtain a factor score  $s_{f,i,t}$  for each security  $i$ . Assuming  $N$  securities and  $F$  factors, they write  $S_{t}$  for the  $F \times N$  factor score matrix. To build the aggregate score  $a_{t}$ , the factor scores are weighted with time-dependent weights  $\phi_{t}$ , i.e.  $a_{t} = \phi_{t}'S_{t}$ . The essential part of the model is the choice of the weights  $\phi$ . As a benchmark they use the naive strategy that equally weights the factor scores over time. Setting the weights equal to the sign function of past factor returns provides the first timing which does not take into account the interaction effects of the other factors. To include interaction among different factors a one-month momentum strategy that invests in the optimal weight combination of the most recent month is created, see the paper for the details how this is done. The final timing strategy is to e information of the covariance matrix, i.e. a minimum risk optimization. To estimate the large dimension covariance matrix the shrinkage estimator of Ledoit and Wolf (2003) is used. Figure 4.27 shows the results for different strategies.

# 4.5.8 Factors and Advisor Portfolios

This section is from Lawler et al. (2019). They analyze from Sept 30, 2017 to Sept 30, 2018 approximately 10'000 advisor portfolios in the Blackrock database. Advisor portfolios are en vogue since they can be constructed with scaled, replicable, and transparent investment processes. By definition, a financial advisor model portfolio consists of a set of identifiers and weights associated with a hypothetical portfolio representing a specific

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/22f771a5db89d949bfd65939ef7d3edf68f2ed5f22ba01711557ac87fd7a2f79.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/aae8603a75871ccaf81aa50d8a8b6439480e188376998d7b4ec0772eceb2110c.jpg)  
Figure 4.27: The cumulative logarithmic excess return in US dollars above the one-month Treasury bill rate of the value weighted market portfolio in the US (MKT US) dashed line, and the optimized one-month momentum strategy 3 FF, 5 FF and 5 FF including momentum (FFC), together with the excess return of the Opt strategy over the MKT strategy for transaction costs of 0, 5, 10, and 15 Bps (bottom). The analyzed period is from July 1963 to June 2018. Source: Leippold et al. [2019]

implementable investment strategy. A client portfolio can differ from the model portfolio due to frictions such as tax constraints for example. On average, advisor portfolios contain 17 direct holdings, with mutual funds and ETFs the main instrument types. Advisor portfolios are grouped in five classes from conservative portfolios (<30% equities) to aggressive portfolios (>80%) in equities. This classification is comparable to the balanced, growth, etc. classification which is common in Europe. Most advisor portfolios have an equity weight of 50% to 65%.

A hierarchical factor model is used to compare the many different types of portfolios. The first factor level are macro factors economic growth, which is mostly accessed through equities, real rates, inflation, credit, EM and commodity. Each macro factor is proxied by a representative portfolio. Economic growth is for example modelled as a weighted basked of various equity indices from around the world. Advisor portfolios are dominated by exposure to economic growth. For  $88\%$  of advisor portfolios economic growth risk account for  $74.7\%$  of portfolio volatility. On average, rates and credit exposures explain  $66.9\%$  and  $21.8\%$ , respectively, of fixed income variation. But the U.S. Bloomberg Barclays Aggregate Bond Index is  $104.3\%$  rates and  $-4.9\%$  - investors are relative short rates and long credit. Furthermore, advisor models are consistently short on duration to safeguard

against the potential of unexpected rising interest rates. The second level are style factors which allow comparison within specific asset classes. For equities, they investigate the exposure to value, momentum, small size and low volatility strategies. Advisors do not have meaningful style factor exposures in equity except for small size stocks. Table ?? summarizes statistics.

<table><tr><td>Type</td><td>Nr. Portfolios</td><td>Vol</td><td>Benchmark Vol</td><td>Average Fee</td></tr><tr><td>Conservative</td><td>12%</td><td>3.3%</td><td>3.3%</td><td>58</td></tr><tr><td>Moderate Conserv.</td><td>15%</td><td>6%</td><td>5.3%</td><td>57</td></tr><tr><td>Moderate</td><td>34%</td><td>7.9%</td><td>7.5%</td><td>54</td></tr><tr><td>Moderate Aggres.</td><td>21%</td><td>9.5%</td><td>9.4%</td><td>54</td></tr><tr><td>Aggressive</td><td>18%</td><td>12.1%</td><td>11.2%</td><td>49</td></tr></table>

Table 4.18: Statistics for advisor portfolios. The total number of BlackRock Portfolios collected between October 2017 and September 2018., as of September 30, 2018, is 9'940. Ex ante average annual volatilities as of 9/30/2018. The benchmark for the Conservative cohort is  $11\%$  S&P500,  $4\%$  MSCI All Country World ex US and  $85\%$  Bloomberg Barclays U.S. Universal Index. For other cohorts the weights of the three indices vary. Fees are in bps. (Lawler et al. (2018)).

The average number of individual equity holdings is 3.5 and the median is 2.5. Figure 4.28 shows the breakdown of macro factors across the different cohort with an increasing exposure to equity for more aggressive advisors and an overall not significant exposure to style factors.

# 4.6 Backtests

Backtests are historical simulations of quantitative investment strategies. The tests compute the P&L of the strategy if it had been run over that time period. The performance is expressed using performance measures such as the Sharpe ratio,.. Backtests often look very promising for investment. But many practitioners fear that once they invested into a backtested strategy, the backtesting-performance evaporates. This fear is justified if statistics is not used appropriately, as it is too often the case.

# 4.6.1 Data Snooping

Data snooping and data mining are often the reasons for a disagreement between backtesting results and future investment performance. They suggest findings which are supported by the data but in fact are spurious. Consider an investment strategy which has been fine-tuned on the in-sample data set. Applying it out-of-sample the claimed in-sample performance can disappear, if the strategy improved on specific in-sample characteristics which are missing out-of-sample. The data snooping example from Andrew Lo (1994) shows how a pure non-sense can lead to a spurious outperformance. The invest-

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0b893ebbede3ede3a5bf2630d14dcb38940f29804da0c8cf9ff82337cc6a17a8.jpg)  
Panel B: Decomposing Macro Factor Exposure  
Figure 4.28: Decomposing macro factor exposure. Other Macro means mostly exposure to equity as of 9/30/2018. Source: Lawler et al. (2019)

meant strategist beliefs that the following mathematical proposition of Fermat regarding prime numbers provides meaningful investment signals:

Proposition 82. For any prime number  $p$ , the division of  $2^{p - 1}$  by  $p$  always leads to a remainder of 1.

Dividing  $2^{13 - 1}$  for example by 13 implies 315 plus the remainder of 1. This holds for all prime numbers. But the converse is not true. If a division of  $2^{p - 1}$  by  $p$  leads to a remainder of 1, it does not imply that  $p$  is a prime number. But the converse is 'almost true': There are very few numbers that satisfy the division property and are not prime. In the first 10,000 numbers there are only seven such numbers, one of them is 1105.

He relates this prime number theorem to stock market performance as follow: Select those stocks where one of these seven numbers are embedded in the CUSIP identifiers.

32 Given the aforementioned seven numbers, there is only one CUSIP code that contains such a number: CUSIP 03110510. This CUSIP represents the stock Ametek. This stock had exhibited, by the time of Lo's writing, extraordinary performance: a Sharpe ratio of 0.86, a Jensen alpha of 5.15, a monthly return of 0.017, and so on.

There is no reason why the link 'Prime Number Theorem - CUSIP Stock Selection' should work in general. The relationship driven return is simple luck. Here the highly

non-linear prime number property leads to a spurious return patterns.

Consider an order statistics example. Assume that there are  $N = 100$  IID securities with standard normal distributed annual returns with mean of 10 percent and standard deviation of 20 percent. The probability that the return of security  $k$  exceeds 50 percent is then 2.3 percent.[33] It is unlikely that security  $k$  will show this strong return. But if we ask for the winner return[34] - that is to say, the probability that the maximum return will exceed 50 percent, the probability is 90 percent.

But this winning question does not tell us anything about the nature of the winning stock since they are IID distributed. Nothing can be inferred about the future return if one knows at a given date which stock is the winner. Choosing today the past winner and predicting that it will also be the future winner is data snooping. The prediction is only related to luck.

# 4.6.2 Overfitting

Researcher in investments algorithms often publish their results using in-sample results where the number of trials is not stated. Not reporting the number of all trials increases the probability of overfitting: The published investment algorithm fails to fit additional data or predict future observations reliably. There is risk that a high Sharpe ratio in-sample but with zero Sharpe ratio out-of-sample is reported. Consider an investment algorithm for stock investment where 1000 paths are simulated. If one selects and publish the best performing path, then all investors using this algorithm will be disappointed.

The example is from Bailey et al. (2014). Consider an IID sequence of normal returns with mean  $\mu$  and volatility  $\sigma$ . The annualized Sharpe ratio can be computed as (Lo (2002))

$$
\mathbf {S R} = \frac {\mu}{\sigma} \sqrt {T}
$$

where  $T$  is the number of returns per year. The true values of the drift and volatility are not known. Hence they are estimated, leading to an estimated annualized Sharpe ratio  $\overline{\mathbf{SR}}$ . Lo proves that this estimate converges asymptotically for large  $y$ , the number of years used to estimate the Sharpe ratio, to:

$$
\overline {{\mathbf {S R}}} \rightarrow \mathcal {N} (\mathbf {S R}, \frac {1 + \frac {\mathbf {S R} ^ {2}}{2 T}}{y}).
$$

If  $\mu = 0$  and  $y = 1$ , then

$$
\overline {{\mathbf {S R}}} \to \mathcal {N} (0, 1).
$$

The following proposition is key:

Proposition 83. Let  $X_{n}, n = 1, \ldots, N$ , be IID standard normally distributed and  $y = 1$ . The expected maximum of the sample is for large  $N$  approximated by:

$$
E \left[ \max  _ {n \in N} X _ {n} \right] \sim (1 - \gamma) \Phi^ {- 1} \left(1 - \frac {1}{N}\right) + \gamma \Phi^ {- 1} \left(1 - \frac {1}{e N}\right), N > > 1, \tag {4.71}
$$

with  $\gamma = 0.57721\ldots$  the Euler-Mascheroni constant. An upper bound for the expected maximum is  $\sqrt{2\ln N}$ .

Figure 4.29 illustrates the proposition. For  $N = 10$  alternative configurations of an investment strategy, one expects to find a strategy with a Sharpe ratio in-sample of 1.57 although all strategies are expected to deliver a Sharpe ratio of zero out-of-sample. Increasing the number of tested strategies, an increasing non-null probability of selecting in-sample a strategy with null expected performance out-of-sample follows. Hence, unless the maximum estimated Sharpe ratio is not much larger than the expected maximum Sharpe ratio, the discovered strategy is likely to be a false positive.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/96da3d8265354965657f23142f29d6fa6516126f5271b1db4ac9d6c06b9a6460.jpg)  
Figure 4.29: Overfitting of backtests for  $\mu = 0$  and  $y = 1$  and minimum expected backtest length.

The results carry over to  $y \neq q$  by scaling the above result. Again, the more independent configurations a researcher tries, the more likely is overfitting. Hence, increasing  $N$  means to use a higher acceptance threshold for the backtested result to be trusted. Increasing the sample size  $y$ , the above overfit problem can be at least partially mitigated. This means that a minimum backtest length can be calculated such that one does not selects an in-sample strategy with Sharpe ratio the expected maximum one but which has an expected out-of-sample Sharpe ratio of zero, see Figure 4.29.

This trade-off implies for say 6 years data at hand, that no more than 100 independent model configurations should be tried. Else, almost surely strategies are produced with positive Sharpe ratios in-sample but zero ones out-of-sample. The authors state: A researcher that does not report the number of trials  $N$  used to identify the selected backtest configuration makes it impossible to assess the risk of overfitting.

# Example Backtest Q&A

The Financial Math Organization present some questions and answers to overfitting in a blog<sup>35</sup> which relates to the paper of Bailey et al. (2014). We focus on some questions and answers.

- Why do so many quantitative investments fail? … some of the most successful investment funds in history apply rigorous mathematical models (… Winton, Citadel, …). Many of them are closed to outside investors, and the public rarely hears about them. This void is often filled by pseudo-mathematical investments, which apply mathematical tools improperly as a marketing strategy. One of the most widely misunderstood experimental techniques is historical simulation, or backtesting.  
- Is it true that every backtest is intrinsically flawed? Not at all…. The purpose of our research is to highlight how easily backtest results can be manipulated, …  
- Can the 'hold-out', i.e., reserving a testing set to validate the model discovered in the training set, method prevent overfitting? Unfortunately, this method cannot prevent overfitting…. Perhaps the most important reason for hold-out's failure is that this method does not control for the number of trials attempted. If we apply the hold-out method enough times (say 20 times for a  $95\%$  confidence level), it is expected that we will obtain a false negative (i.e., the test fails to discard an overfit strategy)….  
- Are you saying that Technical Analysis is a form of charlatanism? No. Technical analysis tools rely on a variety of filters that make them prone to overfitting. We are simply stating that technical analysts and their investors should be particularly aware of the risks of overfitting. When the probability of backtest overfitting is correctly monitored, technical analyses may provide valuable insights to investors.

# 4.6.3 Backtesting and Multiple Testing

We consider adjusting the p-value if multiple testing is considered. The discussion is taken from Harvey and Liu (2015). Consider a single initial zero-dollar investment strategy  $\phi$  and the return  $R_{t}$ . A single test is used to evaluate the hypothesis that the expected return  $E(R_{t})$  of the strategy is different from zero. To test the hypothesis a sample statistics is constructed by considering the time series of historical returns and estimating

the sample mean  $\widehat{\mu}$  and volatility  $\widehat{\sigma}$ . The t-statistics which tests the null hypothesis of zero expected return is  $\mathfrak{t} = \frac{\widehat{\mu}}{\widehat{\sigma}T}$  which implies that

$$
\mathbf {S R} = \sqrt {T} \times \mathfrak {t}. \tag {4.72}
$$

Therefore for a fixed time horizon an increasing SR implies an increasing t-ratio which implies a higher significance level, and vice versa for the other direction. This is equivalent to a lower p-value for a single strategy test:

$$
p ^ {S} = P (| R | > \mathfrak {t}) = P (| R | > \mathbf {S R} \sqrt {T}). \tag {4.73}
$$

Assuming a distribution for the returns, a distribution for the t-statistics and hence the Sharpe ratio follows. Summarizing, if SR is the right measure to value performance, (4.72) states that this is one-to-one related to the t-statistics. Back to a specific trading strategy profitable test, assuming normality and that the strategy is not profitable (hypothesis is null), then the chance to make an error of the first kind is 5 percent: decide to reject, meaning to implement strategy which would lose money. Since the hypothesis is null, the rejection was false - a false discovery happened. What is the appropriate  $p$ -level if multiple tests are used? A practitioner is to apply ad hoc rules in their backtesting rules: Discount the Sharpe ratios of single test in the backtests by  $30\%$  or even  $50\%$ . While easy to implement, this approach fails to have any justification.

We generalize the above discussion to multiple  $N \geq 1$  independent tests. Assume that we want again test whether a single investment strategy is profitable. The hypothesis is that if the strategy is not profitable, then with  $5\%$  we make a wrong decision (error type I) by implementing a strategy which will lose money - false discovery. We test independently 100 strategies. While  $5\%$  is acceptable for one test, for many tests this percentage can result in a large number of false positives. This is the multiple testing problem. In the 100 tests, the chance to err is around  $99\%$ .[36] If we want to keep the  $5\%$  level, a solution is to use  $5\% / 100 = 0.0005$  for each test. This makes sure that the chance of making the wrong decision that one of those 100 strategies is working is less than  $5\%$ . This is called controlling of the Family-wise error rate (FWER). It is a very restrictive control in the multiple testing. The  $p$ -value of 1.66 for  $5\%$  becomes 3.4. Only extremely performing strategies allow us to keep the  $5\%$  decision level. Many strategies which are performing good will be missed.

$$
p ^ {M} = P \left(\max  _ {i = 1, \dots , N} \left| R _ {i} \right| > t\right) = 1 - \left(1 - p ^ {S}\right) ^ {N}. \tag {4.74}
$$

Consider a hedge fund manager using Commodity Trading Advisors (CTAs) strategies. That is, he relates detected changes of trend in the securities to changes in the exposure. Different parameters define the change detection such as length of the time series to calculate the moving averages, thresholds to enter and to exit and from a risk management perspective, stop-loss trigger points. Given that many assets are tested, the number of combinations are millions of even billion ones. Suppose that each strategy is individually tested, say by calculating the Sharpe ratio for each trial and test its significance on  $95\%$  level. Given the large number of individual tests, multiple testing raises the concern that an increasing number of them will be positive purely due to chance. That is, a large fraction of the individual tests that ex post are positive will be false discoveries, i.e. are due to chance. If the false discovery rate is  $100\%$ , the significance of all individual tests is completely uninformative.

The conservative FWER rule was improved by Holm (1979) and Benjamini and Hochberg (1995). They proposed to allow non-performing strategies as long as the there are enough performing ones. In doing this, we gain power to detect the skill-full managers. But how many non-performing strategies are we willing to accept? We fix the rate of false discoveries (FDR) to  $20\%$  - we are willing to accept that out of five strategies one is a non-profitable one. Assume that 2 out of the 100 strategies add value while the other ones destroy wealth. Benjamini and Hochberg found an upper bound, i.e. even if all 100 strategies are null, we will get our 20 percent by adjusting the threshold. In this case it also follows that the strategies are normally distributed. If some strategies are profitable, then we get a better rate than 20 percent.

How do we find the threshold which gives the chosen FDR? The theory is rather involved, but an algorithm is used to derive the correct threshold. We expect  $100 \times 0.05 = 5$  significant variables. Starting with the p-value of 2 we get say 6 variables: We get only one skill-full manager while 5 have no skills. The ratio  $5/7 = 71\%$  is much higher than the  $20\%$  accepted FDR. The algorithm then increases the  $p$ -value from 2 such that the ratio of expected to observed variables becomes  $20\%$ . The resulting number of observed variables  $s$  such that the division of the expected variables by  $s$  equals the FDR rate says that if we know that there are 2 performing strategies among the 100 ones, then by controlling the FDR to  $20\%$ , the test has the power to discover the strategies  $s$ . In variables selection terms, we are willing to add estimation noise to our model (variable which is not important) as long as we add relevant information as well (include more relevant variables).

If the tests are dependent, then  $p^M$  depends on the joint distribution of all  $N$  single test statistics. To limit the occurrence of incorrectly discovered profitable strategies - false rejections of the null hypothesis occurs more likely than in a single test - two methods are used: The method which controls the family-wise error rate (FWER) and the control of the false discovery rate (FDR). Both methods define type I errors in multiple testing thus generalizing type I error probabilities for single tests. Summarizing,

FDR conceptualizes the rate of type I errors in null hypothesis testing when conducting multiple comparisons. FDR-controlling procedures are designed to control the expected proportion of discoveries, i.e. rejected null hypotheses that are false (incorrect rejections).

Formally, we denote by  $R$  the number of rejections,  $N$  the tested hypotheses and  $N_{0|r}$  the fraction of false discoveries.

Definition 84. FWER defined by

$$
F W E R = P \left(N _ {0 | r} \geq 1\right) \tag {4.75}
$$

is the probability of making at least one false discovery.

FDR considers the proportion of false rejections and it is based on the false discovery proportion (FDP), the proportion of type I errors defined by

$$
\mathrm {F D P} = \left\{ \begin{array}{l l} N _ {0, r}, & \text {F r a c t i o n o f f a l s e d i s c o v e r i s i f} R > 0; \\ 0, & \text {i f} R = 0. \end{array} \right. \tag {4.76}
$$

FDR measures the expected proportion of false discoveries among all discoveries, i.e.  $FDR = E[FDP]$ . Given the type I error definitions,  $p$ -value adjustments control for data mining. Based on the adjusted  $p$ -values, the corresponding  $t$ -ratios are transformed into Sharpe ratios. There are different methods to transform  $p$ -values. Two methods for FWER are:

Bonferroni's Method:

$$
p _ {(i)} ^ {B o n f} = \min (N p _ {(i)}, 1)
$$

Holm's Method:

$$
p _ {(i)} ^ {H o l m} = \min  (\max  _ {j <   i} (N - j + 1) p _ {(i)}, 1).
$$

For FDR the method of Benjamini, Hochberg, and Yekutieli (BHY) reads

$$
p _ {(i)} ^ {B H Y} = p _ {(N)} \text {i f} i = M
$$

and if  $i\leq M - 1$

$$
p _ {(i)} ^ {B H Y} = \min  \left(p _ {(i + 1)} ^ {B H Y}, \frac {N c (N)}{i} p _ {(i)}\right)
$$

with the normalization constant  $c(N) = \sum_{k=1}^{N} \frac{1}{k}$  and where the p-values are ordered descending in the algorithm.

To illustrate the methods, consider 8 investment funds given in 4.19.

The constant  $c(N) = 2.72$  and ordering the p-values,  $p_{(8)}^{BHY} = 0.5485$  is the largest adjusted p-value. Using the BHY algorithm,

$$
p _ {(7)} ^ {B H Y} = \min (0. 5 4 8 5, \frac {8 \times 2 . 7 2}{7} 0. 1 6 7 5 8) = 0. 5 2 0 9
$$

<table><tr><td>Fund</td><td>Ret</td><td>Vol</td><td>SR</td><td>\( \sqrt{T} \)</td><td>t-stat</td><td>t-value</td><td>p-value</td></tr><tr><td>Energy</td><td>-19,58</td><td>16,16</td><td>-1,21</td><td>1,41</td><td>-1,71</td><td>0,95637</td><td>0,08726</td></tr><tr><td>Diversified Dividend</td><td>6,70</td><td>3,87</td><td>1,73</td><td>1,41</td><td>2,45</td><td>0,99266</td><td>0,01468</td></tr><tr><td>Multi-Asset Income</td><td>1,58</td><td>3,70</td><td>0,43</td><td>1,41</td><td>0,60</td><td>0,72575</td><td>0,54850</td></tr><tr><td>Global RE Income</td><td>5,14</td><td>2,14</td><td>2,40</td><td>1,41</td><td>3,40</td><td>0,99966</td><td>0,00068</td></tr><tr><td>Low Vol Equity Yield</td><td>8,03</td><td>5,38</td><td>1,49</td><td>1,41</td><td>2,11</td><td>0,98257</td><td>0,03486</td></tr><tr><td>Low Volatility Yield</td><td>7,77</td><td>5,37</td><td>1,45</td><td>1,41</td><td>2,05</td><td>0,97982</td><td>0,04036</td></tr><tr><td>Real Estate</td><td>9,20</td><td>9,37</td><td>0,98</td><td>1,41</td><td>1,39</td><td>0,91621</td><td>0,16758</td></tr><tr><td>Dividend Income</td><td>9,25</td><td>4,37</td><td>2,12</td><td>1,41</td><td>2,99</td><td>0,99861</td><td>0,00278</td></tr></table>

Table 4.19: 8 investment funds from Ivesco. Data from January 2015 to December 2016. (Engesser (2018)).

and the other adjusted p-values follow in the same way. Doing the calculation, we observe that all p-values increased except the highest one and that only two of them,  $p_{(2)}^{BHY} = 0.0302$ ,  $p_{(1)}^{BHY} = 0.0148$  are statistically significant compared to the five significant strategies in 4.19 before correcting the p-values.

The next example considers the FWER for adaption to the momentum strategy following the construction of Kenneth French. He considers all stocks on NYSE and NASDAQ, where six portfolios are formed according to the market cap (small, big) and historical returns (high, medium and low). We consider data from July 1963 to December 2012, i.e. 594 monthly returns. The null hypothesis is that returns are not different from zero. Calculating first the performance of the strategy without any adjustments using the Sharpe ratio we get:

$$
\mathrm {S R} _ {p. a.} = \frac {\mu}{\sigma} \sqrt {1 2} = \frac {0 , 7}{4 . 2 9} \sqrt {1 2} = 0. 5 7.
$$

Calculating the p-value using

$$
p = 2 (1 - \Phi (\mathrm {t - v a l u e}) = 0. 0 0 0 0 6
$$

follows. We reject the null hypothesis. Assuming that there are  $N = 50$  strategy improvements,  $p^{Bonf} = 0.003\$  follows which is significant. If  $N = 1'000$ , then the Bonforroni adjusted p-value becomes 0.06, that is the null hypothesis cannot be rejected for  $1'000$  strategies.

# 4.6.4 Application to Factor Investing

Harvey et al. (2015) used 313 published works and selected working papers and a catalogue 316 risk factors. The 316 risk factors are the result of various sorting mechanism. Which of these factors are truly independent or which of them are subsumed by other variables? The standard criterion of using a t-ratio greater than 2.0 as a hurdle is no longer adequate. There are three main reasons for this.

First, the multiple testing problem using the FDR control replace the single testing problem p-values. Second, there must be a huge number of putative papers that did not find any significant explanation for the cross section of expected returns. These papers were never published and hence their information content did not enter the traditional statistical setup. There are two reasons for these non-publications. You don't make an academic career in finance by publishing non-results and it is also difficult to publish a replication of a successful argument. There is a bias toward publishing papers that establish new factors. Third, Lewellen et al. (2010) show that the explanatory powers of many documented factors are spurious using cross-sectional R-squared and pricing errors to judge the success of new factors. The Fama-French 25 size-B/M portfolios in their three factor model explain more than  $90\%$  (75%) of the time-series variation in portfolios' returns (cross-sectional variation in their average returns). Any new factor added to this model which is correlated with size and value but not with the residuals will produce a large cross-sectional R-squared.

Harvey et al. (2015) apply the false discovery proportion (FDP) and the false discovery rate (FDR). The authors derive the following results. Between 1980 and 1991, only one factor is discovered per year growing to around five factors in the period 1991 - 2003. In the last nine years, the annual FDR has increased sharply to around 18: 164 factors were discovered in the last nine years, doubling the cumulated 84 discovered factors of the past. They calculate t-ratios for each of the 316 factors discovered, including those in working papers. The vast majority of t-ratios exceed the 1.96 benchmark and the non-significant factors typically belong to papers that propose a number of factors.

The authors apply their method first to the case in which all tests of factor cross-section returns are published. This false assumption defines a lower bound of the true  $t$ -ratio benchmark. They obtain three benchmark  $t$ -ratios, two of which we describe:

- Factor-related sorting results in cross-sectional return patterns that are not explained by standard risk factors. The t-ratio for the intercept of the long/short strategy returns regressed on common risk factors is usually reported.  
- Factor loadings as explanatory variables. They are related to the cross section of expected returns after controlling for standard risk factors. Individual stocks or stylized portfolios (for example FF 25 portfolios) are used as dependent variables. The t-ratio for the factor risk premium is taken as the t-ratio for the factor.

They transform the calculated t-ratios into p-values for all three methods. Then, these p-value are transformed back into t-ratios, assuming that standard normal distribution accurately approximates the t-distribution, see Figure 4.30

Figure 4.30 presents the benchmark t-ratios for the three different methods. Using Bonferroni the benchmark t-ratio starts at 1.96 and increases to 3.78 by 2012 and will reach 4.00 in 2032. A corresponding p-values for 3.78 is for example 0.02 percent which is much lower than the starting level of 5 percent. Since Bonferroni detects fewer discoveries than Holm, the t-ratios of the later one are lower. BHY t-ratio benchmarks are not

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/30084bdeec3981e51eb714d37b8b1b557ed09fc5619eb2b5640e7cfc1acb1ec3.jpg)  
Figure 4.30: The green solid curve shows the historical cumulative number of factors discovered, excluding those from working papers. Forecasts (dotted green line) are based on a linear extrapolation. The dark crosses mark selected factors proposed by the literature. They are MRT (market beta; Fama and MacBeth [1973]), EP (earnings-price ratio; Basu [1983]), SMB and HML (size and book-to-market; Fama and French [1992]), MOM (momentum; Carhart [1997]), LIQ (liquidity; Pastor and Stambaugh [2003]), DEF (default likelihood; Vassalou and Xing [2004]), IVOL (idiosyncratic volatility; Ang, Hodrick, Xing, and Zhang [2006]), DCG (durable consumption goods; Yogo [2006]); SRV and LRV (short-run and long-run volatility; Adrian and Rosenberg [2008]), and CVOL (consumption volatility; Boguth and Kuehn [2012]). T-ratios over 4.9 are truncated at 4.9 (Harvey et al. [2015]).

monotonic but fluctuate before the year 2000 and stabilize at 3.39 after 2010.

Figure 4.30 shows the t-ratios of a few prominent factors - the main result in this section:

Result 85. Book-to-market, momentum, durable consumption goods, short-run volatility and market beta are significant across all types of  $t$ -ratio adjustments, consumption volatility, earnings-price ratio and liquidity are sometimes significant and the rest are never significant.

The authors extend the analysis by testing, for example, for robustness and assuming correlation between the factors. The above results did not change notably. The analysis suggests that a newly discovered factor today should have a t-ratio that exceeds 3.0, which corresponds to a p-value of 0.27 percent. The authors argue that the value of 3.0 should not be applied uniformly. For factors derived from first principles, the value should be less.

Harvey et al. (2015) - Many of the factors discovered in the field of finance are likely false discoveries: of the 296 published significant factors, 158 would be considered false discoveries under Bonferonni, 142 under Holm, 132 under  $BHY$  ( $1\%$ ) and 80 under  $BHY$  ( $5\%$ ). In addition, the idea that there are so many factors is inconsistent with the principal component analysis, where, perhaps there are five 'statistical' common factors driving time-series variation in equity returns (Ahn, Horenstein and Wang (2012)).

# 4.6.5 p-Hacking

In general, p-hacking means to push down the p-value to create significance. For example, testing multiple hypotheses increases the likelihood of false results. That is, the null hypothesis is rejected, although it is correct: The p-value is actually larger and not significant. Chordia, Goyal and Saretto (2017) show how the published performance of investment strategies is doubtful since the manner in which they are evaluated does not align with research quality standards. First, there is a publication bias since only those strategies that are significant are reported as only they have a viable path to publication. Second, data snooping leads to a number of false rejections of the null. Finally, a number of data choices, test procedures, and samples may be tried until a significant result is discovered and only the significant result is reported. All this is referred to p-hacking.

They use all accounting variables on Compustat data base and basic market variables on CRSP data base. They construct all possible trading signals based on the data item of Compustat satisfying minimal requirements. The signals consist of all types levels and growth rates, ratios of two levels or growth rates, i.e.

$$
\frac {x _ {1} - x _ {2}}{x _ {3}}
$$

and all possible permutations. This leads to a total of approximately 2.1 million signals in 1972-2015. It is clear, that most of these signals are economically meaningless combinations of items. But this large sample accounts for existing and yet to be studied trading strategies. Using this sample they ask whether they can put a bound on the magnitude of p-hacking and furthermore, after accounting for p-hacking, how likely is a

researcher to find a truly abnormal trading strategy? To strengthen the robustness of the results, non-treadable and peculiar assets are removed: A 6 month period between portfolio formation and the data base timestamp is required, all stocks worth less USD 3 and all stocks in the bottom quintile of NYSE market cap distribution are removed.

The authors use FDP to control the proportion of false discoveries, since the trading strategies are not independent of each other (cross-correlation in stock returns) and FDP deliver statistical cutoffs that rely on the cross-correlations present in the data. They calculate measures of risk-adjusted performance for each strategy by first constructing a long-short portfolio based on the top and bottom decile of each signal's distribution, computing portfolio alphas using the Fama and French (2015) five factor model augmented with the Carhart (1997) momentum factor and they calculate the Fama and MacBeth (1973) (FM) coefficient for each signal.

Imposing a tolerance of 5 percent FDP and the same significance level, the critical value for alpha t-statistic is 3.79 (for FM it is 3.12). This numbers are comparable to those of Harvey et al. (2015). At these thresholds, 2.76 percent of strategies have significant alphas and 10.80 percent have significant FM coefficients.[37] Using single hypothesis testing (SHT) with t-statistic higher than 1.96 rejects the null hypothesis in about 30 percent of the cases for both alpha and FM t-statistics. The majority of the discoveries (rejections of the null of no predictability) based on SHT without accounting for the very large number of strategies that are never made public are likely false.

The authors add economic reasoning to this so far purely statistical considerations to gain more robust conclusions. They impose consistency between performance measures obtained by portfolio sorts (alpha) and those derived from FM regressions. Eliminating strategies that have statistically significant t-value for alpha but insignificant for FM, or vice-versa, reduces the number of successful strategies to 806 under MHT and to 33,881 under SHT.

The second restriction are economic hurdles based on the Sharpe ratio, i.e. they eliminate strategies that do not have a Sharpe ratio higher than that of the value-weighted market portfolio. Imposing the two economic hurdles leaves us with 17 strategies that are both statistically and economically significant under MHT and 801 under SHT. The likelihood of a researcher finding a truly abnormal trading strategy tends to zero.

Surprisingly, the 17 surviving strategies fail to have any economic meaning - the sorting makes no economic sense of these strategies. The authors conclude that the standard of market efficiency is as strong as ever. A different conclusion is that while accounting and economic based sorting is meaningless, this could be different for financial market signal based sorting such as implied vs realized volatility, credit basis trades or carry trades.

# 4.6.6 Active vs Passive Investments

The simple arithmetic drawn from Bill Sharpe, see (2.16)), showed that, before costs, the return on the average actively managed dollar will equal the return on the average passively managed dollar. The analysis did not tell us whether an active manager who beats the average is skilled or just lucky. The skill/luck question is impacted by several factors. Scale for example often impacts performance negatively: A more skillfully managed large fund can under-perform a less skillfully managed small fund. Pastor et al. (2014) empirically analyze the returns-scale relationship in active mutual fund management. They find strong evidence of decreasing returns at the industry level and that a fund's performance deteriorates over its lifetime.

# 4.6.6.1 The Success of the Active Strategy

Leaving the size-skill dependence aside, how can we define and measure skills in active management? We take a skill degree of the asset managers for granted in this and the next section.

Assume IID returns  $R \sim \mathcal{N}(0, \sigma^2)$ . Profitable trades have by definition a positive return and then the expected return  $E(R)$  of one profitable trade is<sup>38</sup>.

$$
E(R) = \sigma \sqrt{\frac{2}{\pi}}\sim 0.8\times \sigma \equiv 80\% \mathrm{percentile} .
$$

Since risk scales with the square root of the number of trades, risk equals for  $n$  trades  $\sqrt{n}\sigma$ . Consider two portfolio managers. One manager is always successful; the other is successful in  $x\%$  of all trades. Both trade  $n$  times. The information ratio (IR), the measure of a manager's generated value, measures the excess return of the active strategy over risk:

$$
\mathbf {I R} = \frac {\text {E x c e s s R e t u r n A c t i v e S t r a t e g y o v e r B e n c h m a r k}}{\text {T r a c k i n g E r r o r (A c t i v e R i s k)}}, \tag {4.77}
$$

where the tracking error is the standard deviation of the active return. For the investor with  $100\%$  success rate, we get

$$
\mathbf {I R} = \frac {n \sigma \sqrt {\frac {2}{\pi}}}{\sqrt {n} \sigma} = \sqrt {\frac {2 n}{\pi}}
$$

The trader with a success rate of  $x$  percent faces a loss in  $1 - x$  percent of the trades leading to a net profit  $x - (1 - x) = 2x - 1$ . Hence, after  $n$  trades

$$
E _ {x} (R) = (2 x - 1) n \sigma \sqrt {\frac {2}{\pi}} , \mathbf {I R} _ {x} = (2 x - 1) \sqrt {\frac {2 n}{\pi}} . \tag {4.78}
$$

For a fixed success rate  $x$  an increasing trading frequency  $n$  increases the information ratio. But raising the trading frequency brings about diminishing returns due to the

$$
^ {3 8} E (R) = \frac {1}{\sqrt {2 \pi \sigma^ {2}}} \int_ {0} ^ {\infty} e ^ {- \frac {x ^ {2}}{\sigma}} d x = \sigma \sqrt {\frac {2}{\pi}}.
$$

square-root function. Numerically, an IR of 50 percent needs a success rate  $x$  of two-thirds if the manager trades quarterly. Hence, a high success rate is necessary to obtain a moderate IR. Assuming that active management is a zero-sum game centered at zero, Table 4.20 relates the IR to the percentiles: It follows that a top-quartile manager has

<table><tr><td>Percentile</td><td>IR</td></tr><tr><td>90</td><td>1</td></tr><tr><td>75</td><td>0.5</td></tr><tr><td>50</td><td>0</td></tr><tr><td>25</td><td>-0.5</td></tr><tr><td>10</td><td>-1</td></tr></table>

Table 4.20: Percentiles of an IR distribution.

an IR of one-half and an IR of  $+1$  is exceptional.

The skill versus frequency of trading (breadth) trade-off reads qualitatively, see (4.78),

$$
x \sim \frac {\operatorname {I R}}{\sqrt {n}} \tag {4.79}
$$

is of different severity for different asset classes. Many investors in interest rate risk trade one a monthly or quarterly basis since they are exposed to fundamental economic variables. They cannot increase their trading frequency arbitrarily. To achieve a high IR they need to be very successful. But if markets are efficient, this is not possible. One expects to observe more skills within (global) asset managers which can exploit inefficiencies between different markets. It is easier to increase the IR by increasing the trading frequency but this increases trading costs. Beside the naive approach to trade more often other methods are to enlarge the set of eligible assets for the asset managers or to expand the risk dimension by allowing investment strategies which generate separate risk premia.

Following this first example, add some structure to the discussion. Skill have different meanings. In its basic form a measure of skill is a hit ratio. It accounts for playing well a game. This is not a statistical measure. The information coefficient IC is such a statistical measure of skill.. The measure correlates forecast residual return with ex post residual return. The information ratio relates skill, say IC, directly to capital market theory such as the CAPM, i.e. by assuming specific IC properties and investor decision process.

The IR has similar to the alpha an ex-post and an ex-ante interpretation. Ex-post it measures an achievement; the a ratio of (annualized) residual return to (annualized) residual risk. Such a realized IR is often negative and in a return regression it is related to the t-statistic one obtains for the alpha. Roughly, the IR is equal to the alpha's t-statistic divided by the square root of observation years. The ex-ante IR measures opportunities given by the expected level of annual residual return per unit of annual residual risk.

# 4.6.6.2 Fundamental Law of Active Management

Formula (4.77) is one of many formulas to be found in the literature related to skills in active portfolio management. The most famous formula, the fundamental law of active management, expressed by Grinold (1989), states:

Proposition 86. Consider mean-variance portfolio optimization where the optimal active weights  $\phi_A$  maximize the utility function  $\mu_A - \lambda \sigma_A^2$  with the expected active return and active return variance. If the residual stock returns are uncorrelated and if no budget constraint is imposed, then:

$$
\mathbf {I R} \sim I C \sqrt {B R} = S k i l l \times F r e q u e n c y, \tag {4.80}
$$

where  $IC$  is the information coefficient of the manager and  $BR$  - the strategy breadth - is the number of independent forecasts of exceptional returns we make per year.

IC measures the correlation between actual realized and predicted returns and provides a measure of a manager's forecasting ability. Equation (4.80) states that the investors have to play often (high BR) and play well (high IC) to win a high IR. The fundamental law (4.80) is additive in the squared information ratios. Formula (4.77) shows the same intuition:  $2x - 1$  represents IC and  $\sqrt{n}$  represents BR. The derivation of (4.80) depends on several assumptions, see Buckle (2005) for a review of the assumptions. Roughly on a behavioral sid, the portfolio manager knows the metric of skill and h optimizes skill, according to a model, say the CAPM. Regarding securities, the same skill level applies to all asset choices and the sources of information are independent - forecasts are unbiased and residual returns have zero expected value. Next, the information coefficient is a small number and the impact of estimation error in investment information on out-of-sample optimized investment performance is not considered. Some consequences following Grinold (1999)are:

- Combine models, because breadth applies across models as well as assets.  
- Don't market-time. Such strategies are unlikely to generate high information ratios. While such strategies can generate very large returns in a particular year, they're heavily dependent on luck. On a risk-adjusted basis, the value added will be small. This will not surprise most institutional managers, who avoid market timing for just this reason.  
- Tactical asset allocation has a high skill hurdle. This strategy lies somewhere between market timing and stock picking - it provides some opportunity for breadth, but not nearly the level available to stock pickers. Therefore, to generate an equivalent information ratio, the tactical asset allocator must demonstrate a higher level of skill.

We apply this to portfolio management. To continue, we restate the definition of the IR of a portfolio given in (4.77) as

$$
\mathbf {I R} = \frac {\text {P o r t f o l i o A l p h a}}{\text {P o r t f o l i o R e s i d u a l R i s k}} = \frac {\alpha_ {p}}{\epsilon_ {p}}. \tag {4.81}
$$

For a portfolio  $P$  relative to a benchmark  $B$  we have:

$$
\epsilon_ {p} ^ {2} = \sigma_ {p} ^ {2} - \beta_ {p} ^ {2} \sigma_ {B} ^ {2}, \tag {4.82}
$$

i.e. residual risk orthogonal to the systematic return. The objective of an active mean-variance asset manager is to maximize:

$$
E (u) = \alpha_ {p} - \frac {\theta}{2} \epsilon_ {p} ^ {2}. \tag {4.83}
$$

Replacing the alpha by the IR using (4.82) implies the optimal level of residual risk:

$$
\epsilon_ {p} ^ {*} = \frac {\mathbf {I R}}{\theta}. \tag {4.84}
$$

Using the fundamental law,

$$
\epsilon_ {p} ^ {*} = \frac {\mathbf {I R}}{\theta} = \frac {\mathrm {I C} \sqrt {\mathrm {B R}}}{\theta}. \tag {4.85}
$$

The breadth allows for diversification among the active bets and skill increases the possibility of success so that the overall level of aggressiveness  $\epsilon^{*}$  can increase.

# Example Grinold and Kahn (2000)

A manager wants to forecast the direction of the market each quarter. The market direction takes only two values - up and down, i.e. the random variable  $x(t) = \pm 1$  with mean zero and standard deviation 1. The forecast of the manager  $y(t)$  takes the same values and has the same mean and standard deviation as  $x(t)$ . The information coefficient IC is given by the covariance of  $x$  and  $y$ . If the manager makes  $N$  bets and is correct  $N_{1}$  times  $(x = y)$  and wrong  $N - N_{1}$  times  $(x = -y)$ , then

$$
\mathrm {I C} = \frac {1}{N} \left(N _ {1} - \left(N - N _ {1}\right)\right). \tag {4.86}
$$

The fundamental law of active management has been generalized. One reason is that the IR given in (4.80) seems to overestimate the IR which a portfolio manager can reach. Assume a forecast signal with an average monthly IC of 0.03 and a stock universe of 1,000, Then, the expected annualized IR from (4.80) is 3.29. This is beyond what the best portfolio managers can realize. Ding (2010) generalizes the law by considering time series dynamics and cross-sectional properties. He shows that cross-sectional ICs are different from time-series ICs and that IC volatility over time is much more important for a portfolio IR than breadth: Playing a little better has a stronger impact on the IR than playing a little more often. He proves

$$
\mathbf {I R} = \frac {\mathrm {I C}}{\sqrt {1 - \mathrm {I C} ^ {2}}} \sqrt {\mathrm {B R}}, \tag {4.87}
$$

o.e. for a small IC, (4.87) is approximately the same as (4.80).

From an information processing point of view, active management is forecasting. There are different types of forecast quality. The naive forecast is the consensus expected return. This is the informationless forecast and if it can be implemented efficiently, the expected returns of the market or the benchmark follow. There are so-called raw and refined forecasts (Grinold and Kahn [2000]). Raw forecasts are based corporate earnings estimates or buy and sell recommendations. It is not directly a forecast of exceptional return. Refined forecasts are conditional expected return forecasts based on the raw forecast information. The following forecast formula for the excess return vector  $R$  and the raw forecast vector  $g$  where the two vectors have a joint normal distribution holds:

$$
E (R | g) = E (R) + \frac {\operatorname {c o v} (R , g)}{\operatorname {v a r} (g)} (g - E (g)). \tag {4.88}
$$

The covariance term is the IC. This equation relates forecasts that differ from their expected levels. The refined forecast is then defined as the difference between  $E(R|g)$  and the naive forecast  $E(R)$ , the consensus expected return. It is the informationless forecast. The naive forecast leads to the benchmark holdings. The forecast formula has the same structure as the CAPM or any other single factor model. This is not a surprise but follows from a linear regression analysis.

# 4.6.6.3 Skill and Luck in Mutual Fund Management I

The approach so far has not addressed the problem of how one can distinguish between skill and luck. Peter Lynch, the manager of the Magellan fund, exhibited statistically significant abnormal performance. Lynch beat the S&P 500 in 11 of the 13 years from 1977 to 1989. This is itself not evidence of value enhancement. Consider 500 coin-flippers. Each flips 13 coins and we count the number of heads for each flipper. The winner, on average, flips 11.63 heads. But the excess return of Lynch in this period relative to S&P is remarkable  $10.5\%$  which is a strong evidence of skills.

We analyze how skill-full are fund managers. Scailet et al. (2013) use the FDR to control for false discoveries or mutual funds that exhibit significant alphas by luck alone. They estimate the proportions of unskilled, zero-alpha, and skilled funds in the population. A fund is unskilled if the return from stock picking is smaller than the costs (alpha is negative net of trading costs and expenses), a zero-alpha fund if the difference is zero, and a skilled fund otherwise (alpha is strictly positive).

We consider the distribution function for the three groups unskilled, zero-alpha, and skilled funds. Grouping the three distribution functions as a function of the  $t$ -statistics, we have three density functions with the zero-alpha group density function in the middle, see Figure 4.31. The two density functions overlap - unskilled overlaps with zero-alpha and zero-alpha with skilled. Pick the latter region of overlap. If a fund has a high enough  $t$ -value, then if the fund belongs to the group of zero-alpha funds, the probability of this

fund having the high  $t$ -value is driven by luck. Therefore, in the cross-section distribution of all funds, some funds with high  $t$ -values are genuinely skilled and others are merely lucky.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/97491a1bfc8cc7f2b4d0e889216f32bf473a1f0de6fbcdca2fee3b071ed1cc37.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8c6b13c9336c5dd055d7dc644d1f1aa0564a92932cf75f4b97ee935b635c41e6.jpg)  
Figure 4.31: Intuition about luck and skill for the three groups of mutual funds unskilled, zero-alpha and skilled. (Scaillet et al. [2013]).

Of course, it is not possible to observe the true alphas for each fund. The inference for the three skill groups is carried out as follows. First, for each fund, the alpha and its standard deviation are estimated. The ratio of the two estimates defines the  $t$ -statistic. Choosing a significance level, the  $t$ -estimate lies within or outside the threshold implied by the significance level. Estimates outside are labelled significant. The FDR measures the proportion of lucky funds among the funds with significant estimated alphas. The data set are monthly returns of 2,076 actively managed US open-end, domestic equity mutual funds that existed at any time between 1975 and 2006 (inclusive).

Of the funds, 75.4 percent are zero-alpha, 24.0 percent are unskilled, and 0.6 percent are skilled. Unskilled funds under-perform for long time periods. Aggressive growth funds have the highest proportion of skilled managers, while none of the growth and income funds exhibit skills. During the period 1990-2006, the proportion of skilled funds decreases from 14.4 to 0.6 percent, while the proportion of unskilled funds increases from

9.2 percent to 24.0 percent. Although the number of actively managed funds increases over this period, skilled managers have become exceptionally rare. This is also reflected in a decreasing overall alpha in the period reaching  $-1\%$  in 2016, see Figure 4.84. These facts seem to be a good motivation for passive investments.

What could be reasons for these facts, although the education level of the average asset manager increased during the two decades? After the peak in 1993 when the alpha started to decline, the internet was launched. The cost of information started to decrease over time. Therefore markets became more and more efficient. In other words, luck has become more important than skill over time. But luck is not persistent. This leads to an overall decreasing alpha of the industry. They authors test whether funds lose their outperformance skills due to their increasing size. They treat each five-year fund record as a separate 'fund' and find that the proportion of skilled funds equals 2.4 percent, implying that a small number of managers have 'hot hands' over short time periods.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/2d7bae0e39ca0461ffafda1506107a23e1a00ebd51bd085056a6365661400958.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/93c96a9d466ee4005e20b9a7fbb16505ece8223efd5daf6fc3988030ec3824e6.jpg)  
Figure 4.32: Proportion of unskilled and skilled funds (Panel A) and total number of mutual funds in the US versus average alpha (Scailet et al. [2013]).

A plausible further explanation is the movement of skilled and performing managers to the hedge funds industry since hedge fund use performance-based fees contrary to payments used in mutual funds, see the same analysis for hedge funds in Section 2.11.

Skilled funds are concentrated in the extreme right tail of the estimated alpha distribution. This suggests a way to detect them. If in a year tests indicate higher proportions of lucky, zero-alpha funds in the right tail, then the goal is to eliminate these false discoveries by moving further to the extreme tail. Carrying out this control each year, they find a significant annual alpha of 1.45 percent. They also find that all outperforming funds waste, through operational inefficiencies, the entire created surplus.

The authors re-examine the relation between fund performance and turnover, expense ratio, and size. For each characteristic, the proportion of zero-alpha funds is around  $75\%$ . The proportion of unskilled funds is qualitatively larger for funds with high turnover - many unskilled funds trade on noise to pretend that they are skilled. The size of the fund has a bipolar effect: Both the proportion of unskilled and skilled funds are larger than for smaller funds.

What about European funds? Scaillet (2015) considers 939 open-end funds between 2001 and 2006. The main findings are first, the proportion of zero-alpha funds is 72.2 percent, the proportion of skilled funds is 1.8 percent, and the proportion of unskilled funds is 26 percent. Second, in skilled funds, we find low betas with respect to MSCI Europe. Some skilled funds are known to play bonds and depart from their pure equity mandates.

# 4.6.6.4 Skill and Luck in Mutual Fund Management II

Leippold and Rueegg (2018) reconsider the skill and luck question by changing or extending the analysis of last section as follow.

First, they do not consider equity markets only but also take into account a multi-risk factor analysis for the fixed income mutual funds. Risk factors change in the level, slope, and curvature of the local yield curve, together with a credit spread. Second, they compare value-weighted returns of active against index mutual funds within the same investment category. This allows them to avoid choosing multi-factor benchmarks and they can compare two investable alternatives where in both alternatives the corresponding friction costs and restrictions are included. They use 30 different investment categories across asset classes. Finally, they distinguish between retail and institutional funds and they change the statistical methods of last section.

We consider the last point in more details. The studies of Scaillet et al. (2010) and Fama and French (2010) state or assume that autocorrelation is of minor importance. Leippold and Ruegg test for autocorrelation in mutual fund returns using a distribution-free test. They find that already in the first three lags serial dependence can be found for 20 percent of single mutual funds and 30 percent of mutual fund portfolios. This evidence calls for temporal dependence control in the analysis of single and portfolios of mutual funds alphas against different benchmark models. They suggest to block-bootstrap the alpha of a strategy to its benchmark returns, see Ledoit and Wolf (2008, 2011). This im

proves inference accuracy for dependent time series data and the bootstrapped t-statistics and p-values are then the inputs in the multiple hypothesis frameworks, see Romano and Wolf (2005a). Since the authors test whether single active or index funds significantly outperform the theoretical multi-factor models, there are many hypotheses and thus they use the FDR. For portfolios of mutual funds there are only a few hypotheses and they use the FWER.

Figure 4.21 summarizes some findings which are comparable to those of the former section. The result shows the differences between retail and institutional funds, for ex  

<table><tr><td>Retail</td><td>US</td><td>Glob.</td><td>EU</td><td>Jap</td><td>Asia</td><td>Aver</td><td>USD</td><td>CHF</td><td>EUR</td><td>GBP</td><td>Aver</td></tr><tr><td>Active</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Zero alpha</td><td>55.1</td><td>39.6</td><td>66.2</td><td>67.9</td><td>83</td><td>62.3</td><td>38.9</td><td>71</td><td>77.8</td><td>83.3</td><td>67.8</td></tr><tr><td>Skilled</td><td>0</td><td>0</td><td>3</td><td>5.7</td><td>0</td><td>1.7</td><td>23.3</td><td>3.3</td><td>22.2</td><td>16.7</td><td>16.4</td></tr><tr><td>Unskilled</td><td>44.9</td><td>60.4</td><td>30.8</td><td>26.4</td><td>17</td><td>35.9</td><td>37.8</td><td>25.7</td><td>0</td><td>0</td><td>15.9</td></tr><tr><td>Index</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Zero alpha</td><td>61.9</td><td>30.1</td><td>76.5</td><td>73.7</td><td>100</td><td>68.4</td><td>41.6</td><td>93.3</td><td>71.6</td><td>100</td><td>76.6</td></tr><tr><td>Skilled</td><td>0</td><td>0</td><td>3.6</td><td>5.9</td><td>0</td><td>1.9</td><td>29.2</td><td>6.7</td><td>28.4</td><td>0</td><td>16.1</td></tr><tr><td>Unskilled</td><td>38.1</td><td>69.9</td><td>19.9</td><td>20.4</td><td>0</td><td>29.7</td><td>29.2</td><td>0</td><td>0</td><td>0</td><td>7.3</td></tr><tr><td>Instit.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Active</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Zero alpha</td><td>69.3</td><td>53.5</td><td>78.5</td><td>88.2</td><td>97.4</td><td>77.4</td><td>38.5</td><td>77.4</td><td>60.1</td><td>82.7</td><td>64.7</td></tr><tr><td>Skilled</td><td>0</td><td>0</td><td>8.2</td><td>9.4</td><td>0</td><td>3.5</td><td>40.7</td><td>22.6</td><td>39.9</td><td>17.3</td><td>30.1</td></tr><tr><td>Unskilled</td><td>30.7</td><td>46.5</td><td>13.3</td><td>2.4</td><td>2.6</td><td>19.1</td><td>20.8</td><td>0</td><td>0</td><td>0</td><td>5.2</td></tr><tr><td>Index</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Zero alpha</td><td>66.9</td><td>55.7</td><td>91.9</td><td>92.5</td><td>90.6</td><td>79.5</td><td>57.5</td><td>71.4</td><td>56.5</td><td>95</td><td>70.1</td></tr><tr><td>Skilled</td><td>0</td><td>0</td><td>6.8</td><td>0</td><td>0</td><td>1.4</td><td>21.3</td><td>26.2</td><td>43.5</td><td>0</td><td>22.7</td></tr><tr><td>Unskilled</td><td>33.1</td><td>44.3</td><td>1.4</td><td>7.5</td><td>9.4</td><td>19.1</td><td>21.3</td><td>2.4</td><td>0</td><td>5</td><td>7.2</td></tr></table>

Table 4.21: For equity the five-factors benchmark model including the regional model of the Fama and French homepage for MKT, SMB, HML and WML and AQR homepage for BAB. For the fixed income benchmark model the four factors are 'shift', 'twist', 'butterfly' and the spread of the BBB to the AAA credit spread from MSCI. The Morningstar database from Dec 1991 to Dec 2016 includes 61,269 funds (Source: Leippold and Ruegg [2018]).

ample the percentage of skilled active institutional funds with  $3.5\%$  compared to  $1.4\%$  and  $1.9\%$  for skilled single mutual funds. For the active and index mutual funds only managers in Europe and Japan have skills. For fixed income funds the number of zero alpha funds is lower. The highest skills are observed in the US and Euro market.

Figure 4.33 represents the hall of fame of successful investors which prove to outperform the S&P500 for at least more than 10 years. The only persistent quantitatively managed investments from Renaissance is based on top secrecy about the used methods

and the hiring of top scientists from the natural and IT sciences which apply algorithms. Only one money manager of the alternative investment group is listed in the hall of fame. Furthermore, it is notable that the macro investors dominate the fundamental investors which cannot be grouped to the Buffet/Graham school. Finally, the appearance of Lord Keynes shows that it was possible to successfully outperform the US markets in days where technology was in a state of infancy but instead relying on deep understanding of the macro economy.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/64d9438773c099ae86514cc165a4d1fc605bc54631caaacdffd4c6ada7475ded.jpg)  
Figure 4.33: Hall of Fame of investors (gurufocs, Hens and FuW [2014]).

# Chapter 5

# Investment Theory Synthesis

We discussed several approaches to portfolio construction where asset prices were exogenous. We first consider absolute asset pricing where all individuals make their optimal choices (such as portfolio weights or consumption) and markets clear, i.e. supply equals demand, which defines the endogenous asset prices. Relative asset pricing is a second approach. Base asset pricing is still exogenous, but prices of derivatives relative to the base asset prices are derived assuming no arbitrage. This assumption is behaviourally minimal (more money preferred to less) and in this sense opposite to the rich absolute pricing models. But relative pricing delivers the most used pricing in finance and the price accuracy is unique in economics. Absolute and relative pricing are related to each other: The absence of arbitrage is necessary for an equilibrium to exist: A general equilibrium cannot exist if money machines are possible.<sup>1</sup>

# 5.1 Absolute Pricing

Investors solve a fully-fledged economic model: they choose optimal consumption and investment portfolios over time to maximize their expected utility function. The optimal policies clear the markets of all goods and financial assets which determines the equilibrium asset price dynamics. Only a few models can be explicitly solved, for more complicated ones numerical approximation methods are used. In equilibrium no rational investor has an incentive to deviate from the equilibrium allocation: If an investor is optimally short, there must be an investor who optimally buys the asset, else markets do not clear.

# 5.2 Simple General Equilibrium Model

We consider two investors  $i = 1,2$  which can consume at the beginning and end of a single period a single good  $c$ . Both derive utility from a logarithmic utility function over consumption.

They face the same endowment (salary) and only differ in their impatience: The time discount rates  $b^{1}$  and  $b^{2}$  are different and hence the time value of money is different. The only asset to invest in the financial market is a risk-free bond  $B$ , which they can exchange, i.e. there is no money.

An optimal policy fixes the optimal consumption levels at the two dates and the investment amount in the bond at the first date. These optimizations determine optimal consumption  $c^i (B)$  and investment  $\phi^i (B)$  for each investor. The policies depend on the yet exogenous given bond price  $B$ . Inserting these strategies in the market clearing condition fixes the endogenous price  $B = e^{-R_f}$  of the bond, i.e. the risk-free interest rate  $R_{f}$  follows from the interaction of the investors. Let  $\phi_k(S)$  be the number of bonds investor  $k$  buys and keeps at time 0. Market clearing means  $\phi_1 + \phi_2 = 0$ : what 1 sells (buys) must 2 buy (sell). Inserting the individual optimal investment strategy functions fixes the equilibrium risk-free interest rate

$$
R _ {f} = \frac {2 (1 - b ^ {1} b ^ {2})}{b ^ {1} + b ^ {2} + 2 b ^ {1} b ^ {2}}.
$$

All quantities which enter symmetrically in the optimization such as endowment have to cancel in the equilibrium expressions. The time value of money is driven by impatience. If impatience is zero, the risk-free rate is zero. Other limit or sensitivity cases follow at once.

We derive formally the solution by allowing for more heterogeneity. The log preferences are:

$$
u ^ {i} (c _ {0} ^ {i}, c _ {1} ^ {i}) = \log (c _ {0} ^ {1}) + b ^ {i} \log (c _ {1} ^ {i}), i = 1, 2, 0 \leq b ^ {i} \leq 1
$$

with  $b^{i}$  the time preference rate. The budget restrictions read for investor  $i$  (with  $e$  the endowment):

$$
{c _ {0} ^ {i} - e _ {0} ^ {i}} = {- \frac {1}{1 + R _ {f}} \phi^ {i}}
$$

$$
c _ {1} ^ {i} - e _ {1} ^ {i} = \phi^ {i}
$$

with  $R_{f}$  the yet unspecified risk free rate. We introduce the Lagrangian  $L$ :

$$
L ^ {i} (c ^ {i}, \phi^ {i}, \lambda^ {i}) = u ^ {i} - \lambda_ {0} ^ {i} (c _ {0} ^ {i} - e _ {0} ^ {i} + \frac {1}{1 + r} \phi^ {i}) - \lambda_ {1} ^ {i} (c _ {1} ^ {i} - e _ {1} ^ {i} - \phi^ {i}).
$$

The FOC read:

$$
0 = \frac {\partial L ^ {i}}{\partial c _ {j} ^ {i}} \Longrightarrow c _ {0} ^ {i} = \frac {1}{\lambda_ {0} ^ {i}}, c _ {1} ^ {i} = \frac {b ^ {i}}{\lambda_ {1} ^ {i}}
$$

$$
0 = \frac {\partial L ^ {i}}{\partial \phi^ {i}} \Longrightarrow \lambda_ {0} ^ {i} = \lambda_ {1} ^ {i} (1 + r)
$$

$$
0 = \frac {\partial L ^ {i}}{\partial \lambda_ {j} ^ {i}}.
$$

Solving these equations implies:

$$
c _ {0} ^ {i} = \frac {e _ {0} ^ {i}}{(1 + b ^ {i})} + \frac {e _ {1} ^ {i}}{(1 + R _ {f}) (1 + b ^ {i})} = \frac {1}{1 + b ^ {i}} \mathrm {P V} (e ^ {i})
$$

$$
c _ {1} ^ {i} = \frac {b ^ {i} \left(e _ {0} ^ {i} \left(1 + R _ {f}\right) + e _ {1} ^ {i}\right)}{1 + b ^ {i}}
$$

$$
\phi^ {i} = \frac {- e _ {1} ^ {i} + e _ {0} ^ {i} b ^ {i} (1 + R _ {f}) - e _ {1} ^ {i}}{1 + b ^ {i}}
$$

$$
\lambda_ {0} ^ {i} = \frac {(1 + R _ {f}) (1 + b ^ {i})}{e _ {0} ^ {i} + R _ {f} e _ {0} ^ {i} + e _ {1} ^ {i}}
$$

$$
\lambda_ {1} ^ {i} = \frac {1 + b ^ {i}}{e _ {0} ^ {i} + R _ {f} e _ {0} ^ {i} + e _ {1} ^ {i}}.
$$

Using market clearing, we get the equilibrium interest rate:

$$
R _ {f} = \frac {e _ {1} ^ {1} + e _ {1} ^ {2} - e _ {0} ^ {1} b ^ {1} + e _ {1} ^ {2} b ^ {1} - e _ {0} ^ {2} b ^ {2} + e _ {1} ^ {1} b ^ {2} - e _ {0} ^ {1} b ^ {1} b ^ {2} - e _ {0} ^ {2} b ^ {1} b ^ {2}}{e _ {0} ^ {1} b ^ {1} + e _ {0} ^ {2} b ^ {2} + e _ {0} ^ {1} b ^ {1} b ^ {2} + e _ {0} ^ {2} b ^ {1} b ^ {2}}
$$

Assuming that endowment is the same for both agents, endowment cancels in the last expression and the above equilibrium rate follows.

If risk enters in the model, the FOC conditions become equations where expected matters but the same logic applies as in this basic example.

# Example - SNB Policy

In January 2015 the Swiss National Bank (SNB) removed the floor value between the euro and the Swiss franc. This floor had been introduced in August 2011 since EUR/CHF had moved from more than 1.6 to close to parity value in three years. This had proved to be a significant burden for the Swiss export industry since two-thirds of exports are denominated in euros. In 2011, the floor was set to 1.2 up from around 1.1. When the floor was removed, the exchange rate fell within minutes from 1.2 to 0.9 and stabilized over the following days at around 1.05. If we consider the non-regulated exchange rate to represent the equilibrium rate, the first intervention forced the rate to

move out of equilibrium, and then removing the floor the rate was allowed to return to its equilibrium value.

Whatever the utility function of the SNB is, the market clearing conditions show their importance. If SNB wants to move a value out of equilibrium, it has to change the demand or supply side. By buying euros, SNB lowered euro demand at the price to accept that its balance sheet grew from CHF 100 bn to almost CHF 800 bn.

# Example - Logarithmic Utility

Logarithmic utility facilitates calculations and they are also specific for investment view. Log investors always act optimally myopic (one-period view) independent of the dynamic context. Their demand for hedging long-term risks is zero. To understand why, a log investor maximizes log returns. Assuming normality of the returns, the log return over a long time horizon is equal to the sum of one-step returns. Long-term return is therefore maximized if the sum over the one-period returns is maximized which is the same that each one-period return is maximal.

# 5.3 Fundamental Asset Pricing Equation

We introduced to asset pricing in Section 4.10 and encountered the asset pricing equation in (3.85) for example. We show first how this equation follows from first economic principles.

We recall that gross return  $R_{j}^{g} = \frac{X_{j}}{S_{j}}$  is payoff  $X_{j}$  divided by price and the net return  $R_{j}$  is gross return minus 1. Assuming separable preferences, rational investors derive expected utility from two-period consumption at the present date  $t$  and a future date  $t + 1$ ,

$$
E _ {t} \left[ u \left(c _ {t}, c _ {t + 1}\right) \right] = E _ {t} \left[ u \left(c _ {t} ^ {1}\right) \right] + b E _ {t} \left[ u \left(c _ {t + 1}\right) \right],, 0 \leq b \leq 1
$$

with  $b$  the time preference rate. He chooses investment to maximize expected utility where consumption is assumed to be already optimally chosen. There is only a single risky asset  $S$  and two budget constraints at time  $t$  and  $t + 1$  (with  $e$  the endowment):

$$
c _ {t} - e _ {t} = - \phi_ {t} S _ {t}
$$

$$
c _ {t + 1} - e _ {t + 1} = \phi_ {t} X _ {t + 1}.
$$

Introducing the Lagrangian, the FOC imply the Fundamental Asset Pricing Equation (5.1)- for asset  $S$  at time  $t$ :

$$
S _ {t} = E _ {t} \left(M _ {t + 1} X _ {t + 1}\right) \tag {5.1}
$$

with  $M$  the stochastic discount factor (SDF),

$$
M _ {t + 1} = b \frac {u ^ {\prime} \left(c _ {t + 1}\right)}{u ^ {\prime} \left(c _ {t}\right)} \tag {5.2}
$$

and  $u^{\prime}(c)$  marginal utility of consumption. Hence, price is expected discounted payoff. (5.1) assumes that there is the underlying general equilibrium model, which ensures that a single SDF exists which can be used to price all assets by discounting payoffs. Since consumption at time  $t + 1$  is stochastic from vista time  $t$ ,  $M_{t + 1}$  is stochastic too. The SDF is high if time  $t + 1$  turns out to be a bad time - consumption is low in future states, see Figure 5.1. Then future payoffs are discounted weakly in the pricing equation (5.1) and they attribute to assets in bad times a high price.

The SDF relationship between asset prices and consumption states that investments proposed by asset managers should protect investors' optimal consumption in the short and long run. This sound theoretical model has drawbacks. First, investments derived from consumption data often underperform. Second, the assumption and knowledge of a single utility function is unrealistic. Data science is a feasible and powerful alternative.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b34d5ca0a3c1a92382190b09d56d255f728fcee51e59270f94b947a7be4ae267.jpg)  
Figure 5.1: Marginal utility  $u'$  is a decreasing function of consumption. Hence, in bad times where consumption is lower at the future  $t + 1$  than at present  $t$ , the ratio of marginal utilities in (5.2) is larger than one.

The ratio of marginal utilities in the SDF reflects that investors value money more when they need it in bad times than in good times. Marginal utility can therefore be

seen as an index of bad times and the SDF as a substitution measure between present and future consumption is an index of growth in different times. The price changes of  $S$  in the fundamental pricing equation (5.1) can have three causes: The probability  $p$ , the discount factor  $M$  or the payoff  $X$ . There is strong evidence that expected return variation over time and across assets dominate and that asset valuation moves far more on news affecting the discount factor than on news of expected cash flows, that is, the payoff  $X$ .

We consider some examples. If we consider a risk-less asset  $S_0$ , that is  $X(s) = 1$  in all states  $s$ , then  $S_0 = E(M)$ . Therefore, the risk-less rate  $R_f$  satisfies

$$
1 + R _ {f} = \frac {S _ {T}}{S _ {0}} = \frac {1}{S _ {0}} = \frac {1}{E (M)}.
$$

Assuming a constant relative risk aversion utility function  $u(c) = c^{1 - \gamma}$ ,  $0 < \gamma < 1$ , the SDF reads

$$
M = b \left(\frac {c _ {t + 1}}{c _ {t}}\right) ^ {- \gamma} = b e ^ {- \gamma \ln \left(\frac {c _ {t + 1}}{c _ {t}}\right)} \sim b (1 - \gamma \Delta c _ {t + 1})
$$

up to the first order where  $\Delta c_{t + 1} = \ln \left(\frac{c_{t + 1}}{c_t}\right)$ . Expanding again up to first order:

$$
1 + R _ {f} = \frac {1}{E (M)} \sim \frac {1}{b} (1 + \gamma E _ {t} (\Delta c _ {t + 1})).
$$

Hence interest rates are higher if people are impatient (low  $b$ ) or if expected consumption growth is high. Since high consumption growth means people get richer in the future one has to offer high risk free rate such that they consume less now and save.

How much does  $R_{f}$  vary over time is the same to ask how much must one offer to individuals to postpone consumption. This variation is given by the risk aversion factor  $\gamma$ . Expanding the risk-free rate relation up to second order:

$$
1 + R _ {f} \sim \frac {1}{b} (1 + \gamma E _ {t} (\Delta c _ {t + 1}) - \frac {1}{2} \gamma^ {2} \sigma_ {t} ^ {2} (\Delta c _ {t + 1}).
$$

Therefore, higher consumption growth volatility lowers interest rates which motivates investors to save more in uncertain times.

Using

$$
E (M R) = E (M) E (R) + \operatorname {c o v} (M, R)
$$

,  $\beta_{i} = \operatorname {cov}(M,R_{i}) / \operatorname {var}(M)$  and  $\lambda = -\mathrm{var}(M) / E(M)$  , beta pricing (deleting time indices):

$$
E \left(R _ {i} ^ {e}\right) = \beta_ {i} \lambda \tag {5.3}
$$

and inserting the explicit utility function up to first order we get in  $(\ref{eq:1})$

$$
E _ {t} (R _ {t + 1} ^ {e}) = \beta \lambda \sim \gamma \mathrm {c o v} (R _ {t + 1} ^ {e}, \Delta c _ {t + 1}) = \underbrace {\gamma \sigma_ {t} ^ {2} (\Delta c _ {t + 1})} _ {= \lambda} \underbrace {\frac {\mathrm {c o v} (R _ {t + 1} ^ {e} , \Delta c _ {t + 1})}{\sigma_ {t} ^ {2} (\Delta c _ {t + 1})}} _ {= \beta}. \qquad (5. 4)
$$

If assets covary positively with consumption growth or equivalently negatively with the SDF then they must pay a higher average return. High expected returns are equivalent to low asset prices. From a risk perspective, the above equations state that average returns are high if beta on the SDF or on consumption growth  $\Delta c$  is large. This is the above 'bad times - low consumption growth - high SDF - high returns or high asset prices' story.

Using the fundamental equation (5.1) with a risk free rate and using the approximation for the SDF we get:

$$
S _ {t} = E _ {t} \left(M _ {t + 1} X _ {t + 1}\right) \sim \frac {E _ {t} \left(X _ {t + 1}\right)}{R _ {f}} - \gamma \operatorname {c o v} \left(X _ {t + 1}, \Delta c _ {t + 1}\right). \tag {5.5}
$$

Again, price is higher if the asset payoff is a good hedge against consumption growth (negative correlation).

# 5.4 State Prices, Risk Neutral Probabilities

There are different equivalent views on asset pricing. States prices is the traditional view in financial economics, risk neutral pricing is the approach in derivative pricing and projection pricing allows to formulate geometrically the Markowitz, CAPM and APT model based on the SDF.

We always assume in this and the next section that there are  $N$  risky assets in a single period with a finite number of states  $\mathbb{S}$ . The  $\mathbb{S}$  states describe future uncertainty.  $S^j (k)$  is the asset price of asset  $j$  in state  $k$ .  $\mathbb{R}^N$  is the space of portfolios where each component represents an amount of an asset hold. The linear payoff map  $\mathbb{P}:\mathbb{R}^N\to \mathbb{R}^S$  associates to a portfolio  $\phi$  a payoff  $\mathbb{P}\phi$ . In the simplest market structure each payoff can be reached by a portfolio given a payoff map. Every risk in the economy can be perfectly replicated. But typically, the space of payoffs which can be reached is smaller than the state space. This smaller vector space is called the asset span  $\langle \mathbb{S}\rangle \subset \mathbb{R}^S$  Properties of the larger state space are mapped to the smaller span using orthogonal projections.

We impose the weak internal consistency condition of no arbitrage in the market: We exclude portfolios which allow to make no losses in all future states and gains in some states in a risky environment. This minimal structure translates to properties of the SDF (or any other equivalent formalism below).

Definition 87. Consider a one-period model with  $\mathbb{S} > 1$  states at time  $T$  and  $N - 1$  risky assets  $S$  and a riskless asset  $B$ . The price of asset  $j$  at time  $T$  in state  $k$  is given

by  $S^j(k)$ . The payoff matrix  $\mathbb{P}$  is defined by

$$
\mathbb {P} = \left( \begin{array}{c c c c} B ^ {1} (1) & S ^ {2} (1) & \dots & S ^ {N} (1) \\ \vdots & \vdots & \ddots & \vdots \\ B ^ {1} (S) & S ^ {2} (S) & \dots & S ^ {N} (S) \end{array} \right). \tag {5.6}
$$

A portfolio or a strategy is a vector  $\phi = (\phi_1, \ldots, \phi_N)'$ .

The matrix  $\mathbb{P}$  has the dimension  $\mathbb{S} \times N$ . The payoff or portfolio value  $X$  at time  $T$  in state  $k$  is

$$
X = \mathbb {P} \phi . \tag {5.7}
$$

Definition 88. A payoff  $X$  is attainable given a market structure  $\mathbb{P}$  if a portfolio  $\phi$  exists such that  $X = \mathbb{P}\phi$ . The portfolio  $\phi$  is called a replication portfolio. The space of attainable payoffs, the asset span, is denoted  $\langle \mathbb{S} \rangle \subset \mathbb{R}^S$ .

Investors are interested to find  $\phi$  given the payoff and the market payoff matrix. The system

$$
X = \mathbb {P} \phi
$$

has the solution

$$
\phi = \mathbb {P} ^ {+} X + N (\mathbb {P}) \tag {5.8}
$$

with  $A^{+}$  the Moore-Penrose Pseudo Inverse

# Chapter 6

# Asset Management Innovation

# 6.1 Big Data

# 6.1.1 Definitions

Big data means a business process, see Figure 6.1. The goal is to answer business questions by using a large amount of different types of data as input and algorithms extracting information on the data to produce an output needed to answer the business questions.<sup>1</sup> From a volume perspective the data volume range is between petato zetabytes (1 mio. petabytes)<sup>2</sup> Data consist of structured and, unstructured one. The growth rate of unstructured data make them encompass structured data. Data are almost fully digital contrary to the situation 30 years ago where data where analogue. The algorithms from machine learning or AI are often open-source. Since storage capacities are almost unlimited and cheap and computational speed is still increasing, the handling of massive data for business purposes is a commodity and profitable.

The process in Figure 6.13 can be split into two steps. First, raw data are transformed into model variables such as averages, aggregates, conditioning of the raw data. The raw data is complex, huge, structured and unstructured. The second step is to generate outputs using algorithms. Pre-processing the data for the second analytic step is a challenge where in the last years extreme progress was achieved. The data are not only available in different formats, they are also not complete, have different integrity properties, are intermittently flexible and are only partially digitized. While in the past years the main focus was on pre-processing, innovation shifted to analytics (algorithms).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/dcc740dc87a7c5bb0fe36ef50cb3984c8cc43ca231a3d814e196490ccb393a5e.jpg)  
Figure 6.1: Definition of big data adapted from Roncalli [2014]. The economic value of the big data process starts at the end with a clear business perspective.

# 6.1.2 Demand for Big Data

One can broadly distinguish big data analytics in the FI in the overlapping clusters 'customers' and 'internal FI'. In the context of customers, big data should help to

1. develop customers,  
2. retain customers,  
3. acquire customers.

Internal goals of data analytics are:

1. optimize distribution, i.e. the relationship managers' performance and potential,  
2. optimize marketing and branding,  
3. analyze competitors and pricing,  
4. digitize all documentation work such as trade confirmations, legal contracts, workflow documentation. Legal - and Reg Tech are two domains considering these issues.  
5. cyber and fraud security.

The market for big data rose from USD 7.3 bn in 2010 to 130 bn in 2016 and to USD 189 bn in 2019 (wikibon.org, Forbes, IDC). The revenues for the providers of large data are distributed in large data hardware, software and service revenues. Large IT companies like IBM, HP or Dell dominate in absolute revenues. But the share of total sales in these companies is still at a low single-digit percentage. New companies with large big data revenues are Palantir and Pivotal.

There are, however, also a number of substantive criticisms regarding big data analytics. Take machine learning. There is a mathematical theory which is not trivial. Many users of machine learning did not learn the theory. They work on the data using concepts and their experience. This can be meaningful in many aspects but also can fail. This then may result in an insufficient performance of the analysis. The plethora of so-called Robo Advisors for example are leaving many investors disappointed. Suppose a Robo uses the Markowitz model which is a common model. Robo then means that the workflow is digital but it does not mean than any intelligence is implemented which considers the shortcomings of the Markowitz model.

Data protection and data privacy are key to data science although many individuals at present do not really care about their privacy. But this will and has to change if humanity wants not to be ruled in the future by data owned by a few firms. This is one of the great challenges for politics and the societies.

# 6.1.3 Algorithms

There are different types of artificial intelligence (AI) algorithms, see Figure 6.2.<sup>3</sup> Vaguely, AI is the theory and application of software to perform tasks which require human intelligence. Machine learning (ML) is a narrower concept. ML, a statistical theory, extends well-known methods such as linear regression to situations where the data set is enormous or where the linearity assumption is not suitable. While econometrics is based on causal inference, ML is not. ML is based on prediction and categorization using optimization. A learner or algorithm detects characteristics on a training set such as typical words in email spamming and applies the insight to new emails. But such an inductive reasoning might lead us to false conclusions. The word 'casino' is labelled as a spamming indicator but the word can also appear in a non-spamming email. While human learners can rely on common sense to filter the meaning of such a word, a machine learner needs well-defined principles in order of not reaching useless conclusions. Basic is the incorporation of prior knowledge that biases the learning mechanism; the inductive bias. Evidently, there is a trade-off between too restrictive and too broad a priori knowledge implementation.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/415296a5a17f26e859232138030df6fbe016080a1782e4479deda5658bc6b0ab.jpg)  
Figure 6.2: Scheme of algorithms and big data.

# 6.1.4 Machine Learning (ML)

Machine learning means learning from examples (training set) which are shown to the machine and the machine tries to infer rules which can then be applied to new, unseen examples, see Figure 6.3: ML is the automation of the process of learning from experience. We study the statistical perspective of learning such as how many samples are needed for learning. We do not consider the important task of how much computation is involved in carrying out a learning task. ML is similar to a child which learns what a car is by showing examples of cars. After learning, the child can decide whether a new object is a car or not. But learning does not mean how a car functions or how a car is driven. Different from general AI, the goal is not to generate any kind of intelligent behaviour but to discover rules, tasks or mechanisms which can be learned by a computer.

If human tells the machine's algorithm  $f$  what is correct on a training set a supervised learning problem is considered. If the values of the output are not known, unsupervised learning, learning means to find structures or meaningful groups on the inputs. This arises in consumer behaviour and investment behaviour situations. The algorithm tries for example to pool customers with similar behaviour. Reinforcement learning means optimal control such as inter-temporal decision making in investment. Reinforcement learning is used in robotics and self-driving cars projects. Deep learning uses algorithms inspired by the structure and function of the brain where the algorithms are called artificial neural networks. These algorithms can be used for supervised, unsupervised, or reinforcement learning. This section is based on Luxburg and Schölkopf

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/a3519b1af71b6f869380dcbc54b6b873c13be92a8e6660bff304ef6af1b72d21.jpg)  
Figure 6.3: Upper panel. Distinction between traditional programming and machine learning. Lower panel. A supervised learning example. Data consists of images of cats and non-cats. A supervisor classifies the images in cats and non-cats. The classification and the corresponding digital animal data feed the training algorithm such that the algorithm is then able to classify with high precision new, not yet seen images into cat or non-cat.

(2008), Shalev-Schwartz (2016), Hazan (2016), Bruna (2018).

Formally,  $X$  is the set of examples or instances (pictures of cats). Every point in  $X$  has features such as four legs, two ears.  $Y$  is the label space.  $Y$  in is simplest form the binary set  $+1, -1$  (cat, no cat). The data set  $S$  consists of all pairs of instances and labels,

$$
S = \{(x _ {1}, y _ {1}), \ldots (x _ {m}, y _ {m}) \} \subset X \times Y.
$$

We always consider this output space unless otherwise stated. The data are randomly split into labelled training data, test data with hidden labels and the validation data used for parameter tuning.

$X, Y, S$  are the inputs in the statistical learning model (ML). The output is a prediction rule, hypotheses  $f: X \to Y$  where  $f \in F$  with  $F$  a space of functions or sets such as circles, rectangles, linear, polynomials or more general functions.  $F$  is called the hypothesis class. A classification algorithm for example takes the training data as input and produces a classifier  $f \in F$  as output. The selection of  $f$  is the algorithm, although we often call  $f$  directly the algorithm.

No assumptions are made about the sets  $X$  and  $Y$  but about the mechanism which generates the data: There exists a joint probability function  $P$  on  $X \times Y$ , each training example  $(x_i, y_i)$  is sampled IID from  $P$  and  $Y$  is given by some unknown function  $h: X \to Y$ .

Note that  $P$  is not known at the time of learning - else learning becomes trivial. By definition,  $P$  is not changing over time is ruled out. The stationarity of the unknown distribution must be relaxed if financial time series are forecasted which are not stationary. We write for the power  $|\mathcal{F}|$  of a set  $\mathcal{F}$ ; i.e. the number of elements. If  $F$  is the set of classifiers from  $X$  with  $m$  examples into a yes/no classifier set, then  $|F| = 2^m$ .

Given a training set  $S$  and a set  $F$ , the goal is to find the 'best function  $f \in F$  such that the classifier is able to classify well all new data defining the test set.

To illustrate what learning means, we consider the problem to classify apples into sweet and sour ones and then regression analysis.

# 6.1.4.1 Classifying Apples

We want to classify apples into sweet and sour ones. We assume that two features weight (g) and diameter (mm) matter. The feature set  $X$  is a two-dimensional lattice with spacing 1mm and 1g, respectively, and  $Y = \pm 1$  according to the outcome sweet or sour is the label set. For each date  $t = 1,2,\ldots$ , an apple  $x_{t}$  is presented. The learner predicts  $\hat{y}_t\in Y$ , i.e. sweet or sour. The environment afterwards reveals the true label  $y_{t}\in Y$ . The goal of the learner is make as few mistakes as possible when he has to classify the randomly chosen apples.

Without any a priori hypotheses, learning cannot be meaningful defined. Suppose first, that there are only a finite number of apples. An algorithm could memorize all labels in the training set but this is not what we would call learning. Assume that the number of apples is not bounded. Without any a priory knowledge from the human, at each date a new apple is shown, the learner might always err. The learner cannot know the label of the apples.

To make learning meaningful we provide the learner with more knowledge. We assume that the environment produces the labels of the apples by applying a function  $h: X \to Y$  which is element of a set  $F$ . This means that there is a relationship between apples' features and their taste sweet or sour. But this is too little information.  $F$  is too big; it can contain any polynomial functions, any trigonometric functions, any geometric figure classifiers or any stochastic process for example. By assumption,  $F$  is a finite set of rectangles which are aligned to the axis'. That is we restrict the set of classifiers to be

finite and given by rectangles. This is a simple type of a priori knowledge by assuming that rectangles are well-suited to separate sweet and sour apples. Often in ML, it turns out that simpler a priori knowledge performs better than more complicated one.

We furthermore assume that the largest rectangle has size  $200\mathrm{g}$  and  $100\mathrm{mm}$ . This rules out negligible monster-sized apples and it turns the learning problem into a finite one - there are only a finite number of possible rectangles as classifier. The prediction rule  $f$  is  $f(x) = 1$  if  $x$  is element of interior of rectangle, else the value is  $-1$ . Therefore, the learner knows  $F$  but not  $h$ . Figure 6.4 illustrates the construction. In the right panel the problem of over-classification, there is no rectangle which classifies the apples. This also shows that learning is different from fitting. The learner prefers in this case a less complex classifier - rectangle - compared to the complex fitting area. A key task is to define complexity in ML.

The apples are shown at random to the learner but so far no assumptions are made about the statistical properties which generate the data: A very general assumption is that there exists a joint probability function  $P$  on  $X \times Y$  and  $Y$  is given by some unknown function  $h: X \to Y$ . Since an apple can be in a rectangle or not, rectangles are characteristic functions which are random in our example. Clearly, we do not want that the apples shown in the training example are drawn by any strategy. Hence, we assume that each training  $(x_i, y_i)$  is sampled IID from  $P$ .  $P$  is not known at the time of learning - else learning becomes trivial. By definition,  $P$  is not changing over time. The stationarity of the unknown distribution must be relaxed if financial time series are forecasted which are not stationary.

Before we continue with our example we write for the power  $|\mathcal{F}|$  of a set  $\mathcal{F}$ ; i.e. the number of elements. If  $F$  is the set of classifiers from  $X$  with  $m$  examples into a yes/no classifier set, then  $|F| = 2^m$ .

Size  $|F|$  bounded

$$
| F | \leq 2 0 0 ^ {2} \times 1 0 0 ^ {2} \times 2 = 8 0 0 \mathrm {m n}
$$

where the multiplication by 2 represents that apples can be sweet or sour.

Given the set  $F$  of rectangles does the unknown  $h$  exists? I.e. does there exist a rectangle which fully determines which apples are sweet? The right panel in Figure 6.4 shows an example where realizability does not hold: There does not exist a rectangle  $f \in F$  such that with probability one  $h$  and  $f$  agree. Realizability means to assume the existence of  $h$ . This simplifies the arguments. This assumption can be waived by using so-called agnostic learning.

Given this hypothesis and all the assumptions, how could we define learning? We consider:

1. Consistent learner. He starts with  $F_{1} = F$ , i.e. all rectangles at date 1. At each

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/ae324c50a7a1f30fbf0aa409cf917e7892fd5d281a460baeb07918187c684fd9.jpg)  
Figure 6.4: Left panel. Optimal rectangle classifier. Blue denotes sour and red sweet apples. Right panel. There exists no optimal classifier. The optimal region, yellow, is complex a complex domain which classifies correctly the shown apples but it will hardly correctly classify additional apples. This corresponds to overclassification (similar to overfitting) which means that the optimal algorithm shown will poorly generalize to further not yet classified apples.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9eac1e7e0b315d89fe1d67e2c55d2e828c016c9f56f32366b50d79c03e810ebf.jpg)

future date  $t$  given an apple  $x_{t}$ , he picks an  $f \in F_{t}$  and predicts  $f(x_{t}) = \hat{y}_{t}$ . Having observed  $y_{t}$ , the set  $F_{t}$  is updated to  $F_{t + 1}$  by removing  $f$  if the hypotheses was not successful ( $\hat{y}_{t} \neq y_{t}$ ). This algorithm rules out more and more of the initial set of rectangles.

2. Halving Learner. He behaves as the consistent learner, except that he predicts the majority of  $f(x_{t})$  where  $f \in F_{t}$ . Hence, if at a time  $t$  the learner errs at least half of the function in  $F_{t}$  will not be in  $V_{t + 1}$ .

Theorem 89. The consistent learner makes at most  $|F| - 1$  errors; the halving learner  $\log_2|F|$ .

The proof is simple. Suppose that at  $t$ , the  $f \in F_t$  used for prediction leads to an error, i.e.  $f \notin F_{t+1}$  and hence,  $|F_{t+1}| \leq |F_t| - 1$ . By induction,

$$
\left| F _ {t + 1} \right| \leq \left| F _ {t} \right| - 1 \leq \left| F _ {t - 1} \right| - 2 \leq \ldots \leq \left| F _ {1} \right| - t.
$$

For the halving learner, the results follow by induction on  $|F_{t + 1}| \leq |F_t| / 2$  since for any error, half of the functions in  $F_{t}$  will not be in  $F_{t + 1}$ . Although the halving learner makes dramatically less errors, the runtime of halving grows with  $|F|$ . That is, efficient computation is needed in learning theory, else the whole methodology becomes useless. hence, the consistent learner can make at most  $800\mathrm{mn} - 1$  errors while the halving learner makes at most 27 errors:

$$
\log_ {2} (8 0 0 ^ {\prime} 0 0 0 ^ {\prime} 0 0 0) = 2 7
$$

# 6.1. BIG DATA

How well does the algorithm  $f$  perform? The error function or true risk measures the performance given a perfect classifier  $h$  (if it exists) and the unknown  $P$

$$
R (f) = P (f (x) \neq h (x)). \tag {6.1}
$$

The identity  $P(A) = E(\chi_A)$  shows for a set  $A$  that risk is an expected value. Therefore,

$$
R (f) = P (f (x) \neq h (x)) = E \left(\chi_ {f (x) \neq h (x)}\right) = E (l (x, y)) \tag {6.2}
$$

with  $l$  the loss function. The error or risk can be equivalently expressed as the expected loss. Since  $P$  is not known, this risk is purely theoretical. To compare risk with the best possible learning rule, we define the minimum risk value, Bayes risk,

$$
R ^ {*} = \inf  _ {f \in F} R (f) .
$$

For a binary classification, the classifier leading to minimum risk can be explicitly calculated.

Theorem 90. Let  $F$  to be the set  $f: X \to Y = \{-1,1\}$  of all possible measurable function  $F_{all}$ . Then the Bayes classifier

$$
f _ {B a y e s} := \left\{ \begin{array}{l l} + 1 & , i f P (Y = 1 | X = x) \geq \frac {1}{2} \\ - 1 & , e l s e \end{array} \right.
$$

defines an optimal classifier, i.e. it attains Bayes' risk.

Although Bayes risk is smaller than for any other chosen classifier  $f$ , since we don't know  $P$ , we cannot compute the Bayes classifier and neither the associated risk. But this classifier serves as a benchmark in theory.

Is it possible to find  $f$  such that  $R$  is zero? No. Consider  $X = \{x_{1}, x_{2}\}$  with  $P(\{x_{1}\}) = 1 - \epsilon$ ,  $P(\{x_{2}\}) = \epsilon$ ,  $0 < \epsilon < 1$ , and  $m$  IID samples: one almost sure and one almost uncertain feature. The probability that  $x_{2}$  is not seen among all samples is  $(1 - \epsilon)^{m} \sim e^{-\epsilon m}$  for  $m$  large. If  $\epsilon$  is much smaller than  $1/m$ , then the probability of not seeing  $x_{2}$  tends to one. Therefore, we are satisfied if

$$
R (f) \leq \epsilon
$$

with the accuracy  $\epsilon$  chosen a priori. There is a second problem arising from the randomness of the input. The probability that the learner observes the same example over and over again is not zero:  $R(f) \leq \epsilon$  cannot be guaranteed by any algorithm. We allow the algorithm to fail with a chosen confidence probability  $\delta$  over the random choice of examples. Summarizing, the learner asks for training data  $S$  containing of  $m(\epsilon, \delta)$  examples. This defines Probably (with probability at least  $1 - \delta$ ) Approximately (up to accuracy  $\epsilon$ ) Correct learning - PAC learning..

Definition 91.  $m(\epsilon, \delta)$  is the sample complexity function.

This function does not depend on  $P$  and  $f$ .

Definition 92 (Statistically Learnable). A set  $F$  is statistically learnable if for all  $\epsilon, \delta > 0$  exist a sample complexity function  $m(\epsilon, \delta) = |S|$  and an algorithm that produces  $f$  with  $R(f) < \epsilon$  with probability  $1 - \delta$  and

$$
m (\epsilon , \delta) = P o l y \left(\frac {1}{\epsilon}, \ln \left(\frac {1}{\delta}\right), \ln | F |\right)
$$

with Poly representing polynomial growth.  $F$  is PAC-learnable if the runtime of the algorithm is polynomial in  $S$ .

Learnability assumes that number of samples required for generalization depends logarithmically on the size of  $F$  and that it increases with increasing accuracy  $\epsilon, \delta$ .

# 6.1.4.2 Regression from a ML Perspective

We follow the review of Mehta et al. (2019). The data set is randomly split into training  $S_{\text{train}}$  and test data  $S_{\text{test}}$ , respectively. As a rule of thumb, the training set is much larger than the test set.

The setup is given by the dataset  $S$ , the model  $f(\theta) \in F$  which is a function of the parameters  $\theta$  and the cost or risk function  $R(S, f(\theta))$  which values how well  $f(\theta)$  performs on the observations. Given  $F$ , the goal is to find  $\theta^*$  that minimizes the squared error risk function  $R$  where the true  $h(x)$  and the model prediction  $f(x)$  differ.

The model is fitted only on the training set:

$$
\theta^ {*} = \operatorname {a r g m i n} _ {\theta} R \left(S _ {\text {t r a i n}}, f (\theta)\right)
$$

. The performance is done by calculating on the test set  $R(S_{\mathrm{test}}, f(\theta^{*}))$ . We define the in-sample error  $R_{in} := R(S_{\mathrm{train}}, f(\theta^{*}))$  and the out-of-sample error  $R_{out} := R(S_{\mathrm{test}}, f(\theta^{*}))$ . The two risks are calculated based on observed data.

In general,  $R_{out} \geq R_{in}$ . More can be said if additional assumptions are made. Consider the case of linear regression.. Then, the averages  $\bar{R}_{out}, \bar{R}_{in}$  satisfy

$$
\bar {R} _ {o u t} = \sigma^ {2} (1 + p / m), \bar {R} _ {i n} = \sigma^ {2} (1 - p / m)
$$

where  $p$  is the number of features in each sample and  $m$  the number of data. Therefore,

$$
| \bar {R} _ {o u t} - \bar {R} _ {i n} | = 2 \sigma^ {2} \frac {p}{m}.
$$

If  $p >> m$ , then the error between the inand out-of-sample (generalization error) is large. The model is not learning. To improve the situation either more samples are

needed or regularization is used such as the Ridge regression or the LASSO penalty.

Since we do not know the exact model  $h \in F$ , several models  $f$  are considered and the model minimizing  $R_{out}$  is chosen as the best model. But typically the model with lowest  $R_{out}$  does not have the lowest  $R_{in}$ . Consider data with a linear drift. Then a first order polynomial model fits not perfectly the training data but it is expected to do well on unseen test data. The opposite holds for a 10th order polynomial; better on the training data but poor on test data. Since the goal is to obtain a model that is useful for prediction and not for the best in-sample fit, the simpler model is preferred. Moreover, the difference  $|R_{in} - R_{out}|$  increases for increasing model complexity since the increasing number of parameters forces us to consider high-dimensional spaces. The 'curse of dimensionality' ensures that many phenomena that are absent or rare in low-dimensional spaces become generic.

Consider a one-dimensional regression

$$
y _ {i} = h \left(x _ {i}\right) + \epsilon_ {i} \tag {6.3}
$$

with  $h$  a unknown polynomial function and  $\epsilon_{i}$  a Gaussian, uncorrelated noise variable with mean zero and variance  $\sigma^2$ . To make predictions, consider the set of all linear polynomials  $F_{1}$ , third order  $F_{3}$  and tenth order polynomials  $F_{10}$ , respectively.  $F_{1}$  has two,  $F_{3}$  four and  $F_{10}$  eleven parameters. This shows the increasing model complexity.

We ask how the size of the training dataset  $S_{trai}$  and the noise strength  $\epsilon$  affect the ability to make predictions. To train the three models,  $x$  are uniformly sampled in an interval,  $S_{trai}$  is constructed using (6.3) and fitting on this sample is done using least-squares regression.

For noisy data,  $\sigma \neq 0$ , and a large training set, the 10th order model provides the lowest  $R_{in}$  but the worst out-of-sample predictions  $R_{out}$  independent of the order of the polynomial  $h$  in data generation. If the data set is sparse, a linear model cannot represent possible complex patterns but complex models can. But the complex model will do poorly out of sample - the overfitting problem. Hence, for small data sets simple models have more predictive power, less variance, although they have a higher bias i.e. how much on an average are the predicted values different from the actual ones. This are the erroneous assumptions about  $F$  such that relevant relations between features and outputs are missing, i.e. underfitting. A high variance leads to modelling random noise in the training data instead in the outputs, i.e. overfitting. The more complex  $F$ , the smaller the bias. Models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa. This is called the bias-variance trade-off, see Figure 6.5.

Figure 6.5 shows the general relationship between  $R_{in}$  and  $R_{out}$ .

The two risks are a function of the amount of training data.  $R_{in}$  increases with the

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0b37fc4fc51f08adfc01305541bb9c76724d77b18c8ff868a8be27350230a30e.jpg)  
Figure 6.5: Left panel.  $R_{in}$  and  $R_{out}$  as a function of training set size where the model by assumption cannot not exactly fit the true function  $h(x)$ . Right Panel: Bias-Variance tradeoff and model complexity. Shown is  $R_{out}$  as a function of the model complexity for a training dataset of fixed size. The bias decreases and the variance increases with model complexity.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/28c8b09f04cef63b0a6ef8e740b9f1866e6a7ace3e5f60432708d7284185dabb.jpg)

number of data points, since our models are not powerful enough to learn the true function.  $R_{out}$  decreases for more data points:  $R_{out}$  and  $R_{in}$  must approach the same value; the 'bias' of our model. The difference between the two errors is called the generalization error.

But infinite data sets are not available. To get best predictive power it is better to minimize  $R_{out}$  rather than the bias.  $R_{out}$  can be decomposed into a bias and a variance. The second panel in Figure 6.5 shows  $R_{out}$  as a function of the complexity of the assumed model class  $F$  to approximate the true function  $h(x)$ . ML makes precise what complexity means.  $R_{out}$  is a non-monotonic function of the model complexity on the training set: It is therefore minimized for models with intermediate complexity. Using more complicated models reduces the bias but the generalization error becomes larger due to high variance. Thus, to minimize  $R_{out}$  a more biased model with small variance is better suited than a less-biased model with large variance (bias-variance tradeoff). Summarizing, an optimal function  $f$  makes both (i) the training error and (ii) the gap between training and test error small. These two goals correspond to underfitting, the model is not able to get a small training error, and overfitting, the gap is too large.

We discuss the bias-variance tradeoff for the noisy model (6.3). We want to find a function  $\hat{f}(x)$  that approximates the true function  $h$  by making the mean squared error between  $(y - \hat{f}(x))^2$  minimal. Finding  $\hat{f}$  that generalizes to points outside of the training set can be done with any algorithm used for supervised learning. Whichever function  $\hat{f}$  we select, we can decompose its expected error on an unseen sample  $x$  as follows:

$$
R _ {o u t} = \operatorname {E} \left[ \left(y - \hat {f} (x)\right) ^ {2} \right] = \left(\operatorname {B i a s} [ \hat {f} (x) ]\right) ^ {2} + \operatorname {V a r} [ \hat {f} (x) ] + \sigma^ {2}
$$

where

$$
\operatorname {B i a s} \left[ \hat {f} (x) \right] = \operatorname {E} \left[ \hat {f} (x) - f (x) \right]
$$

and

$$
\operatorname {V a r} \left[ \hat {f} (x) \right] = \operatorname {E} [ \hat {f} (x) ^ {2} ] - \left(\operatorname {E} [ \hat {f} (x) ]\right) ^ {2}
$$

Since all three terms are non-negative, it is a lower bound on the expected error on unseen samples.

We consider this decomposition for the OLS model. We want to predict  $N$  observations of the response variable  $y = x\beta + \epsilon$  with a linear combination of  $m$  predictor variables,  $x$ , and  $\epsilon \sim \mathcal{N}(0, \sigma^2)$ .

Proposition 93. The minimum of the loss function  $L = ||y - x\beta||^2$  is given by the OLS parameter estimates  $\hat{\beta} = (x'x)^{-1}(x'y)$ . The bias is given by  $Bias(\hat{\beta}) = E(\hat{\beta}) - \beta$  and the variance  $Var(\hat{\beta}) = \sigma^2(x'x)^{-1}$  where  $\sigma^2$  is estimated from the residuals  $\hat{\sigma}^2 = \frac{(y - x\hat{\beta})'(y - x\hat{\beta})}{N - m}$ .

The OLS estimator is unbiased but its variance can be huge if predictor variables are highly correlated or if there are many predictors (for  $m \to N$ , the variance explodes). To reduce variance one has to introduce some bias which makes us move in Figure 6.5 from the right-hand side where unbiased OLS puts us towards the center with an optimized trade-off.

# 6.1.4.3 Penalty approaches in portfolio optimization

There is no analytical way to find the optimal model complexity point in the last section. To overcome overfitting, one can reduce the number of parameters (which one?) or use regularization which we discuss in this section.

The first method is the ridge regression based on the following loss function:

$$
L ^ {\prime} = \min _ {\beta \in \mathbb {R} ^ {N}} \sum_ {j = 1} ^ {N} (y _ {j} - x _ {i} ^ {\prime} \beta) ^ {2} + \lambda \sum_ {j = 1} ^ {N} \beta_ {j} ^ {2} = \min _ {\beta \in \mathbb {R} ^ {N}} | | y - x \beta | | ^ {2} + \lambda | | \beta | | ^ {2} (6. 4)
$$

The extra term is called the penalty term. By changing the values of  $\lambda$  we are controlling the penalty term.

Proposition 94. The minimum of the loss function  $L'$  is given by the parameter estimates  $\hat{\beta} = (x'x + \lambda \mathbb{I})^{-1}(x'y)$  and

$$
B i a s (\hat {\beta} ^ {\prime}) = \lambda (x ^ {\prime} x + \lambda \mathbb {I}) ^ {- 1} \beta , V a r (\hat {\beta}) = \sigma^ {2} (x ^ {\prime} x + \lambda \mathbb {I}) ^ {- 1} x ^ {\prime} x (x ^ {\prime} x + \lambda \mathbb {I}) ^ {- 1}.
$$

If  $\lambda$  increases, variance decreases and the bias increases. Ridge regression shrinks all coefficients of OLS by a uniform factor  $(1 + N\lambda)^{-1}$ . This reduces model complexity. But it does not set any coefficients to zero. What is the optimal value for  $\lambda$ ? A traditional approach is to choose  $\lambda$  such that some information criterion (AIC for example) is smallest. A ML approach is to minimize the cross-validated sum of squared residuals (or some other measure).

We consider next LASSO (Least Absolute Shrinkage Selector Operator) regularization. The problem reads:

$$
L ^ {\prime \prime} = \min _ {\beta \in \mathbb {R} ^ {N}} \sum_ {j = 1} ^ {N} (y _ {j} - x _ {j} ^ {\prime} \beta) ^ {2} + \lambda \sum_ {j = 1} ^ {N} | \beta_ {j} | = \min _ {\beta \in \mathbb {R} ^ {N}} | | y - x \beta | | ^ {2} + \lambda | | \beta | | _ {1} ^ {2}. \qquad (6. 5)
$$

The innocent looking difference is that we consider the penalty term using a different distance measure stick -  $L_{1}$  versus  $L_{2}$  norm. But the impact on the optimal betas is qualitatively and quantitatively different. Increasing lambda, the model parameters are not only becoming smaller but the original small parameters are attaining the value zero. Therefore, LASSO selects only some features while setting other coefficients to zero. A feature selection happens. To understand this, consider a two dimensional problem. The level sets of the quadratic term in the loss function are ellipses. The penalty terms are circles around zero in the  $L_{2}$ -norm and a diamond around zero in the LASSO case. The minimum of the problem is the point where the ellipses and the circle or diamond intersect. In the ridge case, this will be generically at a point which is not on one coordinate axis, i.e. both beta estimates are not zero. In the diamond case there generically the intersection is on one axis and hence one parameter is zero.

The analytical solution of the problem  $L''$  in the case where the  $x_{i}$  are orthonormal is given next:

Proposition 95. Assume that the vectors  $x_{i}$  are orthonormal. The minimum of the loss function  $L''$  is given by the parameter estimates:

$$
\hat {\beta} = \hat {\beta} _ {j} ^ {O L S} \max \left(0, 1 - \frac {N \lambda}{| \hat {\beta} _ {j} ^ {O L S} |}\right).
$$

There is no explicit formula for the Bias and Variance.

The bias increases as lambda increases and the variance decreases as lambda increases.

We consider LASSO for portfolio optimization to reduce estimation risk in the unknown parameters  $\mu$  and  $C$ . There is empirical evidence that this approach provides higher out-of-sample performance and that Sharpe ratios are more stable. The optimization problem is still convex and therefore any local numerically found minimum is

a global minimum. The optimization problem reads:

$$
\min  _ {\phi \in \mathbb {R} ^ {N}} \phi^ {\prime} C \phi + \lambda \sum_ {j = 1} ^ {N} | \phi_ {j} |, s. t.: e ^ {\prime} \phi = 1, \phi^ {\prime} \mu \geq r. \tag {6.6}
$$

Deviations from the zero vector are punished since one superimposes a 'V'-type function to the risk function. Small values of  $\phi$  eventually are reduced to zero. This results in a sparser investment vector. There are many different variants of the LASSO approach, see Fastrich et al. (2013) and Zhou (2006) for the adaptive LASSO approach to counteract some biases inherent in (6.6).

Bruder et. al (2013) compare the OLS-mean variance approach with the LASSO-mean variance one for the S&P 500, with monthly rebalancing between Jan 2000 to Dec 2011, see Table 6.1.

<table><tr><td>Method</td><td>Return</td><td>Volatility</td><td>Sharpe Ratio</td><td>Max. Drawdown</td><td>Turnover</td></tr><tr><td>OLS-MV</td><td>3.60%</td><td>14.39%</td><td>0.25</td><td>-39.71%</td><td>19.4</td></tr><tr><td>LASSO MV</td><td>5.00%</td><td>13.82%</td><td>0.36</td><td>-35.42%</td><td>5.9</td></tr></table>

Table 6.1: OLS-mean variance versus LASSO-mean variance (Bruder [2011])

The LASSO approach shows a better risk adjusted performance than the traditional one. The extreme losses are comparable in both approaches although the LASSO approach does not provide any form of a tail hedge. The turnover is much smaller for the LASSO approach which is a consequence sparse optimal investment vector and information matrix in the LASSO approach. Google stock is for example hedged in the OLS model by 99 stocks compared to 13 stocks only in the LASSO model.

LASSO requires powerful software tools. Take MSCI world with around 1'500 stocks. The LASSO approach requires a numerical optimization. Theoretical convexity of the problem is lost in most type of LASSO approaches due to the sparsity of the matrix, i.e. curvature is almost zero. One therefore needs to search for the true global minimum. Next, since the covariance matrix is of high dimension, its inversion becomes delicate due to the sparsity of the matrix, one has to use advanced algorithms to produce a meaningful inverse.

# 6.1.4.4 Learning Finite Classes

Assume  $F$ ,  $S$  are given and realizability holds. Empirical risk

$$
R _ {\mathrm {e m p}} (f) = \frac {| \left\{\left(x _ {i} , y _ {i}\right) \mid f \left(x _ {i}\right) \neq y _ {i} \right\} |}{m} \tag {6.7}
$$

which counts the errors of the algorithm is observable contrary to theoretical risk (6.1). Empirical risk  $R_{\mathrm{emp}}(f)$  depends on the data set, i.e. one often writes  $R_{\mathrm{emp},m}(f)$ . Empirical Risk Minimization (ERM) is given by any algorithm  $f_{\mathrm{ERM}}$  that minimizes

empirical risk:

$$
f _ {\operatorname {E R M}} (x) := \operatorname {a r g m i n} _ {f \in F} R (f) \tag {6.8}
$$

This is the most important estimator for unknown theoretical risk. It should be considered with care since overfitting may lead to a very low performance of the ERM.

Theorem 96 (ERM PAC Learnable, Finite Case). Assume that  $F$  is a finite set, realizability holds,  $f_{ERM}$  is defined in (6.8) and

$$
m \geq \frac {1}{\epsilon} \log \left(\frac {| F |}{\delta}\right)
$$

for all  $\epsilon, \delta > 0$ , then with probability  $1 - \delta$

$$
R (f _ {E R M}) \leq \epsilon .
$$

This theorem applies to any machine learning model satisfying the assumptions; it does not restrict  $P$  nor  $F$ . We prove more general theorems below.

We reconsider the classification of apples and with two features weight (g) and diameter (mm) where the maximum rectangle classifier of these two features is given by  $200\mathrm{g}$  and  $100\mathrm{mm}$ . We know that

$$
| F | \leq 2 0 0 ^ {2} \times 1 0 0 ^ {2} \times 2 = 8 0 0 \mathrm {m n},
$$

The theorem states that the problem is PAC learnable. Note that  $\log F \leq 50$  and if follows that the sample size  $S$  can be taken as

$$
| S | = 1 0 0 \times \log (1 0 0 ^ {2} \times 2 0 0 ^ {2} \times 2) \leq 1 0 ^ {\prime} 0 0 0.
$$

The theorem is generalized to account to agnostic learning, to the case where  $F$  is not finite and how to choose  $F$  and how to pick the best  $f$ .

# 6.1.4.5 Agnostic Learning

Wee drop the realization assumption but keep the finiteness of  $F$ ; this defines agnostic learning. Reconsider the apple classification problem following equation (6.8). Apples are sampled IID uniformly from a maximum rectangle and  $F$  was chosen to be the set of all indicator functions for all possible rectangles  $R'$  with a precision of 1 g and 1 mm. If there is noise in the data it cannot be possible to perfectly classify the training set with a rectangle, i.e. with error zero on the training set. This absolute error goal is then weakened to a relative PAC.

Given PAC, agnostic learning is defined not to the zero-error case but w.r.t. the error compared to the best  $f \in F$ : Definition 92 remains unchanged except that  $R_P(f) < \epsilon$  is replaced by

$$
R _ {P} (f) <   \min  _ {f * \in F} R _ {P} (f ^ {*}) + \epsilon .
$$

Every finite  $F$  is agnostically ERM learnable: The learning algorithm theorem 96 carries over with a change in the complexity function  $\mu$  (consider square in epsilon term):

$$
\operatorname {P o l y} \left(\frac {1}{\epsilon^ {2}}, \ln \left(\frac {\ln | F |\right)}{\delta}\right).
$$

# 6.1.4.6 Generalization

Consider a hypothesis class  $F$  and  $f_{m}$  the classifier with smallest empirical risk  $R_{\mathrm{emp}}(f_m)$ . Is true risk  $R(f_{m},X) =: R(f_{m})$  small too? Is the error still small if  $f_{m}$  is applied on all (not only test data) of  $X$  with the unknown  $P$ ? The strong law of large number states that  $|R(f_m) - R_{\mathrm{emp}}(f_m)|$  converges to zero for  $m \to \infty$  for a fixed  $f$ . The classifier  $f_{m}$  then generalizes well. There are two issues to consider. First, the rate of convergence is unknown. Convergence speed can be that slow that the number  $m$  of test data needed for a given accuracy becomes extremely large. Second, empirical risk should approximate true risk uniformly in  $F$  and  $P$ , i.e. not only for a fixed  $f$ . This defines the concept of consistency. Why is consistency important? Consider a finite set  $F$  such that for each  $f$  there exists a sample where the difference between true and empirical risk is small. But for a given sample we don't know how many of the functions in  $F$  satisfy the inequality. Furthermore,  $f_{m}$  which minimizes empirical risk need not minimize also true risk - the difference between the two risk measures can become large. We want to rule out both cases; empirical risk needs to converge towards true risk uniformly in  $F$  (independent of  $f \in F$ ). We address these two issues.

Writing  $f_{F} \in F$  for the theoretical classifier which minimizes true risk given we define:

Definition 97. An algorithm is called consistent w.r.t.  $F$  and  $P$  if for all  $\epsilon >0$ :

$$
P \left(R \left(f _ {m}\right) - R \left(f _ {F}\right) > \epsilon\right)\rightarrow 0, m \rightarrow \infty .
$$

The inequalities of Hoeffing and Chernoff address the speed of convergence for a given fixed function  $f <$ . Empirical risk is close to the actual risk:

$$
P \left(\left| R _ {\mathrm {e m p}} (f) - R (f) \right| \leq \epsilon\right) \leq 2 e ^ {- 2 m \epsilon^ {2}}. \tag {6.9}
$$

If  $m$  is sufficiently large, it is highly probable that the training error provides a good estimate of the test error. These results are not sufficient to prove consistency of empirical risk. The difference between empirical and true risk should become simultaneously small for all functions  $f \in F$ . Formally,

$$
\sup  _ {f \in F} | R (f) - R _ {\mathrm {e m p}} (f) | \leq \epsilon .
$$

But then also

$$
\left| R (f _ {m}) - R _ {\mathrm {e m p}} (f) \right| \leq \sup  _ {f \in F} \left| R (f) - R _ {\mathrm {e m p}} (f) \right| \leq \epsilon .
$$

The quantity on the right hand side is what uniform law of large number deals with. Proving uniform convergence of empirical risk implies uniform convergence of  $|R(f_m) - R(f_F)|$ :

$$
\begin{array}{l} \left| R \left(f _ {m}\right) - R \left(f _ {F}\right) \right| \\ = R \left(f _ {m}\right) - R \left(f _ {F}\right) \\ = R \left(f _ {m}\right) - R _ {\text {e m p}} \left(f _ {m}\right) + R _ {\text {e m p}} \left(f _ {m}\right) - R _ {\text {e m p}} \left(f _ {F}\right) + R _ {\text {e m p}} \left(f _ {F}\right) - R \left(f _ {F}\right) \\ \leq R \left(f _ {m}\right) - R _ {\text {e m p}} \left(f _ {m}\right) + R _ {\text {e m p}} \left(f _ {F}\right) - R \left(f _ {F}\right) \\ \leq 2 \sup  _ {f \in F} | R (f) - R _ {\mathrm {e m p}} (f) | \\ \end{array}
$$

where we used in the second last line  $R_{\mathrm{emp}}(f_m) - R_{\mathrm{emp}}(f_F) \leq 0$  by definition of  $f_m$ . Therefore,

$$
P \left(\left| R \left(f _ {m}\right) - R \left(f _ {F}\right) \right| \geq \epsilon\right) \leq P \left(\sup  _ {f \in F} \left| R (f) - R _ {\mathrm {e m p}} (f) \right| \geq \epsilon / 2\right).
$$

Hence, if we can prove consistency for the empirical risk inequality, consistency for  $|R(f_m) - R(f_F)|$  follows. The proof of empirical risk consistency  $\sup_{f \in F} |R(f) - R_{\mathrm{emp}}(f)|$  is done in several steps. We allow  $F$  to be an infinite set.

- Step I Symmetrization or ghost trick.  $R(f)$  is not known. The trick replaces this quantity by observable empirical risk by doubling virtually the existing sample of  $m$  points.

Proposition 98 (Vapnik and Chervonenkis Symmetrization Lemma). Let  $F$  consist of  $m$  elements with  $n$  samples. For  $m\epsilon \geq 2$ :

$$
P \left(\sup  _ {f \in F} | R _ {\text {e m p}} (f) - R (f) | \geq \epsilon\right) \leq 2 P ^ {\prime} \left(\sup  _ {f \in F} | R _ {\text {e m p}} (f) - R _ {\text {e m p}} ^ {\prime} (f) | \geq \epsilon / 2\right)
$$

where the second distribution  $P'$  refers to the IID distribution of a sample with size  $2n$ ,  $R_{\text{emp}}$  measures the risk on the first  $n$  samples and  $R_{\text{emp}}'$  on the second  $n$  samples.

- Step II Finiteness Step I implies that the infinite set  $F$  can be replaced by a finite one  $\mathcal{F}$  with at most  $2^{2m}$  elements in  $F$ :

$$
2 P ^ {\prime} (\sup  _ {f \in F} | R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) | \geq \epsilon / 2) = 2 P ^ {\prime} (\sup  _ {f \in \mathcal {F}} | R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) | \geq \epsilon / 2).
$$

- Step III Shattering Coefficient, Union Bound, Hoeffding The last step is to bound the above expression by:

$$
P ^ {\prime} \left(\sup  _ {f \in \mathcal {F}} \left| R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) \right| \geq \epsilon / 2\right) \leq \mathcal {S} (F, 2 m) e ^ {- m \epsilon^ {2} / 4} \tag {6.10}
$$

with  $S$  the shattering coefficient and where the union bound trick as well the Hoeffding inequality are used.

If the RHS of the last expression converges to zero for  $m$  to infinity, then ERM is consistent for the infinite function set  $F$ . Given the exponential function, if the shattering coefficient is not growing to strong, convergence follows.

Given uniform convergence, how should the space  $F$  be chosen such that the shattering coefficient times the exponential function in Step III converges? If we choose  $F$  to be all functions, then the classifier  $f_{m}$  contains all Bayes classifiers which leads to inconsistency. More precisely, consider an ERM predictor over  $F_{\mathrm{all}}$  from  $X$  to 0,1: No a priori knowledge exists or that every possible function is considered a good candidate. But the No-Free-Lunch theorem of data science predicts that the ERM predictor will fail on some learning task. Therefore, the class of all functions is not PAC learnable.

To prevent such a situation, we use prior information, to restrict  $F$ . Clearly we do not want to reduce it to the extend that the classifier with zero error (PAC) or small error (Agnostic) is ruled out. The error decomposition shows that there is an intermediate reduction, see Figure 6.6:

$$
R \left(f _ {m}\right) - R \left(f _ {\text {B a y e s}}\right) = \underbrace {R \left(f _ {m}\right) - R \left(f _ {F}\right)} _ {\text {E s t i m . e r r o r}} + \underbrace {R \left(f _ {F}\right) - R \left(f _ {\text {B a y e s}}\right)} _ {\text {A p p r o x . e r r o r}} \tag {6.11}
$$

Estimation risk is a random quantity. It measures how close  $f_{m}$  is to the best choice  $f_{F}$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/af6640da4c1d03a4e65f2f275c8d9824c0b2f5eb99156bb3ae1866035eaa288f.jpg)  
Figure 6.6: Estimation and approximation error.

in  $F$ . Approximation risk is not driven by randomness but by the error if we search in a subset  $F$  instead in the space of all functions  $F_{\mathrm{all}}$ . It does not depend on the sample size. Choosing an appropriate space  $F$  balances between the two risks. If the realizability assumption holds, this risk is by definition zero. The estimation error results because the risk  $R(f_{F})$  is only an estimate of Bayes risk. The error depends on the training set size and on the size or complexity of the hypothesis class. We have shown in the finite-  $F$  theory that this error increases logarithmically with the size  $|F|$  and it decreases with  $m$ . In order to minimize total risk, the above decomposition induces the so-called bias-complexity tradeoff. Choosing  $F$  large, decreases the approximation error and increases the estimation error due to overfitting. A very small  $F$  has the opposite effects due to underfitting.

# 6.1.4.7 Inequality of Hoeffding

We provide the details of the three steps in the last section and start with the inequality of Chernoff (1952) and its generalization of Hoeffding (1963). They describe how good finite empirical risk approximates expected true risk. Their bounds are used over and over in statistical learning theory.

Proposition 99 (Hoeffding). Let  $x_{1},\ldots ,x_{m}$  be independent bounded random variables with  $x_{i}$  taking values in  $[a_i,b_i]$ . Let  $S_{m} = \sum_{i}^{m}x_{i}$ . Then for every  $\epsilon >0$ :

$$
P \left(\left| S _ {m} - E \left(S _ {m}\right) \right| \geq \epsilon\right) \leq 2 e ^ {- 2 \frac {\epsilon}{W _ {m} ^ {2}}} \tag {6.12}
$$

with  $W_{m}^{2} = \sum_{i}(b_{i} - a_{i})^{2}$

An increasing number  $m$  of training data reduces the probability of large deviations of the empirical mean from the expected value. Replacing the variables in the theorem with those used in the learning theory where the random variables take values in the unit interval (the cube  $W_{m}$  volume equals 1), we get for the deviation of empirical risk to true risk:

$$
P \left(\left| R _ {\mathrm {e m p}} (f) - R (f) \right| \leq \epsilon\right) \leq 2 e ^ {- 2 m \epsilon^ {2}}. \tag {6.13}
$$

We rewrite (6.13) using  $\delta \coloneqq 2e^{-2me^2}$  as

$$
P \left(\left| R _ {\mathrm {e m p}} (f) - R (f) \right| \leq \sqrt {\frac {\log \frac {2}{\delta}}{2 m}}\right) \leq \delta . \tag {6.14}
$$

Inversion of the probability means that with probability at least  $1 - \delta$

$$
| R _ {\mathrm {e m p}} (f) - R (f) | \leq \sqrt {\frac {\log \frac {2}{\delta}}{2 m}}.
$$

For any function  $f$  and any positive  $\delta$  true risk is bounded by empirical risk plus the  $\sqrt{\frac{\log\frac{2}{\delta}}{2m}}$  with probability at least  $1 - \delta$ . If  $m$  is sufficiently large the training error becomes

a good estimate of true error. But the result is limited since it holds for a given function  $f$ : For this function there is a training set where the bound holds with probability  $1 - \delta$  but for a different function  $f'$  the training set may be different and the bound fails with probability  $\delta$ . The bound does not hold uniformly. Hoeffding's bound is not sufficient to prove consistency of empirical risk minimization. Applying the Glivenko-Cantelli theorem, which holds under the same assumptions as the DKW theorem below, uniform convergence follows if  $F$  is a one-dimensional space.<sup>9</sup>

The next theorem summarizes:

Proposition 101 (Vapnik and Chervonenkis). Uniform convergence for all positive  $\epsilon$  in  $(\ref{eq:1})$  is necessary and sufficient for consistency of empirical risk minimization w.r.t.  $F$ .

This abstract result is not very useful for applications since there is no characterization whether for a given set  $F$  the uniform law of large numbers holds. Since our set  $F$  is high dimensional we face the problem: which properties of  $F$  determine uniform convergence. We start with the union bound trick.

# 6.1.4.8 Union Bound

The trick is based on the elementary statement that the probability of a union of events is smaller or equal to the sum of the individual probabilities. We apply this to the case where  $F$  consists of only finitely  $m$  many functions  $f_{i}$ . Then, we have finitely many 'or' operations:

$$
\begin{array}{l} P(\sup_{f\in F}|R_{\mathrm{emp}}(f) - R(f)|\geq \epsilon) \\ = P \left(\left| R _ {\text {e m p}} \left(f _ {1}\right) - R \left(f _ {1}\right) \right| \geq \epsilon \text {o r} \left| R _ {\text {e m p}} \left(f _ {2}\right) - R \left(f _ {2}\right) \right| \geq \epsilon \dots\right). \tag {6.16} \\ \end{array}
$$

Applying the union bound trick and Hoeffding inequality:

$$
P \left(\sup  _ {f \in F} \left| R _ {\text {e m p}} (f) - R (f) \right| \geq \epsilon\right) \leq \sum_ {i} P \left(\left| R _ {\text {e m p}} \left(f _ {i}\right) - R \left(f _ {i}\right) \right| \geq \epsilon\right) \leq 2 m e ^ {- 2 m \epsilon^ {2}}. \tag {6.17}
$$

This proves that empirical risk minimization over a finite set  $F$  is consistent with respect to  $F$ : The supremum can be taken outside of the probability. Equivalently, for each

$$
F _ {m} (x) = 1 / n \sum_ {i = 1} ^ {m} \chi_ {\{X _ {i} \leq x \}}, \qquad x \in \mathbb {R}.
$$

Proposition 100. (Dvoretzky - Kiefer - Wolfowitz inequality) Let  $X_{i}$  be IID. Then

$$
P \left(\sup  _ {x \in \mathbb {R}} | F _ {m} (x) - F (x) | > \varepsilon\right) \leq 2 e ^ {- 2 m \varepsilon^ {2}} \quad f o r e v e r y \varepsilon \geq \sqrt {\frac {1}{2 m} \ln 2}. \tag {6.15}
$$

function  $f \in F$  we have with probability  $1 - \delta$

$$
R (f) = R _ {\mathrm {e m p}} (f) + \sqrt {\log m + \frac {\log \frac {2}{\delta}}{2 m}}. \tag {6.18}
$$

We see that uniformity increases the error bound by the factor  $\log m$ . This finite dimensional theory cannot be directly generalized to infinite sets  $F$  since for  $m$  to infinity 6.18) becomes meaningless.

# 6.1.4.9 VC Theory

Can  $F$  be learned if its cardinality is infinite, i.e. does the theorem about agnostic learning for finite  $F$  generalize? We start with an example which shows that finiteness of  $F$  is a sufficient condition for learnability but not a necessary one. Hence, the size of the class  $F$  is not the measure needed to classify the complexity of ML models in learnable and non-learnable ones.

Let  $f_{r}(x) = 1$ , if  $x \geq r \in \mathbb{R}$ , and zero else. Set  $F^{+}$  equal to all  $f_{r}$ , where  $r$  runs through the positive reals.  $F^{+}$  consists of all positive half lines. It has uncountable many elements and we set  $X = \mathbb{R}$ ,  $Y = \{0,1\}$ . Despite its dimensionality,  $F^{+}$  is statistically PAC learnable and agnostic learnable. To simplify the calculation assume realizability, i.e.  $f^{*}$  is an algorithm which perfectly classifies the data. To find  $f_{ERM}$ , the algorithm selects the maximal  $r$  such that to no real number  $x < r$  is assigned the value 1, i.e.  $r > f^{*}$ . Let  $\hat{f}$  be the function chosen by our algorithm. Then there is a region  $[f^{*},\hat{f}]$  with probability epsilon where  $f^{*}$  and  $\hat{f}$  disagree:  $\hat{f}$  assigns 0 to an  $x$  in this interval while  $f^{*}$  assigns 1. On the remaining interval  $(\hat{f},\infty)$  both functions agree with probability  $1 - \epsilon$ . Then,

$$
P (R _ {P} (\hat {f}) > \epsilon) \leq P (\forall (x _ {i}, y _ {i}) \in S, x _ {i} \notin [ f ^ {*}, \hat {f} ]) = \prod_ {i = 1} ^ {| S |} P (x _ {i} \notin [ f ^ {*}, \hat {f} ]) \leq (1 - \epsilon) ^ {| S |} \leq e ^ {- \epsilon | S |}.
$$

If we choose  $|S| \geq m(\epsilon, \delta) = \frac{1}{\epsilon} \log \left( \frac{1}{\delta} \right)$ , the probability that the error of  $\hat{f}$  is larger than  $\epsilon$  can be made smaller than  $\delta$ , i.e. the algorithm is learnable. The infinite set  $F$  is described by a single parameter. We guess that if an infinite set  $F$  can be described by a finite number of parameters, then the set is statistically learnable. This is true for the above example in higher dimensions. But it fails in general to be true.

The key step in determining which infinite sets  $F$  can be learned is based on the ghost sample trick idea of Vapnik and Chervonenkis: It reduces an infinite to a finite problem where the union bound trick can be applied and where the factor  $m$  in finite dimension is replaced by a capacity measure which can be computed for infinite sets.

Let  $x_{1}, \ldots, x_{m}$  be data points and  $Z_{m}$  be the sample of the  $m$  points  $(x_{i}, y_{i})$ . Set  $|F_{Z_{m}}|$  equal to the cardinality of  $F$  restricted to  $Z_{m}$ . Although  $F$  is infinite,  $|F_{Z_{m}}|$  is

finite. The shattering coefficient  $S(F,m)$  of  $F$  is defined by:

$$
\mathcal {S} (F, m) = \max  \left\{F _ {Z _ {m}} | x _ {1}, \dots , x _ {m} \in X \right\}
$$

In other words, a set of  $m$  instances  $X_{m}$  from input space  $X$  is shattered by a function class of  $F$  if all possible  $2^{m}$  labellings can be generated using functions from  $F$ . If we consider three points in the plane, i.e.  $m = 2$ , there are  $2^{3} = 8$  labellings. Using hyperplanes as the only functions in  $F$ , the points are shattered by the hyper planes, see Figure 6.7.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/92e0e9067a91d209e27e05dcfa80daf28e16914b64197108489cd28620e111bd.jpg)  
Figure 6.7: Computing the VC dimension of hyperplanes, i.e.  $F =$  hyperplanes, in dimension 2 for three points. For any of the eight possible labellings of these points, we can find a linear classifier that obtains zero training error on them. But there is no set of 4 points that this hypothesis class can shatter: A set of 3 points can be shattered, but no set of four points.

The number  $S(F, m) \leq 2^m$  is independent of the dimension of the set  $F$ . The growth function  $S(F, m)$  is the maximum number how  $m$  points can be classified by  $F$ . Consider the case where  $F$  consists of all possible functions. This class is that rich that it can classify each sample in every possible way. That means  $S(F, 2m) = 2^{2m}$ . To prove convergence of ERM, we have to consider from (99)

$$
\mathcal {S} (F, 2 m) e ^ {- m \epsilon^ {2} / 4} = 2 ^ {2 m} e ^ {- m \epsilon^ {2} / 4} = e ^ {2 m \log 2} e ^ {- m \epsilon^ {2} / 4} = m (\log 2 - \epsilon^ {2} / 4).
$$

If  $\log 2 - \epsilon^2 /4 > 0$ , i.e.  $\epsilon^2 < 4\log 2$ , for  $m$  to infinity the expression diverges. That is, consistency of ERM for the unrestricted set of all functions  $F_{all}$  does not follow. Since

the bound for consistency is only an upper bound, i.e. a sufficient condition, we cannot not directly conclude that the ERM is inconsistent if we use all functions. The following condition

$$
\log \mathcal {S} (F, m) / m \rightarrow 0
$$

defines a necessary and sufficient condition for ERM to be consistent. Using this on the unrestricted set of functions

$$
\log \mathcal {S} (F, 2 m) / (2 m) = 1.
$$

Therefore, finally

Theorem 102.  $ERM$  is not consistent on  $F_{all}$ .

But if the shattering coefficient grows polynomially, say  $S(F, 2m) \leq (2m)^k$ , then ERM is consistent.

The following theorem summarizes the above discussion, i.e. that the growth function is the right one to generalize the finite dimensional theory.

Proposition 103 (Vapnik and Chervonenkis). For any  $\delta > 0$ , with probability  $1 - \delta$  any function  $f \in F$  satisfies

$$
R (f) = R _ {e m p} (f) + \sqrt {\frac {4}{m} \left(2 \log \mathcal {S} (F , 2 n) - \log \delta\right)}. \tag {6.19}
$$

The shattering coefficient which we used so far has the drawback that it is difficult to calculate. It turns out that a different capacity figure, the VC dimension is better suited. To define this number, a sample  $Z_{m}$  of size  $m$  is shattered by the class  $F$  if the function class can realize any labelling on the given sample, i.e.  $|F_{m} = 2^{m}$ . The VC-dimension  $\mathcal{A}(F,m)$  is defined as the largest number  $m$  such that there exists a sample of size  $m$  which is shattered by  $F$ . If the VC dimension of  $F$  is finite, then  $F$  is learnable:

Theorem 104.  $F$  is PAC learnable if and only if the VC dimension of  $F$  is finite. Then, the complexity  $m_{F}(\epsilon, \delta)$  grows at the same rate as

$$
\frac {V C - d i m (F)}{\epsilon} \log \left(\frac {1}{\delta}\right).
$$

For agnostic learning, the first epsilon is replaced by its squared number.

The VC-dimension measures the ability of a set of functions to fit available finite data. A set of functions has VC-dimension  $d$  if there exist  $h$  samples that can be shattered by this set of functions, but there does not exist  $h + 1$  samples that can be shattered. If one considers the half-planes in  $\mathbb{R}^d$ , then VC is  $d + 1$ , see Figure 6.7 for the case  $d = 2$  since there exists three points that can be shattered but four points cannot be shattered. If  $e_n(y), n = 1, \ldots, m$ , is a set of  $m$  linearly independent function, then the function

$$
f (y, \theta) = \chi_ {\sum n} \theta_ {n} e _ {n} (x) + a > 0
$$

is equivalent to linear functions in  $m$ -dimensional space. The VC dimension is  $m + 1$ . If arbitrarily large samples can be shattered, the VC dimension is set equal to infinity.

This concludes our presentation of machine learning theory. Summarizing, PAC learnability discussed so far allow the sample sizes to depend on the accuracy and confidence parameters, but they are uniform with respect to the labeling rule and the underlying data distribution. That is, classes that are learnable must have a finite VC-dimension. We refer to the literature for weaker notions of learnability

# 6.1.5 Linear Threshold Model

Linear predictors are one of the most useful and used families of hypothesis classes  $F$ . They are intuitive, easy to interpret, and they fit the data reasonably well in many problems. To define them, we start with the class of affine functions  $\mathcal{A}_n$  of dimension  $d$

$$
\mathcal {A} _ {d} (x) := \{x \to x _ {0} + \langle \theta , x \rangle \} \theta \in \mathbb {R} ^ {d}, x _ {0} \in \mathbb {R},
$$

that is each function is parametrized by  $\theta$ . The different classifier (hypothesis classes) of linear predictors are compositions  $g \circ \mathcal{A}_n$ , i.e. maps from  $X = \mathbb{R}^d \to \mathbb{R} \to Y$ . In a binary classification, the case under consideration here,  $g$  is chosen to be the sign function and in a regression,  $g$  is the identity function.

The next theorem summarizes learnability:

Theorem 105. If  $x_0 = 0$ , then the VC dimension of the class of halfspaces  $F$  in  $\mathbb{R}^d$  is  $d$ . If  $x_0 \neq 0$ , the VC dimension is  $d + 1$ .

In the case of binary classification,  $F$  is set equal to the class of halfspaces:

$$
F = \mathrm {s i g n} \circ \mathcal {A} _ {d} = \{x \to f (x, \theta) = \mathrm {s i g n} (\langle \theta , x \rangle) \}
$$

where (setting  $x_0 = 0$ )

$$
f (x, \theta) = \mathrm {s i g n} (\langle \theta , x \rangle) = \left\{ \begin{array}{l l} + 1,   \langle \theta , x \rangle \geq 0 \\ - 1,   \langle \theta , x \rangle <   0 \end{array} \right.,   \theta \in d ^ {n}  .
$$

Each classifier forms a hyperplane that is perpendicular to the vector  $\theta$  and intersects at the origin. This transition corresponds to the crossing of the plane  $\langle \theta, x \rangle = 0$ . The  $\theta$  vector is orthogonal to the plane. It points in the direction where  $\langle \theta, x \rangle$  increases most, see Figure 6.8. The sign does not change if we change the order of the  $x$ 's: The linear classifier does not cares about the nearness of the labels.

Assuming  $n$  points in  $S$  and realizability, then the ERM classifier for half-spaces is expected to make zero error on the training set. The ERM can be implemented by using the perceptron algorithm on half-spaces.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/0242a9e836f8d703439bbf23f8d0bb0fe14cdf575d83b4a666cdcc62aeca5752.jpg)  
Figure 6.8: Geometry of the classifier problem.

The idea is to adjust the parameters  $\theta$  incrementally to minimize classifier training error step-by-step. By the perceptron update rule, on an image-by-image basis in the training set, the adjustment after  $k$  steps for image  $m$  reads:

$$
\theta^ {(k + 1)} = \theta^ {(k)} + y _ {m} x _ {m}
$$

if a mistake is realized  $(\langle y_m(\theta^{(k)}),x_m\rangle < 0)$ . Then

$$
y _ {m} \langle \theta^ {(k + 1)}, x _ {m} \rangle = y _ {m} \langle (\theta^ {(k)} + y _ {m} x _ {m}), x _ {m} \rangle = y _ {m} \langle \theta^ {(k)}, x _ {m} \rangle + y _ {m} ^ {2} \langle x _ {m}, x _ {m} \rangle ,
$$

i.e.

$$
y _ {m} \langle \theta^ {(k + 1)}, x _ {m} \rangle = y _ {m} \langle \theta^ {(k)}, x _ {m} \rangle + | | x _ {m} | | ^ {2} \geq y _ {m} \langle \theta^ {(k)}, x _ {m} \rangle .
$$

Therefore, given a mistake the updated value becomes more positive and for a fixed image, after a certain number of updates the value becomes positive and the image is classified correctly. Then the next image is considered. Updating the parameters again leads to a correctly classified new image. But will these updates keep the former updates stable - the convergence question of the algorithm.

Proposition 106. Assume that for all test images  $m$  exists a constant  $\gamma > 0$  such that  $\langle y_m(\theta^*), x_m \rangle \geq \gamma$  and that all training images have bounded norm  $||x_m|| \leq r$ . Then the perceptron algorithm converges in a finite number of steps  $k$  with

$$
k \leq \frac {r ^ {2} \left\| \theta^ {*} \right\| ^ {2}}{\gamma^ {2}}. \tag {6.20}
$$

The number  $\gamma$  is called the margin, a name whose meaning will become clear below.  $\theta^{*}$  is the decision parameter for the plane  $\langle \theta^{*},x\rangle = 0$ . Therefore, the assumption  $\langle y_m(\theta^*),x_m\rangle \geq \gamma >0$  means that there exists a linear classifier in our class with finite parameter values that correctly classifies all training images. The inverse upper bound  $\frac{\gamma^2}{r^2||\theta^*||^2}$  is the smallest distance in the image space from any image to the decision boundary specified by  $\theta^{*}$ . It measures how well the two classes of images are separated by a linear boundary. This is the geometric margin  $\gamma :geom$  and it inverses a measure of how difficult the problem is: The smaller the geometric margin the more difficult the problem, see Figure 6.8.

The bound in the theorem can be rewritten

$$
k \leq \frac {r ^ {2}}{\gamma_ {g e o m} ^ {2}}.
$$

Remarkably, the bound does not depend directly on the dimension of the images (pixels) nor on the number of training images. Nevertheless, the bound turns out as a measure of complexity of the problem of learning linear classifiers - the VC-dimension.

How well does the perceptron classify images which are not in the training set? If the two assumptions of the theorem hold true also for new images, then after  $k \leq \frac{r^2}{\gamma_{geom}^2}$  mistakes in classifying the new images<sup>10</sup>, all further images will be classified correctly. In this sense, the above result generalize to the new images.

We assumed that there exists a linear classifier that has a large geometric margin. Is it possible to find such a large margin classifier directly? The next section provides the answer.

# 6.1.6 Support Vector Machines (SVM)

We show how the optimal margin classifier can be found directly. The classifier is called the Support Vector Machine (SVM). Intuitively, see Figure 6.9 where the optimal and a non-optimal classifier are shown, one could find the maximum margin linear classifier by first identifying any classifier that correctly classifies all examples and then increasing the geometric margin until towards is maximum number: SVM finds the separating hyperplane with the largest margin directly. This hyperplane minimizes the upper bound of the classification error, i.e. it minimizes overfitting.

This defines an optimization problem: Maximize the geometric margin under the constraint that the classifier is correct under all training examples:

$$
\max  _ {\theta} \frac {\gamma^ {2}}{\| \theta \| ^ {2}}, y _ {k} \langle \theta , x _ {k} \rangle \geq \gamma , \forall k. \tag {6.21}
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/30de58488a15472805b6873a74a8ee9ddde8ed7beaef1908c35d93cba19ac3b3.jpg)  
Figure 6.9: The optimal SVM hyperplane is shown together with a non-optimal hyperplane where the margin is smaller than in the optimal case. The two data points which are element of the two hyperplane belonging to the SVM optimal one are denoted by a square.

This problem is recast in a more suitable form. Replacing  $\max$  by  $\min$  provides a quadratic objective function, inserting the usual factor  $1/2$  and since the result depends on the ratio  $\theta/\gamma$ , we set without loss of generality  $\gamma = 1$ . Summarizing, the problem reads

$$
\min  _ {\theta} \frac {1}{2} | | \theta | |, y _ {k} \langle \theta , x _ {k} \rangle \geq 1, \forall k. \tag {6.22}
$$

This defines a quadratic optimization problem which can be generalized. Using the Lagrangian, the Kuhn-Tucker conditions are necessary and also sufficient for this convex problem for an optimum. If  $\alpha_{k}$  is the Lagrange multiplier associated to constraint  $k$  in the optimization problem, the complementarity condition of Kuhn-Tucker

$$
\alpha_ {k} \left(y _ {k} \langle \theta , x _ {k} \rangle - 1\right) = 0
$$

implies that only data points which are elements of the two hyperplanes in Figure 6.9 marked with the square can have  $\alpha_{k} > 0$  since they are the only points where the constraint holds with equality. These two data points are called support vectors. For all other data points the alphas are zero. In the pixel example, the solution depends only on the subset of images which are exactly on the margin. The remaining images do not matter. Hence, the support vectors are sufficient to define the training set.

The many conditions in the Kuhn-Tucker which are due to the inequality constraint make it difficult to solve the problem. Therefore, one transforms the optimization problem from the above formulation (primal model) to its dual model form which is easier to solve. That for, one solves in the primal model the equation  $\frac{\partial L}{\partial\theta} = 0$  with  $L$  the Lagrangian w.r.t. to  $\theta$  and substitutes this solution back into the Lagrangian which implies the dual Lagrangian  $L_{D}$  which depends only on alpha,  $y$  and  $x_{k}$ . From a statistical learning theory perspective, maximizing the margin means minimizing the VC dimension of the support vector machine. Support vector machines minimize bot empirical risk and the confidence interval.

So far we did not consider the typical situation where images are difficult to classify because of labelling errors, i.e. some few images pop-up in the wrong half-plane in the optimal solution. We alter the optimization problem of SVM to account for these types of errors in the maximum margin linear classifier. The simplest form is to introduce 'slack' variables. Slackness means that we measure the degree to which each margin constraint is violated and associate a cost for the violation in the objective function. The problem then reads:

$$
\min  _ {\theta} \frac {1}{2} | | \theta | | + c \sum_ {k = 1} ^ {n} \xi_ {k}, y _ {k} \langle \theta , x _ {k} \rangle \geq 1 - \xi_ {k}, \xi_ {k} \geq 0, \forall k. \tag {6.23}
$$

where  $\xi$  are the slack variables. If we have to set  $\xi_{k} > 0$ , then the margin constraint is violated (possible misspecification) and the penalty costs occur. Increasing the constant  $c$ , i.e. increasing the penalty costs, leads to  $\xi_{k} = 0$  for all  $k$ . We are back in the original problem. For small  $c$  many margin constraints can be violated. It is reasonable to ask whether this is indeed the trade-off we want.

So far we assumed that data sets can be separated linearly by a hyperplane. But often a non-linear curve is needed instead. We refer to the literature for the powerful methods which rely on the clever idea to transform the non-linear into a linear one by mapping the data into a higher dimensional space and then to use the above linear theory in this space (kernel methods).

# 6.1.7 Tree Based Learning

This section is based on the material from AnalyticsVidhya. Tree based (TB) learning algorithms are supervised learning methods. They are very popular since they can be of a high accuracy, stability and easy to interpret. TB algorithms can be used both for classification and regression. Unlike linear models such as linear regressions they can account for non-linear relationships. Examples of TB are random forest, decision trees or boosted trees.

As an example, assume that we have  $N = 30$  stocks which each stock described by three input variables: Creditworthiness score (high, low), sector (energy, transportation)

and its sustainability score (high, low). 15 of the stocks were performing well in the last investment period. The goal is to find a model to predict which stock will perform well in the next period based on the input variables. Decision trees identify the variables which create the best homogeneous sets of stocks. How are these variables and the splitting identified? While the variables in the example are all categorical (of the yes or no type), the variables can also take continuous values. Figure 6.11 explains the main terminology for decision trees. The only missing term is Pruning, i.e. removing sub-nodes of a decision node which is the opposite operation of splitting.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/96239078d6fffc37124216f2d67170b219d54893a0652fb44aae846ec4e36a4e.jpg)  
Figure 6.10: Terminology for decision trees.

It is common to speak about regression trees if the dependent variable is continuous; else the expression classification tree is used.

Definition 107. A classification tree is a decision tree in which each node has a binary decision based on  $X_{i} < a$  or not for a fixed value  $a \in \mathbf{mathbb{R}}$ .

The root node contains all data  $(X_{i},Y_{i})$ . For both models, the prediction space is cut into disjoint subsets. Splitting from top down cuts the prediction space into new branches as long as the user define to terminate the splitting process. If there are too many splits, overfitting follows: Performance will be poor when applied to new data. Pruning is the counter measure to reduce overfitting.

How does the tree decide when to make the next split? Many different algorithms are used. The general goal is that at each node, feature  $X_{i}$  and the threshold  $a$  are

chosen to minimize resulting diversity in the children nodes. Consider the splits w.r.t. Creditworthiness and Sector, respectively. The Gini index split calculates first the index for each sub-node and then the index is calculated for a split weighted Gini score of each node of that split.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c5be2b65c294fc6742e982f2036b5a9aecad7a16d933d5b7e073cf6d63897fd8.jpg)  
Figure 6.11: Split on Creditworthiness and split on Sector.

The weighted Gini index for the split Creditworthiness is then  $1/4 * 10/30 + 1/4 * 20/30 = 1/8 + 1/6 = 0.29$ . For the split Sector, the Gini Index is

$$
1 2 / 3 0 (7 / 1 2) ^ {2} + (5 / 1 2) ^ {2}) + 1 8 / 3 0 (8 / 1 8) ^ {2} + (1 0 / 1 8) ^ {2}) = 0. 5 1.
$$

The Gini score for Split on Sector is higher than the other one. The node split will be on Sector. Intuitively, there is more diversity in the Sector split compared to the other split where prediction is close to random coin toss. From an information perspective, the purer a node is the less information is needed to describe the node. Hence, entropy  $S$  is another quantity to calculate a split. A method for continuous variable are reduction of variance calculations using the above two step procedure of calculating the variance for each node and then using the weighted average for the split variance value.

To control for overfitting, that is extreme  $100\%$  accuracy on training set by making one leaf for each observation, is achieved either by setting constraints or by pruning. Constraints can be set on the parameters in the tree: One can fix the minimum number of observations in the nodes for a split, define the minimum samples for a terminal node, the maximum depth of tree, the maximum number of terminal nodes or the maximum features to consider for split. These restrictions prevent the model from learning relations

which are specific to the node but do not generalize.

Splitting is a myopic approach: The algorithm checks locally whether a split should happen but does not consider a global view. The algorithm only stops if it reaches a constraint value. In this sense, algorithms are greedy: Myopic decision makers which do not take into account any future decisions. They act in the analogy to investment as one period optimizer in a multi-period context. Pruning is the choice which considers effects a few steps ahead. The implementation follows the usual backward induction logic. First, generate the decision tree to a large depth and then work backwards by removing all nodes which imply negative returns.

Comparing tree based models with linear logistic regression for classification and linear regressions the classic models are appropriate if the relationship between dependent and independent variable is indeed linear. But if there non-linearities between the variables then only tree based models can account for them. Further more, tree based models are often simpler to explain than their linear counter-parts.

Often not a single model is used but an ensemble of models to achieve a better accuracy and model stability. Like any ML model, tree based models suffer from the bias-variance tradeoff. Small trees for example lead to low variance and high bias. Increasing the complexity of the model a reduction in prediction error due to lower bias follows. But at some point, high complexity starts to overfit the model that is, variance is increasing. Ensemble models are a method to manage the bias-variance trade-off. Ensemble methods include Bagging, Boosting and Stacking approaches. Boosting combines many 'weak' or high bias models in an ensemble that has lower bias than the individual models, while bagging combines 'strong' learners in a way that reduces their variance.

Bagging reduces the variance of predictions by combining the result of multiple classifiers modelled on different sub-samples of the same data set. Starting with a training set  $X$  of size  $N$ , bagging generates  $M$  new training sets  $X_{i}^{\prime}$  each of size  $M$  by sampling from  $X$  uniformly and with replacement. The  $M$  models are fitted using the above  $M$  samples and combined by averaging the output for regression or voting for classification. This averaging procedure stabilizes the single algorithms.

# 6.1.8 Naive Bayes Classifier

Consider a training set  $X$ , where each training instance  $x$  is an  $n$ -dimensional attribute vector  $x = (x_{1}, x_{2}, \ldots, x_{n})$  and  $C$  is a set of classes  $c_{1}, \ldots, c_{m}$ . In which class should a new instance  $\tilde{x}$  be classified? That is we want to find the most probable class

$$
c^{*} = \operatorname *{arg  max}_{c\in C}P(c|\tilde{c})  .
$$

Using Bayes' theorem,

$$
c ^ {*} = \arg \max  _ {c \in C} \frac {P (x | c) P (c)}{P (x x)}
$$

and since  $P(\tilde{c})$  is the same for all classes,

$$
c ^ {*} = \arg \max  _ {c \in C} P (x | c) P (c). \tag {6.24}
$$

The Naive Bayes Classifier assumes that the attributes are conditionally independent given the classification:

$$
P (x \mid c) = \prod_ {i = 1} ^ {n} P \left(x _ {i} \mid c\right). \tag {6.25}
$$

Definition 108. Naive Bayes classifier finds the most probable class for  $\tilde{c}$ :

$$
c ^ {*} = \arg \max  _ {c \in C} \prod_ {i = 1} ^ {n} P \left(x _ {i} \mid c\right) P (c). \tag {6.26}
$$

We apply this to the following asset management example. Consider 18 investors of an AM firm, which have five attributes Risk Profile, Experience, Home Bias, Liquidity, Buy Portfolio, see Table 6.1.8.

<table><tr><td>ID</td><td>Risk Profile</td><td>Experience</td><td>Home Bias</td><td>Liquidity</td><td>Buy Portfolio</td></tr><tr><td>1</td><td>Low</td><td>High</td><td>No</td><td>Fair</td><td>No</td></tr><tr><td>2</td><td>Low</td><td>High</td><td>No</td><td>Excellent</td><td>No</td></tr><tr><td>3</td><td>Medium</td><td>High</td><td>No</td><td>Fair</td><td>Yes</td></tr><tr><td>4</td><td>High</td><td>Medium</td><td>No</td><td>Fair</td><td>Yes</td></tr><tr><td>5</td><td>High</td><td>Low</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>6</td><td>High</td><td>Low</td><td>Yes</td><td>Excellent</td><td>No</td></tr><tr><td>7</td><td>Medium</td><td>Low</td><td>Yes</td><td>Excellent</td><td>Yes</td></tr><tr><td>8</td><td>Low</td><td>Medium</td><td>No</td><td>Fair</td><td>No</td></tr><tr><td>9</td><td>Low</td><td>Low</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>10</td><td>High</td><td>Medium</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>11</td><td>Low</td><td>Medium</td><td>Yes</td><td>Excellent</td><td>Yes</td></tr><tr><td>12</td><td>Medium</td><td>Medium</td><td>No</td><td>Excellent</td><td>Yes</td></tr><tr><td>13</td><td>Medium</td><td>High</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>14</td><td>High</td><td>Medium</td><td>No</td><td>Excellent</td><td>No</td></tr><tr><td>15</td><td>Low</td><td>Low</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>16</td><td>High</td><td>Medium</td><td>Yes</td><td>Fair</td><td>Yes</td></tr><tr><td>17</td><td>Low</td><td>Medium</td><td>Yes</td><td>Excellent</td><td>Yes</td></tr><tr><td>18</td><td>Medium</td><td>Medium</td><td>No</td><td>Excellent</td><td>Yes</td></tr></table>

The prediction  $\hat{y}$  is whether a new client with given features will buy or not buy the offered portfolio solution. More specifically, we consider a client with features  $\tilde{x} =$  (Risk Profile=Low, Experience=Medium, Bias  $=$  Yes, Liquidity  $=$  Fair) and ask whether she will buy the offered portfolio product. Two classes are of interest:  $c_{1}$  which means that an investor will buy the portfolio and  $c_{2}$  that she will not do so. To decide this question, we use the Naive Bayes Classifier formula and start with  $P(c_{1}) = 13 / 18, P(c_{2}) = 5 / 18$ . Table 6.1.8 summarizes the necessary conditional probabilities.

<table><tr><td>P(RP=Low|c1)=4/13</td><td>P(RP=Low|c2)=3/5</td></tr><tr><td>P(EXP=Med|c1)=7/13</td><td>P(EXP=Medi|c2)=2/5</td></tr><tr><td>P(BIAS=Yes|c1)=9/13</td><td>P(BIAS=Yes|c1)=1/5</td></tr><tr><td>P(LIQ=Fair|c1)=8/13</td><td>P(LIQ=Fair|c2)=2/5</td></tr></table>

Summing the probabilities, implies

$$
P (\tilde {x} | c _ {1}) = 0. 0 7, P (\tilde {x} | c _ {2}) = 0. 0 1 9
$$

and calculating finally

$$
P (c _ {1}) P (\tilde {x} | c _ {1}) = 0. 0 5, P (c _ {2}) P (\tilde {x} | c _ {2}) = 0. 0 0 5,
$$

the individual  $\tilde{x}$  will buy the portfolio product.

# 6.1.9 Nearest Neighbour Analytics

Consider clients where each instance  $x$  is a vector with  $n$  attributes. We want to categorize clients which are near and distant from each other in  $n$  dimensional space. If clients cluster, one knows similar demand for goods and services which allows for up-selling sales activities. Figure 6.12 plots a set of costumers which are scattered according to their risk aversion index and their income. A third feature describes whether the client bought a specific product (green) or whether he refused to do so (blue).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/e09212895fab92b1d602d09bded0ff8562ce97024d32c31fd9187fd7c70b92d6.jpg)  
Figure 6.12: Nearest neighbours.

Consider a new client  $\tilde{x}$  (red dot). If we consider he first nearest neighbour, he belongs to the class who does not buys the product. Considering the 3 nearest neighbours,

we assign to the new client the class blue, i.e. buy the product. Considering the 5 nearest neighbours, a next assignment follows and so on. The reason to consider only an odd number of neighbours is to avoid unambiguous assignment. We denote by  $\mathcal{N}_{\parallel}(\tilde{\S})$  the neighbourhood of  $\tilde{x}$  of the  $k$  instances given a distance metric  $d$ . Which metric  $d$  should one choose? If the inputs  $x$  are real numbers, the Euclidean distance is a possible metric. $^{11}$  If inputs are binary valued, the Hamming distance is used.

If we use the Euclidean distance, the distance in income and the distance in risk aversion are of different sizes. Therefore, the attributes are normalized to take values in [0, 1] and furthermore, it attributes have different weights, the terms in the Euclidean norm are weighted respectively. Typically, the weighting function  $v(x,y)$  can be chosen inversely proportional to  $d(x,y)$ , the closer two components of  $x,y$  are, the more weight is attributed. The classification task is to find the class  $c_{j} \in C$  such that the weighted distance in a neighbourhood is maximized, i.e.

$$
c (\tilde {x}) = \arg \max  _ {c \in C} \sum_ {x \in \mathcal {N} _ {k} (\tilde {x})} v (x, \tilde {x}) d \left(c _ {j}, c (x)\right). \tag {6.27}
$$

# 6.1.10 'Sentimental Risk'

The goal is to integrate additional, forward-looking signals, which are based on the computer-assisted analysis of a variety of corporate and financial news, into a standard factor risk model.

Consider the factor returns

$$
R _ {k} ^ {F} (t) = \sum_ {m} A _ {k, m} \epsilon_ {m} R ^ {F} \in \mathbb {R} ^ {M},
$$

$A = \sqrt{C}$ , with  $C$  the covariance matrix of the factor returns and  $\epsilon$  IID normally distributed. Given the factors, the linear pure time series risk model reads

$$
R _ {n} (t) = \beta_ {n} ^ {\prime} R ^ {F} + \tilde {\sigma} _ {n} \tilde {\epsilon} _ {n}
$$

with  $\tilde{\sigma}_n$  the idiosyncratic volatilities and  $\tilde{\epsilon}$  IID normally distributed. Data analytic providers deliver news statistics for many financial instruments such as stock, stock indices, commodities and many more such as the number of positive and number of negative messages per time unit or a signal which summarizes all sentiments at a given date of an asset. There are many different ways how such sentiment signals can be integrated in the pure time series risk model.

One way is to assume that the signal impact the time series volatility of the factors. This implies that a new adjusted volatility  $\sigma_{a}$  follows which captures the additional

information in the sentiment signals. The simplest relationship between the original and adjusted volatilities is a linear regression

$$
\sigma_ {a} (t) = a _ {0} + a _ {1} \Xi (t) \sigma (t)
$$

with  $\Xi$  the signal following the sentiment analytics. If there exists for each factor an adjusted volatility, then the factor  $\theta_{k} = \sigma_{a,k} / \sigma_{k}$  is integrated in the risk model as follows. Setting

$$
A _ {i j} ^ {\theta} = \theta_ {i} A _ {i j}
$$

we get

$$
\sigma_ {a, k} ^ {2} = \theta_ {k} ^ {2} \sigma_ {k} ^ {2}.
$$

Therefore the modified model  $X = A^{\theta}\epsilon$  would change the volatilities as desired without changing the correlation structure.

# 6.1.11 Customer Retention: Text Mining

Consider an AM firm which receives information from its customers. Some information are Complaints which we distinguish from all other information called General Contacts. The task is to automatically classify any client feedback into a Complaint or a General Contact. Figure 6.13 illustrates the data process for text mining task and the data preprocessing part. We present text classification for four ML algorithms: Naive Bayes (NB), support vector machine (SVM), random forests (RF), and artificial neural networks (ANN). We use the U. S. consumer complaint database and random tweets. The goal is: How accurate can the machine learning algorithms classify between complaints and general texts?

The dataset has two parts. Part I 10,000 consists of complaints regarding three different topics credit reporting, debt collection and mortgage from the U.S. database from October 2018 to March 2019. Part II consists of 10,000 authorized random tweets from various users located in the U.S. Retweets, which don't have meaningful content, and tweets with less than 200 characters are excluded. Each complaint and tweet has around 199 and 46 words, respectively.

Complaints and tweets cannot be processed by algorithms without tokenization. Tokenization segregates individual words from a document. It makes ML more robust and practical. After tokenization, each document consists of numbers of tokens instead of sentences. The number of distinct tokens in all documents determines the dimension of the database.

Four steps follow afterwards in the pre-processing: First, we remove anything that doesn't provide useful information for classification such as 'X' covering private information, web addresses, hashtags, numbers, punctuations. Second, a content transformation takes place. All letters are changes to lowercase (why?) and 'Mr.' is replaced by Mister.

Third, stop words are removed. A stop word is 'the'. This greatly reduces dimension of documents and it is essential for computational efficiency. Fourth, normalization is applied which consists of stemming and lemmatization. Both steps improve information retrieval. Stemming removes suffixes from words that have common root forms and produce the stem. Stemming converts 'studying', 'studies' and 'studied' to 'studi' which is not an existing word (no morphology. Lemmatization distinguish 'lovely' and 'love', while stemming returns 'love'. Lemmatization acquires semantic meaning by looking up in a lexical database like WordNet (Princeton University, 2010). It resolves words like 'good', 'better' and 'best' to their lemma 'good'. After all the clean-up, the average numbers of words in complaints and tweets shrink from 199 and 46 to around 73 and 19, respectively.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/c76e05d9c999b4091f7d28bd2205658316a1151e019fbe8b044f1d893effcbb8.jpg)  
Figure 6.13 shows the pre-processing process.  
Figure 6.13: Text mining big data analytics (Swissquant [2017]).

An original complaint text reads:

To whom it may concern: Can ANYONE help? I have fulfilled all requirements re Claim  $\dagger$  XXXX dd XXXX Green Tree Loan Servicing, & I am being told that I MUST wait until further investigations are complete before the check which was issued by XXXX XXXX can be released to me for completion of repairs to the home I live in. I have an XXXX 15 year old daughter who is suffering in this HEAT WAVE - -along with XXXX cats, a bird my wife and myself. No hotel will take us. My next step will be an attorney & the Media. XXXX XXXX

After the pre-processing:

may concern can anyone help fulfilled requirements re claim dd green tree loan servicing told must wait investigations complete check issued can released completion repairs home live i year old daughter suffering heat wave along cats bird wife no hotel take us my next step attorney media

The confusion matrix for the Naive Bayes classifier is the business relevant output.

<table><tr><td></td><td></td><td>Predicted 
Complaint</td><td>Predicted 
General</td></tr><tr><td>Actual</td><td>Complaint</td><td>49.54%</td><td>3.12%</td></tr><tr><td>Actual</td><td>General</td><td>1.87%</td><td>45.47%</td></tr></table>

The diagonal elements show the correct predictions. The classifier has a very good hit ratio. There is almost no general text predicted to be a complaint (Type I error). About  $8\%$  of the complaints are not detected as such (Type II error). The business risk the firm faces due to big data analytics is that employees who write the answer do not recognize the Type II error communication, then the customer will receive an improper response. The parametrization of the algorithm can change the ratio Type I to Type II error. Figure 6.14 shows the results for the different classifiers.

Table 6: The average in-sample and out-of-sample accuracy rates of four algorithms  

<table><tr><td></td><td>NB</td><td>SVM</td><td>RF</td><td>ANN</td></tr><tr><td>accuracy in-sample</td><td>94.69%</td><td>98.34%</td><td>99.08%</td><td>98.55%</td></tr><tr><td>accuracy out-of-sample</td><td>94.74%</td><td>98.32%</td><td>99.10%</td><td>98.58%</td></tr><tr><td>F2-score</td><td>95.57%</td><td>98.23%</td><td>98.95%</td><td>98.44%</td></tr></table>

Table 7: The average computer processing time (in seconds) of four algorithms.  

<table><tr><td></td><td>NB</td><td>SVM</td><td>RF</td><td>ANN</td></tr><tr><td>Model</td><td>0.06</td><td>11.40</td><td>30.07</td><td>9.40</td></tr><tr><td>Prediction</td><td>7.47</td><td>0.44</td><td>0.17</td><td>0.02</td></tr><tr><td>Total</td><td>7.53</td><td>11.84</td><td>30.24</td><td>9.42</td></tr></table>

Figure 6.14: Performance of the four classifiers. (Zin (2019)).

# 6.1.12 Portfolio Construction with Machine Learning, I

Gu et al. (2018) use machine learning to measure asset risk premia. They perform a comparative analysis of ML methods in the prediction of cross section and time series

stock return. They identify trees and neural nets as the best predictors. That is the non-linear predictor interactions are the source for the result. Regressions fail to account for this type of structure. As a second finding, the methods agree on the same small set of risk premia: Dominant predictive signals are found for momentum, liquidity, and volatility. They measure risk premia both of the aggregate market and individual stocks.

Measurement of an asset's risk premium means predicting conditional expectation of a future realized excess return. Relative to traditional econometric methods, ML provides a far more expansive list of potential predictor variables and richer specifications of functional forms. ML does not forces us linear predictions as in the Fama-French model for example. Furthermore, the zoo of predictors is a serious problem, both for academia and investors. ML is used for variable selection and dimension reduction techniques.

The authors use  $30^{\prime}000$  individual stocks over the time horizon 60 years from 1957 to 2016. Our predictor set includes 94 characteristics for each stock, interactions of each characteristic with eight aggregate time series variables, and 74 industry sector dummy variables, totalling more than 900 baseline signals. Some of our methods expand this predictor set much further by including non-linear transformations and interactions of the baseline signals. Gu et al. (2018)

Their benchmark panel of individual regressions of individual stock returns consists of there lagged stock-level characteristics: size, book-to-market, and momentum. This benchmark is parsimonious, simple and comparison against this benchmark is conservative, since the three characteristics are routinely demonstrated to be among the most robust return predictors. This finding is in line with Lewellen (2015). In their huge sample, the out-of-sample R-squared from the benchmark model is  $0.16\%$  per month for the individual stock returns. Using OLS for such a huge set with more than 900 predictors leads to negative R-squared. OLS is not able to generate any predictive power out-of-sample if that many parameters need to be estimated (overfitting).

Dimension reduction or penalization techniques are needed in the OLS case. Using parameter shrinkage and variable selection, which both limit the degrees of freedom in the regression, brings the out-of-sample R-squared back to  $0.09\%$  per month. Principal component regression (PCR) and partial least square (PLS), which reduces the dimension of the predictor set to a few linear combinations of predictors, raise the out-of-sample R-squared to  $0.28\%$  and  $0.18\%$ , respectively. Non-linear specification further improves predictions. The authors use generalized linear models, regression trees, and neural networks. Regression trees and neural nets lead to a  $R^2$  between  $0.27\%$  and  $0.39\%$ . The economic gains are considerable. An investor in the S&P 500 which uses neural network forecasts reaches a 21 percentage point increase in annualized out-of-sample Sharpe ratio (0.63) relative to the 0.42 Sharpe ratio of a buy-and-hold investor. Forming a long-short decile spread, sorted on stock return predictions from a neural network, the strategy

earns an annualized out-of-sample Sharpe ratio of 2.35 compared to the Sharpe ratio of 0.89 of their benchmark.

We describe some of the used machine learning methods. All methods have the objective to minimize the mean squared predictions error (MSE). They describe an asset's excess return of asset  $j$  as an additive prediction error model:

$$
R _ {t _ {1}} ^ {j} = E \left(R _ {t + 1} ^ {j} \mid \mathcal {F} _ {t}\right) + \epsilon_ {t + 1} ^ {j} = g \left(z _ {t} ^ {j}\right) + \epsilon_ {t + 1} ^ {j} \tag {6.28}
$$

) where  $z^j$  is the vector of predictors. Since predictions do not depend on time and the individual stock the estimates of risk premia are more stable for any individual asset contrary to standard methods where the cross-sectional is re-estimated in each period. Since  $g$  depends on  $z_t^j$  information prior to  $t$  or from other stocks is not used. ML requires careful construction of the sub-samples for testing, estimation and hyperparameter tuning to control model complexity for the out-of-sample performance. Depending on the algorithms used, different tuning methods are in force, see Guo e al (2018) for details.

Different choices of the function  $g$  define different models. In the simple linear model imposes conditional expectations can be approximated by a linear function of the raw predictor variables, i.e.  $g = \langle z_t^i,\phi \rangle$  with the parameter vector  $\phi$ . The objective function is the ordinary mean square error loss

$$
L = \frac {1}{N T} \sum_ {j, t = 1} ^ {N, T} \left(R _ {t + 1} ^ {j} - \langle z _ {t} ^ {i}, \phi \rangle\right) ^ {2}.
$$

Using statistical robustness methods (the Huber loss function), this least square objective can be tuned to account better for observations which are more informative. Penalty models induce sparsity in the sense that they force small variable to become zero.

If predictors are highly correlated, the above shrinkage and selection methods are not optimal. It is better to choose an average of the predictors as the sole predictor in a univariate regression. This average approach is the essence of dimension reduction. Principal components regression (PCR) and partial least squares (PLS) are two approaches. PCR starts with a principal components analysis (PCA), which conserves the covariance structure among the predictors, and then the leading predictors, given by the highest eigenvalues, are used in the predictive regression. PCR rules out coefficients by considering the covariation among the predictors before considering their goodness in predicting future returns. PLS contrarily first performs a dimension reduction by exploiting covariation of predictors with the forecast target. We refer to Yenay and Goktas for a comparison of PCR, OLS, PLS.

The generalized linear model expresses the model return forecast error as a sum of an approximation error (bias, not knowing the true model  $g^{*}$ ), an estimation error (variance, not knowing the true parameters in the model  $g$ ) and an intrinsic error term.

Generalized linear means that non-linear univariate transformations of the predictors are considered. As it turns out ex-post a weakness is that it does not allow for interactions among predictors. Considering multivariate functions of predictors would generate such interactions. But the number of parameters of such a model becomes computationally intractable.

Instead regression trees are used for incorporating multi-way predictor interactions. Formally,

$$
g (z _ {i, t}, \theta , K, L) = \sum_ {k = 1} ^ {K} \theta_ {k} \chi_ {\{z _ {i, t} \in C _ {k} (L) \}}
$$

where  $C_k(L)$  is one of the  $K$  partitions of the data and  $\theta_k$  is the sample average of outcomes within the partition. This formula says that given a tree consider all paths starting from the root node to the end nodes (sum over  $K$ ), at each node in a given path check whether the feature is above or below the threshold value (indicator function), and multiply all indicator functions in a given path. Based on the basic decision tree model, boosting and random forest ensemble methods are introduced in order to stabilize the results, to improve the performance and to manage the bias-variance tradeoff.

Given these models, the out-of-sample  $R^2$  for individual excess stock return forecasts is calculated:

$$
R ^ {2} = 1 - \frac {\sum_ {i , j \in \tau} (R _ {i , t + 1} - \hat {R} _ {i , t + 1}) ^ {2}}{\sum_ {i , j \in \tau} R _ {i , t + 1} ^ {2}}
$$

where  $\tau$  indicates that only the testing sub-sample is used for fitting. The metric is used without demeaning which is meaningful since we consider individual stocks and not broad indices. Using the historical averages adds a lot of noise. All models under consideration increase their monthly  $R^2$  by 3 percentage points when benchmarked to the historical means. Table 6.2 shows the monthly out-of-sample stock level prediction performance.

<table><tr><td></td><td>OLS*</td><td>OLS*-3</td><td>PLS</td><td>ENet*</td><td>RF</td><td>GBKT*</td><td>NN1</td><td>NN3</td><td>NN5</td></tr><tr><td>All</td><td>-4.60</td><td>0.16</td><td>0.18</td><td>0.19</td><td>0.27</td><td>0.30</td><td>0.35</td><td>0.39</td><td>0.35</td></tr><tr><td>Top 1000</td><td>-14.21</td><td>0.15</td><td>-0.10</td><td>0.10</td><td>0.62</td><td>0.53</td><td>0.44</td><td>0.72</td><td>0.69</td></tr><tr><td>Bottom 1000</td><td>-2.13</td><td>0.37</td><td>0.29</td><td>0.18</td><td>0.29</td><td>0.27</td><td>0.41</td><td>0.46</td><td>0.40</td></tr></table>

Table 6.2: Monthly  $R^2$  for the entire panel of stocks using OLS, OLS using only size, book-to-market, and momentum (OLS-3), PLS, elastic net (ENet), random forest (RF), gradient boosted regression trees (GBRT), and neural networks with one to five layers (NN1-NN5). The generalized linear model (GLM) are not reported (bad performance anyway). **' indicates the use of Huber loss instead of the  $l^2$  loss. Top 1,000 or bottom 1,000 means 1000 stocks by market value. (Guo et al. [2018])

The negative results for OLS reflect the in-sample-overfit. Restricting OLS to three style premia or using penalization as in ENet improves the performance significantly.

Regularizing the linear model via dimension reduction improves predictions even further, the PLS case. Hence, dimension reduction dominates variable selection. Boosted trees and random forests are competitive with these methods. Neural networks are the best performing predictor overall. But the drawback of neural network is the difficulty to interpret the results - what is the economic meaning of the different layers one to five, why do they generate the performance. Therefore, neural networks fail to be interpretable which is a serious drawback in asset from a client perspective and also from a regulatory one.

Assessing the statistical significance of the return performances, the authors use Diebold-Mariano test statistics for pairwise comparisons of a column model versus a row model. The statistics implies that the performance differences among regularized linear models are all insignificant, that is all OLS models, ENet, PLS and PCA produce statistically indistinguishable forecast performance. Random forest and boosted trees improve over linear models marginally. Again, neural networks are the only models that produce large and significant statistical over all linear models. When one considers which characteristics matter in the different model, a few characteristics turn out to significantly contribute in all models to the return performance: Momentum on several time scales, volatility characteristics, spreads for example matter. That is, as we have seen in other parts market driven characteristic dominate macro economic or accounting type characteristics.

# 6.1.13 Portfolio Construction with Machine Learning, II

This example is due to de Prado (2016). The authors introduce to so-called Hierarchical Risk Parity (HRP) approach. HRP is concerned about the issues sensitivity, concentration and under-performance of classical optimization models and the Markowitz model as a particular case. One source for these issues is the need to invert the covariance matrix. HRP is a method were this inversion is not needed. HRP is also expected produces less risky portfolios out-of-sample compared to traditional risk parity methods.

Correlation matrices can be represented as complete graphs, which lack the notion of hierarchy: Each investment is substitutable with another. There is no hierarchical relationship. All nodes are of the same importance. Small estimation errors are magnified in such a structure. Consider an investor, which invests in many assets where some assets are close substitutes to each other while others are complementary. Say stocks with a similar liquidity and of the same economic sector are more substitutable than stocks which have different characteristics. Such a classification of the dependence leads to a tree structure which includes hierarchical models and not a symmetric complete graph where weights between any nodes can vary freely, see Figure 6.15.

While a covariance matrix has  $N \times (N - 1) / 2$  edges to connect the  $N$  nodes, a tree has only  $N - 1$  edges to rebalance the weights among peers at various hierarchical levels. Furthermore, in the covariance matrix the weights distribution has no natural point to start with. But in a tree the weights are distributed top-down which is consistent with

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/51ddaabcefa5d356fd975f5a146df22c70c4f11c78667f1d35471881b75d37c6.jpg)  
Figure 6.15: A complete-graph (top) of  $50 \times 50$  correlation matrix and a tree-graph (bottom) structures (Lopez [2016]).

many asset managers investment behaviour.

The HRP algorithm is constructed in three steps: First, similar investments are grouped into clusters, based on a proper distance metric. This defines tree clustering. Second, the rows and columns of the covariance matrix are reorganized such so that the largest values lie along the diagonal. This leads to a quasi-diagonalization of the clustered tree. With such a quasi-diagonalization the problems of inverting the covariance matrix are circumvented. Third, the allocations is split top-down through a recursive bisection of the reordered covariance matrix.

The tree construction, step one, is done in several steps. The first stage is generate tree clustering out of the data. Let a  $T \times N$  matrix of observations  $X$  be given with  $N$  the number of asses and  $T$  the periods. The goal is to map the  $N$  column vectors into a hierarchical structure of clusters, such that allocations can flow downstream. The first step is to define 'distance of distances'. Let  $\rho$  be the correlation matrix of dimension  $N \times N$ . Then  $D$

$$
D = (d _ {i j}) , d _ {i j} = d (X _ {i}, X _ {j}) = \sqrt {\frac {1}{2} (1 - \rho_ {i j})}
$$

is a  $N\times N$  distance function. The Euclidean distance  $\bar{d}$  between any two column-vectors

of  $D$  is defined by

$$
\bar {d} _ {i j} = \sqrt {\sum_ {n = 1} ^ {N} (d _ {n i} - d _ {n j}) ^ {2}}.
$$

Note that  $d_{ij}$  is defined on column-vectors of  $X$  but  $\bar{d}_{ij}$  is defined on column-vectors of  $D$ , the distance of distances: It is a distance function defined on the entire correlation matrix and not only on particular cross-correlations. The distance-of-distances are clustered as

$$
u (1) = \operatorname {a r g m i n} _ {i \neq j} (\bar {d} _ {i j}),
$$

i.e. it is selecting the smallest distance-of-distances number in the  $\bar{d}$  matrix. Since clustering does not apply to the whole distance matrix, we have to define the distance between a new cluster  $u(1)$  and and the unclustered items as follows

$$
\bar {d} _ {i, u (1)} = \min  ((\bar {d} _ {i j}) _ {j \in u (1)}).
$$

Finally, the matrix  $\bar{d}_{ij}$  is updated by appending  $\bar{d}_{i,u(1)}$  and dropping the clustered columns and row  $j\in u(1)$ , see the example for illustration:

$$
\rho = \left( \begin{array}{c c c} 1 & - & - \\ 0. 7 & 1 & - \\ 0. 2 & - 0. 2 & 1 \end{array} \right) \to d = \left( \begin{array}{c c c} 0 & - & - \\ 0. 3 8 7 3 & 0 & - \\ 0. 6 3 2 5 & 0. 0 7 7 4 6 & 0 \end{array} \right) \to \bar {d} = \left( \begin{array}{c c c} 0 & - & - \\ 0. 5 6 5 9 & 0 & - \\ 0. 9 7 4 7 & 1. 1 2 2 5 & 0 \end{array} \right) \to u (1) = (1, 2)
$$

and

$$
u (1) \to d _ {i, u (1)} = \left( \begin{array}{c} 0 \\ 0 \\ 0. 9 7 4 7 \end{array} \right) \to (\bar {d}) _ {i, h = 1, \ldots 4} = \left( \begin{array}{c c c c} 0 & - & - & - \\ 0. 5 6 5 9 & 0 & - & - \\ 0. 9 7 4 7 & 1. 1 2 2 5 & 0 & - \\ 0 & 0 & 0. 9 7 4 7 & 0 \end{array} \right) .
$$

Finally, the above steps are recursively such that  $N - 1$  clusters can be appended to the matrix  $D$  until the algorithm stops when the final cluster contains all of original items. The sequence of the cluster formation can be illustrated using a dendogram.

The next stage, quasi-diagonalization, reorganizes the rows and columns of the covariance matrix, so that the largest values lie along the diagonal. This operation places similar investments close to each other and dissimilar ones far apart. The used algorithm, which we do not discuss, preserves the order of the clustering.

Stage three uses the fact that inverse-variance allocation is optimal for a diagonal matrix. For the quasi-diagonal matrix of stage two one approach to achieve a recursive bisection is split the allocations of the quasi-diagonal matrix between adjacent subsets in inverse proportion to their aggregated variances.

The author compares inand out-of-sample the minimum variance portfolio (GMV), the inverse volatility portfolio construction (IVP) of risk budgeting (where correlation

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/de431c84c8189f1de0cdd18d5ad2748e186f365e5b459fd4db0242dd2b47d46a.jpg)  
Figure 6.16: Quasi-diagonalizes of the clustered correlation matrix, in the sense that the largest values lie along the diagonal. HRP does not require a change of basis unlike the PCA approach for example. HRP works with the original investments. (Lopez [2016]).

information is discarded) and the HRP. In all portfolio constructions he applies long-only constraints. The simulation is done for 10 assets. The GMV allocates  $92.66\%$  on 5 top holdings and 0 to three assets. The HRP allocation is in between the highly concentrated GMV and the IVP almost equal distribution. The GMV and the HRP portfolios have almost the same risk although GMV only uses half of the assets. Therefore, an event impacting the top five assets will have a more severe impact than in the HRP case. From an out-of-sample perspective, Gaussian returns are generated with mean zero and  $10\%$  standard deviation, random shocks are added to account for price jumps and the portfolios are rebalanced monthly (every 22 observations). The simulations are repeated 10,000 times. All mean portfolio returns out-of-sample are essentially zero. But the variance of the out-of-sample portfolio heavily differ. The GMV variance is out-of-sample the highest one,  $72.47\%$  greater than in the HRP's. Intuitively, shocks affecting a specific investment penalize the GMV concentration. Shocks involving several correlated investments penalize IVP which ignores the correlation structure. HRP protects against common and idiosyncratic shocks by balancing between diversification across all investments and diversification across clusters of investments at multiple hierarchical levels.

# 6.2 Blockchain

Blockchain, a technology, Bitcoin, a crypto currency, and cryptography, mathematics of encryption/decription and digital signatures, are the three main pillars in a 'digital asset' world.

# 6.2.1 Cryptography

Cryptography is a main mathematical discipline in a digital world. It makes protection and validation possible in a world of strangers when we want to exchange values in a blockchain at a zero human trust level. The main goals of cryptography are

1. Confidentiality (access protection)  
2. Integrity (change protection)  
3. Authenticity (counterfeit protection)  
4. Obligation (non-repudiation)

For the first goal, encryption and decryption are used. For the other tree goals, digital signatures are used.

Today, the operationalization of these goals means to define mathematical problems (cryptogaphy) which are hard to solve for supercomputers. While the goals matter since thousands of years between humans which want to trade, cooperate or fight, the difference is that today computers are used for encryption, decryption and signing. The main source for cryptography is Goldwasser and Bellare (2008).

The ancient problem of cryptography is secure communication over an insecure channel. Alice wants to send to Bob a secret message. In the traditional solution, Alice and Bob meet before transmissions starts where they agree on a pair of encryption and decryption algorithms  $\mathbb{E},\mathbb{D}$ , and the secret information key  $\mathbb{S}$  which is the same for both of them: They use the same keys and the same algorithm for encryption and decryption. This is called symmetric cryptography or private key encryption. The meeting to exchange the secret information is risky and does not scale to many individuals. Alice encrypts the message  $M$  by computing the ciphertext  $c = \mathbb{E}(\mathbb{S},M)$ , sends it to Bob who decrypts  $c$  by computing

$$
\mathbb {D} (\mathbb {S}, c) = \mathbb {D} (\mathbb {S}, \mathbb {E} (\mathbb {S}, M)) = M.
$$

This shows that cryptography needs inverse functions or properties of the preimage of functions, the so-called one-way function. These are functions where it is easy to calculate  $f(x)$  from  $x$  but hard to invert, i.e. to calculate  $x$  from  $f(x)$ .

Although one-way functions are believed to exist, mathematical proofs about their existence are missing. An example is the factoring function of prime numbers, i.e.

$f:(x,y)\to f(x,y) = xy$ . The product is simple to calculate but finding the prime factors is difficult.

Asymmetric cryptography overcomes the difficulties of symmetric cryptography by still using the same algorithms for encryption and decryption but by allowing for different keys for the sender and receiver of a message, see Diffie and Hellman (1976). Alice and Bob do not have a common secure key  $\mathbb{S}$ . Instead they have their own private key. To achieve this, Bob publishes information, the public key  $vk_{B}$ , which is used for verification. Everybody knows this key and can send messages to Bob using this key without the need to meet Bob. Bob also generates a private key  $pk_{B}$  which is known only to him and allows him to decrypt any message sent to him. For secure public key encryption trapdoor functions are used, i.e. one-way functions for which there exists some trapdoor information known to the receiver Bob alone which Bob can use to invert the one-way function, see Figure 6.17. Alice also generates a public and a private key.

Definition 109. Private keys are denoted  $pk_X$  with  $X$  the owner of private key and  $vk_X$  denotes a public key.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/a15d5c26c6872524fe6f1d5f5bb2fb97074c93495576cbdbf7ca4b8d5df90cb5.jpg)  
Symmetric-key

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/cbdb62b14ef2097375169675efc24fb4f3eaa148aa0354f10ebf0d2c72edfb47.jpg)  
Asymmetric-key

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/6824c9e99fc79b1d22d8ec8475823bae82c3fc076c2d5d5d283d66e1111d627f.jpg)  
Diffie-Hellman key exchange  
Figure 6.17: Symmetric key, asymmetric key and Diffie-Hellman key exchange (Source: Wikipedia [2016]).

Rivest, Shamir and Adelman proposed a first candidate trapdoor function, the RSA system. Before we consider this algorithm, we introduce to basic number theory - modular arithmetic (MA).

# 6.2.2 Modular Arithmetic (MA)

The maths is used to formalize the encryption and decryption algorithms as well as generation of the keys. MA is arithmetic for integers where the addition of two numbers restarts after a certain value (modulus). The clock is a prototype example: Hour arithmetic's is modulo 12, written mod 12.  $3 = 15$  mod 12 means  $3 - 15 = -12$  is an integer multiple of 12. An equivalent definition of  $a = b$  mod  $n$  is that there exists an integer  $k$ :  $a = kn + b$ .<sup>12</sup> We summarize some calculus rules.

Proposition 110. Let  $a_i = b_i \mod n$  with  $i = 1,2$  and  $k$  an integer.

$$
\begin{array}{l} a + k = b + k \mod n \\ k a = k b \mod n \\ a _ {1} \pm a _ {2} = b _ {1} \pm b _ {2} \mod n \\ a _ {1} a _ {2} = b _ {1} b _ {2} \text {m o d} n \\ a ^ {k} = b ^ {k} \text {m o d} n, k > 0 \\ k ^ {a} \neq k ^ {b} \text {m o d} n \\ \end{array}
$$

Basic for cryptography is the existence of the inverse  $a^{-1}$  of  $a$ . If  $c = d \mod \phi(n)$ , where  $\phi$  is Euler's totient function, then  $a^c = a^d (\mod n)$  provided  $a$  is coprime with  $n$ ; this replaces the last false statement in the above properties. The totient function

$$
\phi (n) := \operatorname {c a r d} \{a \in \mathbb {N} | 1 \leq a <   n \wedge \operatorname * {g c d} (a, n) = 1 \},
$$

describes all natural numbers smaller than  $n$  with greatest-common-divisors (gcd) 1 with  $n$ : The totient function counts the positive integers up to a given integer  $n$  that are coprime to  $n$ . For example,  $\phi(20) = \operatorname{card}\{1,3,7,9,11,13,17,19\} = 8$ . The totient function is a multiplicative function:  $\phi(pq) = \phi(p)\phi(q)$  for  $q,p$  prime which is at the basis of the multiplication and inversion in MA. The key property for inversion is Euler's Theorem: If  $a$  and  $n$  are relatively prime then

$$
a ^ {\varphi (n)} \equiv 1 \mod n.
$$

As an application, the solution of  $ax = b \mod n$  is

$$
x = a ^ {\phi (n) 1} b \mathrm {m o d} n
$$

provided  $gcd(a, m) = 1$ . There exists an integer modular multiplicative inverse denoted  $a^{-1}$ , such that  $aa^{-1} = 1 \mod n$  if and only if  $a$  is coprime with  $n$ . If  $a = b \mod n$  and  $a^{-1}$  exists, then  $a^{-1} = b^{-1} \mod n$ . Finally, for  $ax = b \mod n$  and if  $a$  is coprime to  $n$ ,

then  $x = a^{-1}b \mod n$ . For the RSA algorithm, the inverse of the function  $a \to a^{vk} \mod n$ , is the function  $b \to b^{pk}$ , the multiplicative inverse of  $vk \mod (\phi(n))$ . Not knowing the factorization of  $n$  makes it difficult to compute the totient function and hence the computation of the private key.

As an example, assume that to each letter of the alphabet we associate one number 0 to 25. Encryption means

$$
y = a x + b \bmod (n)
$$

and decryption is given by

$$
x = a ^ {- 1} (y - b) \bmod (n).
$$

We set the key  $(a,b) = (9,13)$  and  $gcd(a,26) = 1$ . We decrypt the letter  $C$  which is mapped into the number 2. Then

$$
y = 9 \cdot 2 + 1 3 \bmod (2 6) = 3 1 \bmod (2 6) = 5.
$$

Decryption implies

$$
x = 3 (5 - 1 3) \bmod (2 6) = 2
$$

where the calculation of the inverse is the tedious part. Since the gcd of 9 and 26 is 1, the inverse  $a^{-1}$  exists. The number of possible keys  $12 \cdot 26 = 312$  is very small.

We consider the discrete logarithm which is assumed to be a one-way function. We recall that  $n$  the reals  $x = \log_b a$  solves  $b^x = a$ . To define the discrete analogue the concept of a group is needed.

Definition 111. A set  $G$  is a group if there is an operation  $*$  such that for two elements of  $g_{q}, g_{2} \in G$  also  $g_{1} * g_{2} \in G$ , the operation  $*$  is associative, there exists an unit element  $e$  such that  $g * e = e * g = g$  for all  $g$  and for each  $g$  there exists an inverse  $g^{-1}$  such that  $g * g^{-1} = g^{-1} * g = e$ .

The integer numbers with  $*$  the addition operation, the permutations of  $n$  numbers and the rotations in  $\mathbb{R}^n$  define groups. If  $g$  is a group element,  $g^k = g*g*\ldots *g$  is well defined for  $k$  a positive integer and if  $k$  is negative, the definition applies to  $g^{-1}$ . For  $a,b\in G$ , an integer  $k$  which solves  $b^{k} = a$  is the discrete logarithm  $k = \log_b a$ .

The group of integers modulo  $n$ ,  $\mathbb{Z}_n \coloneqq \mathbb{Z} / n\mathbb{Z}$ , is an important group in cryptography.  $\mathbb{Z}_n$  means that two numbers  $a, c \in \mathbb{Z}$  are the same if they have the same reminder when divided by  $n$ .

We have

$$
a _ {1} + a _ {2} = s _ {1} n + r _ {1} + s _ {2} n + r _ {2} = (s _ {1} + s _ {2}) n + q n + r = r
$$

where  $r_1 + r_2 = qn + r$ . Hence,  $\mathbb{Z}_n = \{0, 1, \dots, n - 1\}$  is an additive group if any number exceeding  $n$  is 'cut'. Consider  $\mathbb{Z}_7$ . Then  $6 + 3 = 9 = 1 \times 7 + 2$  and therefore,  $[6 + 3] = [9] = [2]$  in  $\mathbb{Z}_7$ . The numbers 2 and 9 belong to the same equivalence class [2]

which for simplicity is written 2.

The set  $\mathbb{Z}_n^*$  consists of all integer numbers  $m$ ,  $1 \leq m \leq n$  such that  $gcd(m, n) = 1$ .

Proposition 112.  $\mathbb{Z}_n$  is a group under addition modulo  $n$ .  $\mathbb{Z}_n^*$  is a group under multiplication modulo  $n$ .

$\mathbb{Z}_n^*$  is a group since  $a = b \mod n$  implies  $gcd(a, n) = gcd(b, n)$ , i.e. the congruence classes modulo  $n$  are well-defined. Next,  $gcd(a, n) = 1$  and  $gcd(b, n) = 1$  implies  $gcd(ab, n) = 1$ , i.e. closure under multiplication follows. Finally, given  $gcd(a, n) = 1$  and finding the inverse  $aa^{-1} = 1 \mod n$  is possible using Bézout's Lemma. The inverse satisfies  $gcd(a^{-1}, n) = 1$ , i.e. it is also an element of the group.

The order of the group  $\mathbb{Z}_n^*$  is given by Euler's totient function and the group is cyclic: All group elements can be generated by multiplication of a single element, if and only if  $n = 1,2,4,q^k,2q^k$  where  $k$  is a positive integer and  $q$  any prime number different from 2.

Consider the function  $f:(n,g,x)\to (g^{x}\bmod n,p,g)$  where the group is assumed to be cyclic and  $g$  the unique generator is conjectured to be a one-way function: Computing  $f$  can be done by repeated multiplication but the calculation of the inverse requires to calculate the discrete logarithm. There is no efficient algorithm to invert the function for large enough values of the parameters. This is the basic method used in cryptography. To set-up such a function one needs to find primes and generators, see the literature.

# 6.2.3 RSA Algorithm

We consider the RSA algorithm example based on Sullivan (2013) and Corbellini (2015). The RSA algorithm is used both for encryption, the case we consider now, and for digital signatures. Bob wants to send the message  $M$  'Hello Alice' to Alice. The goal is to convert all letters into a deterministic sequence number, then these numbers are mapped into a random-locking number (encryption) which can only be mapped back to the original sequence if the private decryption key is used. Since computers prefer to work with not too large numbers, a maximum function is used. The private and public key are two numbers larger than zero and smaller than the maximum number.

To start with assume that the two prime number 13 and 7 are chosen. The maximum number is  $91 = 7 \times 13$ . The public key of Alice is the number  $vk_{A} = 5$ . An algorithm based on the information in the system of 91 and 5 generates the private key  $pk_{A} = 29$  for Alice. How can this be used to convert transmit the letter  $C$  in the message 'Hello Alice'? First, the letter has to be turned into a number. The UTF-8 schemes attributes the number 67 to the letter  $C$ . Then, the letter  $C$  is multiplied 5 times - the public key - with itself. Since already  $67 \times 67 > 91$ , the calculation is done modulo the remainder. This means,

$$
6 7 \times 6 7 = 4 4 8 9 = 9 1 \times 4 9 + 3 0.
$$

Therefore, the result after the first multiplication is 30. This is then again multiplied with 67, which is larger than 91 and applying the same division as above, the result is 8 (the remainder). This is repeated in total 5 times leading to the number 58 - the encryption  $\mathbb{E}$  of  $C = 67$  is  $\mathbb{E}(67) = 58$ . This is the message Alice receives. Now she uses the private key number 29 and multiplies the 58 with itself 29 times where she uses the same logic - after each multiplication we do the next multiplication with the remainder - for decryption  $\mathbb{D}$ :

$$
\underbrace{58\times 58}_{\substack{29 \text{times, modulo} 91}} = 67
$$

which is the letter  $C$ . In other words,

$$
\mathbb {D} (5 8) = \mathbb {D} (\mathbb {E} (6 7)) = 6 7.
$$

If you don't know the private key number 29, then you don't know how many times you have to multiply 58 with itself in the above time consuming way to calculate and consider in each step the remainder. Besides the easy part of multiplication (encryption), decryption is a hard to solve factoring-type.

Summarizing,

- Alice choose prime numbers  $p, q$ , which she keeps secret, and set  $n = pq$ .  
- Alice chooses  $vk_{A}$  such that the greatest common divisor of  $vk_{A}$  and  $\phi(n)$  is 1, i.e., the public key and the Euler function number  $\phi(n)$  are coprime  $vk_{a} \in \mathbb{Z}_{\phi(n)}^{*}$ .  
- Alice computes the inverse of  $vk_{A}$ , the private key satisfying  $pk_{A}vk_{A} = 1 \mod (\phi(n))$ .  
- Alice makes  $n$  and the public key public keeping  $p, q$  and the private key secret.  
Bob encrypts  $C = M^{vk_A}$  mod  $(n)$ .  
- Alice decrypts  $C$  as  $M^{vk_Apk_A} = M = C^{pk_A}$  mod  $(n)$ .

Although the example explains the basic concept, real-life algorithm are more refined. $^{14}$

The example did not consider in detail how the keys are distributed and management in a public key system. Diffie and Hellmann invented the Secret Key Exchange (SKE). Fix a prime  $p$  and a generator  $g$  in the cyclic group  $\mathbb{Z}_p^*$  where  $g, p$  are public known. Alice picks at random an element  $x \in \mathbb{Z}_{p-1}^*$  and Bob picks at random an element  $y \in \mathbb{Z}_{p-1}^*$ . Alice calculates

$$
a = g ^ {x} \bmod p
$$

and Bob calculates  $b = g^y \mod p$ . The keys  $x, y$  are private to Alive and Bob, respectively. Alice sends Bob  $a$  and Bob sends Alice  $b$ . But then

$$
a ^ {y} = (g ^ {x}) ^ {y} = g ^ {x y} = (g ^ {y}) ^ {x} = b ^ {x} \in \mathbb {Z} _ {p} ^ {*}.
$$

Hence, Alice and Bob can both calculate the result without a prior meeting to generate a shared key. If Eve wants to calculate  $a^y$  or  $b^x$ , then she faces the problem that she does not know  $x$  or  $y$ . To find these numbers she has to compute the discrete logarithm which is believed to be not tractable.

# 6.2.4 Hash Functions

Important functions in cryptography are cryptographic hash functions (algorithms). To motivate this function, note that many algorithms such as RSA are slow and they generate output with the same size as the input. Therefore, it makes sense to shorten (hash) the message first, and process the short hash. A hash function has 160-512 bit output. SHA1 was finalized 1995 and maps strings from almost arbitrary length to strings of 160 bits. The hash function # acts on the message  $M$  of any length and produces an output - the hash or digest - of fixed length:

$$
\natural : M \to \sharp (M) = \operatorname {h a s h} .
$$

Hash functions accelerate database lookup by detecting duplicated records in a large file. The hash function is deterministic: For the same input always the same hash-output follows. The term 'cryptographic' means that the hash function needs to satisfy some security, authentication or privacy criteria. First, the time to compute the hash should be short for any message input. Second, to reconstruct a message given a hash result is impossible unless one tries all possible combinations; there are too many combinations. Changing the message only by a little amount of information should change the hash value in a way that the new and the old hash look uncorrelated. Example of a SHA224 hash where in one sentence a dot is added:

$$
\begin{array}{r} \mathrm {S H A 2 2 4 (T h e q u i c k b r o w n f o x j u m p s o v e r t h e l a z y d o g)} \\ 0 x 7 3 0 e 1 0 9 b d 7 a 8 a 3 2 b 1 c b 9 d 9 a 0 9 a a 2 3 2 5 d 2 4 3 0 5 8 7 d d b c 0 c 3 8 b a d 9 1 1 5 2 5 \end{array}
$$

$$
\begin{array}{c} {\mathrm {S H A 2 2 4 (T h e q u i c k b r o w n f o x j u m p s o v e r t h e l a z y d o g .)}} \\ {0 x 6 1 9 c b a 8 e 8 e 0 5 8 2 6 e 9 b 8 c 5 1 9 c 0 a 5 c 6 8 f 4 f b 6 5 3 e 8 a 3 d 8 a a 0 4 b b 2 c 8 c d 4 c} \end{array}
$$

Finally, it should be a hard problem to find two different inputs which lead to the same output - the so-called collision resistance. Summarizing, using cryptographic hash function makes it easy to verify that some input data maps to a given hash value, but if the input is unknown, it is difficult to reconstruct it by knowing the hash value. For the proof-of-work in Bitcoin transactions one has for example to compare fast and easily data of arbitrary size and to be sure that the message which was digital signed did not changed.

Hash functions are not one-way functions. Historically, popular cryptographic hash functions have a lifetime of around 10 years before they were broken.

Protocol - the file storage problem

A client wants to store a file on a server. The file has a name F and data M. He wants to retrieve file F later.

In a basic protocol

- Client sends file F with data M to server  
- Server stores (F, M)  
- Client deletes M  
- Client requests F from server  
- Server returns M  
- Client has recovered M

What if server is adversarial and returns M' instead of M? A simple solution is that the client does not delete M and then compares M' with M. But this requires enough memory to store the data M.

In a hash based protocol, client sends file F with data M to server

- Server stores (F, M)  
- Client stores  $\sharp(M)$ , deletes M  
- Client requests F from server  
Server returns M'  
- Client compares  $\sharp(M') = \sharp(M)$

# 6.2.5 Digital Signatures

A digital signature should basically reproduce the properties of physical signatures on paper for digital documents. Two main properties are: First, only the person signing can sign, but any other person can validate the signature. Second, the signature applies to a specific document and cannot be applied to other documents without the consent of the signatory.

A digital signature is a sequence of bits generated by the sender using a signature scheme for a message. Typically, this signature is attached to the message and sent with it so that the recipient can verify that the message actually originates from the sender and has not been modified in the transmission path.

Digital signatures are important in physical and virtual transactions of assets. A digital signature scheme provides a way for Alice and Bob to sign messages so that the signatures can be verified by anyone else. Alice creates a private and public key, signs the message using the private key and sends it to Bob. Bob uses Alice's public key to verify that Alice signed the message, that the message contents have not been altered since the

message was signed and that Alice cannot later repudiate having signed the message, since she is the only owner of her private key. The digital signature  $DS$  depends on the private key  $pk_A$  and the message  $M$ . If Eve, which is the evil in the game, changes  $M$ , then  $DS$  changes to  $DS'$ . Applying the public key of Alice to  $DS'$  does not confirm authorship of Alice. Unlike physical signatures, DS have to change all the time such that they cannot be learned and misused.

The RSA system allows to implement digital signatures as follow. Alice wants to sign electronically a document  $M$ . Alice signs  $M$  by appending the digital signature  $DS(M) = f^{-1}(M)$  with  $f$  is Alice's trapdoor function, i.e. only Alice knows the trapdoor information. But then anybody can check the validity of the signature since  $f(f^{-1}(M)) = M$ . This shows that the signature becomes invalid if in the message  $M$  is changed. In the RSA system,  $DS(M) = M^{pk_A} \mod n$ . Using Alice's public key, anybody can calculate

$$
(M ^ {p k _ {A}}) ^ {v k _ {A}} \bmod n.
$$

If the result equals  $M$ , then the signature  $M^d$  must have been created by Alice which is the only to know  $pk_A$ . Figure 6.18 illustrates the digital signature process for a hashed message.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9043b3a7993cf276e434059efd04d11fddea6074e29219c66800344e8e8d899f.jpg)  
Figure 6.18: The process of signing a hashed document: Hashing the document, signing the hashed document using the private key, broadcasting the document plus the signed hash and decomposition of the broadcast in two pieces: Hashed documents and the verification of the signed hash. If the two results agree, then Alice signed the document and the document did not change during broadcasting.

For a numerical example, the message  $M = 9$  takes values in  $0,1,\ldots ,n - 1$  with  $n$  the largest number. Applying the signature function on  $M$ , i.e.  $\mathbb{E}((n,vk_{A}),M) = M^{pk_{A}}\bmod n = DS$ , where  $n = 1591 = p*q = 37*43$  the product of two prime numbers, the totient function property  $\phi (n) = (p - 1)(q - 1) = 36*42 = 1512$  implies for the public key  $vk_{A} = 17$  with the Euclidean algorithms  $pk_{A} = 89$ . Using this generated key

$$
D S = M ^ {p k _ {A}} \bmod n = 9 ^ {8 9}, \bmod 1 5 9 1 = 4 4 0.
$$

To verify the result,

$$
\mathbb {D} ((n, v k _ {A}), D S) = D S ^ {v k _ {A}} \bmod n = 4 4 0 ^ {1 7} \bmod 1 5 9 1 = 9 = M
$$

i.e. the validation using the public key only and the known number  $n$  proves that Alice signed the document.

In the case of Bitcoin, public keys (or addresses) correspond to identities of Bitcoin users. A Bitcoin user can send a message or transaction from his address by signing it with his private key. At Bitcoin there is no central place which registers and identifies the users. Each user registers himself by generating - as often as he wants - a new address. At first glance, this decentralized identity management gives the impression of granting users a high degree of anonymity and privacy. This impression is put into perspective when looking over time. Movements are assigned to each address, which are visible to all participants and behind which patterns can be identified using data analytics. Furthermore, at some point in time today say a criminal using Bitcoin for money laundering needs to leave the Bitcoin network by exchanging the bitcoins in say dollars. It is there where secret services position their software to reveal the identity of the criminal. One therefore often speaks of Bitcoin as a pseudonymous system.

# 6.2.6 Blockchain

With the implementation of Bitcoin at the beginning of 2009, something new was created: Bitcoin enables joint accounting with participants who do not trust each other, do not know each other and do not know how many other participants are in the system. The technology that makes this possible is called Blockchain and allows a new data management model. The term blockchain refers to the fact that transactions are grouped into blocks and confirmed together. The confirmation in turn attaches the block with the new transactions to a chain of previous blocks and thus incrementally builds up a transaction history. If transactions are not grouped into blocks but the decentralized infrastructure is kept one speaks about Mutual Distributed Ledger Technology (MDLT). We do not differentiate between MDLT and blockchain in the sequel.

Definition 113. A mutual distributed ledger technology (MDLT) defines ownership (mutual), a technology (distributed servers) and the object (ledger)<sup>15</sup>

The basic functionality corresponds to the model of the Replicated State Machine: Participants manage a quantity of data (state) by holding a copy of the data (replica) locally and executing operations on it that change the data. The initial state has to be the same for all participants and the operations are deterministic: Any participant who applies the operations in the same order to the initial state will arrive at exactly the same end result. In such a system, consensus is the consensus when all participants agree on the current state of the data. In the example of Bitcoin, the data is the Bitcoin balance of individual participants and the operations are transactions between these participants.

Less abstract, blockchains<sup>16</sup> are **decentralised** protocols for recording transactions and asset ownership. Contrary to centralised protocols with an authority in charge to maintain a unique common ledger, blockchains operate within a network of participants who possess and update their own version of the ledger (distributed). The ledger act as the custodian of the transaction information. The blockchain in the original format is public (such as for Bitcoin or Ethereum), i.e. it belongs to everyone or nobody and participants are anonymous. In other words, any trust function in a value chain attributed to a third party, such as a bank in payment systems, is transformed to a trust function in the blockchain. We use the expressions blockchain and MDLT as synonyms. Decentralized, public or private architectures, are the alternative to the often existing centralized architectures in the financial industry such as stock exchanges, interbank clearing, monetary policy of a central bank. When does it make sense to replace a centralized architecture by a decentralized one?

While the internet revolutionized information exchange, blockchain can revolutionize value exchange using the internet. Ownership is of low importance for the internet since the goal is to spread information. But it is critical when it comes to the exchange of values. Blockchain technology will compete with well-established structures owned by exchanges, central banks or other financial intermediaries. In fact, the number of blockchain projects is large but the number of working profitable blockchains is yet low: Many centralized solutions in the FI are difficult to beat in terms of costs, performance, privacy or a mixture of all of them.

Two requirements are both necessary for a blockchain making sense: Decentralization dominates centralized architecture and trust. Technological decentralization is a well-known concept. Trust means that trust in a decentralized P2P is preferred over the trust in a central network with say 3rd party validators.

We consider blockchains for money transfer in more details for Bitcoin cryptocurrency which is one of the few up and running blockchain applications. Traditional money

transfer using traditional banking services and trust is shown in Figure 6.19. We do not

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/ae53f36e60cb5ee5029c4e8fd20b3d62141f5e19858082bcab3d792e87a5b22e.jpg)  
Figure 6.19: Alice paying CHF 10 to Bob using the centralized banking system. On a payment level, Alice announce her willingness to pay to her bank A. The bank checks whether Alice possesses CHF 10 and makes sure that there is no double spending. This third party validation is repeated by the central bank where the bank accounts of bank A and B are checked.

consider how money is generated and how money is represented but we consider the third control structure transaction execution. When Alice sends Bob CHF 10, they both use 3rd trusted parties - banks. Alice orders her Bank to transfer the money to Bob's bank. Both banks keep the accounts - i.e. the ledgers. Both banks are trusted - Alice Bob do not need to know each other. The banks check whether the money can be transferred - the transaction legitimization? The central bank is then a trusted 3rd party acting between the ledgers of the two banks and running an own ledger where the bank's account balances are recorded.

This traditional transaction execution consists of three parts:

1. Transaction Feasibility. Using online banking or initiating payments by written payment order.  
2. Transaction Legitimization. Banks are permanently checking the legitimization of payment orders. At each date only a single version of the ledger exists.  
3. Transaction Consensus. At each date a central party allows for efficient execution and it fixes at each date in a unique way the distribution of money in the

whole system.

These parts of transaction execution hold for all monetary system, also for crypto currencies. Blockchain attempt to change this classical money transfer in three respects:

1. There is no central third party validation.  
2. The transactions are done at a higher speed.  
3. The transaction fees are lower.

We describe in principle how this works; leaving aside the many details which matter if one considers an implementation of a blockchain.

Consider this in more details for Alice, Bob and Eve, where Alice sends CHF 10 to Bob and Bob CHF 5 to Eve. One - there is no trusted 3rd party - has to assure for example that Alice is Alice, that Alice possesses the money, that she did not promised to pay the same CHF 10 to multiple recipients and that indeed Bob is receiving the money, see Figure 6.20.

The central open ledger records that Alice indeed has CHF 20 on her account and that she is able to pay CHF 10 to Bob. Both transactions are recorded and time-ordered linked. If Alice wants to pay CHF 15 to Eve while only CHF 10 are left, in the open ledger the participants realize that she fails to have enough cash. In a next step, this central ledger is then removed by making a copy of this ledger and save it on the servers of all participants (the nodes): A distributed or decentralized open ledger architecture.

Transaction feasibility means that a payment from Alice to John who is not directly connected to Alice is possible: Alice broadcasts the payment instructions to her next node Bob, who broadcasts to his next node and so on. There are many paths linking Alice and John. The payment network works also if some links are not functioning: A decentralized system is more robust than a centralized one. The drawback of the decentralized system is that there are no admission constraints, each node can broadcast any type of information: Each node needs to be able to check the validity of each transaction information.

The distribution of the ledgers and unrestricted broadcasting generate challenges. The first is synchronization. All copies of transactions have to be identical at each date: New transactions need to be validated and potential new transaction and the validated transaction has to be added to all ledger copies, see the right hand panel in Figure 6.20. Given the three verified (blue) transactions, the transaction of Alice to Eve of CHF 5 is not yet validated. First verify that indeed Alice generated the transaction message. To achieve this, Alice signs the message using her private key. Everybody in the network can verify that Alice generated the message using Alice's public key. This legitimization check has to be done by each node in a given path in the network afresh. Given transaction legitimation, the transaction ends in a queue of transactions which

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/8abe7a339b055908247c1804eb5bfce7358057568f4f2592eef0bfd12b9d0303.jpg)  
Figure 6.20: Left Panel: Open and distributed open ledger technology. Right Panel: Validation of transactions. New transactions are grouped into a new block and after its validation - the consensus work to install unambiguous asset ownership - the block is added to the existing blockchain. Each block is further marked with a time-stamp and a digital fingerprint (a hash) (identification number) of the previous block. This hash ('K' in the above example) identifies a block uniquely and the verification of the fingerprint can be easily done by any node in the network.

wait to be validated as a block such that they can be written to the ledgers. Validation means to find transaction consensus. This consensus should prevent from double spending. Assume Alice tries to double spend by broadcasting the same amount twice. In a centralized system, the first transaction arriving is valid and hence there is no problem. In a decentralized system, the two messages sent by Alice are a priori ready to be validated. How should one observe that the same amount of money is planned to be spent twice? Which transaction will be finally validated is irrelevant for the network but consensus is needed about the validated one. To achieve this agreement without a central party, the open transactions are arranged into blocks by the miners participants, i.e. the nodes in the network which are willing to do the consensus work.

In a centralized banking architecture, trust in the banks is sufficient for validation. In an anonymous network, a different approach is needed: Economic incentives and cryptography define the incentives for miners to do the validation of the block.

The consensus for Bitcoin is called proof-of-work (PoW). Each miner is free to

choose the amount of transactions which he wants to validate. They solve a purely numerical problem unrelated to the block's content (mining). More precisely they solve a cryptographic puzzle using a try-and-error approach indicated by 'K' in the figure. A miner who solves his problem first attaches his proof-of-work, to his block and then broadcasts it. All other miners can easily verify the correctness of the PoW. The validated block is added to the blockchain. The PoW requires effort such as energy spent by the computers and investment in the hardware for example. Nakamoto (2008) argues that PoW generates a stable consensus, i.e. a single chain, if miners always take the last solved block as the parent for their next block. Each block under PoW-consideration needs to make reference to a yet validated block where the new block after consensus finding should be linked to. This reference is done using a hash value. Changing a past validated block by the miner changes the hash which leads to inconsistencies in the blockchain. The participants by construction consider always the longest chain which contains legitimate transactions. Therefore, to cheat a miner needs to be able to recalculate a whole chain afresh for validation before a single new block is validated by another miner. This is practically not feasible. To generate a new block by a miner takes just a short time. Without restricting this block generation process, validation for consensus would become impossible since the frequency how blocks are generated dominates the speed of propagation in the network. Therefore, the process is slowed down such that on average each ten minutes a new block is mined and verified.

The winner gets remunerated for his efforts (new bitcoins generation). He takes it all. In a PoW one authenticates the fact that resources have been spent to solve a cryptographic problem. These defines the economic incentives: The more computer calculation power a miner invests the higher the likelihood that he will mine the block as first ones. If Alice wants to cheat by using a double-spending strategy, she first has to spend resources in order to validate the block containing her fraudulent transactions. PoW validation is a peer-to-peer type consensus mechanism since the validation can be verified to be true by all miners. No trust is needed and no node can simply claim to have found a key without having spent resources due to the easy possibility of verification of the candidate solution.

# Summarizing:

- The rules are contained in the Bitcoin protocol, an open source cryptographic protocol.  
- A blockchain exchanges values using the internet in a distributed ledger framework.  
- Switch from single third party trust to distributed ledger trust for transactions.  
- Unambiguous ownership rights at any moment in time due to the consensus mechanism.  
- The P2P complete stranger consensus PoW is the most expensive and slowest consensus mechanism.
- Approved data in the distributed ledger cannot be changed - immutable history of transactions exist.  
- Persistence: The blockchain is independent of service providers, device manufacturers or any type of applications.  
- Fork. Assume that a miner attaches his mined block not to the last validated but the second last one - a fork follows. Miners can choose to attach validated block to the original chain or to the other one of the fork. Then there are competing versions of the ledger. Forks reduce the credibility and reliability of the blockchain. Even if, eventually, all miners agree to attach their blocks to the same chain, the occurrence of the fork is not innocuous. A fork can also occur when some miners adopt a new version of the mining software that is incompatible with the current version. Does the blockchain protocol rule out the occurrence of forks?

We close this section with an analogy to the Coin of Yap problem. It is a problem which the population in the Yap islands in Western Pacific Ocean faced. The Yaps produced stone money. There were five different sizes of stones where the largest one needed around 20 men to be transported. It was not possible to carry the stones from one island to the next one for exchange reasons using the canoes. How could one use the stones for payment if they could not be physically exchanged against the goods? The solution was to store the ownership information in the consciousness of the Yap people (the blockchain): The Yap knew who owes the different stone pieces. They did not need to move them when ownership changes since the public memory records the changes in ownership. There is a society consensus over ownership. If there is a conflict, the stronger strain wins. Due to the limited size of islands and population the system costs never became too high to become ineffective.

# 6.2.7 Different Blockchain Types, Type of Consensus

One often speaks of Permissioned or Permissionless DLT systems. A Permissionless Protocol is defined by:

- Anyone can participate in the protocol and receive say Bitcoin as rewards by performing the PoW-based mining operation.  
- The mechanism of pouring currency in the system via proof of work, makes it feasible for anyone (possessing sufficient hashing power) to participate.  
- The ledger itself is public, readable and writeable by anyone who possesses Bitcoin.

In a Permissioned Protocol participation is restricted:

- Producing transactions and/or blocks can only be performed after being authorized by the other nodes.  
- In their simplest form the set of nodes is static: the set of nodes implementing the protocol is fixed and determined at the onset of protocol execution.

Contrary to permissionless networks, the actors in a permissioned network are named. The intention is that they are also legally accountable for their activity. The transactions in such networks will be predominantly so-called off-chain assets - fiat currencies, titles of ownership, digital representation of securities - whereas in the permissionless world on-chain assets such as virtual currency are transacted. Since the number of actors is smaller in permissioned blockchains, only a small number of participants need to operate which makes such networks more scalable than the permissionless ones.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/804d545da6c5d5b518a46c3786ae57e62dada7895c8164d6ae6586cd75844bdd.jpg)  
Figure 6.21: Emergence of different network topologies (Celent [2015], UBS [2015]).

Since actors in a permissioned network are not anonymous, the time-consuming and expensive PoW is not needed. Much simpler and faster consensus schemes apply. It is possible to use classical consensus algorithms from the field of distributed computing such as Paxos or Practical Byzantine Fault Tolerance (PBFT). These protocols are based on polls in which participants vote on the next operation to be applied. This is possible because each participant knows how many votes will result in a majority and when the vote will be successful. An example of a permissioned blockchain is Ripple.

The market dynamics for blockchain consisted 2017 of about 300 start-ups worldwide and more than eighty percent of the global banks running blockchain projects (WEF (2017)).  $20\%$  of the global banks will have a commercial blockchain product by the end of 2017 (IBM (2016)) and global investments in this technology are estimated to be USD 1.5 bn (WEF (2017)). To PoW is a costly way to reach consensus. In February 2018 the energy needed to perform the PoW is similar to total energy consumption of Romania.

There are alternative consensus mechanisms to the PoW. Proof-of-stake is also based on algorithms. Users of the technology are asked to prove ownership over a stake (a currency or any other asset). There is no competitions as in the PoW and the mechanism is much less energy consuming than the PoW, faster and cheaper. For example one selects a random a participant on the basis of the data in the system, say selected tokens which are linked to an address. The chosen address may make the next proposal for the further development of the blockchain. In such a proof-of-stake system, the probability of being allowed to make the next proposal increases with the tokens of a participant. This eliminates the need for time-consuming proof-of-work calculations, and participants with a greater interest in the continued existence of the system (as they have invested in it) make relatively frequent decisions. However, the implementation of this concept is not easy, as participants are able to behave strategically and thus increase their influence in the system or behave incorrectly. Therefore, most proof-of-stake systems so far use a combination of proof-of-stake and proof-of-work to solve these manipulation attempts, but accordingly have the high energy consumption as a disadvantage.

# 6.2.8 Blockchain Examples

Blockchains can be used in many areas. Besides logistics and transportation, healthcare or the energy industry as examples, the technology can have an impact in several areas of the financial industry: Clearing and settlement, brokerage and financial research activities, correspond banking, trade finance, remittance and payments, trust and custody functions in asset management, smart contracts for automated, self-controlled management of financial contracts and distributed storage, authentication, anonymization of private information.

# 6.2.8.1 Bitcoin

Considers miners which want to do the PoW. All the blocks in the Bitcoin block chain have a short string of meaningless data—called a nonce attached to them. The mining computers are required to search for the right meaningless string such that the block as a whole satisfies a certain arbitrary condition. Specifically, it is required that the SHA-256 hash of the block have a certain number of leading zeros. A miner selects the message  $M$  of Alice ready for validation and selects a random number  $k$ , the nonce, and let all information running through the hash, i.e. he calculates  $\sharp(M + k)$ . If this result is larger than the thresholds  $T$ , he chooses a new  $k$  and continues until  $\sharp(M + k) < T$ . Then the miner broadcasts  $k$  and everybody can easily check that the hash is indeed smaller than the threshold level. The nonce is a 32-bit data string. Varying the nonce is a trivial task since  $2^{32}$  amount to around 4 billion possibilities which today can be checked in a few seconds. Therefore, to increase the complexity the transactions are grouped into a so-called Merkle tree form. In a Merkle tree data blocks are grouped in pairs and the hash of each of these blocks is stored in a parent node. The parent nodes are in turn grouped in pairs and their hashes stored one level up the tree. This continues until the root node is reached.

The SHA-256 has function is used whose output is 64 digit string. Consider the hash

000000000000004c296e6376db3a241271f43fd3f5de7ba18986e517a243baa7.

which was the hash 2013 of a block ready for the miners. It has 16 ciphers, all number from 0 to 9 and letters from  $a$  to  $f$ . The hash starts with 16 zeros, the threshold level. The difficulty of the problem is not constant over time, this means the number of zeros in the header is varying in a non-manipulable way. The difficulty is calibrated in such a way that it is possible to find a block in about 10 minutes. The SHA hash goes one way: It has  $2^{256}$  outputs which one needs to evaluate in order to break the hash or to calculate the input.

The Bitcoin system is managed differently from a centralized network. How is the management organized such that the system can be improved and deficiencies can be corrected when there is no central party with the power to do so? To prevent that a member of the network changes the network which is not in the interest of the users can be avoided by either sanctioning such actions or by setting incentives such that for each member the dominating strategy is not to deviate from the existing rules, i.e. a kind of a Nash equilibrium. It is this game theoretic concept which is implemented in the Bitcoin system. To allow for changes, a voting system is used where a predefined majority has to exist before a change is implemented. This democratic rule is very complicated since not all nodes have the same rights and action spaces (miners have an advantage) but other user groups also have the possibility to form coalitions which then can try to enforce their views. In any case, in such a DMLT, no one can be forced to follow any decision. If part of the community is not willing to follow a change but they decide to use the old code, then the system separates into two systems: A forc realized. In a soft forc the rules for consensus are stricter than in the original chain, i.e. new ledger entries are also valid under the old system. In a hard fork, the new register entries are not longer valid under the old rules of the blockchain before the fork happened.

# 6.2.8.2 Settlement

The process where a buyer and a seller agree to exchange a security (trade execution) and the date where the trade is settled (assets are exchanged) can be 2 or 3 days depending on the jurisdiction and the type of asset. A longer period between trade execution and settlement raises settlement risk - the risk that one leg of the transaction may be completed but not the other, and counter party risk - one party defaults on its obligation. Besides the reduction of risk, a decentralized blockchain technology could also reduce the costs the trade and settlement process.

A standard trade-clearing-settlement process life cycle can be described as follow (Bliss and Steigerwald [2006]):

# Trading.

- The investors (buyer and seller) who wish to trade contact their trading member which place their orders on the exchange.  
- The trades are executed in the exchange or any other platform such as a multilateral trading facility or an organized trading system.

# Clearing.

- Clearing members who have access to the clearing house or the central counter party, which are also trading members, settle the trades.  
- Clearing and settlement can be bilateral, i.e. settled by the parties to each contract. The G20 enforces after the GFC to switch from bilateral to central counter party (CCP) clearing for the OTC derivatives. A CCP acts as a counterparty for the two parties in the contract. This simplifies the risk management process, as firms now have a single counterparty to their transactions. Through a process termed novation, the CCP enters into bilateral contracts with the two counterparties, and these contract essentially replace what would have been a single contract in the bilateral clearing case. This also leads to contract standardisation and there is a general reduction in risk capital required due to multilateral netting of cash and fungible securities. Therefore, CCP means that the bilateral clearing topology is transformed into a centralized or star shaped one. From a systemic risk perspective, while the more risky bilateral connections are replaced by less risky centralized ones the major risk concentration is now located in the few CCPs.

# Settlement.

- The two custodians, who are responsible for safeguarding the assets, exchange the assets where a typical instruction is 'delivery versus payment': Delivery of the assets will only occur if the associated payment occurs.

Using a blockchain means to transform the centralized CCP topology back into a decentralized one where there is no need for an CCP. In the trading-clearing-settlement cycle, a consortium blockchain can be used as follow to satisfy the present standards. On the trading level, a consortium of brokers can set up a distributed exchange, where each of them operate a node to validate transactions. The investors still trade through a broker, but the exchange fees can be drastically reduced. On the clearing level, a consortium of clearing members can set up a distributed clearing house, thus eliminating the need for a CCP. Contrary to bilateral clearing, the contract stipulations are administered through a smart contract which reduces risk management issues. If the securities and money are digitalized, settlement does not need any custodians with securities depositories but the assets are part of the permissioned blockchain.

# 6.2.8.3 R3CEV, Corda

R3CEV is a firm that leads a consortium partnership with over 100 of the world's leading financial institutions. The goal is to design and deliver advanced distributed ledger technologies to the financial markets around the world. The blockchain used in described in the white paper Corda (Brown et. al (2016)).

Consider banks (the nodes) which search for a technology to record and enforce financial contracts such as cash, derivative or any other type of products. More precisely, the banks want to record and manage the initiation and the life cycle of financial contracts between two or more parties which is grounded in the legal documentation of the contracts and which is compatible with the existing emerging regulation in an

- efficient way: duplications and reconciliation of transactions are not necessary.  
- open way: every regulated institution can use the technology.  
- appropriate privacy/public mix way: consensus about transactions is reached on a smaller than full ledger level.

These requirements lead to the solution Corda. We state the most important changes compared to the Bitcoin blockchain.

First, there are no miners and there is no proof-of-work since no currency needs to be generated (mining) and due to the mixed private/public association of information no general consensus on the ledger is needed. The advantages are avoidance of costly mining activities, of a deflationary currency and of a concentration of the mining capabilities in a few nodes. Second, bitcoins can only contain a smaller amount of data due to the fixed length data format. This is not useful if one considers all economic, legal and regulatory information in an interest rate swap between two parties. Corda encodes the information of arbitrary complex financial contracts in a contract code - the prosa of the allowable operations defined in term sheets is encoded. Corda call this code state objects. Consider a cash payment from bank  $A$  to a company  $C$ . The state object contains the legal text describing the issuer, the date, the currency, the recipient etc. and the codification of the information. This state is then transformed into a true transaction if the bank digitally signs the transaction and if it verified, that the state object is not used by another transaction. Hence, there are two type of consensus mechanics. First, one has to validate the transaction by running the code in the state object to see whether it is successful and to check all required signatures. This consensus is carried out only by the parties engaged in the transaction. In other words, the state object is a digital document which records all information of an agreement between two or more parties. Second, parties need to be sure that the transaction under consideration is unique. This consensus which checks the whole existing ledger is done by an independent third party. Summarizing, the ledger is not globally visible to all nodes. The state objects in the ledger are immutable in the same way as we described it for blockchains. Given that

not all data is visible to all banks, strong cryptographic hashes are used to identify the different banks and the data.

Why are the leading banks pushing this system? They can all use only one ledger which makes reconciliation and error fixing in today's individual ledgers at topic of the past. Furthermore, the single ledger does not change the competitive power of the banks in the ledger. The economic rationale, profit and risks to enter into a swap remain within UBS and Goldman Sachs but the costs and operational risks of the infrastructure are reduced due to the collaboration to maintain shared records. In other words, while the banks keep the profit and loss from their banking transactions unchanged to the present competitive situation, they reduce the technology cost part by cooperation.

# 6.2.8.4 Smart Contracts, Ethereum

The concept of smart contracts was invented by Szabo (Szabo (1997)):

Definition 114. A smart contract is a computerized transaction protocol that executes the terms of a contract. The general objectives are to satisfy common contractual conditions (such as payment terms, liens, confidentiality, and even enforcement), minimize exceptions both malicious and accidental, and minimize the need for trusted intermediaries. Related economic goals include lowering fraud loss, arbitrations and enforcement costs, and other transaction costs.

The functionality of a smart contract means contracting on contingencies on a decentralized consensus at low-cost with algorithmic execution. Achieving decentralized consensus is a self-executing distributed ledger needed. Contingencies in a smart contract are codified making automated execution feasible and reducing enforcement cost. XXX then define:

Definition 115. Smart contracts are digital contracts allowing terms contingent on decentralized consensus that are self-enforcing and tamper-proof through automated execution.

Thus, in a blockchain, other types of protocols than currency transactions can be performed. Smart contracts, unlike cryptocurrencies, do not require validation (consensus) through a cryptographic system. The blockchain network automatically enforces execution of the contract when trigger events are realized. When an event occurs, the computer code in the document triggers a pre-programmed action. This digitizes the lifecycle management of contracts. The rational is to reduce manual expenses in the management of contracts over time and a reduction in error rates. The risks are that someone improperly programs the smart contracts and then makes wrong decisions.

An examples of a smart contract is a Bitcoin transfer between two agents which is made dependent on some other conditions which extends the Ethereum decentralized blockchain platform that handles smart contracts. Applications run as they were programmed. This takes place without any downtime, censorship, fraud or interference

from third parties. Such contracts are useful cost cutters in the life cycle management of financial contracts since for example the built-in software automatically carries out a corporate action in the documents for given market signals.

Vitalik Buterin wrote 2013 the white-paper. The market capitalization of Ethereum amounted to USD 1 bn in October 2016 and USD 74 bn in December 2017. Ethereum is an application platform. Evelopers can create applications without building their own blockchain with smart contracts are on top of the blockchain. Ethereum enables peer-to-peer contracts and peer-to-peer applications through its own currency carrier. In Ethereum the block time is set to 14 to 15 seconds compared to the 10 minutes at Bitcoin. Ethereum can be used for crowdfunding, voting systems, options markets and many other applications.

What happens if the software of a smart contract has a fault or the logic of the software allows someone to use the software in his favour? This was the case in the so-called Decentralized Anonymous Organization (DAO) Hack. DAO was a form of investor-directed venture capital fund. It was the biggest crowdfunding experiment in the world raising USD 150 millions within 21 days. However, on June 17 2016, a hacker exploited a security bug on the smart contract and transferred USD 50 millions to his own account. Th cryptocurrency Ether lost  $50\%$  of its value on the same day. Since the hacker did nothing illegal but was just smarter than those who wrote the smart contract code there was a priori no reason to consider any actions regarding the validity of the transaction. But many in the community were invested and hence faced personal losses if one would not off-set the hacker's transaction.

The first alternative was to cancel the transaction and restore the money to the DAO users. The second choice was to do nothing. Then the hacker would keep with USD 50 millions and a lot of people invested in the DAO would loose their investment. The cancellation of the transaction, leading to a hard fork, would enable all DAO investors to exchange their tokens at a fixed price, as in a currency reform. They only need to update their software. The old DAO exists on the old Ethereum blockchain, but should die out without an investor. The token of the hacker would become worthless. But parts of the community refuse the update. They see a violation of the ideals of Ethereum. In protest, they stay in the old blockchain and baptize it Ethereum Classic. Instead of losing value, the DAO wins. The event damaged the reputation of the technology from a security perspective. In addition, the community damaged its reputation during the period: responsibilities were not clear, blaming started and it was not possible to find a single solution.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/66afac8538d7e3d346c62fad19f80522b0a7437b8faede750fce181d05df1157.jpg)  
Figure 6.22: The hard fork in the Etherum protocol.

# 6.3 Currencies and Crypto-Currencies

# 6.3.1 Money and Payment Systems

Something is considered to be money if: It stores value, can be used as a medium for exchange of goods and services and is a unit of account.[17]

# 6.3.2 Fiat Money

Fiat money backed by a monetary framework, an economy and a monetary system, Central bank act as monetary policy makers, the ultimate settlement agent for monetary transactions and hold reserves in gold as a trust backing facility. But ultimately, the government's ability to raise taxes and the willingness of banks to lend money define the major monetary policy forces. Most currencies such as the USD, Remimbi are fiat money and most digital money is fiat money too. The economy defines the fluctuating quantity value of a currency given by the GDP, interest rate levels, inflation etc. The monetary framework defines the stable acceptance value - do the population accepts a currency? Trust in a currency is a function of these three system components. For

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f0e9ac08ddb5268d3bad59baf148c970f64651a35e36ef209526b04b5acb8fe0.jpg)  
Figure 6.23: Three components for money.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/f5e818bb667cc7a4df0b2bb09b3e21c2422da0a96126757fb8a9fc7d94868810.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/4f16d6b05c5e18356310a49fcbbe0e41a00c33facac455096b24805ddb25857e.jpg)

cryptocurrencies, the economy component is empty or it consists of a business promise such as in Initial Coin Offerings ICO used by start up firms. An investor sells his dollars to buy say Ether, hands over the Ether to the ICO, receives the start up token, hopes that the ICO business will not default which then boosts the value of the token. The ICO will change Ether with dollars to pay its investment activities. It is difficult to make economic sense out of this long chain of transactions which could be shortened by simply investing directly using dollars and receiving equity or debt capital.

People's belief in the value of money is fundamental to any currency: It is not possible to enforce value to a currency if people do not want to accept the currency. Figure 6.24 provides an overview over different currencies.

Table 6.3 summarizes some features of fiat money, money issued in a permissioned blockchain and money issued in a MDLT.

# 6.3.3 Bitcoin

First, Bitcoin represents a crypto-currency. $^{18}$  This means a unit of a Bitcoin is used to store and transmits values between individuals who believe in this currency. Second, Bitcoin represents a communication medium. All individuals using or creating bitcoins communicate by the Bitcoin protocol via the internet. The protocol is the code which

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/cae2e1a9be45e4b5dc651d185697cde978aae88f91055bdeb1ea9432ad04440d.jpg)  
Figure 6.24: Overview of the different currencies. Source: Source: Bech and Garrati (2017).

contains the set of rules used in the Bitcoin system.

At the time of writing, the number of Bitcoin transactions is around  $300'000$  transaction per day which is approximately equal to USD 3 bn at market exchange rates in November 2017 and the market cap of Bitcoins by the end of 2015 is USD 261 billion (Source: Blockchain.info). A crypto-currency combines two main components: A new currency such as Bitcoin and a new decentralized payment system - the blockchain.

Bitcoin has value because people believe in it. If people stop to believe in it, as long as there is no real economic production backing the coin, then the value evaporates. That belief can be created quickly and vanish also rapidly. We consider the period after the first Gulf War in the Kurds region of Iraq. Kurds used in their areas of Iraq the Iraqi Swiss Dinar.[19] Hence, although a legal tender existed in Iraq, the Saddam dinars, it became worthless in the Kurd regions. People cannot be forced to belief in a currency.

So far, we did not compared digital and crypto curencies, see Figure 6.25.

<table><tr><td>Feature</td><td>Fiat</td><td>Crypto DLT 
Permissioned</td><td>Crypto MDLT</td></tr><tr><td>Storage Holdings</td><td>Accounts FI</td><td>DLT</td><td>MDLT</td></tr><tr><td>Double Spend.</td><td>Identity</td><td>P2P restricted</td><td>P2P open</td></tr><tr><td>TX Processing</td><td>FI</td><td>Trusted ledger nodes</td><td>Proof-of-work</td></tr><tr><td>Settlement</td><td>Central Bank</td><td>Encoded</td><td>Follow longest chain</td></tr><tr><td>Supply</td><td>CB and loan policy</td><td>Protocol</td><td>Protocol</td></tr><tr><td>TCM</td><td>Reputation FI</td><td>Reputation issuer/DLT</td><td>PoW</td></tr><tr><td>Scalability</td><td>High (Visa)</td><td>Not major importance</td><td>Bounded</td></tr><tr><td>Users</td><td>KYC</td><td>KYC</td><td>Anonymous</td></tr><tr><td>Power</td><td>Centralized</td><td>Centr. / Decentr.</td><td>Majority rules</td></tr><tr><td>Recon</td><td>Needed</td><td>Not needed</td><td>Not needed</td></tr><tr><td>Trade Reversal</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>Risk</td><td>Systemic</td><td>Trusted nodes</td><td>Loss pk, exchanges</td></tr></table>

Table 6.3: Summary of different monetary systems. FI Financial Intermediary, CB Commercial Bank, KYC Know Your Customers, TX Transaction, Rep Reputation, Recon Reconciliation, TCM Trust Creating Mechanism, PoW Proof-of-Work, pk Private Key. Source: Adapted and extended from Natarajan et al. (2017)  

<table><tr><td>Digital</td></tr><tr><td>• Every non-physical currency is a digital currency</td></tr><tr><td>• Digital currencies consist of numbers and digits</td></tr><tr><td>• 90% of global currency are digital, most of it is a fiat currency</td></tr><tr><td>• Online banking, mobile payment, Paypal, Mint, credit cards are based on digital currencies</td></tr><tr><td>• Digital currency possess a monetary regulatory and institutional setting. They are accepted as legal tenders</td></tr><tr><td>• Money generation is mostly done by the inside money mechanism and secondary by central banks</td></tr><tr><td>• Convertible in cash. Payments are not public</td></tr><tr><td>• There is no anonymity</td></tr><tr><td>• 7x24, worldwide payments, no need to know the recipient</td></tr><tr><td>• Banks and other intermediaries act as 3rdparty creditors using accounts as ledgers which are centrally stored and not public. Trust is in this creditor. Errors can be off-set, stolen coins are often replaced and a lost identification for authentication can be replaced by a new one (lost ID card)</td></tr></table>

<table><tr><td colspan="2">Crypto</td></tr><tr><td colspan="2">• Subset of digital currencies</td></tr><tr><td colspan="2">• Features: Privacy, distributed mutual ledger for transaction recording, cryptography</td></tr><tr><td colspan="2">• Ethereum, Bitcoin, Ethereum and more than 1&#x27;000 other crypto currencies</td></tr><tr><td colspan="2">• 99% without a regulatory or institutional backing, most are not considered to be legal tenders</td></tr><tr><td colspan="2">• Lost cryptographic key to get access to the cryptocurrency or stolen coins are not replaced and lost for the economic system forever since there is no 3rdparty in the system</td></tr><tr><td colspan="2">• Coins are generated by the mutually distributed ledger technology</td></tr><tr><td colspan="2">• Fully transparent but full anonymous payment system</td></tr><tr><td colspan="2">• 7x24, payments without knowing the recipients, payments only possible in the peer group which accepts the coin</td></tr><tr><td colspan="2">• Trust, security and protection, see below</td></tr><tr><td colspan="2">• High volatility, i.e. Vol BTCUSD is around 14 xtimes larger than Vol CHF USD</td></tr></table>

Figure 6.25: Comparing digital and crypto currencies.

# 6.3.3.1 Fact and Figures

By 2011, 10 USD was worth 1 Bitcoin. In 2013, the exchange rate was up to 266 USD for one Bitcoin. Shortly after the high, the exchange rate dropped by 80 percent. In November 2013 the exchange rate was 1200 USD/Bitcoin. After the default of the plat

form Mt. Gox, the rate dropped to a value of 340 USD/Bitcoin. In 2017, the value of Bitcoin exploded. From around USD 800 in Jan to more than USD 16,000 in Dec 2017 and crashing to less than USD 6'000 at the beginning of Feb 2018. This shows the risks of Bitcoin and in at the present status the non-usability to store value or to make payments.

According to the tokens-economy.com webpage out the around  $18\mathrm{mn}$  mined Bitcoin by the beginning of 2020,  $1.6\mathrm{mn}$  have been stolen and  $5.01\mathrm{mn}$  have been lost. More than 35 percent of all coins have been therefore stolen or lost. Reasons for losing the coins are loss of private keys, operational risks by sending the coins to the wrong address when people do not use the QR code but type wrongly the address or even by sending the coin to the genesis block to exchange them. Bitcoin are not fungible. 1 Bitcoin is not equal to 1 Bitcoin. Premiums of up to  $15\%$  are paid for Bitcoin that is freshly mined. The reason is that these bitcoins certainly do not have a harmful history with their owners and are therefore unproblematic when exchanged for a Fiat currency via stock exchanges or banks. The all-in cost of mining Bitcoin is about USD 5,600 at the beginning of 2020 at a price of about USD 8,500, which means that the miners' profit is currently almost USD 2,000 per Bitcoin received if they win the PoW.

The Bank of England (2014) states that volatility of bitcoins is 17 times larger than the volatility of the British pound: The use of bitcoins as a short-term storage medium is questionable although nothing can be inferred about its value as a long-term storage medium. The number of transactions of retail clients is used to measure their willingness to accept bitcoins as a medium of payment. Since this number is not observable, proxy variables are used instead such as data from 'My Wallet', see Bank of England (2014). The analysis shows that the number of transactions per wallet is decreasing since 2012 to a value 0.02 transactions per wallet. Most clients buy-and-hold their bitcoins instead of using them. Finally, there is little evidence that bitcoins are used as units of account since.

The traditional payment systems are safe, cost-effective and scalable, i.e. they handle high volumes. Visa, Mastercard and Papal handle between 3'500 and 240 transactions per second, while for Bitcoin and Ether the number is a around 7-20.[20] Coins are so far only cheaper to produce than those in centralized system since the miners in the crypto-currency system receive as a subsidy new currency coins for their proof-of-work efforts. Given that the production of new bitcoins is decreasing over the next decades, that energy production to achieve consensus grows over-proportionally and if the exchange value of Bitcoin will not stabilize at a large value compared to the USD, then the effect of subsidies diminishes leading to increasing costs for bitcoins issuance. Removing centralized trust by using a P2P trustless MDLT is costly in several respects. The energy consumption of the Bitcoin miners equals 2018 total energy consumption of the 20 million nation of Romania. Etherum is also highly energy intensive. It will be of vital

<sup>20</sup>Committee on Payments and Market Infrastructures, Statistics on payment, clearing and settlement systems in the CPMI countries, December 2017; www.bitinfocharts.com; Digiconomist; Mastercard; PayPal; Visa; BIS calculations.

importance whether other consensus than the PoW can be designed and which will be accepted such that the MDLT will consume much less energy.

The number of hashes drive energy costs. Aste (2016) estimates that to keep a capital of around USD 10 bn secure in the Bitcoin blockchain annual costs of  $10\%$  are needed. The reason is the number of hashes which are generated every second of 1 bn times 1 bn fro the PoW. Given the high transaction costs, most users access their cryptocurrency not directly but via an intermediary such as crypto-wallet providers or crypto exchanges. That is, the main motivation of Bitcoin of not needing a central third party such as a central bank end by trusting often unregulated third parties. It is then no surprise that fraudulent or hacked institutions such s the Mt Gox leads to thefts and zero-recovery losses for the users.

Permissioned crypto currency often do not face some of the above problems of Bitcoins. The World Food Programme's blockchain-based handle payments for food aid serving Syrian refugees in Jordan. The unit of account is centrally controlled by the World Food Programme. Vsing a permissioned version of the Ethereum protocol, the deficits of Ethereum were overcome (slow, expensive) and transaction costs are reduced by  $98\%$  also relative to bank-based alternatives.

Scalability is another limitation since the transaction ledger is growing over time. The Bitcoin ledgers amount 2017 to 170 GB with a growth of 50 GB in 2017. Therefore a simple Fermi-type calculation shows that the network size needed to replace standard currency regimes is out of any feasible size. This not only means storage of data but also the needed processing capacity for transaction verification.

Figure 6.26 shows market capitalization of Bitcoin, Ripple and Ethereum, the average transaction costs, that Bitcoin mining is around the 10 minutes as it should be and the mining in Ethereum takes much less time reflecting the proof-of-stake approach. Comparing the number of daily Bitcoin - around  $100'000$  by the end of 2015 (Coinometrics, Capgemini) - with the number of daily transactions by Visa (212 mio.), MasterCard (93 mio.) and all other traditional entities together summing up to 340 mio. - the Bitcoin percentage is  $0.03\%$  of this total transaction volume.

Although we focus on Bitcoin, there is an inflation of crypto-currencies. Coinmarketcap.com reports that by September 2015 there were 676 listed crypto-currencies, in December 2017 there were 1,376 crypto-currencies with total market cap USD bn 556. In 2015, Bitcoin consolidated  $85\%$  of market capitalization and number two Ripple following with  $6\%$ . 2017, the consolidated value of Bitcoin is fallen to 43 percent, Ethereum as number two has 12 percent. The tenth largest entity - Bytecoin - represented a market capitalization of only  $0.2\%$  in 2015. In 2017, the currency Monero represented as number ten only  $0.9\%$ . Since the Bitcoin system can be copied, most new coins are pure copies of the Bitcoin system or copies with minor changes. These coins are also called altcoins. The many crypto currencies are undergoing a selection process where some of

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7fa758c8ac42334068cf3224c5d6b478d33d694834a8c71b01bdca0a66332769.jpg)  
Figure 6.26: Bitcoin statistical data (BitInfoCharts.com [2018]).

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/29ca8210cca6f282fce5d9ecd834d83e80d4102f9862ec72c4bbff5d01a97fe0.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/5bed451ea9153f6039fd778fbcc0e009cccc3263c5f9f8b58ae0dde5b1905d13.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/bcb31787bfe31e96bf1072f4fa670c31382a017064c4081e6ba7b8ad766d5777.jpg)

them sharply increase in market share value in a period but then can also fast evaporate to become insignificant. This evolutionary process triggers the question: How often will people accept losses in a crypto currency which vanished unless they lose complete trust in the whole crypto currency business?

The algorithm of the Bitcoin protocol defines the supply side. Therefore supply is fixed and inelastic which is one source of the high price volatility. Since every currency loses value if it fails to be a scarce resource, new bitcoins are issued in a controlled way. Bitcoins do not specify a claim on somebody contrary to digital money created by the creation of loans since each loan creates a deposit position on the loan borrower's bank account. The demand and supply for bitcoins has no physical foundation and the total supply of bitcoins is limited to the creation of 21 million bitcoins. Given the rule-based creation process, this amount will be reached around 2041. With this fixed supply side and its diminishing rate of productions, bitcoins are a deflationary currency. Bitcoin miners are in some sense the clearing houses which maintain the book-keeping system and verify the validity of transactions.

Bitcoin do not have a well-defined governance structure as central banks have. The identity of any participant in the network is for example unverified. This contradicts the increasing regulatory and legal fighting against money laundering or tax hiding activities. Prominent in the early days were the uses of Bitcoin in the anonymous Silk Road platform. The main activity in this platform was trading narcotics. The U.S. investi

gation estimated that in the period Feb 2011 to Jul 2013 9.9 million Bitcoin payments were made with an equivalent of USD 214 million. After the demise of Silk Road an unclear number of successors or competitors are actively using Bitcoin. But the initially significant fraction of money inflow into the Bitcoin system from criminal activities - the residual value - significantly decreased. Tasca (2016) reports that in 2012 the relative income for black market and online gambling had a share in the Bitcoin income flow of around  $70\%$ . This number collapsed in the last two years to less than  $10\%$ . Bitcoin transaction are contrary to real or electronic payments strictly irreversible. This property is due to the desire to keep the Bitcoin system at a manageable level. Changing the protocol, as we discussed above, follows a complicated game theoretic motivation which can lead to forks and where different types of network members have different rights and the possibility to form coalitions if a change in the protocol is suggested.

From the risk perspective counter party risk of currency exchanges is critical. Exchanges active in Bitcoin charge transaction fees between 20 and 200 bps. The number of such exchanges is modest since the exchanges need an internet infrastructure which is able to withstand attacks. The rules to set-up an exchange are strict in the U.S. and also in UK or Germany for example. Prominent is the default of Mt. Gox exchange in Japan in 2012. They reported that they lost  $754'000$  bitcoins of their customers which amounts to USD 450 million. The counter party risk of exchanges matters for the clients since most convert their electronic currencies into bitcoins and leave the Bitcoin at the exchange. The exchange acts as a bank. Moore and Christen (2013) estimate that 45 percent of the currency exchanges terminated operations. While large exchanges often faced security problems, the reasons for the smaller ones are unknown. Therefore, if the exchange which in fact act as a bank holding bitcoins accounts of the customers shuts down counter party risk realized. The loss given default following Moore and Christen (2013) is  $46\%$  - only  $54\%$  of the closed exchanges reimburse their customers.

Furthermore, the proof-of-work mechanics consumes a lot of physical energy. The PoW is estimated to need as much energy in 2021 as Denmark. Therefore, only a few networks such as that one for Bitcoin can be added in the world before touching the limits of energy consumption.

The following statements which are often heard in the FI summarize the discussion:

# Blockchain yes; Bitcoin no.

But this statement does not mean that a different coin based on a blockchain which is more mature can become an important crypto currency, see the Section about Libra below.

Figure ?? gives an overview of different blockchain consensus mechanism. The figure shows that there is no such thing as 'the' blockchain technology but that there are many different types of technologies. All technology has pros and cons which are to be

considered if a specific application is to be implemented.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/b3a5c38b2ca734ada5159a56449c796df1bf795079806dc47bb45f0bbdea8487.jpg)  
Figure 6.27: Overview of different consensus mechanism for blockchains. (wwwtokenizer-economy.com (2020)

# 6.3.4 Bitcoin Blockchain Security

So far the Bitcoin network did not suffered from a fork. This leads to the folklore that the blockchain underlying Bitcoin is secure. Can this statement be proven?

We start with some market facts. In 2016 the most active miners are located in China who cover around  $50\%$  of the total market share (Tasca (2016)), followed by Europe with around  $25\%$ . This is also reflected in the traded currency pairs. The traded volume CNY/BTC is about three times larger than the USD/BTC one. This dominance of Chinese activity can also be observed in the number of active Bitcoin clients normalized by the number of users which have direct access to the internet: The number in China is around 5 times larger than the second largest numbers of the US or Russia. Bitcoin start-ups raised around USD 1 bn in the three years 2012 - 2015 with an annual growth rate of  $150\%$ . This rate dominates other start-up rates such as crowdfunding, lending or banking in general by factor 2 - 3. If a mining pool gains 51 percent of computing capacity, they can attack the network by rewriting in principle all blocks and generate a new blockchain. The pool gash.io in January 9, 2014 possessed 45 percent of the mining power and needed to appeal pool members to exit the pool. Summarizing, mining industry is an oligopoly where the market share of the ten largest miners is between  $70\% - 80\%$  by the end of 2015 (Tasca (2016)). This raises security concerns since to gain

51% consensus about a block transaction verification becomes more risky the less miners contribute to the majority value.

A stream of theoretical work focuses on a rational analysis of the system. They treat Bitcoin as a game between competing rational single miners or pools of miners which maximize a utility function which captures the incentive structure for the system. The goal is to prove under which condition Bitcoin achieves a stable game theoretic equilibrium. Overall, the results are rather pessimistic. This means, unless one does not impose strong conditions attacks on the Bitcoin mining protocol follow leading for example to forks on the blockchain. Eyal and Sirer (2013) for example show that the Bitcoin protocol is not incentive-compatible. They show that an attack from colluding miners leads to a revenue which exceeds their fair revenue value. They propose a modification of the protocol which then protects against selfish mining pools. Sompolinsky and Zohar (2013) analyze the implications of high volume throughput on Bitcoin's security against double-spend attacks. They show that the strength of the attacks can weaken to reverse even accepted transactions if volume increases. They propose a reorganization of the Bitcoin blockchain by new rules which have been implemented by the Ethereum project. the expected success outlook of a competing mining pool. Lewenberg et al. (2015) analyze the stability of mining pools. The authors examine the dynamics of pooled mining and how they should share the rewards when they behave in a cooperative way. Using cooperative game theory, for particular networks under under high transaction loads the distribution of the rewards is unstable. This means, some miners have an incentive to switch between the pools. These findings are in contrast with the empirical observation no fork or substantial slowdown that is attributed to rational attacks has been observed to date.

Given this difference between theory and observations, Badertscher et al. (2018) ask:

How come Bitcoin is not broken using such an attack? Or, stated differently, why does it work and why do majorities not collude to break it?

Why do honest miners keep mining given the plausibility of such attacks?

They use a rational-cryptography framework for capturing the economic forces that underly the tension between honest miners and deviating miners, and explain how these forces affect the miners' behavior. They show how expected revenues of the miners in combination with a high monetary value of Bitcoin, can explain the fact that Bitcoin is not being attacked in reality even though majority coalitions are in fact possible. Hence, assumptions about the miners' incentives, which depend solely on costs and rewards for mining, can substitute the honest-majority assumption.

# 6.3.5 Libra

Facebook (FB) published in June 2019 the details of the Libra blockchain. Compared to most small Fintech initiatives, the Libra Association was populated by economic and

technological giants: Mastercard, PayPal, Visa, eBay, Uber, Lyft, Spotify, Vodafone, Coinbase among others. Some of them such as Mastercard, PayPal or Visa are financial intermediaries whereas Facebook is social network and Vodafone is a telecommunication firm. Hence, the Libra Association consisted of around 100 firms of different sectors. Note that during 2019 almost all payment firms withdraw due to the strong political pressure in the US on Libra, see below. The cryptocurrency coins should have low volatility (stable coin) relative to some stable fiat currency to avoid Bitcoin-like volatility. Therefore, Libra is linked to a broad basket of ordinary currencies and low-risk government bonds. The coins should transfer via Facecook channels to the payment centers PayPal or Visa, they are traded at Coinbase, stored at Xapo and accepted at eBay, Uber and Spotify. Summarizing, see Figure 6.28, Libra is a hybrid structure.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3783feff9f398c4870e49829f34710c36883f25e20051a6f8b7072166f337fd7.jpg)  
Figure 6.28: The structure of Libra. The figure shows the interconnected balance sheet in the economy which is split into the traditional finance sector which backs Libra, the traders linking the P2P economy of Libra with the blockchain (BC) and the financial sector. in the P2P part, end users can act in a P2P way with other end users or with the traders (Adapted from Müller (2019)).

The linkage to the financial sector via the reserves stabilizes the currency which is a main advantage to the else highly volatile crypto currencies. But this link also generates some delicate issues. Libra is linked to the traditional payment system infrastructure which is old and has to be renewed. It is too costly and too slow in particular if cross country payments are considered. Given this link, Libra can be seen as a New USD where the old infrastructure is only partly used but the currency is privately controlled and mined. In this sense Libra can be seen as a wake-up call for the traditional payment

infrastructure: Either they develop a new system in the near future or the private sector will simply install such a system.

Therefore, political actors are watching the currency project of Facebook suspiciously. Some fear that Libra could put systemically important banks under pressure and severely restrict the monetary policy leeway of states. Above all, financial politicians in the USA are critical. Some accuses Libra of endangering national security, posing a risk to cyber security and torpedoing data protection. The fact that FB is the figurehead of Libra is proving to be a heavy burden in the political arena. Many politicians are currently worried about data protection. Facebook has already repeatedly trampled on the protection of the data of billions of people in the past, which is why Libra can also be expected to commit gross data protection violations, according to the tenor.

Critical voices can also be heard in Europe. Some predict that Facebook could become a shadow bank that circumvents regulations. The French Finance Minister called on central banks worldwide to investigate whether the new Facebook currency could be a possible gateway for money laundering and terrorist financing. FB announced that it has a technological solution up its sleeve for the anonymity problem of its blockchain platform and that identities could be verified. In addition to data protection and system stability, the governments in Europe and the USA also have concrete interests at stake. If Libra were to become a success and its reserve policy increasingly abandoned the traditional currencies, this could considerably reduce the money creation profits of states. In Switzerland, the Swiss National Bank (SNB) currently distributes one billion francs a year to the Confederation and the cantons. Since the dollar is still the world's reserve currency, seigniorage is particularly important in the USA. US President Donald Trump recently stressed the international supremacy of the dollar and explained that there is only one right currency in the US.

While Libra is facing this opposition, maybe the real problem for the monetary system is in China. China is heavily investing in new payment technologies and while the western governments focus and stop Libra a Chinese crypto currency can emerge which cannot be stopped as Libra and which is then likely to challenge the USD as the main world currency. The Chinese initiative is based on the advanced technological status and its acceptance by the population.

To understand the impact of networks, we consider Tencent. Tencent WeChat dominates the Chinese messaging app market because it combines social media with e-commerce and payment functionality. Everyday life in China is now characterized by new opportunities: When you get to know each other, you scan your WeChat QR code, and anyone who buys sweet potatoes from a street shop also pays with WeChat - even the beggars have now switched to the new form of payment and have labels with a QR code at hand. Analysts assume that WeChat was successful not only because of its ease of use and broad functionality, but also because WeChat was able to build on many

existing users, and so network effects came into play from the very beginning. This could be an indication of Libra's future success. Finally, Facebook with WhatsApp dominates the messaging market in many countries, which is why network effects are likely to have an impact right from the start.

A further problem is that Libra can be seen as a derivative of the USD. But then several intricate regulatory questions arise.

Since regulators emphasize 'mass regulation before mass adoption' Libra faces a rough regulatory process; By Libra's goals it will have systemic importance and thus has to comply with highest prudential standards. The importance of central governance and FB data privacy track record add to the concerns.

Who could use Libra? There are almost 2.5 billion Facebook users. This defines an enormous client potential if Libra would be open to retail clients too. Many of these users live in places where there is little trust in the traditional financial and state institutions. If Libra is stable in value preservation, why should these people not use this system? Even if the system receives a vast amount of data about the behavior and preferences of customers?

The Libra code is open source and Facebook creates a own blockchain using its own programming language Move. The blockchain is not owned by Facebook but by the association. The association is based in Switzerland and hence Facebook is relieving itself of its responsibility to governments and regulators. Each member operates validatornodes (miners) and the fee to become a member is  $10\mathrm{mn}$  USD. This amount times the 100 starting member defines the 1 bn USD backing of the coin by USD. Facebook is just one member. With this structure Facebook cannot be accused to control a possible worldwide crypto-currency and the decentralization simplifies it for Facebook that the currency is used on the Facebook channels which is the goal of Facebook. It is intended that Libra which at the beginning should be a wholesale cryptocurrency should become open to anybody.

As in a classic blockchain, miners attach to a read-only database transactions bundled into blocks as part of a consensus process. The blockchain uses the best features of other structures such as Ethereum, Ripple and IOTA among others. The blockchain should scale to billions of accounts, require high transaction throughput, low latency and an efficient storage system for high capacity. Source: LIBRA White Paper. It is a centralised enterprise, potentially a gigantic systemically relevant fund manager (100% backup), supporting government debt. Even if Libra could technically manage blockchain consensus for many miners it will have no self-interest to go the 100 nodes, as this would dilute RoE. As it is also explicitly stated, LIBRA is just the starting point: The system should become the basis for future innovations in the financial sector. Note that the programming language Move allows to create digital assets and smart contracts in general. Transactions are only functions of the current state of the blockchain and not of historical states. It thus keeps the option open to prune old transaction data or to enable full nodes to verify transactions even if they do not have

the full history. This would reduce the storage problem dramatically. Ethereum data base which requires the full history has to date reached 1 and 2 terabytes in size.

The blockchain is transparent and users can store their own keys and verify the blockchain. Libra is a permission-free, low-cost digital payment method. Libra is challenging payment service providers not in the association and the issuers or fiat money.

# Chapter 7

# Proofs

We prove Proposition 39:

Proof. To prove the proposition the standard no arbitrage argument is used. Assume  $F(t,T) > S(t)\cdot e^{r(T - t)}$ . We set up a portfolio  $W$  as follows. We borrow a money amount  $S(t)$  to buy the cheap stock  $S$  and go short the more expensive forward for the same amount. Then  $W(t) = 0$ . At  $T$ , we pay back the loan, sell the stock to fulfil the forward contract obligation and settle the forward contract which pays  $S(T) - F(t,T)$ . The cash balance at  $T$  is

$$
\begin{array}{l} W (T) = - S (T) \cdot e ^ {r (T - t)} + S (T) - (S (T) - F (t, T)) \\ = - S (T) \cdot e ^ {r (T - t)} + F (t, T) > 0 \\ \end{array}
$$

Using such a strategy we start with zero value and end at  $T$  with certainty with a positive value - this is an arbitrage which allows for the construction of a money machine. A similar argument applies for the other inequality.

We prove Proposition 4:

Proof. The proof follows from the fact that the variance of the sum is equal to the sum of the variances since there is no covariance:

$$
\sigma_ {p} ^ {2} = \mathrm {v a r} \left(\sum_ {j = 1} ^ {N} \frac {1}{N} R _ {j}\right) = \frac {1}{N ^ {2}} \mathrm {v a r} \left(\sum_ {j = 1} ^ {N} R _ {j}\right) \leq \frac {N c}{N ^ {2}}
$$

with  $c$  the largest variance of all  $N$  assets.

We prove Proposition 5:

Proof. The proof is only slightly more complicated than the former proof, and leads to the result:

$$
\sigma_ {p} ^ {2} = \frac {\overline {{\mathrm {v a r}}}}{N} + (1 - \frac {1}{N}) \overline {{\mathrm {c o v}}} .
$$

By increasing the number  $N$  of assets, the average portfolio variance  $\overline{\text{var}}$  can be made arbitrarily small - the portfolio variance is determined by the average covariance. But the average portfolio covariance approaches a non-zero value.

We prove Proposition 7:

Proof. Differentiate both sides of the equation  $f(tu) = tf(u)$  with respect to  $t$ , apply the chain rule, and choose  $t = 1$ . For the converse, let  $g(t) = f(tu)$ . Since  $\langle tu, \nabla f(tu) \rangle = f(tu)$  we have

$$
g ^ {\prime} (t) = \langle u, \nabla f (t u) \rangle = \frac {1}{t} f (t u) = \frac {1}{t} g (t).
$$

Solving this differential equation for  $g$  implies  $g(t) = g(1)t$ . This implies  $f(tu) = g(t)t(fu)$ .

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/1247560e6d78ab8fdf726ed15cafa81f547553bbf4a4aeabd7ca5cef883bf51f.jpg)

We prove Proposition ??:

Proof. Starting for the assumption  $\mu_{m} = \lambda \mu_{a} + (1 - \lambda)\mu_{p}$  and assuming that the expected return of the passive investment equals market return at once also follows that active return has to be equal to passive return.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7fe57cfaf77caea0142cfd85934e179c8b7d9a9b7c7920b0f72822be5e33d7e8.jpg)

We prove the optimal dynamic investment decision rules of the Merton models 4.13:

Proof. We first split the integral in two parts for small  $dt$ :

$$
\begin{array}{l} J \left(t _ {0}, w _ {0}\right) = \max  _ {c} E _ {t _ {0}, w _ {0}} \left[ \int_ {t _ {0}} ^ {t _ {0} + d t} u (t, c, W) d t + \int_ {t _ {0} + d t} ^ {T} u (t, c, W) d t + f (W (T), T) \right] \\ d W _ {t} = g (t, c, W) d t + \sigma (t, c, W) d B _ {t}, W (t _ {0}) = w _ {0}. \tag {7.1} \\ \end{array}
$$

Using the Principle of Optimality, the control function in the second integral should be optimal for the problem beginning at  $t_0 + dt$  in the state  $W(t_0 + dt) = w_0 + dW$ . Hence,

$$
J (t _ {0}, w _ {0}) = \max _ {c} E _ {t _ {0}, w _ {0}} \left[ \int_ {t _ {0}} ^ {t _ {0} + d t} u (t, c, W) d t + E _ {t _ {0} + d t, w _ {0} + d W} \left[ \int_ {t _ {0} + d t} ^ {T} u (t, c, W) d t + f (W (T), T) \right] \right].
$$

Optimality implies  $E_{t_0 + dt, w_0 + dW} \left[ \int_{t_0 + dt}^T u(t, c, W) dt \right] = J(t_0 + dt, w_0 + dW)$ , i.e.

$$
J (t _ {0}, w _ {0}) = \max _ {c} E _ {t _ {0}, w _ {0}} \left[ \int_ {t _ {0}} ^ {t _ {0} + d t} u (t, c, W) d t + J (t _ {0} + d t, w _ {0} + d W) \right]. \quad (7. 2)
$$

We next approximate the second value function since  $dt$  is small. This also allows us to assume that the control  $c$  is constant over a time interval with length  $dt$ . We get:

$$
\begin{array}{l} {J (t _ {0}, w _ {0})} = {\max _ {c} E t _ {0}, w _ {0} [ u (t, c, W) d t + J (t _ {0}, w _ {0}) + \partial_ {t} J (t _ {0}, w _ {0}) d t} \\ + \partial_ {w} J (t _ {0}, w _ {0}) d W + \frac {1}{2} \partial_ {w w} ^ {2} J (t _ {0}, w _ {0}) (d W) ^ {2} ] + o (d t). \tag {7.3} \\ \end{array}
$$

This looks like a second order expansion in the state variable - but the square of Brownian motion  $(dB)^2$  is linear in time (see the part and appendix on continuous time finance), i.e.  $(dW)^2 = (g(t,u,W)dt + \sigma (t,u,W)dB)^2 = \sigma^2 dt$ . The only random component in the above value function expression is therefore the term  $\partial_wJdW$ . Since  $E[dB] = 0$ , we get

$$
E [ \partial_ {w} J d W ] = \partial_ {w} J g d t.
$$

Dividing by  $dt$  we finally get the fundamental partial differential equation (PDE)

$$
0 = \max _ {c} \left[ u + \partial_ {t} J + \partial_ {w} J g + + \frac {1}{2} \partial_ {w w} ^ {2} J \sigma^ {2} \right]. \tag {7.4}
$$

Therefore,

1. Taking formally the derivative w.r.t. to  $c$  in the above PDE gives us optimal decision making  $c$  as a function of the unknown value function  $J$ .  
2. Reinsert this candidate into the fundamental PDE (7.4) solve the resulting  $J$ -equation with the boundary and initial conditions (if any).  
3. Use this explicit solution  $J$  to obtain the fully specified optimal policy  $c_{t}^{*}$  and the optimal controlled state dynamics  $W_{t}^{*}$ .

Inserting  $J(t,W) = e^{-rt}V(W)$ . into the fundamental PDE leads after cancelling of the exponential function to

$$
0 = \max  _ {c, \omega} \left[ \frac {c ^ {a}}{a} - r V + \partial_ {w} V g + + 1 / 2 \partial_ {w w} ^ {2} V \sigma^ {2} \right]. \tag {7.5}
$$

The wealth dynamics  $W_{t}$  follows from the asset dynamics and the consumption rate. There is a risky asset with dynamics  $dS / S = \mu dt + \sigma dB$  where the drift and the volatility are constant and a so-called riskless asset with dynamics  $d\mathcal{B} = \mathcal{B}rdt$ . The growth rate of wealth is the equal to the weighted sum of the asset growth rates minus the consumption rate, i.e.

$$
d W / W = \omega d S / S + (1 - \omega) d \mathcal {B} / \mathcal {B} - c / W d t.
$$

The weight  $\omega$  is equal to the number of risky assets times their price  $S$  divided by total wealth. Inserting the asset dynamics in the wealth growth rate equations gives the final wealth dynamics:

$$
d W = (\omega \mu W + (1 - \omega) r W - c) d t + \sigma \omega W d B.
$$

Inserting this dynamics in the fundamental PDE gives:

$$
0 = \max  _ {c, \omega} \left[ \frac {c ^ {a}}{a} - r V + (\omega \mu W + (1 - \omega) r W - c) \partial_ {w} V + + \frac {1}{2} (\sigma \omega W) ^ {2} \partial_ {w w} ^ {2} V \right]. \tag {7.6}
$$

Taking the derivative w.r.t. to the two choice variables, setting them to zero gives the candidate solutions (First Order Conditions):

$$
c ^ {*} = \left(\partial_ {w} V\right) ^ {\frac {1}{a - 1}} , \omega^ {*} = \partial_ {w} V \left(\frac {r - \mu}{\sigma^ {2}} \frac {1}{W \partial_ {w w} ^ {2} V}\right) . \tag {7.7}
$$

This candidate optimal choice solution possesses a drawback - they depend on the yet unknown value function. One has to determine the value function  $V$ . To achieve this, we insert the optimal candidate functions into the fundamental PDE. This gives an equation for the unknown value function  $V$ :

$$
V = (\partial_ {w} V) ^ {\frac {1}{a - 1}} \frac {1 - a}{a} + r W \partial_ {w} V - \frac {(r - \mu) ^ {2}}{2 \sigma^ {2}} \frac {(\partial_ {w} V) ^ {2}}{\partial_ {w w} ^ {2} V}. (7. 8)
$$

This is a highly non-linear equation but the value function  $V(w)$  is proportional to the expected value of  $c^a$ . Therefore, a guess is  $V(W) = \alpha W^a$  as a candidate solution with  $\alpha$  a constant. Testing this guess in the PDE we see that all terms are proportional to  $W^a$ : We can factor out this power function times a complicated function which does not depend on the state variable  $W$ . Since this product has to be zero for all  $W$ , the complicated function has to be zero which gives us a value for the constant  $\alpha$  and we obtained in this way a solution for the unknown value function. To carry this out we insert this guess into (7.8):

$$
0 = W ^ {a} \alpha \underbrace {\left(\frac {1 - a}{a} \alpha^ {\frac {1}{a - 1}} - 1 + r a - \frac {(r - \mu) ^ {2}}{2 \sigma^ {2}} \frac {a}{a - 1}\right)} _ {=: F (\alpha)}.
$$

That is, the state variable dependence  $W^{a}$  appears in each term of the original PDE and can be factored out. Therefore  $V(W) = \alpha W^{a}$  solves the PDE if  $F(\alpha) = 0$ . This equation can be solved explicitly, leading to a constant  $\alpha^{*}$ . Hence we found a solution for the value function PDE which then provides us an explicit solution for the choice variables:

$$
V (W) = \alpha^ {*} W ^ {a} , c ^ {*} = W (a \alpha^ {*}) ^ {\frac {1}{a - 1}} , \omega^ {*} = \frac {\mu - r}{\sigma^ {2}} \frac {1}{1 - a} .
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/509f722365a83fd5596a65f57a268f35da82e20dc9741e964022e583e840d75b.jpg)

We prove the Markowitz Proposition 71:

Proof. With the Lagrangian

$$
L = \frac {1}{2} \langle \phi , C \phi \rangle + \lambda_ {1} (1 - \langle e, \phi \rangle) + \lambda_ {2} (r - \langle \mu , \phi \rangle),
$$

the first order conditions

$$
0 = \frac {\partial L}{\partial \phi} := \left( \begin{array}{c} \frac {\partial L}{\partial \phi_ {1}} \\ \frac {\partial L}{\partial \phi_ {2}} \\ \vdots \\ \frac {\partial L}{\partial \phi_ {N}} \end{array} \right) ， \tag {7.9}
$$

are a set of  $N$  equations. From

$$
\frac {1}{2} \frac {\partial \langle \phi , C \phi \rangle}{\partial \phi} = C \phi , \frac {\partial \langle \phi , \mu \rangle}{\partial \phi} = \mu
$$

we get

$$
0 = C \phi - \lambda_ {1} e - \lambda_ {2} \mu \tag {7.10}
$$

$$
1 = \langle e, \phi \rangle \tag {7.11}
$$

$$
r = \langle \mu , \phi \rangle . \tag {7.12}
$$

The optimality conditions are therefore  $N + 2$  linear equations in the  $N + 2$  variables  $\phi, \lambda_1, \lambda_2$ . To solve this system, we proceed as follows. Since  $C$  is strictly positive definite,  $C^{-1}$  exists and (7.11) implies

$$
\phi = \lambda_ {1} C ^ {- 1} e + \lambda_ {2} C ^ {- 1} \mu .
$$

Multiplying this last equation from the left with  $e$  and  $\mu$ , respectively, and using the normalization condition and the return constraint, we get a linear system for the two Lagrange multipliers:

$$
{ 1 } { = } \lambda _ { 1 } \langle e , C ^ { - 1 } e \rangle + \lambda _ { 2 } \langle e , C ^ { - 1 } \mu \rangle
$$

$$
r = \lambda_ {1} \left\langle \mu , C ^ {- 1} e \right\rangle + \lambda_ {2} \left\langle \mu , C ^ {- 1} \mu \right\rangle . \tag {7.13}
$$

If we set  $\tau = (\lambda_1, \lambda_2)'$  and  $y = (1, r)'$  the last system reads

$$
y = \left( \begin{array}{l l} \langle e, C ^ {- 1} e \rangle & \langle e, C ^ {- 1} \mu \rangle \\ \langle \mu , C ^ {- 1} e \rangle & \langle \mu , C ^ {- 1} \mu \rangle \end{array} \right) \tau =: A \tau . \tag {7.14}
$$

If  $A$  is invertible, we are done since then  $y = A\tau$  can be trivially solved for  $\tau$ . This determines the Lagrange multipliers  $\lambda_{i}^{*}$  and inserting this result in  $\phi^{*} = \lambda_{1}^{*}C^{-1}e + \lambda_{2}^{*}C^{-1}\mu$  gives us the optimal portfolio and proves the proposition. We prove that within the given model, the matrix  $A$  is invertible, i.e. we claim that  $\det A = \Delta > 0$ . To prove this we use the Cauchy-Schwartz inequality, i.e. for two arbitrary vectors  $x, y$  we have

$$
| x | ^ {2} | y | ^ {2} \geq \langle x, y \rangle^ {2},
$$

where the strict inequality holds if the two vectors are independent. To rewrite the determinant in the form needed for the Cauchy-Schwartz inequality, we have first to define the vectors  $x, y$ . Therefore, we use the decomposition  $C = UU'$ , which always exists for strictly positive definite, symmetric matrices. Using this, we get

$$
\langle e, C ^ {- 1} e \rangle = \langle e, (U U ^ {\prime}) ^ {- 1} e \rangle = \langle e, (U ^ {\prime}) ^ {- 1} U ^ {- 1} e \rangle = \langle U ^ {- 1} e, U ^ {- 1} e \rangle =: \langle x, x \rangle ,
$$

where we used

$$
\langle x, A ^ {\prime} A x \rangle = \langle A x, A x \rangle
$$

and properties of the matrix inverse. Proceeding in the same form with the other elements of  $A$  and defining  $\langle \mu, C^{-1}e \rangle = \langle y, x \rangle$  we get

$$
\det A = \langle x, x \rangle \langle y, y \rangle - \langle x, y \rangle^ {2}.
$$

Hence, using the Cauchy-Schwartz inequality  $\operatorname{det} A \geq 0$  follows. Since  $\mu$  and  $e$  are linearly independent, the same holds for  $x = U^{-1} e$  and  $y = U^{-1} \mu$  too. This finally proves  $\operatorname{det} A > 0$  and the prove of the proposition is completed. For further reference, we note the optimal multiplier values:

$$
\lambda_ {1} ^ {*} = (A ^ {- 1} y) _ {1} = \frac {1}{\Delta} (- \langle \mu , C ^ {- 1} \mu \rangle + r \langle e, C ^ {- 1} \mu \rangle) \tag {7.15}
$$

$$
\lambda_ {2} ^ {*} = (A ^ {- 1} y) _ {2} = \frac {1}{\Delta} (- \langle e, C ^ {- 1} \mu \rangle + r \langle e, C ^ {- 1} e \rangle). \tag {7.16}
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/3d883a0673eb3cc2fd0e9a6792cf1aa033af2ca258b71094dcb151a2e69a403b.jpg)

We prove the Mutual Fund Proposition 72:

Proof. Let  $\phi$  and  $\psi$  be two solutions of the Markowitz portfolio problem. Then they satisfy linear FOC but then also any convex linear combination  $a\phi + (1 - a)\psi$  also satisfies the FOC. Using the sum of weights times the Lagrange multipliers add up to one, the weight  $a$  follows.

We prove the Value-at-Risk formula (4.21)

Proof. The  $VaR_{\alpha}$  for the quantile  $\alpha$  and a fixed time horizon solve implicitly the inequality:

$$
P (X \leq - \operatorname {V a r} _ {\alpha}) \leq \alpha .
$$

If  $P\sim \mathcal{N}(\mu ,\sigma^2)$  , the inequality reads

$$
\frac {1}{\sqrt {2 \pi} \sigma} \int_ {- \infty} ^ {- \mathrm {V a R} _ {\alpha}} e ^ {- \frac {(x - \mu) ^ {2}}{2 \sigma^ {2}}} d x \leq \alpha .
$$

With the change of coordinates  $z = \frac{x - \mu}{\sigma}$  this becomes

$$
\frac {1}{\sqrt {2 \pi} \sigma} \int_ {- \infty} ^ {- \mathrm {V a R} _ {\alpha}} e ^ {- \frac {1}{2} z ^ {2}} \sigma d z \leq \alpha ,
$$

with  $\sigma$  the Jacobian, i.e.

$$
\frac {1}{\sqrt {2 \pi}} \int_ {- \infty} ^ {- \frac {\mathrm {V a R} _ {\alpha} - \mu}{\sigma}} e ^ {- \frac {1}{2} z ^ {2}} d z \leq \alpha .
$$

The upper limit of the integral depends on  $\alpha$ , the mean and variance. Setting the variance to unity and the mean to zero, then for a given  $\alpha$  the critical factor  $k$  or the VaR follows. For  $\alpha = 0.01$ , i.e. a VaR of  $99\%$  confidence, numerically solving

$$
\frac {1}{\sqrt {2 \pi}} \int_ {- \infty} ^ {k _ {\alpha}} e ^ {- \frac {1}{2} z ^ {2}} d z \leq 0. 0 1
$$

$k_{\alpha} = -2.33$  follows. Increasing the confidence interval to 99.9 percent, i.e.  $\alpha = 0.001$ , the critical value becomes  $k_{\alpha} = -3.09$ .

We use these insights in the VaR calculation. From

$$
\frac {1}{\sqrt {2 \pi}} \int_ {- \infty} ^ {- \frac {\mathrm {V a R} _ {\alpha} - \mu}{\sigma}} e ^ {- \frac {1}{2} z ^ {2}} d z \leq \alpha .
$$

follows

$$
- \frac {\mathrm {V a R} _ {\alpha} - \mu}{\sigma} \leq k _ {\alpha},
$$

or the  $VaR_{\alpha}$  is under normality equal to

$$
- \mathrm {V a R} _ {\alpha} \leq \sigma k _ {\alpha} + \mu .
$$

Since the VaR-constraint binds,

$$
- \mathrm {V a R} _ {\alpha} = \sigma k _ {\alpha} + \mu .
$$

This is the VaR for a fixed time horizon. Calculating for example variance on an annual basis but the VaR on a weekly basis, the square-root rule implies:

$$
- \mathrm {V a R} _ {\alpha} = \sigma k _ {\alpha} \sqrt {T}
$$

assuming zero mean and in the example  $T = 52$ .

$$
\hat {s} _ {F} (x) = \lim  _ {z \in \mathbb {C} ^ {+}} s _ {F} (z)
$$

We prove Proposition 81:

Proof. We prove the SML relationship and form a portfolio consisting of asset  $i$  and the market portfolio  $M$  where we invest the fraction of wealth  $\phi$  in  $i$  and  $1 - \phi$  in  $M$ . The expected rate of return of this portfolio is

$$
\mu_ {\phi} = \phi \mu_ {i} + (1 - \phi) \mu_ {M}
$$

and the variance is

$$
\sigma_ {\phi} ^ {2} = \phi^ {2} \sigma_ {i} ^ {2} + (1 - \phi) ^ {2} \sigma_ {M} + 2 \phi (1 - \phi) \mathrm {c o v} (i, M).
$$

As a function of  $\phi$ , the pair  $(\sigma_{\phi}, \mu_{\phi})$  traces out a curve in the risk-return space. The curve cannot cross the CML, this would violate the property that the CML is an efficient boundary of the feasible region. Hence, as  $a$  passes through zero, the curve traced out by  $(\sigma_{\phi}, \mu_{\phi})$  must be tangent to the CML at  $M$ . In other words, the slope of the CML and of the curve at the point  $M$  must be equal, where the point  $M$  is where  $\phi = 0$ .

Calculating the slopes and setting them equal, implies

$$
\mu_ {i} - \mu_ {0} = \beta_ {i} \left(\mu^ {T} - \mu_ {0}\right). \tag {7.17}
$$

To check this:

$$
\frac {d \sigma_ {\phi}}{d \phi} | _ {\phi = 0} = \operatorname {c o v} (i, M) - \sigma_ {M} ^ {2} \sigma_ {M}.
$$

Next,

$$
\frac {d r _ {\phi}}{d \sigma_ {\phi}} | _ {\phi = 0} = \frac {\frac {d r _ {\phi}}{d \phi} | _ {\phi = 0}}{\frac {d \sigma_ {\phi}}{d \phi} | _ {\phi = 0}} = \frac {(\mu_ {i} - \mu_ {M}) \sigma_ {M}}{\operatorname {c o v} (i , M) - \sigma_ {M} ^ {2}}.
$$

Since the slope of  $\left.\frac{dr_{\phi}}{\sigma_{\phi}}\right|_{\phi = 0}$  should equal the slope of the CML, we have

$$
\frac {(\mu_ {i} - \mu_ {M}) \sigma_ {M}}{\operatorname {c o v} (i , M) - \sigma_ {M} ^ {2}} = \frac {\mu_ {M} - R _ {f}}{\sigma_ {M}} .
$$

Solving for the expected return of asset  $i$  proves the claim.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/cc0d6c4691f712cce0da39d2438fc2255f15f56b338a57f17d528754dc2b0b78.jpg)

We prove Proposition 86:

Proof.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/9a871e0ec8d265382a243bf0ba27d843ce108d6fa96b0685da2ebdf8550c13b3.jpg)

We prove Proposition 32:

Proof. The proof uses the Separating Hyperplane Theorem. A hyperplane can be written in the form

$$
\langle x, a \rangle = d.
$$

Subspaces of  $\mathbf{R}^n$  are kernels of linear maps  $F$ . The Riesz-Fischer theorem implies

$$
F (x) = \langle x, a \rangle = 0
$$

for the kernel. Since each affine subspace is representable by  $F(x) = d$  we define:

Definition 116. The hyperplane  $H_{x}$  through the vector  $x$  is defined by:

$$
H _ {x} = \left\{a \in \mathbf {R} ^ {n} | \langle x, a \rangle = d \right\}, \tag {7.18}
$$

and the half spaces  $H_{x}^{+, - }$  are defined by:

$$
H _ {x} ^ {+, -} = \left\{a \in \mathbf {R} ^ {n} | \langle x, a \rangle \stackrel {\geq} {\leq} d \right\}. \tag {7.19}
$$

Let  $U, V$  be two subsets of  $\mathbf{R}^n$ . The hyperplane  $H$  separates the sets  $U, V \iff U$  and  $V$  are in different half spaces. The hyperplane  $H$  separates the sets  $U, V$  strictly  $\iff H_x$  separates the sets and the sets are disjoint.

Proposition 117 (Separating hyperplane theorem). Let  $C$  and  $K$  be two disjoint and convex subsets of  $\mathbf{R}^n$ . Let  $C$  be compact and  $K$  be closed. Then there exists a hyperplane  $H$ , which separates  $C$  and  $K$  strictly.

The compactness of one set is necessary:

$$
U = \{(x, y) \in \mathbf {R} ^ {2} | x > 0, y \geq \frac {1}{x} \}, V = \{(x, y) \in \mathbf {R} ^ {2} | x > 0, y \geq - \frac {1}{x} \}.
$$

The sets are disjoint and convex. But they are not compact and therefore they cannot be strictly separated.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/7d768aa957478074109c1c9b3692b994155eab40add64c0835abd6a7e5e12f92.jpg)  
Figure 7.1: The hyperplane separates the two convex sets  $A$  and  $B$  in  $\mathbf{R}^2$ . A set is convex if any 'line with end and starting point in the set remains fully in the set'.

We show that there exists a hyperplane through  $z_0$ , which is perpendicular to  $y_0x_0$  and which does not intersect  $U, V$ . Let

$$
d (C, K) = \inf  _ {x \in C, y \in K} | | x - y | |
$$

be the shortest distance between  $C$  and  $K$ . For  $C$  compact and  $K$  closed a minimizing point  $x_0, y_0$  exist, i.e.

$$
d (C, K) = | | x _ {0} - y _ {0} | | > 0.
$$

Let  $H_{x_0}$  be the hyperplane through  $x_0$ , which is perpendicular to the line  $y_0x_0$ . We write  $H_{x_0}$  as follows:

$$
H _ {x _ {0}} = \left\{z \in \mathbf {R} ^ {n} | \langle y _ {0} - x _ {0}, z - x _ {0} \rangle = 0 \right\}.
$$

The function  $\phi (\lambda)$  measures the distance between  $y_{0}$  and  $x$ :

$$
\begin{array}{l} \phi (\lambda) := | | y _ {0} - (x _ {0} + \lambda (x - x _ {0})) | | ^ {2} \\ { = } { \langle y _ { 0 } - x _ { 0 } , y _ { 0 } - x _ { 0 } \rangle - 2 \lambda \langle y _ { 0 } - x _ { 0 } , x - x _ { 0 } \rangle + \lambda ^ { 2 } \langle x - x _ { 0 } , x - x _ { 0 } \rangle . } \\ \end{array}
$$

This function is continuously differentiable and we have  $\phi (\lambda)\geq \phi (0),\forall \lambda \in [0,1]$  , since  $x_0$  is closest to  $y_{0}$  . Therefore,  $\phi^{\prime}(\lambda) = -2\langle y_0 - x_0,x - x_0\rangle +2\lambda \langle x - x_0,x - x_0\rangle$  and

$$
\phi^ {\prime} (0) = - 2 \langle y _ {0} - x _ {0}, x - x _ {0} \rangle \geq 0,
$$

i.e.

$$
\langle x _ {0} - y _ {0}, x - x _ {0} \rangle \leq 0, \forall x \in U,
$$

since  $C$  is convex. In the same way one shows that for  $H_{y_0}$  the inequality

$$
\langle y _ {0} - x _ {0}, y - y _ {0} \rangle \leq 0, \forall x \in U
$$

holds. Since for all  $y \in V$

$$
\langle y _ {0} - x _ {0}, y - y _ {0} \rangle = \langle y _ {0} - x _ {0}, y _ {0} - x _ {0} \rangle + \langle y _ {0} - x _ {0}, y - y _ {0} \rangle \geq 0,
$$

it follows that  $H_{x_0}$  separates the sets  $C, V$  and the same is true for  $H_{y_0}$ . Therefore,  $H_{z_0}$  separates the sets strictly.

We prove Proposition 32.

Proof.  $\Rightarrow$ . Let  $\psi$  be a vector where all components are strictly positive. We claim that it is a state vector if each attainable payoff  $V = \mathbb{P}\phi$  implies  $\langle \psi, V \rangle = \langle S_0, \phi \rangle$  (we omit the time index  $T$ ).  $V = \mathbb{P}\phi$  implies

$$
\langle \psi , V \rangle = \langle \psi , \mathbb {P} \phi \rangle = \langle \mathbb {P} ^ {\prime} \psi , \phi \rangle .
$$

If  $\psi$  is a state vector,  $S_0 = \mathbb{P}'\psi$ , i.e.  $\langle \psi, V \rangle = \langle S_0, \phi \rangle$  follows. If  $\langle \psi, V \rangle = \langle S_0, \phi \rangle$ ,

$$
\left\langle \mathbb {P} ^ {\prime} \psi , \phi \right\rangle = \left\langle S _ {0}, \phi \right\rangle .
$$

This proves the claim.

Hence, for each attainable payoff  $V = \mathbb{P}\phi$  the identity  $\langle \psi ,V\rangle = \langle S_0,\phi \rangle$  holds. Therefore, if all components of  $V$  are positive, also  $\langle S_0,\phi \rangle \geq 0$  holds, i.e. arbitrage is not possible.

$\Leftarrow$  .We set

$$
M = \left\{\left(x, x _ {K + 1}\right) \in \mathbb {R} ^ {K + 1} \mid x = \mathbb {P} \phi , x _ {K + 1} = - \langle S _ {0}, \phi \rangle = - V _ {0} \right\}
$$

and

$$
K = \left\{x \in \mathbb {R} ^ {K + 1} \mid x _ {i} \geq 0, \sum_ {i} x _ {i} = 1 \right\}.
$$

$M$  is an augmented space of payoffs. It consists of all payoffs at date  $T$  plus the price of the portfolio  $-\langle S_0, \phi \rangle$  at time zero.  $K$  is a simplex.  $M$  is a convex and closed set and  $K$  is compact. Since the compact set lies in the positive orthant the definition of no

arbitrage implies that  $M$  and  $K$  are disjoint. The Separation Theorem then applies:

There exists a vector  $z \in \mathbb{R}^{K+1}$  such that  $\langle z, x \rangle < b < \langle z, y \rangle$  for all  $x \in M, y \in K$ .

Since  $M$  is a linear space, these inequalities can only hold if the vector  $z \in M^{\perp}$ . But then  $b > 0$ . Since also  $\langle z, y \rangle > b > 0$  for  $y \in K$ , all components of the vector  $z$  are strictly positive. This allows us to define the state price density as  $\psi_k := \frac{z_k}{z_{K+1}}$  and  $\psi$  solves  $S_0 = \mathbb{P}'\psi$ . To prove this, recall that  $z \in M^{\perp}$  and therefore for each strategy vector  $\phi \in \mathbb{R}^N$ :

$$
0 = \langle z _ {K + 1} \psi , \mathbb {P} \phi \rangle - z _ {K + 1} \langle S _ {0}, \phi \rangle = z _ {K + 1} \big (\langle \mathbb {P} ^ {\prime} \psi , \phi \rangle - \langle S _ {0}, \phi \rangle \big).
$$

Therefore,  $\langle \mathbb{P}'\psi ,\phi \rangle = \langle S_0,\phi \rangle$  , i.e.  $\mathbb{P}^{\prime}\psi = S_{0}$  , holds for all strategies  $\phi$  . This proves the claim.

We prove the Riesz-Fischer Proposition 57 in finite dimension. That is we prove:

Theorem 118. (Riesz) Let  $X$  be a Hilbert space and  $p: X \to \mathbb{R}$  a linear map. There exists a vector  $r^* \in X$ , the Riesz kernel, such that

$$
p (x) = \langle r ^ {\prime} x \rangle
$$

for all  $x\in X$

Proof. We recall some facts from linear algebra and projection geometry first:

Let  $M$  and  $M'$  be subspaces of  $\mathbf{R}^n$ . Then  $M'$  is the complement of  $M$ . If  $M$  is a linear subspace of  $\mathbf{R}^n$ , we define the orthogonal complement  $M^\perp$ :

$$
M ^ {\perp} = \left\{x \in \mathbf {R} ^ {n} | \langle x, y, \rangle = 0, \forall y \in M \right\}.
$$

iff each vector  $x \in \mathbf{R}^n$  can be written as the sum of two vectors  $z \in M$  and  $z' \in M'$  i.e.

$$
x = z + z ^ {\prime}.
$$

We write  $\mathbf{R}^n = M\oplus M'$ . Then  $M^{\prime}$  is the complement of  $M$  iff  $M$  and  $M^{\prime}$  have only the zero vector in common and the two spaces span  $\mathbf{R}^n$ , i.e.

$$
\dim M + \dim M ^ {\prime} = \dim \mathbf {R} ^ {n} = n.
$$

If two vectors  $x, y$  are orthogonal, i.e.  $\langle x, y, \rangle = 0$ , and the norm norm  $||\bullet|| = \sqrt{\langle\bullet,\bullet\rangle}$  is induced by the scalar product. Considering the orthogonal decomposition of  $\mathbf{R}^n$  in  $M \oplus M^\perp$ , the vector  $y \in M$  defined by

$$
x = y + y ^ {\prime}, y ^ {\prime} \in M ^ {\perp},
$$

is the orthogonal projection of  $x$  onto  $M$ :  $y = P_{M}x$ . This vector has minimal distance to  $x$ , i.e.

$$
y = \arg \min _ {w \in M} | | x - w | | ^ {2}, \mathrm {i f} x = y + y ^ {\prime}, y ^ {\prime} \in M ^ {\perp}, y \in M.
$$

The kernel and the image of a linear map  $f: \mathbf{R}^n \to \mathbf{R}^m$  are defined as follow:

$$
\ker f := \left\{x \in \mathbf {R} ^ {n} \mid f (x) = 0 \right\} \subset \mathbf {R} ^ {n}
$$

and

$$
\mathrm {i m} f := \left\{y \in \mathbf {R} ^ {m} \mid y = f (x), x \in \mathbf {R} ^ {n} \right\} \subset \mathbf {R} ^ {m}.
$$

The dimension formula

$$
\dim \mathbf {R} ^ {n} = \dim \ker f + \dim \operatorname {i m} f
$$

holds.

We start to prove the theorem. If  $l(y) = 0$ , we set  $z = 0$ . Suppose that  $l(y) \neq 0$ . Since  $\mathrm{im}l \subset \mathbf{R}$ , we have

$$
\dim M = \dim \ker l + \dim \operatorname {i m} l = \dim \ker l + 1 = \dim \ker l + \dim (\ker l) ^ {\perp}.
$$

Since the kernel is a subspace it follows  $\dim (\ker l)^\perp = 1$ . Let  $e\in M$  be a basis of  $(\ker l)^{\perp}$ . We decompose the vector  $y\in M$

$$
y = y ^ {\prime} + \lambda e, y ^ {\prime} \in \ker l, \lambda \in \mathbf {R}.
$$

Since  $e$  and  $y^\prime$  are orthogonal,

$$
\langle e, y \rangle = \langle e, y ^ {\prime} \rangle + \lambda \langle e, e, \rangle = \lambda \langle e, e, \rangle
$$

and therefore

$$
\lambda = \frac {\langle e , y \rangle}{\langle e , e , \rangle} .
$$

For all  $y \in M$  we get:

$$
l (y) = l \left(y ^ {\prime} + \lambda e\right) = l \left(y ^ {\prime}\right) + \lambda l (e) = \lambda l (e),
$$

where we used the linearity of  $l$  and that  $y^\prime \in \ker l$ . But this implies

$$
l (y) = \lambda l (e) = \frac {\langle e , y \rangle}{\langle e , e , \rangle} l (e) = \langle \tilde {e}, y \rangle , \tilde {e} = \frac {l (e) e}{\langle e , e , \rangle}.
$$

This proves, that each linear functional can be represented in the claimed form by a scalar product. Uniqueness follows by taking two different vectors  $\tilde{e}$  and  $\tilde{e}'$  and showing that they indeed have to agree.

We prove Proposition 59:

Proof. To do.

□

We prove Proposition 61:

Proof. To do.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/d758064f01428bb366905f8010b5c457c795a086ca1f0ec95ff0edc7a13feb9a.jpg)

We prove Proposition 65:

Proof. We prove the direction 'SDF implies the expected return representation'. Take a SDF  $M = a + b'f$  and consider an asset  $i$  with return  $R_i$ . The general covariance formula applied to  $1 = E[MR]$  implies

$$
E [ R _ {i} ] = \frac {1}{E [ M ]} - 1 - \frac {1}{E [ M ]} \mathrm {c o v} (M, R _ {i}) = \frac {1}{E [ M ]} - 1 - \frac {1}{E [ M ]} b ^ {\prime} \mathrm {c o v} (f, R _ {i}).
$$

For the multivariate regression of asset  $i$  on the factors

$$
R _ {i} = \alpha_ {i} + \beta_ {i} ^ {\prime} f + \epsilon_ {i}
$$

the vector of betas is given by  $\beta_i' = C_f^{-1}\mathrm{cov}(f,R_i)$  with  $C_f$  the factor covariance matrix. Substituting this expression into the above expected return formula for the asset return we get

$$
E [ R _ {i} ] = \kappa + \Lambda^ {\prime} \beta_ {i}
$$

where

$$
\kappa = \frac {1}{E [ M ]} - 1, \Lambda = \frac {1}{E [ M ]} b C _ {f}.
$$

This proves the claim.

To prove the other direction, we assume that  $E[R_i] = \kappa + \Lambda' \beta_i$  holds for some scalar  $\kappa$  and some vector  $\Lambda$  for each asset  $i$ . We search for  $a, b$  such that  $M = a + b'f$  follows. Since

$$
E [ R _ {i} ] = \kappa + \Lambda^ {\prime} \beta_ {i} = \kappa + \Lambda^ {\prime} C _ {f} ^ {- 1} \operatorname {c o v} (f, R _ {i})
$$

it suffices to have  $\kappa = \frac{1}{E[M]} - 1$  and  $b = -E[M]C_f^{-1}\Lambda$ . Choosing

$$
b = - \frac {1}{1 + \kappa} C _ {f} ^ {- 1} \Lambda , a = \frac {1}{1 + \kappa} (1 + \mu_ {f} ^ {\prime} C _ {f} ^ {- 1} \Lambda)
$$

the random variable  $M = a + b'f$  is such that for each asset  $i$  the equation  $E[R_i] = \kappa + \Lambda' \beta_i$  holds. Therefore,

$$
E [ R _ {i} ] = \frac {1}{E [ M ]} - 1 - \frac {1}{E [ M ]} b ^ {\prime} \mathrm {c o v} (f, R _ {i})
$$

holds too and  $M$  is a SDF.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/82b80eead8ef9ccab4b6dacfcc38cd46733153735adb5416434061b9caedc75e.jpg)

The proof is taken from Wikipedia. We prove the bias-variance equation 6.4:

Proof. For any random variable  $X$  we have

$$
\operatorname {V a r} [ X ] = \operatorname {E} \left[ X ^ {2} \right] - \left(\operatorname {E} [ X ]\right) ^ {2}
$$

Rearranging:

$$
\operatorname {E} \left[ X ^ {2} \right] = \operatorname {V a r} [ X ] + \left(\operatorname {E} [ X ]\right) ^ {2}
$$

Since  $f$  is deterministic,  $\operatorname{E}[f] = f$ . Given  $y = f + \varepsilon$  and  $\operatorname{E}[\varepsilon] = 0$ , implies  $\operatorname{E}[y] = \operatorname{E}[f + \varepsilon] = \operatorname{E}[f] = f$ . Since  $\operatorname{Var}[\varepsilon] = \sigma^2$

$$
\mathrm {V a r} [ y ] = \mathrm {E} [ (y - \mathrm {E} [ y ]) ^ {2} ] = \mathrm {E} [ (y - f) ^ {2} ] = \mathrm {E} [ (f + \varepsilon - f) ^ {2} ] = \mathrm {E} [ \varepsilon^ {2} ] = \mathrm {V a r} [ \varepsilon ] + \left(\mathrm {E} [ \varepsilon ]\right) ^ {2} = \sigma^ {2}
$$

Thus, since  $\varepsilon$  and  $\hat{f}$  are independent, we can write

$$
\begin{array}{l} \operatorname {E} \left[ (y - \hat {f}) ^ {2} \right] = \operatorname {E} [ y ^ {2} + \hat {f} ^ {2} - 2 y \hat {f} ] = \operatorname {E} [ y ^ {2} ] + \operatorname {E} [ \hat {f} ^ {2} ] - \operatorname {E} [ 2 y \hat {f} ] \\ = \operatorname {V a r} [ y ] + \operatorname {E} [ y ] ^ {2} + \operatorname {V a r} [ \hat {f} ] + \operatorname {E} [ \hat {f} ] ^ {2} - 2 f \operatorname {E} [ \hat {f} ] \\ = \operatorname {V a r} [ y ] + \operatorname {V a r} [ \hat {f} ] + \left(f ^ {2} - 2 f \operatorname {E} [ \hat {f} ] + \operatorname {E} [ \hat {f} ] ^ {2}\right) \\ = \mathrm {V a r} [ y ] + \mathrm {V a r} [ \hat {f} ] + (f - \mathrm {E} [ \hat {f} ]) ^ {2} = \sigma^ {2} + \mathrm {V a r} [ \hat {f} ] + \mathrm {B i a s} [ \hat {f} ] ^ {2} \\ \end{array}
$$

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/5642b857ade2d8b9c969d75f7c0549c32d9ecab324c8f00aa7b302e6b4857e21.jpg)

We prove Proposition 99:

Proof. The following bounds are used over and over in statistical learning theory.

Theorem 119 (Hoeffding). Let  $X_{1},\ldots ,X_{n}$  be independent bounded random variables with  $X_{i}$  taking values in  $[a_i,b_i]$ . Let  $S_{n} = \sum_{i}^{n}X_{i}$ . Then for every  $\epsilon >0$ :

$$
P \left(\left| S _ {n} - E \left(S _ {n}\right) \right| \geq \epsilon\right) \leq 2 e ^ {- 2 \frac {\epsilon}{W _ {n} ^ {2}}} \tag {7.20}
$$

with  $W_{n}^{2} = \sum_{i}(b_{i} - a_{i})^{2}$

The proof uses a technical lemma and the Chernoff bounding method.

Lemma 120. Let  $X$  be a random variable with expected value zero and taking values in the interval  $[a, b]$ . For  $s > 0$ ,

$$
E [ e ^ {s X} ] \leq e ^ {s ^ {2} (b - a) ^ {2} / 8}.
$$

Proof. The convexity of the exponential function implies

$$
e ^ {s x} \leq \frac {x - a}{b - a} e ^ {s b} + \frac {b - x}{b - a} e ^ {s a}.
$$

Since  $E[X] = 0$  and setting  $p = -a / (b - a)$  if follows

$$
E [ e ^ {s X} ] \leq - \frac {a}{b - a} e ^ {s b} + \frac {b}{b - a} e ^ {s a} = (1 - p + p e ^ {s (b - a)}) e ^ {- s p (b - a)}.
$$

Setting  $g(u) = -pu + \log (-p + pe^u), u \coloneqq s(b - a)$  we can write

$$
E [ e ^ {s X} ] \leq e ^ {g (u)}.
$$

The function  $g$  satisfies  $g(0) = g'(0) = 0$  by taking the derivative the second derivative satisfies  $g''(u) \leq 1/4$ . Taylor's theorem up to second order around zero implies for some  $c \in [0, u]$  (the first two terms in the series are zero):

$$
g (u) = \frac {1}{2} u ^ {2} g ^ {\prime \prime} (c) \leq \frac {u ^ {2}}{8} = \frac {s ^ {2} (b - a) ^ {2}}{8}.
$$

□

Using this lemma, we prove Hoeffding's theorem.

Let  $X$  be a non-negative random variable and  $\epsilon > 0$ . The inequality of Markov states

$$
P [ X \geq \epsilon ] \leq \frac {E [ X ]}{\epsilon}.
$$

Hence for  $s > 0$ :

$$
P [ X \geq \epsilon ] = P [ e ^ {s X} \geq e ^ {s \epsilon} ] \leq \frac {E [ e ^ {s X} ]}{e ^ {s \epsilon}}.
$$

The Chernoff method means to find a positive  $s$  such that an upper bound on a random expression is minimized:

$$
\begin{array}{l} P \left(S _ {n} - E \left[ S _ {n} \right] \geq \epsilon\right) \leq e ^ {- s \epsilon} E \left[ e ^ {s \sum_ {i} \left(X _ {i} - E \left[ X _ {i} \right]\right)} \right] \\ = e ^ {- s \epsilon} \prod_ {i} E \left[ e ^ {s \left(X _ {i} - E \left[ X _ {i} \right]\right)} \right] \\ \leq e ^ {- s \epsilon} \prod_ {i} e ^ {s (X _ {i} - E [ X _ {i} ])} \\ = e ^ {- s \epsilon} e ^ {s \sum_ {i} (b _ {i} - a _ {i}) ^ {2}) / 8} \\ := e ^ {- 2 \epsilon^ {2} / W _ {n} ^ {2}} \\ \end{array}
$$

by using first the Markov inequality, then the independence of the random variables, then the technical lemma and finally by choosing  $s$  appropriately. This concludes the proof for  $S_{n} - E[S_{n}]$ . The same bounds hold for  $E[S_{n}] - S_{n}$  and hence the proof of the theorem follows.

We prove Proposition 103:

Proof. Let  $f$  be the function were the supremum is attained. Then

$$
\begin{array}{l} \mathcal {X} (R _ {\mathrm {e m p}} (f) - R (f) | \geq \epsilon) \mathcal {X} (R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) \leq \epsilon / 2) \\ = \chi \left(R _ {\text {e m p}} (f) - R (f) \geq \epsilon \wedge R _ {\text {e m p}} (f) - R _ {\text {e m p}} ^ {\prime} (f) \geq - \epsilon / 2\right) \\ \leq \chi_ {R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) > \epsilon / 2}. \\ \end{array}
$$

Taking expectations w.r.t the ghost sample:

$$
\chi_ {R _ {\mathrm {e m p}} (f) - R (f) \geq \epsilon} P \left(R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) \leq \epsilon / 2\right) \leq P ^ {\prime} \left(R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) > \epsilon / 2\right).
$$

The inequality of Chebyshev implies:

$$
P ^ {\prime} (R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) > \epsilon / 2) \leq \frac {4 \mathrm {v a r} (f)}{n \epsilon^ {2}} \leq \frac {1}{n \epsilon^ {2}}
$$

since random variables with values in the unit interval have a variance of less than  $1/4$ . Putting things together we have:

$$
\chi_ {R _ {\mathrm {e m p}} (f) - R (f) \geq \epsilon} \left(1 - \frac {1}{n \epsilon^ {2}}\right) \leq P ^ {\prime} \left(R _ {\mathrm {e m p}} (f) - R _ {\mathrm {e m p}} ^ {\prime} (f) > \epsilon / 2\right).
$$

Taking expectations w.r.t. the first sample proves the result.

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-06/2b692f90-c24f-4261-a355-510960e02c89/74f9e919bc9702abb508e693bc4ff009f05d1d1aa205f03fd09f20f69ca9638f.jpg)

We prove Proposition 106:

Proof. By definition, we get in update  $k$

$$
\langle \theta^ {*}, \theta^ {(k)} \rangle = \langle \theta^ {*}, \theta^ {(k - 1)} \rangle + \langle y _ {m} (\theta^ {*}), x _ {m} \rangle \geq \langle \theta^ {*}, \theta^ {(k - 1)} \rangle + \gamma .
$$

Iteration for  $k$  updates

$$
\langle \theta^ {*}, \theta^ {(k)} \rangle \geq k \gamma .
$$

The next step is to bound the norm  $||\theta^{(k)}||^2$ . By definition, the boundness assumption of  $x$  and  $k$  iterations we get:

$$
| | \theta^ {(k)} | | ^ {2} = | | \theta^ {(k - 1)} + y _ {m} x _ {m} | | ^ {2} \leq | | \theta^ {(k - 1)} | | ^ {2} + r ^ {2} \leq k r ^ {2}.
$$

Therefore,  $\langle \theta^{*},\theta^{(k)}\rangle$  grows at least linearly and  $||\theta^{(k)}||^2$  increases at most linearly. We consider the cosine

$$
\cos (\theta^ {*}, \theta^ {(k)}) = \frac {\langle \theta^ {*} , \theta^ {(k)} \rangle}{| | \theta^ {(k)} | | ^ {2} | | \theta^ {*} | | ^ {2}} \geq \frac {k \gamma}{\sqrt {k r ^ {2}} | | \theta^ {*} | |}.
$$

By combining the two we can show that the cosine of the angle between  $\theta^{(k)}$  and  $\theta^*$  has to increase by a finite increment due to each update. Since cosine is bounded, we can only make a finite number of updates.

# Chapter 8

# Appendix

<table><tr><td>AM Firm</td><td>Description</td><td>USD bn</td><td>52w</td><td>2y</td><td>3y</td><td>5y</td></tr><tr><td>Vanguard</td><td>S&amp;P 500 ETF</td><td>224</td><td>20.2</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>Vanguard</td><td>500 Inx</td><td>182</td><td>19.6</td><td>14.1</td><td>10.3</td><td>15.6</td></tr><tr><td>Vanguard</td><td>TSM Idx, Adm</td><td>138</td><td>20.2</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>iShares:Core</td><td>Instl Idx, Inst</td><td>133</td><td>20.2</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>Vanguard</td><td>S&amp;P 500</td><td>123</td><td>19.5</td><td>14</td><td>10.1</td><td>15.48</td></tr><tr><td>Vanguard</td><td>TSM Idx;Inv</td><td>121</td><td>19.6</td><td>14.1</td><td>na</td><td>na</td></tr><tr><td>Vanguard</td><td>TSM Idx;Inst+</td><td>116</td><td>28.1</td><td>12.6</td><td>6.7</td><td>8.1</td></tr><tr><td>Vanguard</td><td>Tot I Stk, Ins</td><td>108</td><td>19.6</td><td>14.1</td><td>10.3</td><td>15.6</td></tr><tr><td>Vanguard</td><td>TSM Idx, Inst</td><td>92</td><td>20.2</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>Fidelity</td><td>Instl Indx, InsP</td><td>89</td><td>30.8</td><td>15.5</td><td>13.3</td><td>16.8</td></tr><tr><td>Vanguard</td><td>Contrafund</td><td>88</td><td>28.3</td><td>12.7</td><td>6.8</td><td>8.2</td></tr><tr><td>Vanguard</td><td>Tot I Stk, Ins</td><td>86</td><td>19.6</td><td>14.1</td><td>10.3</td><td>15.6</td></tr><tr><td>Vanguard</td><td>TSM, Idx, ETF</td><td>85</td><td>14.3</td><td>10.5</td><td>7.7</td><td>10.8</td></tr><tr><td>Vanguard</td><td>Wellington;Adm</td><td>85</td><td>3.5</td><td>2.75</td><td>2.3</td><td>1.9</td></tr><tr><td>American</td><td>Tot Bd II, INV</td><td>84</td><td>24.1</td><td>15</td><td>12.1</td><td>16.4</td></tr><tr><td>iShares:MSCI</td><td>Funds Gro, A</td><td>81</td><td>27.4</td><td>9.8</td><td>6.1</td><td>8.7</td></tr><tr><td>Vanguard</td><td>EAFE ETF</td><td>81</td><td>3.7</td><td>2.9</td><td>2.4</td><td>2.0</td></tr><tr><td>Vanguard</td><td>Tot BD, Adm</td><td>78</td><td>20.2</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>American</td><td>500 Index, ETF</td><td>77</td><td>12.7</td><td>9.8</td><td>6.2</td><td>9.6</td></tr><tr><td>Fidelity</td><td>Funds Inc, A</td><td>72</td><td>20.1</td><td>14</td><td>10.4</td><td>15.7</td></tr><tr><td>American</td><td>500 Idx, Pr</td><td>71</td><td>15.08</td><td>8.5</td><td>4.9</td><td>7.9</td></tr><tr><td>Dodge</td><td>Funds CIB, A</td><td>68</td><td>14.9</td><td>15.1</td><td>9.6</td><td>16.4</td></tr><tr><td>Vanguard</td><td>Cox Stock</td><td>65</td><td>27.5</td><td>11.2</td><td>7.3</td><td>9.3</td></tr><tr><td>Dodge</td><td>FTSE ETF</td><td>65</td><td>26.5</td><td>11.8</td><td>4.51</td><td>10</td></tr></table>

Table 8.1: Source: Lipper Performance Report. November 2017

Largest Custodians  

<table><tr><td>Rank</td><td>Provider</td><td>Assets under custody USD bn</td><td>Reference date</td></tr><tr><td>1</td><td>BNY Mellon</td><td>28,300</td><td>Sep 30, 2014</td></tr><tr><td>2</td><td>J.P. Morgan</td><td>21,000</td><td>Mar 31, 2014</td></tr><tr><td>3</td><td>State Street</td><td>20,996</td><td>Mar 31, 2014</td></tr><tr><td>4</td><td>Citi</td><td>14,700</td><td>Mar 31, 2014</td></tr><tr><td>5</td><td>BNP Paribas</td><td>9,447</td><td>Jun 30, 2014</td></tr><tr><td>6</td><td>HSBC Securities Services</td><td>6,210</td><td>Dec 31, 2013</td></tr><tr><td>7</td><td>Northern Trust</td><td>5,910</td><td>Sep 30, 2014</td></tr><tr><td>8</td><td>Societe Generale</td><td>4,915</td><td>Sep 30, 2014</td></tr><tr><td>9</td><td>Brown Brothers Harriman</td><td>3,800</td><td>Mar 31, 2014</td></tr><tr><td>10</td><td>UBS AG</td><td>3,438</td><td>Sep 30, 2014</td></tr><tr><td>11</td><td>SIX Securities Services</td><td>3,247</td><td>Dec 31, 2013</td></tr><tr><td>12</td><td>CACEIS</td><td>3,200</td><td>Dec 31, 2013</td></tr></table>

Table 8.2: Source: globalcustody.net.

# Chapter 9

# References

1. D. Acemoglu, A. Malekian and A. Ozdaglar, Network Security and Contagion, Journal of Economic Theory 166, 536-585, 2016.  
2. A. Acquisti, C. Taylor, and L. Wagman, The Economics of Privacy, Journal of Economic Literature 54. 2442-492, 2016.  
3. Accenture, Digital Business Era: Stretch Your Boundaries, Accenture Technology Vision 2015, 2015.  
4. C. Ackermann, R. McEnally and D. Ravenscraft, The Performance of Hedge Funds: Risk, Return, and Incentives. Journal of Finance, 833-874, 1999.  
5. V. Agarwal, N.D. Daniel and N.Y. Naik, Role of Managerial Incentives and Discretion in Hedge Fund Performance. The Journal of Finance, 64(5), 2221-2256, 2009.  
6. A. Agrawal, J. Horton, N. Lacetera and E. Lyons, Digitization and the Contract Labor Market: A Research Agenda, in A. Goldfarb, S. Greenstein and C. Tucker, Economics of Digitization: An Agenda. National Bureau of Economic Research, 2013.  
7. h. Albrecher, P. Embrechts, D. Filipovic, G. W. Harrison, P. Koch, S. Loisel, P. Vanini and J. Wagner, Old-Age Provision: Past, present, Future. European actuarial journal, 6(2), 287-306, 2016.  
8. G.S. Amin and H.M. Kat, Hedge Fund Performance 1990 - 2000: Do the 'Money Machines' Really add Value?, Journal of financial and quantitative analysis, 38(02), 251-274, 2003.  
9. M. Andersson, P. Bolton and F. Samama, Hedging Climate Risk, Financial Analysts Journal, 72(3), pp. 13-32, 2016.  
10. R.M. Anderson, S.W. Bianchi and L.R. Goldberg, Determinants of Levered Portfolio Performance, Forthcoming Financial Analysts Journal, UCLA at Berkeley, 2014.  
11. R. Anderson and T. Moore, The Economics of Information Security, Science 314, 610-613, 2006.  
12. A. Ang, Mean-Variance Investing, Lecture Notes Columbia University, ssnr.com, 2012.  
13. A. Ang, Asset Management. A Systematic Approach to Factor Investing, Oxford University Press, 2014.  
14. A. Ang, W. Goetzmann, and S. Schaefer, Evaluation of Active Management of the Norwegian GPFG, Norway: Ministry of Finance, 2009. (the Professor's Report)
15. A. Ang, S. Gorovyy and G.B. Van Inwegen, Hedge Fund leverage. Journal of Financial Economics, 102(1), 102-126, 2011.  
16. A. Ang, D. Basu, M. D. Gates and V. Karir, Model Portfolios, ssnr.com, 2018.  
17. A. M. Antonopoulos, Mastering Bitcoin, O'Reilly Books, New York, 2015.  
18. F. Allen and D. Gale, Financial Markets, Intermediaries and Intertemporal Smoothing, J. Pol. Econom., 105, 523-546, 1997.  
19. A. Artzner, F. Delbaen, J.-M. Eber and D. Heaths, Coherent Measures of Risk, Mathematical Finance, 9(3), 203-228, 1999.  
20. T. Aste, Blockchain, University College London, Center for Blockchain Technologies, preprint ssnr.com, 2016.  
21. C. S. Asness, Hedge Funds: The (Somewhat Tepid) Defense, AQR, October 24, 2014.  
22. C.S. Asness, How Can a Strategy Still Work if Everyone Knows About it? International Invest Magazine, September, 2015.  
23. C.S. Asness and J. Liew, The Great Divide of Market Efficiency, Institutional Investor, March 03, 2014.  
24. C.S. Asness, A. Frazzini, R. Israel and T. Mokowitz, Fact, Fiction, and Value Investing, Forthcoming, Journal of Portfolio Management, Fall 2015, 2015.  
25. V. Agarwal, N. D. Daniel, and N. Y. Naik, Do Hedge Funds Manage Their Reported Returns?, Review of Financial Studies, forthcoming, 2011.  
26. V. Agarwal and N.Y. Naik, Multi-Period Performance Persistence Analysis of Hedge Funds, JFQE, 35(03), 327-342, 2000.  
27. F. Allen, J. Barth and G. Yago, Fixing the Housing Market: Financial Innovations for the Future, Wharton School Publishing-Milken Institute Series on Financial Innovations, Upper Saddle River, NJ: Pearson Education, 2012.  
28. F. Allen and G. Yago, Financing the Futures. Market-Based Innovations for Growth. Wharton School of Publishing and Milken Institute, 2012.  
29. G.O. Aragon and J.S. Martin, A Unique View of Hedge Fund Derivatives Usage: Safeguard or Speculation? Journal of Financial Economics, 105(2), 436-456, 2012.  
30. Assenagon Asset Management, 1. Assenagon Derivatetag am See, 2013.  
31. M. Avellaneda and D. Dobi, Structural Slippage of Leveraged ETFs, ssnr.com, 2012.  
32. D. Avramov, R. Kosowski, N.Y. Naik and M. Teo, Hedge Funds, Managerial Skill, and Macroeconomic Variables. Journal of Financial Economics, 99(3), 672-692, 2011.  
33. Ph. Bacchetta, C. Tille and E. van Wincoop, Self-Fulfilling Risk Panics, American Economic Review 102, 3674-3700, 2013.  
34. K. E. Back, Asset Pricing and Portfolio Choice Theory, Oxford University Press, 2010.  
35. Bank of England, The Economics of Digital Currencies, Quarterly Bulletin, Q3, 2014.  
36. D. H. Bailey, J. M. Borwein, M. L. de Prado and O. J. Zhux, Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-Of-Sample Performance, Notices of the American Mathematical Society, 61(5), 458-471, 2014.
37. M. Baker, B. Bradley and J. Wurgler, Benchmarks as Limits to Arbitrage: Understanding the Low-Volatility Anomaly, Financial Analysts Journal, 67(1):40-54, 2011.  
38. N. Barberis and A. Shleifer, Style Investing, Journal of Financial Economics 68 (2), 181-99, 2003.  
39. L. Barras, O. Scailet, and R. Wermers, False Discoveries in Mutual Fund Performance: Measuring Luck in Estimated Alphas, The Journal of Finance 65.1, 179-216, 2010.  
40. G. Baquero and M. Verbeek, A Portrait of Hedge Fund Investors: Flows. Performance and Smart Money, ssnr.com, 2005.  
41. P.A. Bares, R. Gibson and Gyger, Performance in the Hedge Funds Industry: An Analysis of Short-and Long-Term Persistence, The Journal of Alternative Investments, 6(3), 25-41, 2003.  
42. M. Bech and R. Garratt, Central Cank Cryptocurrencies, BIS Quarterly Review, September, 55-70, 2017.  
43. L. Bennanni, T. Le Guenedal, F. Lepetit, L. Ly, V. Mortier, and T. Roncalli, How ESG Investing Has Impacted the Asset Pricing in the Equity Market, 2018.  
44. I. Ben-David, F. Franzoni, A. Landier and R. Moussawi, 2012, Do Hedge Funds Manipulate Stock Prices, Fisher College of Business Working Paper Series.  
45. R. Berentsen and F. Schaer, Bitcoin: A Currency Here to Stay?, Swiss Finance Institute Seminar, Zurich, October, 2014.  
46. R. Berentsen and F. Schaer, Bitcoin, Blockchain, Kryptoassets, Universität Basel, 2017.  
47. Roland Berger, FinTechs in Europe - Challenger and Partner, Zurich, November, 2016.  
48. P. L. Bernstein, Wimps and Consequences, The Journal of Portfolio Management, p.1, 1999.  
49. BIS, Cryptocurrencies: Looking Beyond the Hype, Bank of International Settlement, Basel, 2018.  
50. Black Rock, ETF landscape: Global Handbook Q1, 2011.  
51. F. Black, M. C. Jensen and M.S. Scholes, The Capital Asset Pricing model: Some Empirical Tests, papers.ssrn.com, 1972.  
52. F. Black and R. Litterman, Robert, Asset Allocation: Combining Investor Views with Market Equilibrium, Goldman Sachs Fixed Income Research Note, September, 1990.  
53. R. B. Bliss and R. Steigerwald, Derivatives Clearing and Settlement: A Comparison of Central Counterparties and Alternative Structures, Economic Perspectives, 30(4), 2006.  
54. D. Blitz, Strategic Allocation to Premiums in the Equity Market, ssnr.com, 2011.  
55. J.-P. Bouchaud and M. Potters, Financial Applications of Random Matrix Theory: a Short Review, arXiv preprint arXiv:0910.1205, 2009.  
56. D. Blitz, Is Rebalancing the Source of Factor Premiums?, The Journal of Portfolio Management, Summer 2015, 2015.  
57. R. Boehme, N. Christin, B. Edelmann and T. Moore, Bitcoin: Economics, Technology and Governance, Journal of Economic Perspectives, Vol. 29, 2, Spring 2015, 213-238, 2015.
58. A. Borsch-Supan, K. H. Alcser, Health, Aging and Retirement in Europe: First Results from the Survey of Health, Ageing and Retirement in Europe. Mannheim: Mannheim Research Institute for the Economics of Aging (MEA), 2005.  
59. A. Börsch-Supan, A. Ludwig, and J. Winter, Ageing, Pension Reform and Capital Flows: A Multi-Country Simulation Model, Economica 73.292, 625-658, 2006.  
60. A. Börsch-Supan, M. Brandt, C. Hunkler, T. Kneip, J. Korbmacher, F. Malter and S. Zuber, Data resource profile: the Survey of Health, Ageing and Retirement in Europe (SHARE), International journal of epidemiology, dyt088, 2013.  
61. C. Badertscher, J. Garay, U. Maurer, D. Tschudi and V. Zikas, But why does it Work? A Rational Protocol Design Treatment of Bitcoin, In Annual International Conference on the Theory and Applications of Cryptographic Techniques, Springer, Cham 34-65, 2018.  
62. T. Bourgeron, E. Lezmi and T. Roncalli, Robust Asset Allocation for Robo-Advisors, arXiv, arxiv.org/abs/1902.07449, 2018.  
63. M.W. Brandt, Portfolio Choice Problems, Brandt, in Y. Ait-Sahalia and L.P. Hansen (eds.), Handbook of Financial Econometrics, Volume 1: Tools and Techniques, North Holland, 269-336, 2010.  
64. M. Brenner and Y. Izhakian, Asset Prices and Ambiguity: Empirical Evidence, Stern School of Business, Finance Working Paper Series, FIN-11-10, 2011.  
65. R. Brian, F. Nielsen and D. Steffek, Portfolio of Risk Premia: A New Approach to Diversification, MSCI Barra Research Insights, 2009.  
66. S. Browne, Reaching Goals by a Deadline: Digital Options and Continuous-Time Active Portfolio Management, Adv. Appl. Prob. 31, 551-557, 1999.  
67. S. J. Byun and B.H. Jeon Momentum Crashes and the 52-Week High, 2018.  
68. R. G. Brown, J. Carlyle, I. Grigg and M. Hearn, Corda: An Introduction, squarespace.com, 2016.  
69. S.J. Brown, W. Goetzmann, R.G. Ibbotson and S.A. Ross, Survivorship Bias in Performance Studies, Review of Financial Studies, 5(4), 553-580, 1992.  
70. S.J. Brown, W. Goetzmann and R.G. Ibbotson, Offshore Hedge Funds: Survival and Performance, 1989-95, Journal of Business, 72(1), 1999.  
71. S.J. Brown, W. Goetzmann and J.M. Park, Conditions for Survival: Changing Risk and the Performance of Hedge Fund Managers and CTAs, ssnr.com, 1999.  
72. B. Bruder, N. Gaussel, J.-C. Richard and T. Roncalli, Regularization of Portfolio Allocation, Lyxor White Paper Series, 10, 2013.  
73. J. Bruna, Mathematics of Deep Learning, Courant Institute of Mathematical Science, NYU, 2018.  
74. C. Burges, A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery, 2. Jg., Nr. 2, S. 121-167, 1998.  
75. A. Corbellini, Elliptic Curve Cryptography: A Gentle Introduction, webpage of A. Corbellini, 2015.
76. R.J. Caballero, Macroeconomics after the Crisis: Time to Deal with the Pretense-of-Knowledge Syndrome, Journal of Economic Perspectives, Volume 24, Number 4, Fall, 85 - 102, 2010.  
77. R.J. Caballero and A. Krishnamurthy, Collective risk management in a flight to quality episode. The Journal of Finance, 63(5), 2195-2230, 2008.  
78. C. Camerer, G. Loewenstein, and D. Prelec. Neuroeconomics: How Neuroscience can Inform Economics. Journal of economic literature: 9-64, 2005.  
79. J.Y. Campbell and L. M. Viceira, Strategic Asset Allocation: Portfolio Choice for Long-Term Investors, books.gooble.com; 2002.  
80. C. Cao, Y. Chen, B. Liang and A.W. Lo, Can Hedge Funds Time Market Liquidity?, Journal of Financial Economics, 109(2), 493-516, 2013.  
81. M.M. Carhart, On Persistence in Mutual Fund Performance, The Journal of finance, 52(1), 57-82, 1997.  
82. Z. Cazalet and T. Roncalli, Style Analysis and Mutual Fund Performance Measurement Revisited, Lyxor Research Paper, 2014.  
83. Y. Chen, Timing Ability in the Focus Market of Hedge Funds, Journal of Investment Management, 5(2), 66, 2007.  
84. Y. Chen, Derivatives Use and Risk Taking: Evidence from the Hedge Fund industry, Journal of Financial and Quantitative Analysis, 46(04), 1073-1106, 2011.  
85. CEM Benchmarking, CEM Toronto, 2014.  
86. N. Chatsanga and A.J. Parkes, International portfolio optimisation with integrated currency overlay costs and constraints. Expert Systems with Applications, 83, 333-349, 2017.  
87. P.Cheridito and E. Kromer, Reward-Risk Ratios, Journal of Investment Strategies 3(1), 1-16, 2013.  
88. T. Chordia, A. Goyal and A. Saretto, p-hacking: Evidence from Two Million Trading Strategies, University of Lausanne, preprint, 2017.  
89. Y. Choueifaty and YCoignard, Toward Maximum Diversification. Journal of Portfolio Management, 35(1), 40, 2008.  
90. M.M. Christensen, On the History of the Growth Optimal Portfolio, University Southern Denmark, Preprint, 2005.  
91. J. Cochrane, Asset Pricing, Princeton University Press, 2005.  
92. J. Cochrane, The Dog That Did Not Bark: A Defense of Return Predictability, Review of Financial Studies 21 (4): 1533 - 75, 2077.  
93. J. Cochrane, Discount Rates, Presidential Address AFA 2010, Journal of Finance, Vol LXVI, 4, August, 2011.  
94. P. Cocoma, M. Czasonis, M. Kritzman and D. Turkington, Facts about Factors. The Journal of Portfolio Management, 43(5), 55-65, 2017.  
95. N. Cuche-Curti, O. Sigrist and F. Boucard, Blockchain: An Introduction, Research and Policy Notes, Swiss National Bank, 2016.
96. J. Cui, F. De Jong and E. Ponds, Intergenerational Risk Sharing within Funded Pension Schemes. Journal of Pension Economics and Finance 10.01, 1-29, 2011.  
97. C. Culp and J. Cochrane, Equilibrium Asset Pricing and Discount Factors: Overview and Implications for Derivatives Valuation and Risk Management, Modern Risk Management: A History. Peter Field, ed. London: Risk Books, 2003.  
98. T. Dangl, O. Randl and J. Zechner, Risk Control in Asset Management: Motives and Concepts, K. Glau et al. (eds), Innovation in Quantitative Risk Management, Springer Proceedings in Mathematics and Statistics 99, 239-266, 2015.  
99. V. DeMiguel, V. Galappi and R. Uppal, Optimal Versus Naive Diversification: How Inefficient is the 1/n Portfolio Strategy?, Review of Financial Studies, 22(5), 1915-1953, 2009.  
100. V. DeMiguel, Y. Plyakha, R. Uppal, G. Vilkov, Improving Portfolio Selection using Option-Implied Volatility and Skewness, Forthcoming in Journal of Financial and Quantitative Analysis, 2010.  
101. G. De Nard, O. Ledoit, and M. Wolf, Factor Models for Portfolio Selection in Large Dimensions: The Good, the Better and the Ugly, Working Paper No. 290, 2018.  
102. M. L. de Prado, Building Diversified Portfolios that Outperform out-of-sample, ssnr.com, May, 2016.  
103. L. Deville, Exchange Traded Funds: History, Trading, and Research, Handbook of Financial Engineering, Zopounidis, Doumpos and Pardalos (eds), 67-99, 2007.  
104. K. Daniel and T. Moskowitz, Momentum Crashes, The Q-Group: Fall Seminar, 2012.  
105. K. Daniel and S. Titman, Evidence on the Characteristic of Cross Sectional Variation in Stock Returns, Journal of Finance 55 (1), 380-406, 1997.  
106. Deutsche Bank, Equity Risk Premia, Deutsche Bank London, February, 2015.  
107. Deutsche Bank, A New Asset Allocation Paradigm, Deutsche Bank London, July, 2012.  
108. F.X. Diebold, A. Hickman, A. Inoue, and T. Schuermann, Converting 1-Day Volatility to h-Day Volatility: Scaling by Root-h is Worse than You Think, Risk, 11, 104-107, 1998.  
109. D. Dobi and M. Avellaneda, Structural Slippage of Leveraged ETFs, Preprint NYU, 2012.  
110. J. Dow and S. R. d. C.Werlang, Uncertainty Aversion, Risk Aversion, and the Optimal Choice of Portfolio, Econometrica, Vol. 60, No. 1, 197 - 204, 1992.  
111. M. Dudler, B. Gmur and S. Malamud, Risk-Adjusted Time Series Momentum, Working Paper, 2014.  
112. S. Duivestein, M. van Doorn, T. van manen, J. Bloem and E. van Ommeren, Design to Disrupt, Blockchain: Cryptoplatform for a Frictionless Economy, SogetiLabs, 2016.  
113. E. Van Duuren, A. Plantinga and B. Scholtens, ESG integration and the investment management process: Fundamental investing reinvented. Journal of Business Ethics, 138(3), 525-533, 2016.  
114. F.R. Edwards and M.O. Caglayan, Hedge Fund Performance and manager skill, ssnr.com, 2011.  
115. EFAMA, European Fund and Asset Management Association, Annual Figure 2013, 2014.
116. EFAMA, European Fund and Asset Management Association, Annual Figure 2017, 2018.  
117. D. Ellsberg, Risk, Ambiguity, and the Savage Axioms, Quarterly Journal of Economics, 75, 643-669, 1961.  
118. E.J. Elton and M. J. Gruber, Risk Reduction and Portfolio Size: An Analytical Solution, Journal of Business: 415-437, 1977.  
119. Ernst & Young, What's new? Innovation for Asset Management, 2012 Survey, 2012.  
120. Ethereum, www.ethereum.org, 2016.  
121. ETF Staff, A Short Course in Currency Overlay. etf.com, April, 1999.  
122. I. Eyal and E. G. Sirer, Majority is not Enough: Bitcoin Mining is Vulnerable, International Conference on Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2014.  
123. F. Fabozzi, R. J. Shiller, and R. Tunaru, Hedging Real-Estate Risk, working paper 09-12, Yale International Center for Finance, 2009.  
124. M. Faber, A Quantitative Approach to Tactical Asset Allocation. Journal of Wealth Management 9 (4), 69 - 79, 2007.  
125. E.F. Fama, The Behavior of Stock Market Prices, Journal of Business, 38, 34-101, 1965.  
126. E.F. Fama, Efficient Capital Markets: A Review of Theory and Empirical Work, Journal of Finance 25, 383 - 417, 1970.  
127. E.F. Fama, Efficient Markets: II, Journal of Finance, 46(5), 1575-1618, 1991.  
128. E. F. Fama and J. D. MacBeth, Risk, Return, and Equilibrium: Empirical Tests, Journal of political economy, 81(3), 607-636, 1973.  
129. E.F. Fama and K. R. French, Permanent and Temporary Components of Stock Prices, Journal of Political Economy 96: (2): 246 - 67. 1988.  
130. E.F. Fama and K.R. French, Disagreement, Tastes, and Asset Prices, Journal of Financial Economics 83 (3), 667-89, 2007.  
131. E.F. Fama and K.R. French, A Five-Factor Asset Pricing Model, Journal of Financial Economics, 116, 1-22, 2015.  
132. B. Fastrich, S. Paterlini and P. Winker, Constructing Optimal Sparse Portfolios Using Regularization Methods, ssnr.com, 2013.  
133. J. D. Fisher, D.M. Geltner, and R.B. Webb, Value indices of commercial real estate: a comparison of index construction methods. The journal of real estate finance and economics, 9(2), 137-164, 1994  
134. T. Fletcher, Machine Learning for Financial Market Prediction, PhD Thesis University College London, 2012.  
135. A. Frazzini and L. H. Pedersen, *Betting Against Beta*, Journal of Financial Economics 111.1, 1-25, 2014.  
136. G. Frahm and C. Memmel, Dominating estimators for minimum-variance portfolios. Journal of Econometrics, 159(2), 289-302, 2010.
137. P. Franco, Understanding Bitcoin: Cryptography, Engineering and Economics. John Wiley & Sons, 2014.  
138. J. Freire, Massive Data Analysis: Course Overview, NYU School of Engineering, 2015.  
139. C.B. Frey und M.A. Osborne, The Future of Employment: How Susceptible are Jobs to Computerisation?, Oxford, September, 2013.  
140. W. Fung, D.A. Hsieh, N.Y. Naik and R. Ramadorai, Hedge Funds: Performance, Risk, and Capital Formation, The Journal of Finance, 63(4), 1777-1803, 2008.  
141. W. Fung and D.A. Hsieh, Empirical Characteristics of Dynamic Trading Strategies: The Case of Hedge Funds, Review of financial studies, 10(2), 275-302, 1997.  
142. W. Gale and R. Levine, Financial Literacy: What Works? How could it be more Effective, Financial Security Project, Boston College, 2011.  
143. J. Gatheral, Random Matrix Theory and Covariance Estimation, New York, October 3, 2008.  
144. M. Gao and J. Huang, Capitalizing on Capitol Hill: Informed Trading by Hedge Fund Managers, In Fifth Singapore International Conference on Finance, 2011.  
145. D.M. Geltner, N. G. Miller, J. Clayton, and P. Eichholtz, Commercial real estate analysis and investments (Vol. 1, p. 642). Cincinnati, OH: South-western, 2001.  
146. C. R. Genovese, A Tutorial on False Discovery Control, Carnegie Mellon University, 2004.  
147. D.M. Geltner and J. Fisher, Pricing and Index Considerations in Commercial Real Estate Derivatives Journal of Portfolio Management Special Issue: Real Estate, 1 - 21, 2007.  
148. E. Gerbl, Robo-Advisors. Kampf um das große Geld, Bilanz, 22.10.2019.  
149. M. Getmansky, B. Liang, C. Schwarz and R. Wermers, Share Restrictions and Investor Flows in the Hedge Fund Industry, Working Paper, University of Massachusetts, Amherst, 2015.  
150. M. Getmansky, M.P. Lee, and A. Lo, Hedge Funds: A Dynamic Industry In Transition, NBER, 2015.  
151. G. Gigerenzer and G. Goldstein, Reasoning the Fast and Frugal Way: Models of Bounded Rationality, in Heuristics: The Foundations of Adaptive Behavior, eds Gigerenzer G., Hertwig R., Pachur T., editors. (New York: Oxford University Press; ), 31-57, 2011.  
152. C. Gini, Measurement of Inequality of Incomes, The Economic Journal: 124-126, 1921.  
153. P. W. Glimcher, and E. Fehr, eds. Neuroeconomics: Decision making and the brain. Academic Press, 2013.  
154. Global Sustainable Investment Alliance, 2016 Global Sustainable Investment Review, GSIA Report, March, 2017.  
155. W.N. Goetzmann, J.E. Ingersoll and S.A. Ross, High-water Marks and Hedge Fund Management Contracts, Journal of Finance 58, 1685 - 1717, 2003.  
156. W.N. Goetzmann and A. Kumar, Equity Portfolio Diversification, Review of Finance, Vol. 12, No. 3, 433 - 463, 2008.  
157. W.N. Goetzmann and K. Rouwenhorst, The History of Financial Innovation, Carbon Finance Spearker Series at Yale, 2007.
158. S. Goldwasser and M. Bellare, Lecture Notes on Cryptography, MIT, 2008.  
159. I. Goodfellow, Y. Bengio and A. Courville, Deep Learning, MIT Press, 2016.  
160. A. Goyal, Empirical Cross-Sectional Asset Pricing: a Survey, Financial Markets and Portfolio Management, 26(1), 3-38, 2012.  
161. A. Goval and N. Jegadesh, Cross-Sectional and Time-Series Tests of Return Predictability: What Is the Difference? Review of Financial Studies, 31(5), 1784 - 1824, 2018.  
162. A. Goyal and S. Wahal The Selection and Termination of Investment Management Firms by Plan Sponsors, Journal of Finance 63, 1805 - 1847, 2008.  
163. M. Grinblatt and S. Titman, Mutual Fund Performance: An analysis of quarterly portfolio holdings, Journal of business: 393-416, 1989.  
164. R.C. Grinold, The Fundamental Law of Active Management, The Journal of Portfolio Management 15.3, 30-37, 1989.  
165. R.C. Grinold and R.N. Kahn, Active Portfolio Management. A Quantitative Approach for Providing Superior Returns and Controlling Risk, McGraw-Hill, Second Edition, New York, 2000.  
166. S.J. Grossman and J. E. Stiglitz, On the Impossibility of Informationally Efficient Markets. The American Economic Review: 393-408, 1980.  
167. S. Gu, B. T. Kelly and D. Xiu, D., Empirical Asset Pricing Via Machine Learning, Chicago Booth, 2018.  
168. Harvey, C. R., Liu, Y. and Zhu, H., … and the cross-section of expected returns. The Review of Financial Studies, 29(1), 5-68, 2016.  
169. W. Hallerbach, Disentangling Rebalancing Return, Journal of Asset Management, 15, 301-316, 2014.  
170. J. Hansen, Australian house prices: A comparison of hedonic and repeat-sales measures. Economic Record, 85(269), 132-145, 2009.  
171. L. Hansen and T. Sargent, Robust Control and Model Uncertainty. American Economic Review 91 (2), 60-66, University Press, 2008.  
172. C.R. Harvey, Y. Liu and H. Zhu, The Cross-Section of Expected Returns, Working Paper ssrn.com, 2015.  
173. J. Hasanhodzic, A. W. Lo, and E. Viola, Is It Real, or Is It Randomized?: A Financial Turing Test, MIT Working Papers, 2010.  
174. M. Hassine and R. Roncalli, Measuring Performance of Exchange Traded Funds. ssnr.com, 2013.  
175. C. R. Harvey and Y. Liu, Backtesting, Journal of Portfolio Management, Volume 42, Number 1, 13-28, 2015.  
176. C. Harvey and A. Siddique, Conditional Skewness in Asset Pricing Tests, Journal of Finance, 55:1263-1295, 2000.  
177. R. Haugen and A. Heins, Risk and the Rate of Return on Financial Assets: Some old Wine in new Bottles, Journal of Financial and Quantitative Analysis, 10:775-784, 1975.
178. S. Hayley, Diversification Returns, Rebalancing Returns and Volatility Pumping, City University London, 2015.  
179. J. M. Griffin, Are the Fama and French Factors Global or Country Specific?, Review of Financial Studies, 15(3), 783-803, 2002.  
180. S. Gu, B. Kelly and D. Xio, Empirical Asset Pricing via Machine Learning, Booth School of Business University of Chicago, July 21, 2018.  
181. E. Hazan, Theoretical Machine Learning, Princeton University, 2017.  
182. G. He and R. Litterman, The Intuition Behind Black-Litterman Model Portfolios, Goldman Sachs Asset Management Working paper, 1999.  
183. R.D. Henriksson and R.C. Merton, On Market Timing and Investment Performance. II. Statistical Procedures for Evaluating Forecasting Skills, Journal of business, 513-533, 1981.  
184. O.C. Herfindahl, Concentration in the Steel Industry, Diss. Columbia University, 1950.  
185. U. Herold, Portfolio Construction with Qualitative Forecasts, Journal of Portfolio Management, Fall 2003, 61-72, 2003.  
186. E. Hjalmarsson, Portfolio Diversification Across Characteristics, The Journal of Investing, Vol. 20, No. 4, 2011.  
187. S. Holden and J. VanDerhei, 401 (k) Plan Asset Allocation, Account Balances, and Loan Activity in 2003, Investment Company Institute, Perspective, Vol. 6, No. 1., 2004.  
188. K. Hou, C. Xue, and L. Zhang. Replicating Anomalies. No. w23394. National Bureau of Economic Research, 2017.  
189. H. Hong and M. Kacperczyk, The Price of Sin: The Effects of Social Norms on Markets, Journal of Financial Economics, 93(1), 15-36, 2009.  
190. G. Huberman and Z. Wang, Arbitrage Pricing Theory, Federal Reserve Bank of New York Staff Reports, Staff Report no.216, 2005.  
191. J. Huij and M. Verbeek, On The Use of Multifactor Models to Evaluate Mutual Fund Performance, Financial Management, 38(1), 75-102, 2009.  
192. M. Hulbert, The Precient are Few, New York Times, July 13, 2008.  
193. R.G. Ibbotson, P. Chen and K.X. Zhu, The ABCs of Hedge Funds: Alphas, Betas, and Costs, Financial Analysts Journal, 67(1), 15-25, 2011.  
194. T. Idzorek, A Step-By-Step guide to the Black-Litterman Model, Incorporating User-Specified Confidence Levels, Working paper, 2005.  
195. T. Idzorek, and M. Kowara, Factor-Based Asset Allocation vs. Asset-Class-Based Asset Allocation, Financial Analysts Journal, Vol. 69 (3), 2013.  
196. A. Ilmanen, Expected Returns: An Investor's Guide to Harvesting Market Rewards, Wiley Finance, 2011.  
197. A. Ilmanen and J. Kizer, The Death of Diversification Has Been Greatly Exaggerated, The Journal of Portfolio Management, Vol. 38, No. 3, 2012.  
198. Investment Company Institute, Profile of Mutual Fund Shareholders, 2014, ICI Research Report, 2014.
199. T. Jaakola, Machine Learning, MIT OpenCourseWare, MIT, 2016.  
200. R. Jagannathan and T. Ma, Risk Reduction in Large Portfolios: Why Imposing the Wrong Constraints Helps, Journal of Finance 58, 1651 - 1684, 2003.  
201. R. Jagannathan, A. Malakhov and D. Novikov, Do Hot Hands Exist Among Hedge Fund Managers? An Empirical Evaluation. The Journal of Finance, 65(1), 217-255, 2010.  
202. T. Jaakkola, Machine Learning, MIT OpenCourseWare, 2016.  
203. N. Jegadeesh and S. Titman, Profitability of Momentum Strategies: An Evaluation of Alternative Explanations. The Journal of Finance, 56(2), 699-720, 2001.  
204. T. Jenkinson, H. Jones and J.V. Martinez, Picking winners? Investment consultants' recommendations of fund managers, Forthcoming Journal of Finance, 2014.  
205. M.C. Jensen, Some Anomalous Evidence Regarding Market Efficiency, Journal of Financial Economics, 6, 95-101, 1978.  
206. H. Jiang and B. Kelly, Tail risk and Hedge Fund Returns, Chicago Booth Research Paper, (12-44), 2012.  
207. B. Johnson, A. Laszka, J. Grossklags, M. Vasek and T. Moore, Game-Theoretic Analysis of DDoS Attacks Against Bitcoin Mining Pools, International Conference on Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2014.  
208. B. Jones, Re-thinking Asset Allocation - The Role of Risk Factor Diversification, Deutsche Bank Macro Investment Strategy, September 2011.  
209. B. Jones, Rethinking Portfolio Construction and Risk Management, Deutsche Bank Macro Investment Strategy, January 2012.  
210. JP Morgan and Oliver Wyman, Unlocking Economic Advantage with Blockchain. A Guide for Asset Managers, 2016.  
211. J. Jogenfors, Key Distribution and Trust, Elliptic Curve Cryptography, Cryptography Lecture 9, Linkoping University, 2014.  
212. J. Jogenfors, Digital Cash and Bitcoin, Cryptography Lecture 12, Linkoping University, 2014.  
213. E. Jurczenko and J. Teiletche, Active Risk-Based Investing, Working Paper ssrn.com, 2015.  
214. Khan Academy, https://www.khanacademy.org.  
215. D. Kahneman, Thinking Fast and Slow. New York: Farrar, Straus and Giroux, 2011.  
216. D. Kahneman and A. Tversky, Prospect Theory: An Analysis of Decision under Uncertainty, Econometrica 47: 236 - 91, 1979.  
217. S. Kandel and R. F. Stambaugh, On the Predictability of Stock Returns: An Asset-Allocation Perspective, The Journal of Finance, Vol LI, No. 2, 385-424, 1996.  
218. H. Kaya, W. Lee and Y. Wan, Risk Budgeting with Asset Class and Risk Class Approaches', The Journal of Investing, Vol. 21, No. 1, 2012.  
219. J.L. Kelly, A new Interpretation of Information Rate, Bell System Technical Journal, 35, 917-926, 1956.
220. W. Kinlaw, M. Kritzman, and D. Turkington, The Divergence of Highand Low-Frequency Estimation: Causes and Consequences, The Journal of Portfolio Management. Special 40th Anniversary Issue. 2014.  
221. W. Kinlaw, M. Kritzman, and D. Turkington, The Divergence of Highand Low-Frequency Estimation: Implications for Performance Measurement, The Journal of Portfolio Management, 2015.  
222. F. Knight, Risk, Uncertainty, and Profit, New York: Houghton Mifflin, 1921.  
223. M.P. Kritzman, Puzzles of Finance: Six Practical Problems and Their Remarkable Solutions, John Wiley, New York, NY, 2000.  
224. R. Kunz, Asset Management, DAS in Banking and Finance, SFI, 2014.  
225. Y.K. Kwok, Lecture Notes, University of Hong Kong, 2010.  
226. C.H. Lanter, Institutional Portfolio Management, Swiss Finance Institute, Asset Management Program, 2015.  
227. B. Lawler, B. Mossmann, P. Nolan, and A. Ang, Factors and Advisor Portfolios, preprint SSRN, July 15, 2019.  
228. O. Ledoit and M. Wolf, Improved Estimation of the Covariance Matrix of Stock Returns with an Application to Portfolio Selection, Journal of Empirical Finance, 10(5), 603-621, 2003.  
229. O. Ledoit and M. Wolf, The Power of (Non-)Linear Shrinking: A Review and Guide to Covariance Matrix Estimation, Working Paper University of Zurich No. 323, 2019.  
230. W. Lee, Advanced Theory and Methodology of Tactical Asset Allocation, Duke University, 2000.  
231. W. Lee and D.Y. Lam, Implementing Optimal Risk Budgeting, The Journal of Portfolio Management, 28, 1, 73-80, 2001.  
232. O. Ledoit and M. Wolf, A well-conditioned estimator for large-dimensional covariance matrices. Journal of multivariate analysis, 88(2), 365-411, 2003.  
233. O. Ledoit and M. Wolf, Nonlinear Shrinkage of the Covariance Matrix for Portfolio Selection: Markowitz Meets Goldilocks, Revue of Financial Studies, vol 30, 2018.  
234. B. Lehmann and D.M. Modes, Mutual Fund Performance Evaluation: a Comparison of Benchmarks and Benchmarks' Comparisons, Journal of Finance, 233 - 265 June, 1987.  
235. M. Leippold, Resampling and Robust Portfolio Optimization, Lecture Notes University of Zurich, 2010.  
236. M. Leippold, Asset Management, Lecture Notes University of Zurich, 2011.  
237. M. Leippold and R. Ruegg, Fifty Shades of Active and Index Alpha, ssnr.com, 2018.  
238. M. Leippold and R. Ruegg, *Fama-French factor timing: The long-only integrated approach*, University of Zurich, June 29, 2019.  
239. E. Levina and R. Vershynin, *Partial Estimation of Covariance Matrices*, Probability theory and related fields, 153(3-4), 405-419, 2012.  
240. S. F. LeRoy and J. Werner, Principles of Financial Economics, Lecture Notes, UC Santa Barbara and U Minnesota, 2000.
241. J. Lewellen, S. Nagel and J. Shanken, A Sceptical Appraisal of Asset Pricing Tests, Journal of Financial Economics 96, 175-194, 2010.  
242. Y. Lewenberg, Y. Bachrach, Y. Sompolinsky, A. Zohar and J. Rosenschein, Bitcoin Mining Pools: A Cooperative Game Theoretic Analysis, Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems. International Foundation for Autonomous Agents and Multiagent Systems, 2015.  
243. H. Li, X. Zhang and R. Zhao, Investing in Talents: Manager Characteristics and Hedge Fund Performance, Journal of Financial and Quantitative Analysis, 46(01), 59-82, 2011.  
244. B. Liang, Hedge Funds: The Living and the Dead. Journal of Financial and Quantitative Analysis, 35(03), 309-326, 2000.  
245. C.-Y. Lin, Big Data Analytics, Lecture Notes, University of Columbia, 2015.  
246. A. Lo, Data-Snooping Biases in Financial analysis. AIMR Conference Proceedings. Vol. 1994. No. 9. Association for Investment Management and Research, 1994.  
247. A. Lo, The Statistics of Sharpe Ratios, Financial Analysts Journal, (58)4, 2002.  
248. A. Lo, Efficient Markets Hypothesis, The New Palgrave: A Dictionary of Economics, L. Blume, S. Durlauf, eds., 2nd Edition, Palgrave Macmillan Ltd., 2007.  
249. D. Luenberger, Projection Pricing, Stanford University, researchgate.net, 2014.  
250. F. Maccheroni, M. Marinacci and D. Ruffino, Alpha as Ambiguity: Robust Mean-Variance Portfolio Analysis, Econometrica. Volume 81, Issue 3, pages 1075 - 1113, May, 2013.  
251. G. Magnus, The Age of Ageing: Global Demographics, Destinies, and Coping Mechanisms, First webcast: The Conference Board, 2013.  
252. D. Mahringer, W. Pohl and P. Vanini, Structured Products: Performance, Costs and Investments, SFI White Papers, 2015.  
253. S. Maillard, T. Roncalli and J. Teiletche, On the Properties of Equally-Weighted Risk Contributions Portfolios, ssnr.com 1271972, 2008.  
254. B.G. Malkiel, The Efficient Market Hypothesis and Its Critics, Journal of economic perspectives, 59-82, 2003.  
255. B.G. Malkiel and A. Saha, Hedge Funds: Risk and Return, Financial analyst journal, 61(6), 80-88, 2005.  
256. L. Martellini and V. Milhau, Factor Investing: A Welfare-Improving New Investment Paradigm or Yet Another Marketing Fad? EDHEC-Risk Institute Publication, July, 2015.  
257. W. Marty, Portfolio Analytics. An Introduction to Return and Risk Measurement, Springer Texts in Business and Economics (2nd edition), Springer Berlin, 2015.  
258. J. F. May, World Population Policies: Their Origin, Evolution, and Impact, Canadian Studies in Population 39, No. 1 - 2 (Spring/Summer 2012): 125 - 34, Dordrecht: Springer, 2012.  
259. McKinsey & Company, Looking Ahead in Turbulent Times - Strategic Imperatives for Asset Managers Going Forward, SFI Asset Management Education, R. Matthias, 2015.  
260. McKinsex & Company, State of the Industry 2014/15 - a Perspective on Global Asset Management, SFI Asset Management Education, R. Matthias, 2015.
261. A. Mehtaa, M. Bukov, C.-H. Wang, A.G.R. Daya, C. Richardson, C.K. Fisher and D. J. Schwab, A high-bias, low-variance Introduction to Machine Learning for Physicists, Physics Reports, March, 2019.  
262. Melbourne Mercer Global Pension Index, Report, 2015.  
263. The Memo, Looking for a UK business loan? Amazon might be the answer, 2015.  
264. The Millennial Disruption Index, Viacom Media Networks, 2013.  
265. MIT, Applied Macroand International Economics II, Spring 2016, MIT OpenCourseWare, 2016.  
266. E. Moritz, The Big Four - werden Amazon, Google, Apple und Facebook die betteren Banken?, Finance News, 2016.  
267. R. C. Merton, Lifetime Portfolio Selection under Uncertainty: the Continuous-Time Case, The Review of Economics and Statistics 51 (3): 247 - 257, 1969.  
268. R. C. Merton, Optimum consumption and portfolio rules in a continuous-time model, Journal of Economic Theory 3 (4): 373 - 413, 1971.  
269. R. C. Merton, An Intertemporal Capital Asset Pricing Model, Econometrica: Journal of the Econometric Society, 867-887, 1973.  
270. R. C. Merton, On the Pricing of Corporate Debt: The Risk Structure of Interest Rates, Journal of Finance, 29:449-470, 1974.  
271. A. Meucci, Black - Litterman Approach, Encyclopedia of Quantitative Finance, Wiley Finance, 2010.  
272. A. Meucci, Fully Flexible Views: Theory and Practice, ssnr.com library, 2010b.  
273. The Millennial Disruption Index, Viacom Media Networks, 2013.  
274. P. Milnes, The Top 50 Hedge Funds in the World, hedgethink.com, 2014.  
275. T. J. Moskowitz, Y.H. Ooi, and L. H. Pedersen, Time series momentum, Journal of Financial Economics 104.2, 228-250, 2012.  
276. J. Müller, Steht uns die Libralisierung der globalen Währungsordnung bevor? Presentation SFIRT, November, Zurich, 2019.  
277. A. H. Munnell, M.S. Rutledge and A. Webb, Are Retirees Falling Short? Reconciling the Conflicting Evidence, Reconciling the Conflicting Evidence (November 2014). CRR WP 16, 2014.  
278. A.H. Munnell and M. Soto, State and Local Pensions are Different from Private Plans, Center for Retirement Research at Boston College, Number 1, November, 2007.  
279. S. Nakamoto, Bitcoin: A Peer-to-Peer Electronic Cash System, 2008.  
280. NHGRI Genome Sequencing Program (GSP), www.genome.gov/sequencingcostsdata. 2017  
281. S.V. Nieuwerburgh and R.S.J. Kojen, Financial Economics, Return Predictability, and Market Efficiency, University of Tilburg, Preprint, 2007.  
282. R. Novy-Marx and J. D. Rauh, Policy Options for State Pension Systems and their Impact on Plan Liabilities, Journal of Pension Economics and Finance 10.02: 173-194, 2011.  
283. OECD Science, Technology and Industry Scoreboard: Innovation for Growth, Paris, 2013.
284. S. Pafka and I. Kondor, Estimated Correlation Matrices and Portfolio Optimization, Physica A, 343, 623-634, 2004.  
285. S. Pal and T.K.L. Won, Energy, Entropy, and Arbitrage, arXiv preprint arXiv:1308.5376, 2013.  
286. A. Patton, T. Ramadorai and M. Streatfield. Change You Can Believe In? Hedge Fund Data Revisions. Journal of Finance, 2013.  
287. L. Pastor, R. F. Stambaugh and L. A. Taylor, Scale and Skill in Active Management, Journal of Financial Economics, 2014  
288. L. Pastor, and R. F. Stambaugh, Comparing Asset Pricing Models: An Investment Perspective, Journal of Financial Economics, 56, 335-381, 2000.  
289. A. F. Perold and W. F. Sharpe, Dynamic Strategies for Asset Allocation, Financial Analyst Journal, Jan, 16-27, 1988.  
290. L. H. Pedersen, Sharpening the arithmetic of active management. Financial Analysts Journal, 74(1), 21-36, 2018.  
291. G. W. Peters, E. Panayi and A. Chapelle, Trends in Crypto-Currencies and Blockchain Technologies: A Monetary Theory and Regulation Perspective, arXiv preprint, 2015.  
292. S. Perrin and T. Roncalli, Machine Learning Optimization Algorithms and Portfolio Allocation, preprint, ssnr.com, 2019.  
293. E. Podkaminer, Risk Factors as Building Blocks for Portfolio Diversification: The Chemistry of Asset Allocation, Investment Risk and Performance, CFA Institute, 2013.  
294. PriceWaterhouseCoupers, Asset Management 2020, A Brave New World, assetmanagement, 2014  
295. PriceWaterhouseCoupers, Asset & Wealth Management Revolution: Embracing Exponential Change, 2018.  
296. E. Quian, A Mathematical and Empirical Analysis of Rebalancing Alpha, www.ssrn.com, 2014.  
297. N. Rab and R. Warnung, Scaling Portfolio Volatility and Calculating Risk Contributions in the Presence of Serial Cross-Correlations, arxiv.q-fin.RM, preprint, 2011.  
298. M. Rabin, Risk Aversion and Expected-Utility Theory: A Calibration Theorem, Econometrica 68.5, 1281-1292, 2000.  
299. T. Ramadorai, Capacity Constraints, Investor Information, and Hedge Fund Returns, Journal of Financial Economics, 107(2), 401-416, 2013.  
300. S. Ramaswamy, Market Structures and Systemic Risks of Exchange-Traded funds, BIS, 2011.  
301. S.C. Rambaud, J.G. Perez, M.A. Granero and J.E. Segovia, Markowitz Model with Euclidean Vector Spaces, European Journal of Operational Research, 196, 1245-1248, 2009.  
302. R. Rebonato and A. Denev, Portfolio Management under Stress: A Baysian Net Approach to Coherent Asset Allocation, Cambridge University Press, Cambridge, 2013.  
303. L. M. Rotando and E.O. Thorp, The Kelly Criterion and the Stock Market, The American Mathematical Monthly, December, 1992.
304. J. Rifkin, The Zero Marginal Cost Society: The Internet of Things, the Collaborative Commons, and the Eclipse of Capitalism, Palgrave Macmillan Trade, 2014.  
305. C. O. Roche, Understanding Modern Portfolio Construction, ssnr.com working paper, 2016.  
306. P. Rohner, Seminar Asset Management, University of Zurich, 2014.  
307. R. Roll, A Critique of the Asset Pricing Theory's Tests, Journal of Financial Economics 4: 129 - 176, 1977.  
308. T. Roncalli, Introduction to Risk Parity and Budgeting, Chapman & Hall, Financial Mathematics Series, 2014.  
309. T. Roncalli, How Machine Learning Can Improve Portfolio Allocation of Robo-Advisors, swissQuant Conference, 2018.  
310. S.A. Ross, The Arbitrage Theory of Capital asset Pricing, Journal of Economic Theory 13, 341 - 60, 1976.  
311. S. Satchell and A. Scowcroft, A Demystification of the Black-Litterman Model: Managing Quantitative and Traditional Portfolio Construction, Journal of Asset Management, Vol 1, 2, 138-150, 2000.  
312. C.J. Savage, The foundation of statistics, Wiley, New York, 1954.  
313. W. F. Sharpe, Capital asset prices: A theory of market equilibrium under conditions of risk, Journal of Finance, 19 (3), 425-442, 1964.  
314. B. Scherer, Portfolio Construction and Risk Budgeting, Third Edition, Risk Books, 2007.  
315. SEC, Mutual Funds: A Guide for Investors, New York, 2008.  
316. S. Schaefer, Factor Investing, Lecture at SFI Annual Meeting, 2015.  
317. P. Schneider, Generalized Risk Premia, Journal of Financial Economics. forthcoming, 2015.  
318. P. Schneider, C. Wagner and J. Zechner, Low Risk Anomalies, Preprint SFI, 2016.  
319. C. Shimizu, H. Takatsuji, H. Ono, and K. Nishimura, Structural and temporal changes in the housing market and hedonic housing price indices: A case of the previously owned condominium market in the Tokyo metropolitan area. International Journal of Housing Markets and Analysis, 3(4), 351-368, 2010.  
320. J. Siegel, Stocks for the Long Run, McGraw-Hill, New York, NY, 1994.  
321. S. Shalev-Shwartz, Introduction to machine Learning, Lecture Notes The Hebrew University of Jerusalem, 2016.  
322. R. J. Shiller, The Uses of Volatility Measures in Assessing Market Efficiency, Journal of Finance 36: 291 - 304, 1981.  
323. R. J. Shiller, From Efficient Markets Theory to Behavioral Finance, Journal of Economic Perspectives 17 (1): 83 - 104, 2003.  
324. R. J. Shiller, Speculative Asset Prices, Cowles Foundation Paper No. 1424, 2014.  
325. R. J. Shiller, Market Efficiency and Role of Finance in Society, Key Note Lecture, EFA 2014, Lugano, 2014.
326. R. J. Shiller and A.N. Weiss, Home Equity Insurance, The Journal of Real Estate Finance and Economics, 19(1): 21-47, 1999.  
327. M. Silver, How to better measure hedonic residential property price indexes, IMF Working Paper, 2018.  
328. A. J. Smola and B. Schölkopf, A tutorial on support vector regression. Statistics and computing, 14. Jg., Nr. 3, S. 199-222, 2004.  
329. Y. Sompolinsky and A. Zohar, Secure High-Rate Transaction Processing in Bitcoin, International Conference on Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2015.  
330. State Street, The Folklore of Finance, Center of Applied Research. 2014.  
331. G.V.G. Stevens, On the Inverse of the Covariance Matrix in Portfolio Analysis, The Journal of Finance, Vol. 53(5), 1821-1827, 1998.  
332. R. Sullivan, A. Timmermann, and H. White, Data-snooping, Technical Trading Rule Performance, and the Bootstrap, The Journal of Finance 54 (5), 1647 - 1691, 1999.  
333. M. Swan, Blockchain: Blueprint for a New Economy, O'Reilly Media, 2015.  
334. Swissquant, Costumer Retention, Big Data Analytics, 2017.  
335. J. Syz, M. Salvi and P. Vanini, Property Derivatives and Index-Linked Mortgages, Journal of Real Estate Finance and Economics, Vol. 36, No. 1, 2008.  
336. J. Syz and P. Vanini, Real Estate, Swiss Finance Institute Annual Meeting, 2008.  
337. N. Sullivan, A (Relatively Easy To Understand) Primer on Elliptic Curve Cryptography, Cloudfare blog, 2013.  
338. N. Szabo, Formalizing and Securing Relationships on Public Networks, First Monday, 2(9), 1997.  
339. P. Tasca, Economic Foundation of the Bitcoin Economy, University College London, Center for Blockchain Technologies, Blockchain Workshop Zurich, 2016.  
340. N. Taleb, The Black Swan. The Impact of the Highly Improbable. New York: Random House, 2010.  
341. J. Teiletche, Risk-Based Investing: Myths and Realities, CFA UK Masterclass, London June 9th, 2015.  
342. J. Teiletche, Active Risk-Based Investing, CQ Asia, Hong Kong, 2014.  
343. M. Teo, The Liquidity Risk of Liquid Hedge Funds, Journal of Financial Economics, 100(1), 24-44, 2011.  
344. J. Ter Horst and M. Verbeek, Fund Liquidation, Self-Selection, and Look-Ahead Bias in the Hedge Fund Industry, Review of Finance, 11(4), 605-632, 2007.  
345. J. Treynor and K. Mazuy, Can Mutual Funds Outguess the Market, Harvard business review, 44(4), 131-136, 1966.  
346. F. Trojani and P. Vanini, A Note on Robustness in Merton's Model of Intertemporal Consumption and Portfolio Choice, Journal of Economic Dynamics and Control, Vol. 26, No. 3, 423-435, 2002.
347. Tu and Zhou, Data-Generating Process Uncertainty, What Difference Does it Make in Portfolio Decisions?, Journal of Financial Economics, 72, 385-421, 2003.  
348. S. Tilly and F. Triebel, Automobilindustrie 1945-2000, Stepanhie Tilly % Florian Triebel (eds), Oldenburg Verlag München, 2013.  
349. UBS, Strategy and Regulation. Impact of Regulation on Strategy and Execution, SFI Conference on Managing International Asset Management, N. Karrer, 2015.  
350. UBS, Distribution Strategies in Action, SFI Conference on Managing International Asset Management, A. Benz, 2015.  
351. Vershynin, R., How close is the sample covariance matrix to the actual covariance matrix?. Journal of Theoretical Probability, 25(3), 655-686, 2012.  
352. Viacom Media Networks, 2013.  
353. L. Vignola and P. Vanini, Optimal Decision-Making with Time Diversification, Review of Finance, 6.1, 1-30, 2002.  
354. I. Walter, The Asset Management Industry Dynamics of Growth, Structure and Performance, edited By Michael Pinedo and Ingo Walter, 2013.  
355. J.H. White, Volatility Harvesting: Extracting Return from Randomness, arXiv, November, 2015.  
356. World Economic Forum, The Future of Long-term Investing, New York, 2011.  
357. World Economic Forum, Future of Financial Services, New York, 2015.  
358. World Economic Forum, Beyond Fintech: A Pragmatic Assessment Of Disruptive Potential In Financial Services, New York, 2017.  
359. A. Yeniy and A. Goktas, A Comparison of Partial Least Square Regression with other Prediction Methods, Journal of Mathematics and Statistics Volume 31, 99-111, 2002.  
360. A. Zelltner and V.K. Chetty, Prediction and Decision Problems in Regression Models from the Baysian Point of View, Journal of the American Statistical Association, 60, 608-616, 1965.  
361. ZKB, Index Methods, 2013.  
362. H. Zou, The Adaptive LASSO and its Oracle Properties, Journal of the American Statistical Association 101(476), 1418-1429, 2006.  
363. G. Zyskind, N. Oz and A. Pentland, Enigma: Decentralized Computation Platform with Guaranteed Privacy, arXiv preprint, 2015.

# Index

Permissioned Protocol, 481

Active Investment and Benchmarking, 299

Active versus Passive

Sharpe'sArithmetic,67

Altcoins, 494

Alternative Investments (AIs)

Insurance-Linked Investments, 102

Arithmetical Relative Return (ARR), 179

Asset Class

Definition, 13

Asset Management Industry

Wealth 2020, 17

Asset Management Overview, 14

Asset Pricing

Absolute Pricing, 261, 413

Fundamental Asset Pricing Equation, 263, 416

General Equilibrium, 414

Good and Bad Times, 264, 417

Low Volatility Strategies, 282

MultiFactorModels,281

Multi Period, 281

What Happens if an Investment Strategy is Known to Everyone?, 285

Asset Pricing in Financial Markets, 193

Average Investment Capital (AIC), 182

Back-to-Back Swap, 155

Backtests

Data Snooping, 389

False Discovery Rate (FDR), 396

Multiple Testing, 395

Barrier Reverse Convertibles, 56

Basis of Forwards, 200

Basis Risk, 200

Benchmark Return, 179

Benchmarking, 69

Beta and Volatility Based Low Risk Anomalies, 282

Beta Pricing Model, 260

Bias-Variance Trade-Off, 431

Bitcoin Protocol, 480

Bitcoin Security, 497

Black-Litterman Model, 329

Black-ScholesEquation,222

Black-Scholes,FormulaforCall,218

Black-Scholes, Interpretation, 219

Black-Scholes, Interpretation No Arbitrage, 218

Brinson-Hood-Beebower (BHB) Effect, 179

Broken Covered Interest Parity (CIP), 206

Buy-and-hold,static,164

Call Option, 195

Capital Weighted Index Funds, 91

Capital-Guaranteed Products (CP), 226

CAPM

Appraisal (Information) Ratio, 376

Assumption, 372

Beta Pricing Model, 371

CML and SML, 374

ConditionalCAPM，380

Empirical Failure, 378

Jensen's alpha, 376

Performance Measurement, 376

Proposition, 373

Treynor Ratio, 376

CAPM Cross Section, 378

CAPM Time Series, 378

Cash Flow (CF), 149

Centralized and Decentralized Architecture, 476

Cholesky Decomposition, 260

CIO Investment Process, 333

Complete Market, 185

Compounding, 151

Conduct Risk, 47

Cost and Risk Function, 430

Covered Interest Parity (CIP), 204

Cox-Ross-Rubinstein Model, 211

Cross-Sectional vs Time Series Predictability, 251

CRR

Accuracy, 215

Discrete and Continuous Time, 215

Equivalent Martingale Measure, 213

Filtration, 213

Martingale Representation Theorem, 212

NoArbitrage,212

Possible State, 212

Pricing Call, 214

Self Financing Strategy, 212

cryptocurrencies, 489

Currency Overlay, 204, 208

Data Pre-Processing, 421

Demography and Pension Funds, 29

Dietz Return, 182

Digital Signatures, 466, 473

DiscountFactor,150

Discount Function, 150

Discrete Logarithm, 469

Discrete Model

Arrow-Debreu Securities, 194

Cox-Ross-Rubinstein (CRR), 211

DiscountFactor,193

First Fundamental Theorem of Finance (FFTF), 193

Hedge Risk, 210

NoArbitrage,192

Payoff Matrix, 191, 420

Risk Neutral Probabilities (RNP), 193

Second Fundamental … , 194

State Prices, 193

Trinomial Model, 210

Complete Market, 192

Diversification, 51

Asset Allocation Europe, 65

Conservative, Balanced, Dynamic, Growth Portfolios, 52

Costs and Performance, 66

Different Portfolio Constructions, 63

Herfindahl Index, 62

Needed Investment Amount, 55

Risk Scaling, Square-root Rule, 66

Shannon Entropy, 62

Tasche Index, 61

Two Statistical Propositions, 55

DriftedWeights，165

Dynamic Investment

Goal Based Investment (GBI), 311

Merton Model, 310

Effective Rate, 152

EllsbergParadoxon,305

EnergyTerm，177

Environment, Social, Governance (ESG) Investment, 132

Estimation Risk, 341

ETF

Construction, 95

Different Asset Classes, 99

LeveragedETFs(LETFs),100

Unfunded Swap-Based Approach, 98

ExactFactorModel,260

ExactFactorPricingEquation,269

Excess Return, 254

Expectation Functionas, 266

Expectation Kernel, 266

Expected Loss, 429

Expense Ratios for Actively Managed Funds, Index Funds and ETFs, 102

Factor Investing, 381

Factor Investment

Industry Approach, 363

Factor Model, 259

Factor Risk Premium, 260

Factors, 259

False Discovery Methodology FDR, 119

False Discovery Rate FDR, 406

Fama-French

3-Factor Model, 381

5-Factor Model, 384

Feature Set, 426

Fee Models, 10

Fork, 484

Forward Rate Agreements (FRA), 153

Forwards and Futures, 198

FrobeniusNorm,352

Frontier Returns, 268

Fund Industry

Mutual Funds,81

Taxonomy of Mutual Funds, 82

Mutual Funds and SICAVs, 79

Overview, 77

US Mutual Funds versus European UCITS, 80

Active vs Passive Investments, 402

Fees for Mutual Funds, 84

Fundamental Law of Active Management, 404

Skill and Luck in Mutual Fund Management, 406

Success of the Active Strategy, 402

TERand Performance,85

UCITS,86

FX Forward, 204

Game Theoretic Concept Blockchain, 484

Gamma,220

General Linear Model, 460

Generalization Error, 430

Geometric Margin, 447

Global AM

2014-2020, 74

AM versus Trading, 75

AM versus Wealth Management, 77

Demand and Supply Side, 70

Eurozone, 70

Global Figures 2007-2014, 72

Great Financial Crisis 2008 (GFIC), 59

Greece and EU Uncertainty, 306

Greeks and Black and Scholes, 222

Greeks, Delta, 219

Greeks,Rho,221

Greeks, Vega, 221

Gross Return, 254

Growth of Wealth, 9

Growth Optimal Portfolios, 303

Growth Rate of Wealth, 164

Growth Rates AuM, 16

Hansen-Jagannathan Bound, 255

Hedge Funds

CTA Strategy, 111

Definition, 108

Entries and Exits, 114

Fees, 112

Industry, 109

Investment Performance, 115

Strategies, 111

Withdrawing Restrictions, 113

Hedging Approach, 187

Hedonic Index, 275

Herding of Pension Funds, 292

Heuristic Models, 305

ial assets,299

Incomplete Market, 185

Independent Sample Error, 369

Index Construction, 89

Index Funds and ETFs, 88

Index Sampling, 299

Information Coefficient (IC), 403

Information Ratio IR, 335, 403

Interest Rate Parity

CIP, 205

Covered, 204

Trilemma, 206

UIP, 206

Uncovered, 204

Interest Rate Swaps (IRS), 153

Internal Rate of Return (IRR), 182

Interval Error, 369

Investment Consultants, 35

Kelly Criterion, 303

Label Set, 426

Law of One Price, 186

Ledoit-Wolf Shrinkage, 329

Libra, 498

Log Utility, 172

Long Run Return and Risk, 51

Longevity and Demographics, 9

Machine Learning, 424

Agnostic Learning, 436

Approximation Error, 439

Batch Setting, 426

BayesClassifier，429

Bias-VarianceTradeoff,432

Classification Algorithm, 426, 427

Complexity, 427

Consistency, 437

Customer Retention: Text Mining, 456

Dvoretzky - Kiefer - Wolfowitz inequality, 441

Empirical Risk Minimization, 441

Empirival Risk Minimization (ERM), 435

Ensemble Models, 452

Error Function, 429

Estimation Error, 439

Generalization, 437

Geometric Margin, 447

Hypothesis Class, 425

Inequality ofHoeffding,440

Linear Threshold Model, 445

Margin, 447

Naive Bayes Classifier, 452

No-Free-Lunch Theorem, 439

On-line Setting, 426

Perceptron Rule, 446

Probably Approximately Correct (PAC), 429

Realizability, 427

Sentimental Risk Model, 455

Support Vector Machines (SVM), 447

Symmetrization Trick, 438

Threshold Linear Classifier, 445

Tree Based Learning, 449

Union Bounds, 441

Vapnik and Chervonenkis, 441

Vapnik and Chervonenkis Symmetrization Lemma, 438

Macro Economic Uncertainty, 306

Margins, 201

Market Evolution

Option Trading Book, 222

Market Neutral, 357

Market Portfolio, 176

Market Price of Risk (MPR), 310

Market Weighted Indizes, 68

Markowitz, 297

Comparing Other Models, 324

Many Risky Assets, 313

Mutual Fund Theorem, 317

Principle, 297

Principle Component Analysis (PCA), 346

Risk-Free Asset, 318

TAA and SAA, 323

Tangency Portfolio, Capital Market Line, 319

Martingale Property, One Period Model, 188

Mean-Variance with Benchmark, 299

Minimal Market Model, 184

Minimum Risk Value, 429

Money-Weighted Rate of Return (MWR), 181

Moore-Penrose Pseudo Inverse, 192, 420

Mutual Distributed Leader Technology, 475

NoArbitrage,191

No Arbitrage Condition, 150

Normalized Portfolio, 163

One Period Model

Risk Neutral Pricing, 188

Risk Neutral Probability, 188

One-Way Function, 466

Optimal Investment

Introduction, 170

Long-term (hedging demand), 170

Rebalancing  $=$  Short Volatility, 168

Rebalancing andLeverage,183

Rebalancing Facts, 170

Short-term (myopic), 170

VolatilityDrag,166

Ordinary Risk Premium, 260

Par Swap Rate, 155

Parameter Uncertainty, Estimation Risk, 342

Payoff Pricing Functional, 266

Pension Fund

DB versus DC, 25

Management, 27

Pension Funds, 32

Defined Benefit (DB), 22, 24

Defined Contribution (DC), 22, 24

Longevity and Fertility, 23

SAA，TAA，27

TAA and SAA, 28

Technical Interest Rates, 26

Three Pillar System, 22

Performance Attribution Tree, 180

Permissionless Protocol, 481

Platform-as-a-Service (PaaS), 39

Popularity of Markowitz Model, 325

Portfolio, 163

Predictability

Definition, 243

Forecast Regression, 247

Fundamental Asset Pricing Equation, 254

Martingale, 244

Return Predictability, 247

Pricing Kernel, 266

Prime Finance, 235

Principal Component Analysis, 346

Private Investors and Institutional Investors, 18

Private Markets, 106

Profit and Loss P&L, 223

Projection Theorem, 259

Projections AuM 2020, 17

Proof-of-WorkPoW，480

Proof-of-WorkPoW),479

Put Option, 195

Put-Call Parity, 209

PV, FV, 150

Quadratic Programming (QP), 298

Real Estate Equilibrium Valuation, 280

Real Estate Replication Portfolio Valuation, 280

Real Estate Risk, 274

Rebalanced, 164

Redundant Dimensionality Error, 369

Regularization, 431, 433

Regularization Techniques, 346

Regulation

Anti-Tax-Evasion, 48

CIO Investment Process, 43

Client Segmentation, 41

Conduct Risk, 47

Fines in UK, 48

Hedge Fund Disclosure, 49

Impact Swiss Banking Industry, 38

Intermediation Channel Segmentation, 40

Mandate Solutions, 45

MiFID II, 39

Overview, 38

Product Suitability, 42

Relative Entropy Return Decomposition, 178

Relative or Derivative Asset Pricing, 184

Relative Pricing

Arbitrage Pricing Theory (APT), 272

Renaissance Medallion Fund, 253

Replication Portfolio, 185

Repo Transaction, 236

Return and Leverage, 182

Ridge Regression, 433

Riesz Kernel, 261

Riesz-Fischer Theorem, 261, 513

Risk Budgeting

Budgeting Problem, 337

Equal Risk / Risk Parity Contribution (ERC), 338

Introduction, 335

Risk Allocation, 336

RiskMeasurements,336

Risk Factors

Industry Evolution, 362

Momentum, 358

Quality, 357

Risk Free Return, 254

Risk Preferences, 300

Risk Weighted Index Funds, 94

Rule 2/20 for Hedge Funds, 109

Securities Lending Business SLB, 235

Self-financing, 163

Self-FinancingStrategy,163

Sharpe Ratio (SR), 61

Short-Term versus Long-Term Investment Horizons, 286

Small Sample Error, 369

Sovereign wealth fund (SWFs), 21

Stability Markowitz, 314

Statistical Learning Model, 425

StatisticalModels,297

Stochastic Discount Factor (SDF), 193, 254, 261

Stochastic Portfolio Theory (SPT), 175

Structured Products, 223, 224

Symmetric Cryptography, 466

Synchronization in Blockchains, 478

TAA Construction, 196

Technology

Cryptography Examples, 483

Different Currencies, 489

Big Data Definition, 421

Bitcoin, 490

Customer-centricity, 125

DAOhack，488

Disruptive Efficiency, 125

Etherum, 487

Hierarchical Risk Parity Portfolio Construction, 462

Test Set, 426

The Nodes, 478

Theta, 220

Thikonov Regularization, 327

Time Value of Money, 149

Time-Weighted Rate of Return (TWR), 180

Tobin Separation, 374

Tracking Error, 68

Training Set, 426

Transaction Consensus, 477

Transaction Execution, 477

Transaction Feasibility, 477

Transaction Legitimization, 477

True Risk, 429

Two-Pass Regressions, 379

Uncertainty, 299

Uncovered Interest Parity, 205

Uniformity of Minds, 145

Universality, 349

Value Chain, Investment Process and Technology, 128

Vector Space  $\mathcal{E}$  ，266

Vega, 223

VolatilityDragEquation,166

VolatilityHarvesting,166

WarrenBuffet,253

Wealth of Nations, 15

WhenDiversificationFails,59

Yap problem, 481

Yield-to-Maturity (YtM), 151